<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Hello World</title>
      <link href="/posts/16107.html"/>
      <url>/posts/16107.html</url>
      
        <content type="html"><![CDATA[<div id="binft"></div>  <script>    var binft = function (r) {      function t() {        return b[Math.floor(Math.random() * b.length)]      }        function e() {        return String.fromCharCode(94 * Math.random() + 33)      }      function n(r) {        for (var n = document.createDocumentFragment(), i = 0; r > i; i++) {          var l = document.createElement("span");          l.textContent = e(), l.style.color = t(), n.appendChild(l)        }        return n      }      function i() {        var t = o[c.skillI];        c.step ? c.step-- : (c.step = g, c.prefixP < l.length ? (c.prefixP >= 0 && (c.text += l[c.prefixP]), c.prefixP++) : "forward" === c.direction ? c.skillP < t.length ? (c.text += t[c.skillP], c.skillP++) : c.delay ? c.delay-- : (c.direction = "backward", c.delay = a) : c.skillP > 0 ? (c.text = c.text.slice(0, -1), c.skillP--) : (c.skillI = (c.skillI + 1) % o.length, c.direction = "forward")), r.textContent = c.text, r.appendChild(n(c.prefixP < l.length ? Math.min(s, s + c.prefixP) : Math.min(s, t.length - c.skillP))), setTimeout(i, d)      }      var l = "",      o = ["大家好，这是我的第一篇文章，欢迎查看"].map(function (r) {      return r + ""      }),      a = 2,      g = 1,      s = 5,      d = 75,      b = ["rgb(110,64,170)", "rgb(150,61,179)", "rgb(191,60,175)", "rgb(228,65,157)", "rgb(254,75,131)", "rgb(255,94,99)", "rgb(255,120,71)", "rgb(251,150,51)", "rgb(226,183,47)", "rgb(198,214,60)", "rgb(175,240,91)", "rgb(127,246,88)", "rgb(82,246,103)", "rgb(48,239,130)", "rgb(29,223,163)", "rgb(26,199,194)", "rgb(35,171,216)", "rgb(54,140,225)", "rgb(76,110,219)", "rgb(96,84,200)"],      c = {        text: "",        prefixP: -s,        skillI: 0,        skillP: 0,        direction: "forward",        delay: a,        step: g      };      i()      };      binft(document.getElementById('binft'));  </script><span id="more"></span><div id="binft"></div>  <script>    var binft = function (r) {      function t() {        return b[Math.floor(Math.random() * b.length)]      }        function e() {        return String.fromCharCode(94 * Math.random() + 33)      }      function n(r) {        for (var n = document.createDocumentFragment(), i = 0; r > i; i++) {          var l = document.createElement("span");          l.textContent = e(), l.style.color = t(), n.appendChild(l)        }        return n      }      function i() {        var t = o[c.skillI];        c.step ? c.step-- : (c.step = g, c.prefixP < l.length ? (c.prefixP >= 0 && (c.text += l[c.prefixP]), c.prefixP++) : "forward" === c.direction ? c.skillP < t.length ? (c.text += t[c.skillP], c.skillP++) : c.delay ? c.delay-- : (c.direction = "backward", c.delay = a) : c.skillP > 0 ? (c.text = c.text.slice(0, -1), c.skillP--) : (c.skillI = (c.skillI + 1) % o.length, c.direction = "forward")), r.textContent = c.text, r.appendChild(n(c.prefixP < l.length ? Math.min(s, s + c.prefixP) : Math.min(s, t.length - c.skillP))), setTimeout(i, d)      }      var l = "",      o = ["青青陵上柏，磊磊涧中石。", "人生天地间，忽如远行客。","斗酒相娱乐，聊厚不为薄。", "驱车策驽马，游戏宛与洛。","洛中何郁郁，冠带自相索。","长衢罗夹巷，王侯多第宅。","两宫遥相望，双阙百余尺。","极宴娱心意，戚戚何所迫？"].map(function (r) {      return r + ""      }),      a = 2,      g = 1,      s = 5,      d = 75,      b = ["rgb(110,64,170)", "rgb(150,61,179)", "rgb(191,60,175)", "rgb(228,65,157)", "rgb(254,75,131)", "rgb(255,94,99)", "rgb(255,120,71)", "rgb(251,150,51)", "rgb(226,183,47)", "rgb(198,214,60)", "rgb(175,240,91)", "rgb(127,246,88)", "rgb(82,246,103)", "rgb(48,239,130)", "rgb(29,223,163)", "rgb(26,199,194)", "rgb(35,171,216)", "rgb(54,140,225)", "rgb(76,110,219)", "rgb(96,84,200)"],      c = {        text: "",        prefixP: -s,        skillI: 0,        skillP: 0,        direction: "forward",        delay: a,        step: g      };      i()      };      binft(document.getElementById('binft'));  </script><h1 id="欢迎查看我的第一篇文章"><a href="#欢迎查看我的第一篇文章" class="headerlink" title="欢迎查看我的第一篇文章"></a>欢迎查看我的第一篇文章</h1><p>写在前面：这是我的Github，欢迎star：<a href="https://github.com/du2279664786">https://github.com/du2279664786</a></p><p>大一的时候搭建过一次博客，但是由于长时间不使用，导致配置文件丢失<br>所以在大三上学期我又重新搭建了一下，将去年（大二）所学的知识进行了“简单”的汇总（PS：李明虎老师讲的实在是太丰富了，我只整理了简单的）</p><p>本博客为学习博客，旨在记录自己的学习经历和知识回顾</p><p>转眼间已经大三了，回顾过去两年：<br>        ·大一上：人工智能导论<br>        ·大一下：爬虫<br>        ·大二上：机器学习<br>        ·大二下：深度学习和神经网络<br>….. …..</p><p>希望考研可以成功上岸！</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Pre-training</title>
      <link href="/posts/36882.html"/>
      <url>/posts/36882.html</url>
      
        <content type="html"><![CDATA[<p>Pre-train BERT (Chinese language model) from scratch</p><span id="more"></span><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> transformers,tokenizers</span><br><span class="line">transformers.__version__,tokenizers.__version__</span><br></pre></td></tr></table></figure><pre><code>(&#39;4.24.0&#39;, &#39;0.13.2&#39;)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tokenizers</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> BertTokenizer, LineByLineTextDataset</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> BertConfig, BertForMaskedLM, DataCollatorForLanguageModeling</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> Trainer, TrainingArguments</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> pipeline</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Train a tokenizer</span></span><br><span class="line"></span><br><span class="line">bwpt = tokenizers.BertWordPieceTokenizer(vocab_file=<span class="literal">None</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># filepath = &quot;../input/bert-bangla/raw_bangla_for_BERT.txt&quot;</span></span><br><span class="line">filepath = <span class="string">&quot;./train.txt&quot;</span></span><br><span class="line"></span><br><span class="line">bwpt.train(</span><br><span class="line">    files=[filepath],</span><br><span class="line">    vocab_size=<span class="number">50000</span>,</span><br><span class="line">    min_frequency=<span class="number">3</span>,</span><br><span class="line">    limit_alphabet=<span class="number">1000</span></span><br><span class="line">)</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bwpt.save(<span class="string">&#x27;./训练中文的bert输出/&#x27;</span>, <span class="string">&#x27;name&#x27;</span>)</span><br></pre></td></tr></table></figure><pre><code>[&#39;./训练中文的bert输出/name-vocab.txt&#39;]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Load the tokenizer</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># vocab_file_dir = &#x27;/kaggle/input/bert-bangla/bangla-vocab.txt&#x27; </span></span><br><span class="line">vocab_file_dir = <span class="string">&#x27;./vocab.txt&#x27;</span> </span><br><span class="line"></span><br><span class="line">tokenizer = BertTokenizer.from_pretrained(vocab_file_dir)</span><br><span class="line"></span><br><span class="line">sentence = <span class="string">&#x27;今天晚上我要吃啵啵鱼&#x27;</span></span><br><span class="line"></span><br><span class="line">encoded_input = tokenizer.tokenize(sentence)</span><br><span class="line"><span class="built_in">print</span>(encoded_input)</span><br><span class="line"><span class="comment"># print(encoded_input[&#x27;input_ids&#x27;])</span></span><br></pre></td></tr></table></figure><pre><code>[&#39;今&#39;, &#39;天&#39;, &#39;晚&#39;, &#39;上&#39;, &#39;我&#39;, &#39;要&#39;, &#39;吃&#39;, &#39;啵&#39;, &#39;啵&#39;, &#39;鱼&#39;]C:\Users\dupeibo\Anaconda3\envs\pt\lib\site-packages\transformers\tokenization_utils_base.py:1679: FutureWarning: Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated and won&#39;t be possible anymore in v5. Use a model identifier or the path to a directory instead.  warnings.warn(</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">%%time</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">transformers has a predefined class LineByLineTextDataset()</span></span><br><span class="line"><span class="string">which reads your text line by line and converts them to tokens</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">dataset= LineByLineTextDataset(</span><br><span class="line">    tokenizer = tokenizer,</span><br><span class="line"><span class="comment">#     file_path = &#x27;/kaggle/input/bert-bangla/raw_bangla_for_BERT.txt&#x27;,</span></span><br><span class="line">    file_path = <span class="string">&#x27;./train.txt&#x27;</span>,</span><br><span class="line">    block_size = <span class="number">128</span>  <span class="comment"># maximum sequence length</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;No. of lines: &#x27;</span>, <span class="built_in">len</span>(dataset)) <span class="comment"># No of lines in your datset</span></span><br><span class="line">dataset</span><br></pre></td></tr></table></figure><pre><code>No. of lines:  24494Wall time: 10.4 s&lt;transformers.data.datasets.language_modeling.LineByLineTextDataset at 0x2084eb42ac8&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">config = BertConfig(</span><br><span class="line">    vocab_size=<span class="number">50000</span>,</span><br><span class="line">    hidden_size=<span class="number">768</span>, </span><br><span class="line">    num_hidden_layers=<span class="number">6</span>, </span><br><span class="line">    num_attention_heads=<span class="number">12</span>,</span><br><span class="line">    max_position_embeddings=<span class="number">512</span></span><br><span class="line">)</span><br><span class="line"> </span><br><span class="line">model = BertForMaskedLM(config)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;No of parameters: &#x27;</span>, model.num_parameters())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 做掩码机制</span></span><br><span class="line">data_collator = DataCollatorForLanguageModeling(</span><br><span class="line">    tokenizer=tokenizer, mlm=<span class="literal">True</span>, mlm_probability=<span class="number">0.15</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><pre><code>No of parameters:  82556240</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">training_args = TrainingArguments(</span><br><span class="line">    output_dir=<span class="string">&#x27;./训练中文的bert输出/&#x27;</span>,</span><br><span class="line">    overwrite_output_dir=<span class="literal">True</span>,</span><br><span class="line">    num_train_epochs=<span class="number">1</span>,</span><br><span class="line">    per_device_train_batch_size=<span class="number">4</span>,</span><br><span class="line">    save_steps=<span class="number">10_000</span>,</span><br><span class="line">    save_total_limit=<span class="number">2</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">trainer = Trainer(</span><br><span class="line">    model=model,</span><br><span class="line">    args=training_args,</span><br><span class="line">    data_collator=data_collator,</span><br><span class="line">    train_dataset=dataset,</span><br><span class="line">    prediction_loss_only=<span class="literal">True</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">%%time</span><br><span class="line">trainer.train()</span><br><span class="line"></span><br></pre></td></tr></table></figure><pre><code>Epoch:   0%|          | 0/1 [00:00&lt;?, ?it/s]Iteration:   0%|          | 0/6124 [00:00&lt;?, ?it/s]&#123;&quot;loss&quot;: 7.0956006441116335, &quot;learning_rate&quot;: 4.591770084911823e-05, &quot;epoch&quot;: 0.08164598301763554, &quot;step&quot;: 500&#125;&#123;&quot;loss&quot;: 6.214028715133667, &quot;learning_rate&quot;: 4.183540169823645e-05, &quot;epoch&quot;: 0.16329196603527107, &quot;step&quot;: 1000&#125;&#123;&quot;loss&quot;: 5.860672056674957, &quot;learning_rate&quot;: 3.775310254735467e-05, &quot;epoch&quot;: 0.24493794905290658, &quot;step&quot;: 1500&#125;&#123;&quot;loss&quot;: 5.599938702583313, &quot;learning_rate&quot;: 3.367080339647289e-05, &quot;epoch&quot;: 0.32658393207054215, &quot;step&quot;: 2000&#125;&#123;&quot;loss&quot;: 5.412256263256073, &quot;learning_rate&quot;: 2.958850424559112e-05, &quot;epoch&quot;: 0.4082299150881777, &quot;step&quot;: 2500&#125;&#123;&quot;loss&quot;: 5.261007954120636, &quot;learning_rate&quot;: 2.550620509470934e-05, &quot;epoch&quot;: 0.48987589810581317, &quot;step&quot;: 3000&#125;&#123;&quot;loss&quot;: 5.095327672958374, &quot;learning_rate&quot;: 2.1423905943827566e-05, &quot;epoch&quot;: 0.5715218811234487, &quot;step&quot;: 3500&#125;&#123;&quot;loss&quot;: NaN, &quot;learning_rate&quot;: 1.734160679294579e-05, &quot;epoch&quot;: 0.6531678641410843, &quot;step&quot;: 4000&#125;&#123;&quot;loss&quot;: NaN, &quot;learning_rate&quot;: 1.3259307642064011e-05, &quot;epoch&quot;: 0.7348138471587198, &quot;step&quot;: 4500&#125;&#123;&quot;loss&quot;: NaN, &quot;learning_rate&quot;: 9.177008491182235e-06, &quot;epoch&quot;: 0.8164598301763554, &quot;step&quot;: 5000&#125;&#123;&quot;loss&quot;: NaN, &quot;learning_rate&quot;: 5.094709340300458e-06, &quot;epoch&quot;: 0.8981058131939909, &quot;step&quot;: 5500&#125;&#123;&quot;loss&quot;: NaN, &quot;learning_rate&quot;: 1.0124101894186806e-06, &quot;epoch&quot;: 0.9797517962116263, &quot;step&quot;: 6000&#125;Wall time: 17min 31sTrainOutput(global_step=6124, training_loss=nan)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># trainer.save_model(&#x27;./训练中文的bert输出&#x27;)</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">model = BertForMaskedLM.from_pretrained(<span class="string">&#x27;./&#x27;</span>)</span><br><span class="line"></span><br><span class="line">fill_mask = pipeline(</span><br><span class="line">    <span class="string">&quot;fill-mask&quot;</span>,</span><br><span class="line">    model=model,</span><br><span class="line">    tokenizer=tokenizer</span><br><span class="line">)</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fill_mask(<span class="string">&#x27;心[MASK]病&#x27;</span>)</span><br></pre></td></tr></table></figure><pre><code>[&#123;&#39;score&#39;: 0.3431047201156616,  &#39;token&#39;: 5552,  &#39;token_str&#39;: &#39;脏&#39;,  &#39;sequence&#39;: &#39;心 脏 病&#39;&#125;, &#123;&#39;score&#39;: 0.07011183351278305,  &#39;token&#39;: 2552,  &#39;token_str&#39;: &#39;心&#39;,  &#39;sequence&#39;: &#39;心 心 病&#39;&#125;, &#123;&#39;score&#39;: 0.05838495120406151,  &#39;token&#39;: 4567,  &#39;token_str&#39;: &#39;病&#39;,  &#39;sequence&#39;: &#39;心 病 病&#39;&#125;, &#123;&#39;score&#39;: 0.014283978380262852,  &#39;token&#39;: 107,  &#39;token_str&#39;: &#39;&quot;&#39;,  &#39;sequence&#39;: &#39;心 &quot; 病&#39;&#125;, &#123;&#39;score&#39;: 0.011550793424248695,  &#39;token&#39;: 7315,  &#39;token_str&#39;: &#39;闷&#39;,  &#39;sequence&#39;: &#39;心 闷 病&#39;&#125;]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fill_mask(<span class="string">&#x27;怀[MASK]&#x27;</span>)</span><br></pre></td></tr></table></figure><pre><code>[&#123;&#39;score&#39;: 0.4942161738872528,  &#39;token&#39;: 2097,  &#39;token_str&#39;: &#39;孕&#39;,  &#39;sequence&#39;: &#39;怀 孕&#39;&#125;, &#123;&#39;score&#39;: 0.050573259592056274,  &#39;token&#39;: 2577,  &#39;token_str&#39;: &#39;怀&#39;,  &#39;sequence&#39;: &#39;怀 怀&#39;&#125;, &#123;&#39;score&#39;: 0.01493070088326931,  &#39;token&#39;: 107,  &#39;token_str&#39;: &#39;&quot;&#39;,  &#39;sequence&#39;: &#39;怀 &quot;&#39;&#125;, &#123;&#39;score&#39;: 0.010810167528688908,  &#39;token&#39;: 5307,  &#39;token_str&#39;: &#39;经&#39;,  &#39;sequence&#39;: &#39;怀 经&#39;&#125;, &#123;&#39;score&#39;: 0.00741073302924633,  &#39;token&#39;: 1453,  &#39;token_str&#39;: &#39;周&#39;,  &#39;sequence&#39;: &#39;怀 周&#39;&#125;]</code></pre>]]></content>
      
      
      <categories>
          
          <category> 自然语言处理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> NLP </tag>
            
            <tag> HuggingFace </tag>
            
            <tag> Pre-training </tag>
            
            <tag> BERT </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于BERT的文本分类</title>
      <link href="/posts/20881.html"/>
      <url>/posts/20881.html</url>
      
        <content type="html"><![CDATA[<p>通过智能化手段识别其中是否存在“虚报、假报”的情况</p><span id="more"></span><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>企业自主填报安全生产隐患，对于将风险消除在事故萌芽阶段具有重要意义。企业在填报隐患时，往往存在不认真填报的情况，“虚报、假报”隐患内容，增大了企业监管的难度。采用大数据手段分析隐患内容，找出不切实履行主体责任的企业，向监管部门进行推送，实现精准执法，能够提高监管手段的有效性，增强企业安全责任意识。</p><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>本赛题提供企业填报隐患数据，参赛选手需通过智能化手段识别其中是否存在“虚报、假报”的情况。</p><h1 id="数据简介"><a href="#数据简介" class="headerlink" title="数据简介"></a>数据简介</h1><p>本赛题数据集为脱敏后的企业填报自查隐患记录,数据说明如下：</p><ul><li><p>训练集数据包含“【id、level_1（一级标准）、level_2（二级标准）、level_3（三级标准）、level_4（四级标准）、content（隐患内容）和label（标签）】”共7个字段。<br>其中“id”为主键，无业务意义；“一级标准、二级标准、三级标准、四级标准”为《深圳市安全隐患自查和巡查基本指引（2016年修订版）》规定的排查指引，一级标准对应不同隐患类型，二至四级标准是对一级标准的细化，企业自主上报隐患时，根据不同类型隐患的四级标准开展隐患自查工作；“隐患内容”为企业上报的具体隐患；“标签”标识的是该条隐患的合格性，“1”表示隐患填报不合格，“0”表示隐患填报合格。</p></li><li><p>预测结果文件results.csv</p></li></ul><p><img src="C:\Users\dupeibo\AppData\Roaming\Typora\typora-user-images\1669078534834.png" alt="1669078534834"></p><h1 id="评测标准"><a href="#评测标准" class="headerlink" title="评测标准"></a>评测标准</h1><p>本赛题采用F1 -score作为模型评判标准。</p><h1 id="具体实现代码如下："><a href="#具体实现代码如下：" class="headerlink" title="具体实现代码如下："></a>具体实现代码如下：</h1><h2 id="导入所以需要的包"><a href="#导入所以需要的包" class="headerlink" title="导入所以需要的包"></a>导入所以需要的包</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入transformers</span></span><br><span class="line"><span class="keyword">import</span> transformers</span><br><span class="line"><span class="comment"># from transformers import BertModel, BertTokenizer,BertConfig, AdamW, get_linear_schedule_with_warmup</span></span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModel, AutoTokenizer,AutoConfig, AdamW, get_linear_schedule_with_warmup</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn, optim</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="comment"># 常用包</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> pylab <span class="keyword">import</span> rcParams</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> rc</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix, classification_report</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"><span class="keyword">from</span> textwrap <span class="keyword">import</span> wrap</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">&quot;ignore&quot;</span>)</span><br><span class="line">%matplotlib inline</span><br><span class="line">%config InlineBackend.figure_format=<span class="string">&#x27;retina&#x27;</span> <span class="comment"># 主题</span></span><br></pre></td></tr></table></figure><h2 id="初始化设置"><a href="#初始化设置" class="headerlink" title="初始化设置"></a>初始化设置</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">sns.<span class="built_in">set</span>(style=<span class="string">&#x27;whitegrid&#x27;</span>, palette=<span class="string">&#x27;muted&#x27;</span>, font_scale=<span class="number">1.2</span>)</span><br><span class="line">HAPPY_COLORS_PALETTE = [<span class="string">&quot;#01BEFE&quot;</span>, <span class="string">&quot;#FFDD00&quot;</span>, <span class="string">&quot;#FF7D00&quot;</span>, <span class="string">&quot;#FF006D&quot;</span>, <span class="string">&quot;#ADFF02&quot;</span>, <span class="string">&quot;#8F00FF&quot;</span>]</span><br><span class="line">sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))</span><br><span class="line">rcParams[<span class="string">&#x27;figure.figsize&#x27;</span>] = <span class="number">12</span>, <span class="number">8</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 固定随机种子</span></span><br><span class="line">RANDOM_SEED = <span class="number">42</span></span><br><span class="line">np.random.seed(RANDOM_SEED)</span><br><span class="line">torch.manual_seed(RANDOM_SEED)</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">device</span><br></pre></td></tr></table></figure><pre><code>device(type=&#39;cuda&#39;, index=0)</code></pre><h1 id="读取数据"><a href="#读取数据" class="headerlink" title="读取数据"></a>读取数据</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sub=pd.read_csv(<span class="string">&#x27;./data/02企业隐患排查/sub.csv&#x27;</span>)</span><br><span class="line">test=pd.read_csv(<span class="string">&#x27;./data/02企业隐患排查/test.csv&#x27;</span>)</span><br><span class="line">train=pd.read_csv(<span class="string">&#x27;./data/02企业隐患排查/train.csv&#x27;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train.head()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>id</th>      <th>level_1</th>      <th>level_2</th>      <th>level_3</th>      <th>level_4</th>      <th>content</th>      <th>label</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>0</td>      <td>工业/危化品类（现场）—2016版</td>      <td>（二）电气安全</td>      <td>6、移动用电产品、电动工具及照明</td>      <td>1、移动使用的用电产品和I类电动工具的绝缘线，必须采用三芯(单相)或四芯(三相)多股铜芯橡套软线。</td>      <td>使用移动手动电动工具,外接线绝缘皮破损,应停止使用.</td>      <td>0</td>    </tr>    <tr>      <th>1</th>      <td>1</td>      <td>工业/危化品类（现场）—2016版</td>      <td>（一）消防检查</td>      <td>1、防火巡查</td>      <td>3、消防设施、器材和消防安全标志是否在位、完整；</td>      <td>一般</td>      <td>1</td>    </tr>    <tr>      <th>2</th>      <td>2</td>      <td>工业/危化品类（现场）—2016版</td>      <td>（一）消防检查</td>      <td>2、防火检查</td>      <td>6、重点工种人员以及其他员工消防知识的掌握情况；</td>      <td>消防知识要加强</td>      <td>0</td>    </tr>    <tr>      <th>3</th>      <td>3</td>      <td>工业/危化品类（现场）—2016版</td>      <td>（一）消防检查</td>      <td>1、防火巡查</td>      <td>3、消防设施、器材和消防安全标志是否在位、完整；</td>      <td>消防通道有货物摆放 清理不及时</td>      <td>0</td>    </tr>    <tr>      <th>4</th>      <td>4</td>      <td>工业/危化品类（现场）—2016版</td>      <td>（一）消防检查</td>      <td>1、防火巡查</td>      <td>4、常闭式防火门是否处于关闭状态，防火卷帘下是否堆放物品影响使用；</td>      <td>防火门打开状态</td>      <td>0</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">test.head()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>id</th>      <th>level_1</th>      <th>level_2</th>      <th>level_3</th>      <th>level_4</th>      <th>content</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>0</td>      <td>交通运输类（现场）—2016版</td>      <td>（一）消防安全</td>      <td>2、防火检查</td>      <td>2、安全疏散通道、疏散指示标志、应急照明和安全出口情况。</td>      <td>RB1洗地机占用堵塞安全通道</td>    </tr>    <tr>      <th>1</th>      <td>1</td>      <td>工业/危化品类（选项）—2016版</td>      <td>（二）仓库</td>      <td>1、一般要求</td>      <td>1、库房内储存物品应分类、分堆、限额存放。</td>      <td>未分类堆放</td>    </tr>    <tr>      <th>2</th>      <td>2</td>      <td>工业/危化品类（现场）—2016版</td>      <td>（一）消防检查</td>      <td>1、防火巡查</td>      <td>3、消防设施、器材和消防安全标志是否在位、完整；</td>      <td>消防设施、器材和消防安全标志是否在位、完整</td>    </tr>    <tr>      <th>3</th>      <td>3</td>      <td>商贸服务教文卫类（现场）—2016版</td>      <td>（二）电气安全</td>      <td>3、电气线路及电源插头插座</td>      <td>3、电源插座、电源插头应按规定正确接线。</td>      <td>插座随意放在电器旁边</td>    </tr>    <tr>      <th>4</th>      <td>4</td>      <td>商贸服务教文卫类（现场）—2016版</td>      <td>（一）消防检查</td>      <td>1、防火巡查</td>      <td>6、其他消防安全情况。</td>      <td>检查中发现一瓶灭火器过期</td>    </tr>  </tbody></table></div><h2 id="查看数据的形状"><a href="#查看数据的形状" class="headerlink" title="查看数据的形状"></a>查看数据的形状</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;train.shape,test.shape,sub.shape&quot;</span>,train.shape,test.shape,sub.shape)</span><br></pre></td></tr></table></figure><pre><code>train.shape,test.shape,sub.shape (12000, 7) (18000, 6) (18000, 2)</code></pre><h2 id="查看是否存在空值"><a href="#查看是否存在空值" class="headerlink" title="查看是否存在空值"></a>查看是否存在空值</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train[train[<span class="string">&#x27;content&#x27;</span>].isna()]</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>id</th>      <th>level_1</th>      <th>level_2</th>      <th>level_3</th>      <th>level_4</th>      <th>content</th>      <th>label</th>    </tr>  </thead>  <tbody>    <tr>      <th>6193</th>      <td>6193</td>      <td>工业/危化品类（现场）—2016版</td>      <td>（一）消防检查</td>      <td>1、防火巡查</td>      <td>3、消防设施、器材和消防安全标志是否在位、完整；</td>      <td>NaN</td>      <td>1</td>    </tr>    <tr>      <th>9248</th>      <td>9248</td>      <td>工业/危化品类（现场）—2016版</td>      <td>（一）消防检查</td>      <td>1、防火巡查</td>      <td>4、常闭式防火门是否处于关闭状态，防火卷帘下是否堆放物品影响使用；</td>      <td>NaN</td>      <td>1</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;train null nums&#x27;</span>)</span><br><span class="line">train.shape[<span class="number">0</span>]-train.count()</span><br></pre></td></tr></table></figure><pre><code>train null numsid         0level_1    0level_2    0level_3    0level_4    0content    2label      0dtype: int64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;test null nums&#x27;</span>)</span><br><span class="line">test.shape[<span class="number">0</span>]-test.count()</span><br></pre></td></tr></table></figure><pre><code>test null numsid         0level_1    0level_2    0level_3    0level_4    0content    4dtype: int64</code></pre><h2 id="查看标签的分布"><a href="#查看标签的分布" class="headerlink" title="查看标签的分布"></a>查看标签的分布</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train[<span class="string">&#x27;label&#x27;</span>].value_counts()</span><br></pre></td></tr></table></figure><pre><code>0    107121     1288Name: label, dtype: int64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># sns.countplot(train.label)</span></span><br><span class="line"><span class="comment"># plt.xlabel(&#x27;label count&#x27;)</span></span><br></pre></td></tr></table></figure><h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train.fillna(<span class="string">&quot;空值&quot;</span>,inplace=<span class="literal">True</span>)</span><br><span class="line">test.fillna(<span class="string">&quot;空值&quot;</span>,inplace=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train.shape[<span class="number">0</span>]-train.count()</span><br></pre></td></tr></table></figure><pre><code>id         0level_1    0level_2    0level_3    0level_4    0content    0label      0dtype: int64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train[<span class="string">&#x27;level_3&#x27;</span>].value_counts()</span><br></pre></td></tr></table></figure><pre><code>1、防火巡查             42252、防火检查             29112、配电箱（柜、板）          7101、作业通道              6643、电气线路及电源插头插座       497                   ... 3、安全带                 14、特种设备及操作人员管理记录       14、安全技术交底              13、停车场                 11、水库安全                1Name: level_3, Length: 153, dtype: int64</code></pre><h3 id="对训练集处理"><a href="#对训练集处理" class="headerlink" title="对训练集处理"></a>对训练集处理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train[<span class="string">&#x27;level_1&#x27;</span>] = train[<span class="string">&#x27;level_1&#x27;</span>].apply(<span class="keyword">lambda</span> x:x.split(<span class="string">&#x27;（&#x27;</span>)[<span class="number">0</span>])</span><br><span class="line">train[<span class="string">&#x27;level_2&#x27;</span>] = train[<span class="string">&#x27;level_2&#x27;</span>].apply(<span class="keyword">lambda</span> x:x.split(<span class="string">&#x27;）&#x27;</span>)[<span class="number">1</span>])</span><br><span class="line">train[<span class="string">&#x27;level_3&#x27;</span>] = train[<span class="string">&#x27;level_3&#x27;</span>].apply(<span class="keyword">lambda</span> x:re.split(<span class="string">&#x27;[0-9]、&#x27;</span>,x)[-<span class="number">1</span>])</span><br><span class="line">train[<span class="string">&#x27;level_4&#x27;</span>] = train[<span class="string">&#x27;level_4&#x27;</span>].apply(<span class="keyword">lambda</span> x:re.split(<span class="string">&#x27;[0-9]、&#x27;</span>,x)[-<span class="number">1</span>])</span><br></pre></td></tr></table></figure><h3 id="对测试集处理"><a href="#对测试集处理" class="headerlink" title="对测试集处理"></a>对测试集处理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">test[<span class="string">&#x27;level_1&#x27;</span>] = test[<span class="string">&#x27;level_1&#x27;</span>].apply(<span class="keyword">lambda</span> x:x.split(<span class="string">&#x27;（&#x27;</span>)[<span class="number">0</span>])</span><br><span class="line">test[<span class="string">&#x27;level_2&#x27;</span>] = test[<span class="string">&#x27;level_2&#x27;</span>].apply(<span class="keyword">lambda</span> x:x.split(<span class="string">&#x27;）&#x27;</span>)[-<span class="number">1</span>])</span><br><span class="line">test[<span class="string">&#x27;level_3&#x27;</span>] = test[<span class="string">&#x27;level_3&#x27;</span>].apply(<span class="keyword">lambda</span> x:re.split(<span class="string">&#x27;[0-9]、&#x27;</span>,x)[-<span class="number">1</span>])</span><br><span class="line">test[<span class="string">&#x27;level_4&#x27;</span>] = test[<span class="string">&#x27;level_4&#x27;</span>].apply(<span class="keyword">lambda</span> x:re.split(<span class="string">&#x27;[0-9]、&#x27;</span>,x)[-<span class="number">1</span>])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train.head()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>id</th>      <th>level_1</th>      <th>level_2</th>      <th>level_3</th>      <th>level_4</th>      <th>content</th>      <th>label</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>0</td>      <td>工业/危化品类</td>      <td>电气安全</td>      <td>移动用电产品、电动工具及照明</td>      <td>移动使用的用电产品和I类电动工具的绝缘线，必须采用三芯(单相)或四芯(三相)多股铜芯橡套软线。</td>      <td>使用移动手动电动工具,外接线绝缘皮破损,应停止使用.</td>      <td>0</td>    </tr>    <tr>      <th>1</th>      <td>1</td>      <td>工业/危化品类</td>      <td>消防检查</td>      <td>防火巡查</td>      <td>消防设施、器材和消防安全标志是否在位、完整；</td>      <td>一般</td>      <td>1</td>    </tr>    <tr>      <th>2</th>      <td>2</td>      <td>工业/危化品类</td>      <td>消防检查</td>      <td>防火检查</td>      <td>重点工种人员以及其他员工消防知识的掌握情况；</td>      <td>消防知识要加强</td>      <td>0</td>    </tr>    <tr>      <th>3</th>      <td>3</td>      <td>工业/危化品类</td>      <td>消防检查</td>      <td>防火巡查</td>      <td>消防设施、器材和消防安全标志是否在位、完整；</td>      <td>消防通道有货物摆放 清理不及时</td>      <td>0</td>    </tr>    <tr>      <th>4</th>      <td>4</td>      <td>工业/危化品类</td>      <td>消防检查</td>      <td>防火巡查</td>      <td>常闭式防火门是否处于关闭状态，防火卷帘下是否堆放物品影响使用；</td>      <td>防火门打开状态</td>      <td>0</td>    </tr>  </tbody></table></div><h2 id="文本拼接"><a href="#文本拼接" class="headerlink" title="文本拼接"></a>文本拼接</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">train[<span class="string">&#x27;text&#x27;</span>]=train[<span class="string">&#x27;content&#x27;</span>]+<span class="string">&#x27;[SEP]&#x27;</span>+train[<span class="string">&#x27;level_1&#x27;</span>]+<span class="string">&#x27;[SEP]&#x27;</span>+train[<span class="string">&#x27;level_2&#x27;</span>]+<span class="string">&#x27;[SEP]&#x27;</span>+train[<span class="string">&#x27;level_3&#x27;</span>]+<span class="string">&#x27;[SEP]&#x27;</span>+train[<span class="string">&#x27;level_4&#x27;</span>]</span><br><span class="line">test[<span class="string">&#x27;text&#x27;</span>]=test[<span class="string">&#x27;content&#x27;</span>]+<span class="string">&#x27;[SEP]&#x27;</span>+test[<span class="string">&#x27;level_1&#x27;</span>]+<span class="string">&#x27;[SEP]&#x27;</span>+test[<span class="string">&#x27;level_2&#x27;</span>]+<span class="string">&#x27;[SEP]&#x27;</span>+test[<span class="string">&#x27;level_3&#x27;</span>]+<span class="string">&#x27;[SEP]&#x27;</span>+test[<span class="string">&#x27;level_4&#x27;</span>]</span><br><span class="line">train.head()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>id</th>      <th>level_1</th>      <th>level_2</th>      <th>level_3</th>      <th>level_4</th>      <th>content</th>      <th>label</th>      <th>text</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>0</td>      <td>工业/危化品类</td>      <td>电气安全</td>      <td>移动用电产品、电动工具及照明</td>      <td>移动使用的用电产品和I类电动工具的绝缘线，必须采用三芯(单相)或四芯(三相)多股铜芯橡套软线。</td>      <td>使用移动手动电动工具,外接线绝缘皮破损,应停止使用.</td>      <td>0</td>      <td>使用移动手动电动工具,外接线绝缘皮破损,应停止使用.[SEP]工业/危化品类[SEP]电气安...</td>    </tr>    <tr>      <th>1</th>      <td>1</td>      <td>工业/危化品类</td>      <td>消防检查</td>      <td>防火巡查</td>      <td>消防设施、器材和消防安全标志是否在位、完整；</td>      <td>一般</td>      <td>1</td>      <td>一般[SEP]工业/危化品类[SEP]消防检查[SEP]防火巡查[SEP]消防设施、器材和消...</td>    </tr>    <tr>      <th>2</th>      <td>2</td>      <td>工业/危化品类</td>      <td>消防检查</td>      <td>防火检查</td>      <td>重点工种人员以及其他员工消防知识的掌握情况；</td>      <td>消防知识要加强</td>      <td>0</td>      <td>消防知识要加强[SEP]工业/危化品类[SEP]消防检查[SEP]防火检查[SEP]重点工种...</td>    </tr>    <tr>      <th>3</th>      <td>3</td>      <td>工业/危化品类</td>      <td>消防检查</td>      <td>防火巡查</td>      <td>消防设施、器材和消防安全标志是否在位、完整；</td>      <td>消防通道有货物摆放 清理不及时</td>      <td>0</td>      <td>消防通道有货物摆放 清理不及时[SEP]工业/危化品类[SEP]消防检查[SEP]防火巡查[...</td>    </tr>    <tr>      <th>4</th>      <td>4</td>      <td>工业/危化品类</td>      <td>消防检查</td>      <td>防火巡查</td>      <td>常闭式防火门是否处于关闭状态，防火卷帘下是否堆放物品影响使用；</td>      <td>防火门打开状态</td>      <td>0</td>      <td>防火门打开状态[SEP]工业/危化品类[SEP]消防检查[SEP]防火巡查[SEP]常闭式防...</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train[<span class="string">&#x27;text_len&#x27;</span>]=train[<span class="string">&#x27;text&#x27;</span>].<span class="built_in">map</span>(<span class="built_in">len</span>)</span><br><span class="line">train[<span class="string">&#x27;text&#x27;</span>].<span class="built_in">map</span>(<span class="built_in">len</span>).describe()<span class="comment"># 298-12=286</span></span><br></pre></td></tr></table></figure><pre><code>count    12000.000000mean        80.444500std         21.910859min         43.00000025%         66.00000050%         75.00000075%         92.000000max        298.000000Name: text, dtype: float64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">test[<span class="string">&#x27;text&#x27;</span>].<span class="built_in">map</span>(<span class="built_in">len</span>).describe() <span class="comment"># 520-12=518</span></span><br></pre></td></tr></table></figure><pre><code>count    18000.000000mean        80.762611std         22.719823min         43.00000025%         66.00000050%         76.00000075%         92.000000max        520.000000Name: text, dtype: float64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train[<span class="string">&#x27;text_len&#x27;</span>].plot(kind=<span class="string">&#x27;kde&#x27;</span>)</span><br></pre></td></tr></table></figure><pre><code>&lt;AxesSubplot:ylabel=&#39;Density&#39;&gt;</code></pre><p><img src="C:\Users\dupeibo\AppData\Roaming\Typora\typora-user-images\1669079055167.png" alt="1669079055167"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sum</span>(train[<span class="string">&#x27;text_len&#x27;</span>]&gt;<span class="number">100</span>) <span class="comment"># text文本长度大于100的个数     1878</span></span><br><span class="line"><span class="built_in">sum</span>(train[<span class="string">&#x27;text_len&#x27;</span>]&gt;<span class="number">200</span>) <span class="comment"># text文本长度大于200的个数     11</span></span><br></pre></td></tr></table></figure><h1 id="模型的加载和配置"><a href="#模型的加载和配置" class="headerlink" title="模型的加载和配置"></a>模型的加载和配置</h1><h3 id="embedding"><a href="#embedding" class="headerlink" title="embedding"></a>embedding</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">PRE_TRAINED_MODEL_NAME = <span class="string">&#x27;bert-base-chinese&#x27;</span></span><br><span class="line"><span class="comment"># PRE_TRAINED_MODEL_NAME = &#x27;hfl/chinese-roberta-wwm-ext&#x27;</span></span><br><span class="line"><span class="comment"># PRE_TRAINED_MODEL_NAME = &#x27;hfl/chinese-roberta-wwm&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)</span></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tokenizer</span><br></pre></td></tr></table></figure><pre><code>PreTrainedTokenizerFast(name_or_path=&#39;bert-base-chinese&#39;, vocab_size=21128, model_max_len=512, is_fast=True, padding_side=&#39;right&#39;, truncation_side=&#39;right&#39;, special_tokens=&#123;&#39;unk_token&#39;: &#39;[UNK]&#39;, &#39;sep_token&#39;: &#39;[SEP]&#39;, &#39;pad_token&#39;: &#39;[PAD]&#39;, &#39;cls_token&#39;: &#39;[CLS]&#39;, &#39;mask_token&#39;: &#39;[MASK]&#39;&#125;)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sample_txt = <span class="string">&#x27;今天早上9点半起床，我在学习预训练模型的使用.&#x27;</span></span><br><span class="line"><span class="built_in">len</span>(sample_txt)</span><br></pre></td></tr></table></figure><pre><code>23</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tokens = tokenizer.tokenize(sample_txt)</span><br><span class="line">token_ids = tokenizer.convert_tokens_to_ids(tokens)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;文本为: <span class="subst">&#123;sample_txt&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;分词的列表为: <span class="subst">&#123;tokens&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;词对应的唯一id: <span class="subst">&#123;token_ids&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure><pre><code>文本为: 今天早上9点半起床，我在学习预训练模型的使用.分词的列表为: [&#39;今&#39;, &#39;天&#39;, &#39;早&#39;, &#39;上&#39;, &#39;9&#39;, &#39;点&#39;, &#39;半&#39;, &#39;起&#39;, &#39;床&#39;, &#39;，&#39;, &#39;我&#39;, &#39;在&#39;, &#39;学&#39;, &#39;习&#39;, &#39;预&#39;, &#39;训&#39;, &#39;练&#39;, &#39;模&#39;, &#39;型&#39;, &#39;的&#39;, &#39;使&#39;, &#39;用&#39;, &#39;.&#39;]词对应的唯一id: [791, 1921, 3193, 677, 130, 4157, 1288, 6629, 2414, 8024, 2769, 1762, 2110, 739, 7564, 6378, 5298, 3563, 1798, 4638, 886, 4500, 119]</code></pre><h3 id="查看特殊的Token"><a href="#查看特殊的Token" class="headerlink" title="查看特殊的Token"></a>查看特殊的Token</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tokenizer.sep_token,tokenizer.sep_token_id</span><br></pre></td></tr></table></figure><pre><code>(&#39;[SEP]&#39;, 102)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tokenizer.cls_token,tokenizer.cls_token_id</span><br></pre></td></tr></table></figure><pre><code>(&#39;[CLS]&#39;, 101)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tokenizer.pad_token,tokenizer.pad_token_id</span><br></pre></td></tr></table></figure><pre><code>(&#39;[PAD]&#39;, 0)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tokenizer.mask_token,tokenizer.mask_token_id</span><br></pre></td></tr></table></figure><pre><code>(&#39;[MASK]&#39;, 103)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tokenizer.unk_token,tokenizer.unk_token_id</span><br></pre></td></tr></table></figure><pre><code>(&#39;[UNK]&#39;, 100)</code></pre><h3 id="简单的编码测试"><a href="#简单的编码测试" class="headerlink" title="简单的编码测试"></a>简单的编码测试</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">encoding=tokenizer.encode_plus(</span><br><span class="line">    sample_txt,</span><br><span class="line">    <span class="comment"># sample_txt_another,</span></span><br><span class="line">    max_length=<span class="number">32</span>,</span><br><span class="line">    add_special_tokens=<span class="literal">True</span>,<span class="comment"># [CLS]和[SEP]</span></span><br><span class="line">    return_token_type_ids=<span class="literal">True</span>,</span><br><span class="line">    pad_to_max_length=<span class="literal">True</span>,</span><br><span class="line">    return_attention_mask=<span class="literal">True</span>,</span><br><span class="line">    return_tensors=<span class="string">&#x27;pt&#x27;</span>,<span class="comment"># Pytorch tensor张量</span></span><br><span class="line"></span><br><span class="line">)</span><br><span class="line">encoding</span><br></pre></td></tr></table></figure><pre><code>Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to &#39;longest_first&#39; truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.&#123;&#39;input_ids&#39;: tensor([[ 101,  791, 1921, 3193,  677,  130, 4157, 1288, 6629, 2414, 8024, 2769,         1762, 2110,  739, 7564, 6378, 5298, 3563, 1798, 4638,  886, 4500,  119,          102,    0,    0,    0,    0,    0,    0,    0]]), &#39;token_type_ids&#39;: tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,         0, 0, 0, 0, 0, 0, 0, 0]]), &#39;attention_mask&#39;: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,         1, 0, 0, 0, 0, 0, 0, 0]])&#125;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">encoding[<span class="string">&#x27;attention_mask&#x27;</span>][<span class="number">0</span>]</span><br></pre></td></tr></table></figure><pre><code>tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,        1, 0, 0, 0, 0, 0, 0, 0])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">token_lens = []</span><br><span class="line"><span class="comment"># 选的是每一句话的长度</span></span><br><span class="line"><span class="keyword">for</span> txt <span class="keyword">in</span> train.text:</span><br><span class="line"><span class="comment">#     print(txt)</span></span><br><span class="line">    tokens = tokenizer.encode(txt, max_length=<span class="number">512</span>)</span><br><span class="line">    token_lens.append(<span class="built_in">len</span>(tokens))</span><br><span class="line"><span class="comment"># token_lens</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sns.distplot(token_lens)</span><br><span class="line">plt.xlim([<span class="number">0</span>, <span class="number">256</span>]);</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Token count&#x27;</span>);</span><br></pre></td></tr></table></figure><p><img src="C:\Users\dupeibo\AppData\Roaming\Typora\typora-user-images\1669079168255.png" alt="1669079168255"></p><p>​    </p><h3 id="通过分析，长度一般都在160之内"><a href="#通过分析，长度一般都在160之内" class="headerlink" title="通过分析，长度一般都在160之内"></a>通过分析，长度一般都在160之内</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MAX_LEN = <span class="number">160</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">encoding[<span class="string">&#x27;input_ids&#x27;</span>].flatten()</span><br></pre></td></tr></table></figure><pre><code>tensor([ 101,  791, 1921, 3193,  677,  130, 4157, 1288, 6629, 2414, 8024, 2769,        1762, 2110,  739, 7564, 6378, 5298, 3563, 1798, 4638,  886, 4500,  119,         102,    0,    0,    0,    0,    0,    0,    0])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">encoding[<span class="string">&#x27;input_ids&#x27;</span>]</span><br></pre></td></tr></table></figure><pre><code>tensor([[ 101,  791, 1921, 3193,  677,  130, 4157, 1288, 6629, 2414, 8024, 2769,         1762, 2110,  739, 7564, 6378, 5298, 3563, 1798, 4638,  886, 4500,  119,          102,    0,    0,    0,    0,    0,    0,    0]])</code></pre><h2 id="处理数据"><a href="#处理数据" class="headerlink" title="处理数据"></a>处理数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">EnterpriseDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,texts,labels,tokenizer,max_len</span>):</span><br><span class="line">        self.texts=texts</span><br><span class="line">        self.labels=labels</span><br><span class="line">        self.tokenizer=tokenizer</span><br><span class="line">        self.max_len=max_len</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.texts)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self,item</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        item 为数据索引，迭代取第item条数据</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        text=<span class="built_in">str</span>(self.texts[item])</span><br><span class="line">        label=self.labels[item]</span><br><span class="line">        </span><br><span class="line">        encoding=self.tokenizer.encode_plus(</span><br><span class="line">            text,</span><br><span class="line">            add_special_tokens=<span class="literal">True</span>,</span><br><span class="line">            max_length=self.max_len,</span><br><span class="line">            return_token_type_ids=<span class="literal">True</span>,</span><br><span class="line">            pad_to_max_length=<span class="literal">True</span>,</span><br><span class="line">            return_attention_mask=<span class="literal">True</span>,</span><br><span class="line">            return_tensors=<span class="string">&#x27;pt&#x27;</span>,</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line"><span class="comment">#         print(encoding[&#x27;input_ids&#x27;])</span></span><br><span class="line">        <span class="keyword">return</span> &#123;</span><br><span class="line">            <span class="string">&#x27;texts&#x27;</span>:text,</span><br><span class="line">            <span class="string">&#x27;input_ids&#x27;</span>:encoding[<span class="string">&#x27;input_ids&#x27;</span>].flatten(),</span><br><span class="line">            <span class="string">&#x27;attention_mask&#x27;</span>:encoding[<span class="string">&#x27;attention_mask&#x27;</span>].flatten(),</span><br><span class="line">            <span class="comment"># toeken_type_ids:0</span></span><br><span class="line">            <span class="string">&#x27;labels&#x27;</span>:torch.tensor(label,dtype=torch.long)</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><h3 id="分割数据集"><a href="#分割数据集" class="headerlink" title="分割数据集"></a>分割数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df_train, df_test = train_test_split(train, test_size=<span class="number">0.1</span>, random_state=RANDOM_SEED)</span><br><span class="line">df_val, df_test = train_test_split(df_test, test_size=<span class="number">0.5</span>, random_state=RANDOM_SEED)</span><br><span class="line">df_train.shape, df_val.shape, df_test.shape</span><br></pre></td></tr></table></figure><pre><code>((10800, 9), (600, 9), (600, 9))</code></pre><h3 id="创建DataLoader"><a href="#创建DataLoader" class="headerlink" title="创建DataLoader"></a>创建DataLoader</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">create_data_loader</span>(<span class="params">df,tokenizer,max_len,batch_size</span>):</span><br><span class="line">    ds=EnterpriseDataset(</span><br><span class="line">        texts=df[<span class="string">&#x27;text&#x27;</span>].values,</span><br><span class="line">        labels=df[<span class="string">&#x27;label&#x27;</span>].values,</span><br><span class="line">        tokenizer=tokenizer,</span><br><span class="line">        max_len=max_len</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> DataLoader(</span><br><span class="line">        ds,</span><br><span class="line">        batch_size=batch_size,</span><br><span class="line"><span class="comment">#         num_workers=4 # windows多线程</span></span><br><span class="line">    )</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">BATCH_SIZE = <span class="number">4</span></span><br><span class="line"></span><br><span class="line">train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)</span><br><span class="line">val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)</span><br><span class="line">test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">next</span>(<span class="built_in">iter</span>(train_data_loader))</span><br></pre></td></tr></table></figure><pre><code>&#123;&#39;texts&#39;: [&#39;指示标识不清楚[SEP]工业/危化品类[SEP]消防检查[SEP]防火巡查[SEP]安全出口、疏散通道是否畅通，安全疏散指示标志、应急照明是否完好；&#39;,  &#39;发现本月有灭火器过期，已安排购买灭火器更换[SEP]商贸服务教文卫类[SEP]消防检查[SEP]防火检查[SEP]灭火器材配置及有效情况。&#39;,  &#39;安全出口标志灯有一个有故障，已买回安装改正。[SEP]工业/危化品类[SEP]消防检查[SEP]防火巡查[SEP]安全出口、疏散通道是否畅通，安全疏散指示标志、应急照明是否完好；&#39;,  &#39;堵了消防通道[SEP]工业/危化品类[SEP]消防检查[SEP]防火巡查[SEP]安全出口、疏散通道是否畅通，安全疏散指示标志、应急照明是否完好；&#39;], &#39;input_ids&#39;: tensor([[ 101, 2900, 4850, 3403, 6399,  679, 3926, 3504,  102, 2339,  689,  120,          1314, 1265, 1501, 5102,  102, 3867, 7344, 3466, 3389,  102, 7344, 4125,          2337, 3389,  102, 2128, 1059, 1139, 1366,  510, 4541, 3141, 6858, 6887,          3221, 1415, 4517, 6858, 8024, 2128, 1059, 4541, 3141, 2900, 4850, 3403,          2562,  510, 2418, 2593, 4212, 3209, 3221, 1415, 2130, 1962, 8039,  102,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0],         [ 101, 1355, 4385, 3315, 3299, 3300, 4127, 4125, 1690, 6814, 3309, 8024,          2347, 2128, 2961, 6579,  743, 4127, 4125, 1690, 3291, 2940,  102, 1555,          6588, 3302, 1218, 3136, 3152, 1310, 5102,  102, 3867, 7344, 3466, 3389,           102, 7344, 4125, 3466, 3389,  102, 4127, 4125, 1690, 3332, 6981, 5390,          1350, 3300, 3126, 2658, 1105,  511,  102,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0],         [ 101, 2128, 1059, 1139, 1366, 3403, 2562, 4128, 3300,  671,  702, 3300,          3125, 7397, 8024, 2347,  743, 1726, 2128, 6163, 3121, 3633,  511,  102,          2339,  689,  120, 1314, 1265, 1501, 5102,  102, 3867, 7344, 3466, 3389,           102, 7344, 4125, 2337, 3389,  102, 2128, 1059, 1139, 1366,  510, 4541,          3141, 6858, 6887, 3221, 1415, 4517, 6858, 8024, 2128, 1059, 4541, 3141,          2900, 4850, 3403, 2562,  510, 2418, 2593, 4212, 3209, 3221, 1415, 2130,          1962, 8039,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0],         [ 101, 1843,  749, 3867, 7344, 6858, 6887,  102, 2339,  689,  120, 1314,          1265, 1501, 5102,  102, 3867, 7344, 3466, 3389,  102, 7344, 4125, 2337,          3389,  102, 2128, 1059, 1139, 1366,  510, 4541, 3141, 6858, 6887, 3221,          1415, 4517, 6858, 8024, 2128, 1059, 4541, 3141, 2900, 4850, 3403, 2562,           510, 2418, 2593, 4212, 3209, 3221, 1415, 2130, 1962, 8039,  102,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0]]), &#39;attention_mask&#39;: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,          1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,          1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), &#39;labels&#39;: tensor([0, 0, 0, 0])&#125;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data = <span class="built_in">next</span>(<span class="built_in">iter</span>(train_data_loader))</span><br><span class="line">data.keys()</span><br></pre></td></tr></table></figure><pre><code>dict_keys([&#39;texts&#39;, &#39;input_ids&#39;, &#39;attention_mask&#39;, &#39;labels&#39;])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(data[<span class="string">&#x27;input_ids&#x27;</span>].shape)</span><br><span class="line"><span class="built_in">print</span>(data[<span class="string">&#x27;attention_mask&#x27;</span>].shape)</span><br><span class="line"><span class="built_in">print</span>(data[<span class="string">&#x27;labels&#x27;</span>].shape)</span><br></pre></td></tr></table></figure><pre><code>torch.Size([4, 160])torch.Size([4, 160])torch.Size([4])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bert_model = AutoModel.from_pretrained(PRE_TRAINED_MODEL_NAME)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">encoding[<span class="string">&#x27;input_ids&#x27;</span>]</span><br></pre></td></tr></table></figure><pre><code>tensor([[ 101,  791, 1921, 3193,  677,  130, 4157, 1288, 6629, 2414, 8024, 2769,         1762, 2110,  739, 7564, 6378, 5298, 3563, 1798, 4638,  886, 4500,  119,          102,    0,    0,    0,    0,    0,    0,    0]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">last_hidden_state, pooled_output = bert_model(</span><br><span class="line">    input_ids=encoding[<span class="string">&#x27;input_ids&#x27;</span>], </span><br><span class="line">    attention_mask=encoding[<span class="string">&#x27;attention_mask&#x27;</span>],</span><br><span class="line">    return_dict = <span class="literal">False</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><h2 id="查看输出结果"><a href="#查看输出结果" class="headerlink" title="查看输出结果"></a>查看输出结果</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">last_hidden_state[<span class="number">0</span>][<span class="number">0</span>].shape</span><br></pre></td></tr></table></figure><pre><code>torch.Size([768])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pooled_output</span><br></pre></td></tr></table></figure><pre><code>tensor([[ 0.9999,  0.9998,  0.9989,  0.9629,  0.3075, -0.1866, -0.9904,  0.8628,          0.9710, -0.9993,  1.0000,  1.0000,  0.9312, -0.9394,  0.9998, -0.9999,          0.0417,  0.9999,  0.9458,  0.3190,  1.0000, -1.0000, -0.9062, -0.9048,          0.1764,  0.9983,  0.9346, -0.8122, -0.9999,  0.9996,  0.7879,  0.9999,          0.8475, -1.0000, -1.0000,  0.9413, -0.8260,  0.9889, -0.4976, -0.9857,         -0.9955, -0.9580,  0.5833, -0.9996, -0.8932,  0.8563, -1.0000, -0.9999,          0.9719,  0.9999, -0.7430, -0.9993,  0.9756, -0.9754,  0.2991,  0.8933,         -0.9991,  0.9987,  1.0000,  0.4156,  0.9992, -0.9452, -0.8020, -0.9999,          1.0000, -0.9964, -0.9900,  0.4365,  1.0000,  1.0000, -0.9400,  0.8794,          1.0000,  0.9105, -0.6616,  1.0000, -0.9999,  0.6892, -1.0000, -0.9817,          1.0000,  0.9957, -0.8844, -0.8248, -0.9921, -0.9999, -0.9998,  1.0000,          0.5228,  0.1297,  0.9932, -0.9999, -1.0000,  0.9993, -0.9996, -0.9948,         -0.9561,  0.9996, -0.5785, -0.9386, -0.2035,  0.9086, -0.9999, -0.9993,          0.9959,  0.9984,  0.6953, -0.9995,  1.0000,  0.8610, -1.0000, -0.4507,         -1.0000,  0.2384, -0.9812,  0.9998,  0.9504,  0.5421,  0.9995, -0.9998,          0.9320, -0.9941, -0.9718, -0.9910,  0.9822,  1.0000,  0.9997, -0.9990,          1.0000,  1.0000,  0.8608,  0.9964, -0.9997,  0.9799,  0.5985, -0.9098,          0.5329, -0.6345,  1.0000,  0.9872,  0.9970, -0.9719,  0.9988, -0.9933,          1.0000, -0.9999,  0.9973, -1.0000, -0.6550,  0.9996,  0.8899,  1.0000,          0.2969,  0.9999, -0.9983, -0.9991,  0.9906, -0.6590,  0.9872, -1.0000,          0.7658,  0.7876, -0.8556,  0.6304, -1.0000,  1.0000, -0.7938,  1.0000,          0.9898,  0.2216, -0.9942, -0.9969,  0.8345, -0.9998, -0.9779,  0.9914,          0.5227,  0.9992, -0.9893, -0.9889,  0.2325, -0.9887, -0.9999,  0.9885,          0.0340,  0.9284,  0.5197,  0.4143,  0.8315,  0.1585, -0.5348,  1.0000,          0.2361,  0.9985,  0.9999, -0.3446,  0.1012, -0.9924, -1.0000, -0.7542,          0.9999, -0.2807, -0.9999,  0.9490, -1.0000,  0.9906, -0.7288, -0.5263,         -0.9545, -0.9999,  0.9998, -0.9286, -0.9997, -0.5303,  0.8886,  0.5605,         -0.9989, -0.3324,  0.9804, -0.9075,  0.9905, -0.9800, -0.9946,  0.6855,         -0.9393,  0.9929,  0.9874,  1.0000,  0.9997, -0.0714, -0.9440,  1.0000,          0.1676, -1.0000,  0.5573, -0.9611,  0.8835,  0.9999, -0.9980,  0.9294,          1.0000,  0.7968,  1.0000, -0.7065, -0.9793, -0.9997,  1.0000,  0.9922,          0.9999, -0.9984, -0.9995, -0.1701, -0.5426, -1.0000, -1.0000, -0.6334,          0.9969,  0.9999, -0.1620, -0.9818, -0.9921, -0.9994,  1.0000, -0.9759,          1.0000,  0.8570, -0.7434, -0.9164,  0.9438, -0.7311, -0.9986, -0.3936,         -0.9997, -0.9650, -1.0000,  0.9433, -0.9999, -1.0000,  0.6913,  1.0000,          0.8762, -1.0000,  0.9997,  0.9764,  0.7094, -0.9294,  0.9522, -1.0000,          1.0000, -0.9965,  0.9428, -0.9972, -0.9897, -0.7680,  0.9922,  0.9999,         -0.9999, -0.9597, -0.9922, -0.9807, -0.3632,  0.9936, -0.7280,  0.4117,         -0.9498, -0.9666,  0.9545, -0.9957, -0.9970,  0.4028,  1.0000, -0.9798,          1.0000,  0.9941,  1.0000,  0.9202, -0.9942,  0.9996,  0.5352, -0.5836,         -0.8829, -0.9418,  0.9497, -0.0532,  0.6966, -0.9999,  0.9998,  0.9917,          0.9612,  0.7289,  0.0167,  0.3179,  0.9627, -0.9911,  0.9995, -0.9996,         -0.6737,  0.9991,  1.0000,  0.9932,  0.4880, -0.7488,  0.9986, -0.9961,          0.9995, -1.0000,  0.9999, -0.9940,  0.9705, -0.9970, -0.9856,  1.0000,          0.9846, -0.7932,  0.9997, -0.9386,  0.9938,  0.9738,  0.8173,  0.9913,          0.9981,  1.0000, -0.9998, -0.9918, -0.9727, -0.9987, -0.9955, -1.0000,         -0.1038, -1.0000, -0.9874, -0.9287,  0.5109, -0.9056,  0.1022,  0.7864,         -0.8197,  0.5724, -0.5905,  0.2713, -0.7239, -0.9976, -0.9844, -1.0000,         -0.9988,  0.8835,  0.9999, -0.9997,  0.9999, -0.9999, -0.9782,  0.9383,         -0.5609,  0.7721,  0.9999, -1.0000,  0.9585,  0.9987,  1.0000,  0.9960,          0.9993, -0.9741, -0.9999, -0.9989, -0.9999, -1.0000, -0.9998,  0.9343,          0.6337, -1.0000,  0.0902,  0.8980,  1.0000,  0.9964, -0.9985, -0.6136,         -0.9996, -0.8252,  0.9996, -0.0566, -1.0000,  0.9962, -0.8744,  1.0000,         -0.8865,  0.9879,  0.8897,  0.9571,  0.9823, -1.0000,  0.9145,  1.0000,          0.0365, -1.0000, -0.9985, -0.9075, -0.9998,  0.0369,  0.8120,  0.9999,         -1.0000, -0.9155, -0.9975,  0.7988,  0.9922,  0.9998,  0.9982,  0.9267,          0.9165,  0.5368,  0.1464,  0.9998,  0.4663, -0.9989,  0.9996, -0.7952,          0.4527, -1.0000,  0.9998,  0.4073,  0.9999,  0.9159, -0.5480, -0.6821,         -0.9904,  0.9938,  1.0000, -0.4229, -0.4845, -0.9981, -1.0000, -0.9861,         -0.0950, -0.4625, -0.9629, -0.9998,  0.6675, -0.5244,  1.0000,  1.0000,          0.9924, -0.9253, -0.9974,  0.9974, -0.9012,  0.9900, -0.2582, -1.0000,         -0.9919, -0.9986,  1.0000, -0.9716, -0.9262, -0.9911, -0.2593,  0.5919,         -0.9999, -0.4994, -0.9962,  0.9818,  1.0000, -0.9996,  0.9918, -0.9970,          0.7085, -0.1369,  0.8077,  0.9955, -0.3394, -0.5860, -0.6887, -0.9841,          0.9970,  0.9987, -0.9948, -0.8401,  0.9999,  0.0856,  0.9999,  0.5099,          0.9466,  0.9567,  1.0000,  0.8771,  1.0000, -0.0815,  1.0000,  0.9999,         -0.9392,  0.5744,  0.8723, -0.9686,  0.5958,  0.9822,  0.9997,  0.8854,         -0.1952, -0.9967,  0.9994,  1.0000,  1.0000, -0.3391,  0.9883, -0.4452,          0.9252,  0.4495,  0.9870,  0.3479,  0.2266,  0.9942,  0.9990, -0.9999,         -0.9999, -1.0000,  1.0000,  0.9996, -0.6637, -1.0000,  0.9999,  0.4543,          0.7471,  0.9983,  0.3772, -0.9812,  0.9853, -0.9995, -0.3404,  0.9788,          0.9867,  0.7564,  0.9995, -0.9997,  0.7990,  1.0000,  0.0752,  0.9999,          0.2912, -0.9941,  0.9970, -0.9935, -0.9995, -0.9743,  0.9991,  0.9981,         -0.9273, -0.8402,  0.9996, -0.9999,  0.9999, -0.9998,  0.9724, -0.9939,          1.0000, -0.9752, -0.9998, -0.3806,  0.8830,  0.8352, -0.8892,  1.0000,         -0.8875, -0.8107,  0.7083, -0.8909, -0.9931, -0.9630,  0.0800, -1.0000,          0.7777, -0.9611,  0.5867, -0.9947, -0.9999,  1.0000, -0.9084, -0.9414,          0.9999, -0.8838, -1.0000,  0.9549, -0.9999, -0.6522,  0.7967, -0.6850,          0.1524, -1.0000,  0.4800,  0.9999, -0.9998, -0.7089, -0.9129, -0.9864,          0.6220,  0.8855,  0.9855, -0.8651,  0.3988, -0.2548,  0.9793, -0.7212,         -0.2582, -0.9999, -0.8692, -0.6282, -0.9999, -0.9999, -1.0000,  1.0000,          0.9996,  0.9999, -0.5600,  0.7442,  0.9460,  0.9927, -0.9999,  0.4407,         -0.0461,  0.9937, -0.4887, -0.9994, -0.9198, -1.0000, -0.6905,  0.3538,         -0.7728,  0.6622,  1.0000,  0.9999, -0.9999, -0.9994, -0.9995, -0.9979,          0.9998,  0.9999,  0.9996, -0.9072, -0.5844,  0.9997,  0.9689,  0.5231,         -0.9999, -0.9981, -0.9999,  0.7505, -0.9922, -0.9986,  0.9971,  1.0000,          0.8730, -1.0000, -0.9533,  1.0000,  0.9997,  1.0000, -0.7768,  0.9999,         -0.9838,  0.9819, -0.9993,  1.0000, -1.0000,  1.0000,  0.9999,  0.9809,          0.9984, -0.9928,  0.9776, -0.9998, -0.7407,  0.9298, -0.4495, -0.9902,          0.8053,  0.9996, -0.9952,  1.0000,  0.9243, -0.2028,  0.8002,  0.9873,          0.9419, -0.6913, -0.9999,  0.8162,  0.9995,  0.9509,  1.0000,  0.9177,          0.9996, -0.9839, -0.9998,  0.9914, -0.6991, -0.7821, -0.9998,  1.0000,          1.0000, -0.9999, -0.9227,  0.7483,  0.1186,  1.0000,  0.9963,  0.9971,          0.9857,  0.3887,  0.9996, -0.9999,  0.8526, -0.9980, -0.8613,  0.9999,         -0.9899,  0.9999, -0.9981,  1.0000, -0.9858,  0.9944,  0.9989,  0.9684,         -0.9968,  1.0000,  0.8246, -0.9956, -0.8348, -0.9374, -0.9999,  0.7827]],       grad_fn=&lt;TanhBackward0&gt;)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">last_hidden_state.shape <span class="comment"># 每个token的向量表示</span></span><br></pre></td></tr></table></figure><pre><code>torch.Size([1, 32, 768])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bert_model.config</span><br></pre></td></tr></table></figure><pre><code>BertConfig &#123;  &quot;_name_or_path&quot;: &quot;bert-base-chinese&quot;,  &quot;architectures&quot;: [    &quot;BertForMaskedLM&quot;  ],  &quot;attention_probs_dropout_prob&quot;: 0.1,  &quot;classifier_dropout&quot;: null,  &quot;directionality&quot;: &quot;bidi&quot;,  &quot;hidden_act&quot;: &quot;gelu&quot;,  &quot;hidden_dropout_prob&quot;: 0.1,  &quot;hidden_size&quot;: 768,  &quot;initializer_range&quot;: 0.02,  &quot;intermediate_size&quot;: 3072,  &quot;layer_norm_eps&quot;: 1e-12,  &quot;max_position_embeddings&quot;: 512,  &quot;model_type&quot;: &quot;bert&quot;,  &quot;num_attention_heads&quot;: 12,  &quot;num_hidden_layers&quot;: 12,  &quot;pad_token_id&quot;: 0,  &quot;pooler_fc_size&quot;: 768,  &quot;pooler_num_attention_heads&quot;: 12,  &quot;pooler_num_fc_layers&quot;: 3,  &quot;pooler_size_per_head&quot;: 128,  &quot;pooler_type&quot;: &quot;first_token_transform&quot;,  &quot;position_embedding_type&quot;: &quot;absolute&quot;,  &quot;transformers_version&quot;: &quot;4.24.0&quot;,  &quot;type_vocab_size&quot;: 2,  &quot;use_cache&quot;: true,  &quot;vocab_size&quot;: 21128&#125;</code></pre><h2 id="bert后面又接了一个全连接层"><a href="#bert后面又接了一个全连接层" class="headerlink" title="bert后面又接了一个全连接层"></a>bert后面又接了一个全连接层</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">EnterpriseDangerClassifier</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, n_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(EnterpriseDangerClassifier, self).__init__()</span><br><span class="line">        self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)</span><br><span class="line">        self.drop = nn.Dropout(p=<span class="number">0.3</span>)</span><br><span class="line">        self.out = nn.Linear(self.bert.config.hidden_size, n_classes) <span class="comment"># 两个类别</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, input_ids, attention_mask</span>):</span><br><span class="line">        _, pooled_output = self.bert(</span><br><span class="line">            input_ids=input_ids,</span><br><span class="line">            attention_mask=attention_mask,</span><br><span class="line">            return_dict = <span class="literal">False</span></span><br><span class="line">        )</span><br><span class="line">        output = self.drop(pooled_output) <span class="comment"># dropout</span></span><br><span class="line">        <span class="keyword">return</span> self.out(output)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">class_names=[<span class="number">0</span>,<span class="number">1</span>]</span><br></pre></td></tr></table></figure><h2 id="将数据和模型送到CUDA"><a href="#将数据和模型送到CUDA" class="headerlink" title="将数据和模型送到CUDA"></a>将数据和模型送到CUDA</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> BertModel, BertTokenizer,BertConfig, AdamW, get_linear_schedule_with_warmup</span><br><span class="line"></span><br><span class="line">model = EnterpriseDangerClassifier(<span class="built_in">len</span>(class_names))</span><br><span class="line">model = model.to(device)</span><br></pre></td></tr></table></figure><pre><code>Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: [&#39;cls.seq_relationship.bias&#39;, &#39;cls.predictions.transform.dense.bias&#39;, &#39;cls.predictions.bias&#39;, &#39;cls.predictions.transform.dense.weight&#39;, &#39;cls.predictions.decoder.weight&#39;, &#39;cls.predictions.transform.LayerNorm.bias&#39;, &#39;cls.predictions.transform.LayerNorm.weight&#39;, &#39;cls.seq_relationship.weight&#39;]- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">input_ids = data[<span class="string">&#x27;input_ids&#x27;</span>].to(device)</span><br><span class="line">attention_mask = data[<span class="string">&#x27;attention_mask&#x27;</span>].to(device)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(input_ids.shape) <span class="comment"># batch size x seq length</span></span><br><span class="line"><span class="built_in">print</span>(attention_mask.shape) <span class="comment"># batch size x seq length</span></span><br></pre></td></tr></table></figure><pre><code>torch.Size([4, 160])torch.Size([4, 160])</code></pre><h2 id="得到单个batch的输出token"><a href="#得到单个batch的输出token" class="headerlink" title="得到单个batch的输出token"></a>得到单个batch的输出token</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model(input_ids, attention_mask)</span><br></pre></td></tr></table></figure><pre><code>tensor([[ 0.2120, -0.4050],        [ 0.3156, -0.4160],        [ 0.5127, -0.4634],        [ 0.3168,  0.5057]], device=&#39;cuda:0&#39;, grad_fn=&lt;AddmmBackward0&gt;)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">F.softmax(model(input_ids, attention_mask), dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><pre><code>tensor([[0.4999, 0.5001],        [0.5258, 0.4742],        [0.5899, 0.4101],        [0.4575, 0.5425]], device=&#39;cuda:0&#39;, grad_fn=&lt;SoftmaxBackward0&gt;)</code></pre><h2 id="训练模型前期配置"><a href="#训练模型前期配置" class="headerlink" title="训练模型前期配置"></a>训练模型前期配置</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">EPOCHS = <span class="number">10</span> <span class="comment"># 训练轮数</span></span><br><span class="line"></span><br><span class="line">optimizer = AdamW(model.parameters(), lr=<span class="number">2e-5</span>, correct_bias=<span class="literal">False</span>)</span><br><span class="line">total_steps = <span class="built_in">len</span>(train_data_loader) * EPOCHS</span><br><span class="line"></span><br><span class="line"><span class="comment"># Warmup预热学习率的方式，可以使得开始训练的几个epoches或者一些steps内学习率较小,在预热的小学习率下，模型可以慢慢趋于稳定,</span></span><br><span class="line"><span class="comment"># 等模型相对稳定后再选择预先设置的学习率进行训练,使得模型收敛速度变得更快，模型效果更佳</span></span><br><span class="line">scheduler = get_linear_schedule_with_warmup(</span><br><span class="line">  optimizer,</span><br><span class="line">  num_warmup_steps=<span class="number">0</span>,</span><br><span class="line">  num_training_steps=total_steps</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># optimizer： 优化器</span></span><br><span class="line"><span class="comment"># num_warmup_steps：初始预热步数</span></span><br><span class="line"><span class="comment"># num_training_steps：整个训练过程的总步数</span></span><br><span class="line"></span><br><span class="line">loss_fn = nn.CrossEntropyLoss().to(device)</span><br></pre></td></tr></table></figure><h2 id="定义模型的训练"><a href="#定义模型的训练" class="headerlink" title="定义模型的训练"></a>定义模型的训练</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_epoch</span>(<span class="params"></span></span><br><span class="line"><span class="params">  model, </span></span><br><span class="line"><span class="params">  data_loader, </span></span><br><span class="line"><span class="params">  loss_fn, </span></span><br><span class="line"><span class="params">  optimizer, </span></span><br><span class="line"><span class="params">  device, </span></span><br><span class="line"><span class="params">  scheduler, </span></span><br><span class="line"><span class="params">  n_examples</span></span><br><span class="line"><span class="params"></span>):</span><br><span class="line">    model = model.train() <span class="comment"># train模式</span></span><br><span class="line">    losses = []</span><br><span class="line">    correct_predictions = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> d <span class="keyword">in</span> data_loader:</span><br><span class="line">        input_ids = d[<span class="string">&quot;input_ids&quot;</span>].to(device)</span><br><span class="line">        attention_mask = d[<span class="string">&quot;attention_mask&quot;</span>].to(device)</span><br><span class="line">        targets = d[<span class="string">&quot;labels&quot;</span>].to(device)</span><br><span class="line">        outputs = model(</span><br><span class="line">            input_ids=input_ids,</span><br><span class="line">            attention_mask=attention_mask</span><br><span class="line">        )</span><br><span class="line">        _, preds = torch.<span class="built_in">max</span>(outputs, dim=<span class="number">1</span>)</span><br><span class="line">        loss = loss_fn(outputs, targets)</span><br><span class="line">        correct_predictions += torch.<span class="built_in">sum</span>(preds == targets)</span><br><span class="line">        losses.append(loss.item())</span><br><span class="line">        loss.backward()</span><br><span class="line">        nn.utils.clip_grad_norm_(model.parameters(), max_norm=<span class="number">1.0</span>)</span><br><span class="line">        optimizer.step()</span><br><span class="line">        <span class="comment"># 预热学习率</span></span><br><span class="line">        scheduler.step()</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">    <span class="keyword">return</span> correct_predictions.double() / n_examples, np.mean(losses)</span><br></pre></td></tr></table></figure><h2 id="模型的评估函数"><a href="#模型的评估函数" class="headerlink" title="模型的评估函数"></a>模型的评估函数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">eval_model</span>(<span class="params">model, data_loader, loss_fn, device, n_examples</span>):</span><br><span class="line">    model = model.<span class="built_in">eval</span>() <span class="comment"># 验证预测模式</span></span><br><span class="line"></span><br><span class="line">    losses = []</span><br><span class="line">    correct_predictions = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> d <span class="keyword">in</span> data_loader:</span><br><span class="line">            input_ids = d[<span class="string">&quot;input_ids&quot;</span>].to(device)</span><br><span class="line">            attention_mask = d[<span class="string">&quot;attention_mask&quot;</span>].to(device)</span><br><span class="line">            targets = d[<span class="string">&quot;labels&quot;</span>].to(device)</span><br><span class="line"></span><br><span class="line">            outputs = model(</span><br><span class="line">                input_ids=input_ids,</span><br><span class="line">                attention_mask=attention_mask</span><br><span class="line">            )</span><br><span class="line">            _, preds = torch.<span class="built_in">max</span>(outputs, dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">            loss = loss_fn(outputs, targets)</span><br><span class="line"></span><br><span class="line">            correct_predictions += torch.<span class="built_in">sum</span>(preds == targets)</span><br><span class="line">            losses.append(loss.item())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> correct_predictions.double() / n_examples, np.mean(losses)</span><br></pre></td></tr></table></figure><h2 id="训练模型：10EPOCHS"><a href="#训练模型：10EPOCHS" class="headerlink" title="训练模型：10EPOCHS"></a>训练模型：10EPOCHS</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">history = defaultdict(<span class="built_in">list</span>) <span class="comment"># 记录10轮loss和acc</span></span><br><span class="line">best_accuracy = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(EPOCHS):</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Epoch <span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;EPOCHS&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;-&#x27;</span> * <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    train_acc, train_loss = train_epoch(</span><br><span class="line">        model,</span><br><span class="line">        train_data_loader,</span><br><span class="line">        loss_fn,</span><br><span class="line">        optimizer,</span><br><span class="line">        device,</span><br><span class="line">        scheduler,</span><br><span class="line">        <span class="built_in">len</span>(df_train)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Train loss <span class="subst">&#123;train_loss&#125;</span> accuracy <span class="subst">&#123;train_acc&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    val_acc, val_loss = eval_model(</span><br><span class="line">        model,</span><br><span class="line">        val_data_loader,</span><br><span class="line">        loss_fn,</span><br><span class="line">        device,</span><br><span class="line">        <span class="built_in">len</span>(df_val)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Val   loss <span class="subst">&#123;val_loss&#125;</span> accuracy <span class="subst">&#123;val_acc&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line"></span><br><span class="line">    history[<span class="string">&#x27;train_acc&#x27;</span>].append(train_acc)</span><br><span class="line">    history[<span class="string">&#x27;train_loss&#x27;</span>].append(train_loss)</span><br><span class="line">    history[<span class="string">&#x27;val_acc&#x27;</span>].append(val_acc)</span><br><span class="line">    history[<span class="string">&#x27;val_loss&#x27;</span>].append(val_loss)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> val_acc &gt; best_accuracy:</span><br><span class="line">        torch.save(model.state_dict(), <span class="string">&#x27;best_model_state.bin&#x27;</span>)</span><br><span class="line">        best_accuracy = val_acc</span><br></pre></td></tr></table></figure><pre><code>Epoch 1/10----------Train loss 0.4988938277521757 accuracy 0.8899999999999999Val   loss 0.4194765945523977 accuracy 0.9Epoch 2/10----------Train loss 0.4967574527254328 accuracy 0.8905555555555555Val   loss 0.43736912585794924 accuracy 0.9Epoch 3/10----------Train loss 0.49347498720511795 accuracy 0.8905555555555555Val   loss 0.41818931301434836 accuracy 0.9Epoch 4/10----------Train loss 0.4900011462407807 accuracy 0.8905555555555555Val   loss 0.42409916249414287 accuracy 0.9Epoch 5/10----------Train loss 0.4952681002088098 accuracy 0.8888888888888888Val   loss 0.31909402589624125 accuracy 0.9Epoch 6/10----------Train loss 0.2478140213253425 accuracy 0.9463888888888888Val   loss 0.1787985412031412 accuracy 0.9666666666666667Epoch 7/10----------Train loss 0.17434944392257387 accuracy 0.9677777777777777Val   loss 0.15001839348037416 accuracy 0.9700000000000001Epoch 8/10----------Train loss 0.12048366091100939 accuracy 0.9775925925925926Val   loss 0.11547344802587758 accuracy 0.9783333333333334Epoch 9/10----------Train loss 0.10136666681817992 accuracy 0.9813888888888889Val   loss 0.10292303454208498 accuracy 0.9800000000000001Epoch 10/10----------Train loss 0.08721379442805402 accuracy 0.9831481481481481Val   loss 0.12598223814862042 accuracy 0.9766666666666667</code></pre><h2 id="准确率绘图"><a href="#准确率绘图" class="headerlink" title="准确率绘图"></a>准确率绘图</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">plt.plot([i.cpu() <span class="keyword">for</span> i <span class="keyword">in</span> history[<span class="string">&#x27;train_acc&#x27;</span>]], label=<span class="string">&#x27;train accuracy&#x27;</span>)</span><br><span class="line">plt.plot([i.cpu() <span class="keyword">for</span> i <span class="keyword">in</span> history[<span class="string">&#x27;val_acc&#x27;</span>]], label=<span class="string">&#x27;validation accuracy&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&#x27;Training history&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Accuracy&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Epoch&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.ylim([<span class="number">0</span>, <span class="number">1</span>]);</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="C:\Users\dupeibo\AppData\Roaming\Typora\typora-user-images\1669079408883.png" alt="1669079408883"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">test_acc, _ = eval_model(</span><br><span class="line">  model,</span><br><span class="line">  test_data_loader,</span><br><span class="line">  loss_fn,</span><br><span class="line">  device,</span><br><span class="line">  <span class="built_in">len</span>(df_test)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">test_acc.item()</span><br></pre></td></tr></table></figure><pre><code>0.9783333333333334</code></pre><h2 id="预测模型"><a href="#预测模型" class="headerlink" title="预测模型"></a>预测模型</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_predictions</span>(<span class="params">model, data_loader</span>):</span><br><span class="line">    model = model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    raw_texts = []</span><br><span class="line">    predictions = []</span><br><span class="line">    prediction_probs = []</span><br><span class="line">    real_values = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> d <span class="keyword">in</span> data_loader:</span><br><span class="line">            texts = d[<span class="string">&quot;texts&quot;</span>]</span><br><span class="line">            input_ids = d[<span class="string">&quot;input_ids&quot;</span>].to(device)</span><br><span class="line">            attention_mask = d[<span class="string">&quot;attention_mask&quot;</span>].to(device)</span><br><span class="line">            targets = d[<span class="string">&quot;labels&quot;</span>].to(device)</span><br><span class="line"></span><br><span class="line">            outputs = model(</span><br><span class="line">                input_ids=input_ids,</span><br><span class="line">                attention_mask=attention_mask</span><br><span class="line">            )</span><br><span class="line">            _, preds = torch.<span class="built_in">max</span>(outputs, dim=<span class="number">1</span>) <span class="comment"># 类别</span></span><br><span class="line"></span><br><span class="line">            probs = F.softmax(outputs, dim=<span class="number">1</span>) <span class="comment"># 概率</span></span><br><span class="line"></span><br><span class="line">            raw_texts.extend(texts)</span><br><span class="line">            predictions.extend(preds)</span><br><span class="line">            prediction_probs.extend(probs)</span><br><span class="line">            real_values.extend(targets)</span><br><span class="line"></span><br><span class="line">    predictions = torch.stack(predictions).cpu()</span><br><span class="line">    prediction_probs = torch.stack(prediction_probs).cpu()</span><br><span class="line">    real_values = torch.stack(real_values).cpu()</span><br><span class="line">    <span class="keyword">return</span> raw_texts, predictions, prediction_probs, real_values</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">y_texts, y_pred, y_pred_probs, y_test = get_predictions(</span><br><span class="line">  model,</span><br><span class="line">  test_data_loader</span><br><span class="line">)</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred, target_names=[<span class="built_in">str</span>(label) <span class="keyword">for</span> label <span class="keyword">in</span> class_names])) <span class="comment"># 分类报告</span></span><br></pre></td></tr></table></figure><pre><code>              precision    recall  f1-score   support           0       0.99      0.99      0.99       554           1       0.84      0.89      0.86        46    accuracy                           0.98       600   macro avg       0.91      0.94      0.93       600weighted avg       0.98      0.98      0.98       600</code></pre><h2 id="查看混淆矩阵"><a href="#查看混淆矩阵" class="headerlink" title="查看混淆矩阵"></a>查看混淆矩阵</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">show_confusion_matrix</span>(<span class="params">confusion_matrix</span>):</span><br><span class="line">    hmap = sns.heatmap(confusion_matrix, annot=<span class="literal">True</span>, fmt=<span class="string">&quot;d&quot;</span>, cmap=<span class="string">&quot;Blues&quot;</span>)</span><br><span class="line">    hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=<span class="number">0</span>, ha=<span class="string">&#x27;right&#x27;</span>)</span><br><span class="line">    hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=<span class="number">30</span>, ha=<span class="string">&#x27;right&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;True label&#x27;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;Predicted label&#x27;</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cm = confusion_matrix(y_test, y_pred)</span><br><span class="line">df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)</span><br><span class="line">show_confusion_matrix(df_cm)</span><br></pre></td></tr></table></figure><p><img src="C:\Users\dupeibo\AppData\Roaming\Typora\typora-user-images\1669079467197.png" alt="1669079467197">    </p><h2 id="评估单条数据"><a href="#评估单条数据" class="headerlink" title="评估单条数据"></a>评估单条数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">idx = <span class="number">2</span></span><br><span class="line"></span><br><span class="line">sample_text = y_texts[idx]</span><br><span class="line">true_label = y_test[idx]</span><br><span class="line">pred_df = pd.DataFrame(&#123;</span><br><span class="line">  <span class="string">&#x27;class_names&#x27;</span>: class_names,</span><br><span class="line">  <span class="string">&#x27;values&#x27;</span>: y_pred_probs[idx]</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pred_d</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>class_names</th>      <th>values</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>0</td>      <td>0.999889</td>    </tr>    <tr>      <th>1</th>      <td>1</td>      <td>0.000111</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span>.join(wrap(sample_text)))</span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;True label: <span class="subst">&#123;class_names[true_label]&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure><pre><code>小A班应急照明灯坏[SEP]商贸服务教文卫类[SEP]消防检查[SEP]防火巡查[SEP]安全出口、疏散通道是否畅通，安全疏散指示标志、应急照明是否完好。True label: 0</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sns.barplot(x=<span class="string">&#x27;values&#x27;</span>, y=<span class="string">&#x27;class_names&#x27;</span>, data=pred_df, orient=<span class="string">&#x27;h&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;sentiment&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;probability&#x27;</span>)</span><br><span class="line">plt.xlim([<span class="number">0</span>, <span class="number">1</span>]);</span><br></pre></td></tr></table></figure><p><img src="C:\Users\dupeibo\AppData\Roaming\Typora\typora-user-images\1669079499324.png" alt="1669079499324"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sample_text = <span class="string">&#x27; &#x27;</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">encoded_text = tokenizer.encode_plus(</span><br><span class="line">  sample_text,</span><br><span class="line">  max_length=MAX_LEN,</span><br><span class="line">  add_special_tokens=<span class="literal">True</span>,</span><br><span class="line">  return_token_type_ids=<span class="literal">False</span>,</span><br><span class="line">  pad_to_max_length=<span class="literal">True</span>,</span><br><span class="line">  return_attention_mask=<span class="literal">True</span>,</span><br><span class="line">  return_tensors=<span class="string">&#x27;pt&#x27;</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">input_ids = encoded_text[<span class="string">&#x27;input_ids&#x27;</span>].to(device)</span><br><span class="line">attention_mask = encoded_text[<span class="string">&#x27;attention_mask&#x27;</span>].to(device)</span><br><span class="line"></span><br><span class="line">output = model(input_ids, attention_mask)</span><br><span class="line">_, prediction = torch.<span class="built_in">max</span>(output, dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Sample text: <span class="subst">&#123;sample_text&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Danger label  : <span class="subst">&#123;class_names[prediction]&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure><pre><code>Sample text:  Danger label  : 1</code></pre>]]></content>
      
      
      <categories>
          
          <category> 自然语言处理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> NLP </tag>
            
            <tag> HuggingFace </tag>
            
            <tag> BERT </tag>
            
            <tag> 文本分类 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Transformer总结和梳理</title>
      <link href="/posts/55106.html"/>
      <url>/posts/55106.html</url>
      
        <content type="html"><![CDATA[<p>Transformer最终总结版，超级详细！</p><span id="more"></span><p>首先来看一下Transformer结构的结构：<br><img src="https://img-blog.csdnimg.cn/de74182b27f24a84a28fdd5f7204f0cd.png" alt="在这里插入图片描述"><br>Transformer是由Encoder和Decoder两大部分组成，首先我们先来回顾一下Transformer的结构：Transformer结构主要分为两大部分，一是Encoder层结构，另一个则是Decoder层结构。<br>        Encoder 的输入由 Input Embedding 和 Positional Embedding 求和输入Multi-Head-Attention，然后又做了一个ADD&amp;Norm，再通过Feed Forward进行输出，最后又做了一个ADD&amp;Norm，这就是Decoder。<br>        Decoder和Encoder有很多相同的地方，Decoder首先也是需要进行 Input Embedding 和 Positional Embedding 求作为输入，并且Decoder中的第一个Attention模块为Mask Attention，还有一个就是Decoder的K和V分别均来自Encoder。<br>        接下来看一下每个模块的具体理解：</p><h1 id="Positional-encoding"><a href="#Positional-encoding" class="headerlink" title="Positional encoding"></a>Positional encoding</h1><p>首先对于文本特征，需要进行Embedding，由于transformer抛弃了Rnn的结构，不能捕捉到序列的信息，交换单词位置，得到相应的attention也会发生交换，并不会发生数值上的改变，所以要对input进行Positional Encoding。</p><p>Positional encoding和input embedding是同等维度的，所以可以将两者进行相加，的到输入向量<br><img src="https://img-blog.csdnimg.cn/be30b27838dd411c89d793432ff72582.png" alt="在这里插入图片描述"><br>接下来看一些Positional Encoding的计算公式：<br><img src="https://img-blog.csdnimg.cn/6e9a80e756b94a70aeef8a79097eb7a6.png" alt="在这里插入图片描述"><br>其中pos表示token在sequence中的位置，d_model表示词嵌入的维度，i则是range(d_model)中的数值，也就是说：对于单个token的d_model维度的词向量，奇数位置取cos，偶数位置取sin，最终的到一个维度和word embedding维度一样的矩阵，接下来可以看一下代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_positional_encoding</span>(<span class="params">max_seq_len, embed_dim</span>):</span><br><span class="line">    <span class="comment"># 初始化一个positional encoding</span></span><br><span class="line">    <span class="comment"># embed_dim: 字嵌入的维度</span></span><br><span class="line">    <span class="comment"># max_seq_len: 最大的序列长度</span></span><br><span class="line">    positional_encoding = np.array([</span><br><span class="line">        [pos / np.power(<span class="number">10000</span>, <span class="number">2</span> * i / embed_dim) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(embed_dim)] <span class="keyword">if</span> pos != <span class="number">0</span> <span class="keyword">else</span> np.zeros(embed_dim) <span class="keyword">for</span> pos <span class="keyword">in</span> <span class="built_in">range</span>(max_seq_len)])</span><br><span class="line"></span><br><span class="line">    positional_encoding[<span class="number">1</span>:, <span class="number">0</span>::<span class="number">2</span>] = np.sin(positional_encoding[<span class="number">1</span>:, <span class="number">0</span>::<span class="number">2</span>])  <span class="comment"># dim 2i 偶数</span></span><br><span class="line">    positional_encoding[<span class="number">1</span>:, <span class="number">1</span>::<span class="number">2</span>] = np.cos(positional_encoding[<span class="number">1</span>:, <span class="number">1</span>::<span class="number">2</span>])  <span class="comment"># dim 2i+1 奇数</span></span><br><span class="line">    <span class="keyword">return</span> positional_encoding</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">positional_encoding = get_positional_encoding(max_seq_len=<span class="number">100</span>, embed_dim=<span class="number">16</span>)</span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line">sns.heatmap(positional_encoding)</span><br><span class="line">plt.title(<span class="string">&quot;Sinusoidal Function&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;hidden dimension&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;sequence length&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>首先求初始向量：positional_encoding，然后对其奇数列求sin，偶数列求cos：<br><img src="https://img-blog.csdnimg.cn/2da3445d7953426394ab2e46d8820baf.png" alt="在这里插入图片描述"><br>最终得到positional encoding之后的数据可视化：<br><img src="https://img-blog.csdnimg.cn/507cc7ca0ba34f8fb2ec87216689857c.png" alt="在这里插入图片描述"></p><h1 id="Self-attention"><a href="#Self-attention" class="headerlink" title="Self-attention"></a>Self-attention</h1><p>何为self-attention？首先我们要明白什么是attention，对于传统的seq2seq任务，例如中-英文翻译，输入中文，得到英文，即source是中文句子（x1 x2 x3）,英文句子是target（y1 y2 y3）<br><img src="https://img-blog.csdnimg.cn/296c379fd77c475ebf77c06fa8e42e59.png" alt="在这里插入图片描述"><br>attention机制发生在target的元素和source中的所有元素之间。简单的将就是attention机制中的权重计算需要target参与，即在上述Encoder-Decoder模型中，Encoder和Decoder两部分都需要参与运算。</p><p>而对于self-attention，它不需要Decoder的参与，而是source内部元素之间发生的运算，对于输入向量X，对其做线性变换，分别得到Q、K、V矩阵<br><img src="https://img-blog.csdnimg.cn/17358bbb1cf641d78117625fb5a00d31.png" alt="在这里插入图片描述"><br>然后去计算attention，Q、K点乘得到初步的权重因子，并对Q、K点乘结果进行放缩，除以sqrt（dk），Q、K点乘之后的方差会随着维度的增大而增大，而大的方差会导致极小的梯度，为了防止梯度消失，所以除以sqrt(dk)来减小方差，最终再加一个softmax就得到了self attention的输出。<br><img src="https://img-blog.csdnimg.cn/07fdbd802d114b7193c70e9fc451ba22.png" alt="在这里插入图片描述"></p><h2 id="Multi–head-attention"><a href="#Multi–head-attention" class="headerlink" title="Multi–head-attention"></a>Multi–head-attention</h2><p>Multi–head-attention使用了多个头进行运算，捕捉到了更多的信息，多头的数量用h表示，一般h&#x3D;8，表示8个头<br><img src="https://img-blog.csdnimg.cn/7cad1e37120b4d40ad64140677452ec1.png" alt="在这里插入图片描述"><br>在输入每个self-attention之前，我们需将输入X均分的分到h个头中，得到Z1-Z7八个头的输出结果。<br><img src="https://img-blog.csdnimg.cn/d5763f726a5c48f292a140f84c0e5200.png" alt="在这里插入图片描述"><br>对于每个头计算相应的attention score，将其进行拼接，再与W0进行一个线性变换，就得到最终输出的Z。<br><img src="https://img-blog.csdnimg.cn/05bfb9eb87bb4f3b8066c8190c0dff0f.png" alt="在这里插入图片描述"></p><h1 id="Add-amp-Norm"><a href="#Add-amp-Norm" class="headerlink" title="Add&amp;Norm"></a>Add&amp;Norm</h1><h2 id="Add操作"><a href="#Add操作" class="headerlink" title="Add操作"></a>Add操作</h2><p>首先我们还是先来回顾一下Transformer的结构：Transformer结构主要分为两大部分，一是Encoder层结构，另一个则是Decoder层结构，Encoder 的输入由 Input Embedding 和 Positional Embedding 求和输入Multi-Head-Attention，再通过Feed Forward进行输出。</p><p>由下图可以看出：在Encoder层和Decoder层中都用到了Add&amp;Norm操作，即残差连接和层归一化操作。<br><img src="https://img-blog.csdnimg.cn/5ef722ad3c5b407482ac132b0883c59c.png" alt="在这里插入图片描述"><br>什么是残差连接呢？残差连接就是把网络的输入和输出相加，即网络的输出为F(x)+x，在网络结构比较深的时候，网络梯度反向传播更新参数时，容易造成梯度消失的问题，但是如果每层的输出都加上一个x的时候，就变成了F(x)+x，对x求导结果为1，所以就相当于每一层求导时都加上了一个常数项‘1’，有效解决了梯度消失问题。</p><h2 id="Norm操作"><a href="#Norm操作" class="headerlink" title="Norm操作"></a>Norm操作</h2><p>首先要明白Norm做了一件什么事，从刚开始接触Transformer开始，我认为所谓的Norm就是BatchNorm，但是有一天我看到了这篇<a href="https://mp.weixin.qq.com/s/HNCl6MPS_hjTVHNt7UkYyw">文章</a>，才明白了Norm是什么。</p><p>假设我们输入的词向量的形状是（2，3，4），2为批次（batch），3为句子长度，4为词向量的维度，生成以下数据：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[[w11, w12, w13, w14], [w21, w22, w23, w24], [w31, w32, w33, w34]</span><br><span class="line">[w41, w42, w43, w44], [w51, w52, w53, w54], [w61, w62, w63, w64]]</span><br></pre></td></tr></table></figure><p>如果是在做BatchNorm（BN）的话，其计算过程如下：BN1&#x3D;(w11+w12+w13+w14+w41+<br>w42+w43+w44)&#x2F;8，同理会得到BN2和BN3，最终得到[BN1,BN2,BN3] 3个mean</p><p>如果是在做LayerNorm（LN）的话，则会进如下计算：LN1&#x3D;(w11+w12+w13+w14+w21+<br>w22+w23+w24+w31+w32+w33+w34)&#x2F;12，同理会得到LN2，最终得到[LN1,LN2]两个mean</p><p>如果是在做InstanceNorm（IN）的话，则会进如下计算：IN1&#x3D;(w11+w12+w13+w14)&#x2F;4，同理会得到IN2，IN3，IN4，IN5，IN6，六个mean，[[IN1，IN2，IN3],[IN4，IN5，IN6]]<br>下图完美的揭示了，这几种Norm<br><img src="https://img-blog.csdnimg.cn/a143d6b41e654fa1849f44580401110c.png" alt="在这里插入图片描述"><br>接下来我们来看一下Transformer中的Norm：首先生成[2,3,4]形状的数据，使用原始的编码方式进行编码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> InstanceNorm2d</span><br><span class="line">random_seed = <span class="number">123</span></span><br><span class="line">torch.manual_seed(random_seed)</span><br><span class="line"></span><br><span class="line">batch_size, seq_size, dim = <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span></span><br><span class="line">embedding = torch.randn(batch_size, seq_size, dim)</span><br><span class="line"></span><br><span class="line">layer_norm = torch.nn.LayerNorm(dim, elementwise_affine = <span class="literal">False</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;y: &quot;</span>, layer_norm(embedding))</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">y:  tensor([[[ <span class="number">1.5524</span>,  <span class="number">0.0155</span>, -<span class="number">0.3596</span>, -<span class="number">1.2083</span>],</span><br><span class="line">         [ <span class="number">0.5851</span>,  <span class="number">1.3263</span>, -<span class="number">0.7660</span>, -<span class="number">1.1453</span>],</span><br><span class="line">         [ <span class="number">0.2864</span>,  <span class="number">0.0185</span>,  <span class="number">1.2388</span>, -<span class="number">1.5437</span>]],</span><br><span class="line">        [[ <span class="number">1.1119</span>, -<span class="number">0.3988</span>,  <span class="number">0.7275</span>, -<span class="number">1.4406</span>],</span><br><span class="line">         [-<span class="number">0.4144</span>, -<span class="number">1.1914</span>,  <span class="number">0.0548</span>,  <span class="number">1.5510</span>],</span><br><span class="line">         [ <span class="number">0.3914</span>, -<span class="number">0.5591</span>,  <span class="number">1.4105</span>, -<span class="number">1.2428</span>]]])</span><br></pre></td></tr></table></figure><p>接下来手动去进行一下编码:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">eps: <span class="built_in">float</span> = <span class="number">0.00001</span></span><br><span class="line">mean = torch.mean(embedding[:, :, :], dim=(-<span class="number">1</span>), keepdim=<span class="literal">True</span>)</span><br><span class="line">var = torch.square(embedding[:, :, :] - mean).mean(dim=(-<span class="number">1</span>), keepdim=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;mean: &quot;</span>, mean.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;y_custom: &quot;</span>, (embedding[:, :, :] - mean) / torch.sqrt(var + eps))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mean:  torch.Size([<span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>])</span><br><span class="line">y_custom:  tensor([[[ <span class="number">1.1505</span>,  <span class="number">0.5212</span>, -<span class="number">0.1262</span>, -<span class="number">1.5455</span>],</span><br><span class="line">         [-<span class="number">0.6586</span>, -<span class="number">0.2132</span>, -<span class="number">0.8173</span>,  <span class="number">1.6890</span>],</span><br><span class="line">         [ <span class="number">0.6000</span>,  <span class="number">1.2080</span>, -<span class="number">0.3813</span>, -<span class="number">1.4267</span>]],</span><br><span class="line">        [[-<span class="number">0.0861</span>,  <span class="number">1.0145</span>, -<span class="number">1.5895</span>,  <span class="number">0.6610</span>],</span><br><span class="line">         [ <span class="number">0.8724</span>,  <span class="number">0.9047</span>, -<span class="number">1.5371</span>, -<span class="number">0.2400</span>],</span><br><span class="line">         [ <span class="number">0.1507</span>,  <span class="number">0.5268</span>,  <span class="number">0.9785</span>, -<span class="number">1.6560</span>]]])</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>可以发现和LayerNorm的结果是一样的，也就是说明Norm是对d_model进行的Norm，会给我们[batch,sqe_length]形状的平均值。<br>加下来进行batch_norm,</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">layer_norm = torch.nn.LayerNorm([seq_size,dim], elementwise_affine = <span class="literal">False</span>)</span><br><span class="line">eps: <span class="built_in">float</span> = <span class="number">0.00001</span></span><br><span class="line">mean = torch.mean(embedding[:, :, :], dim=(-<span class="number">2</span>,-<span class="number">1</span>), keepdim=<span class="literal">True</span>)</span><br><span class="line">var = torch.square(embedding[:, :, :] - mean).mean(dim=(-<span class="number">2</span>,-<span class="number">1</span>), keepdim=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;mean: &quot;</span>, mean.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;y_custom: &quot;</span>, (embedding[:, :, :] - mean) / torch.sqrt(var + eps))</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mean:  torch.Size([<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">y_custom:  tensor([[[ <span class="number">1.1822</span>,  <span class="number">0.4419</span>, -<span class="number">0.3196</span>, -<span class="number">1.9889</span>],</span><br><span class="line">         [-<span class="number">0.6677</span>, -<span class="number">0.2537</span>, -<span class="number">0.8151</span>,  <span class="number">1.5143</span>],</span><br><span class="line">         [ <span class="number">0.7174</span>,  <span class="number">1.2147</span>, -<span class="number">0.0852</span>, -<span class="number">0.9403</span>]],</span><br><span class="line">        [[-<span class="number">0.0138</span>,  <span class="number">1.5666</span>, -<span class="number">2.1726</span>,  <span class="number">1.0590</span>],</span><br><span class="line">         [ <span class="number">0.6646</span>,  <span class="number">0.6852</span>, -<span class="number">0.8706</span>, -<span class="number">0.0442</span>],</span><br><span class="line">         [-<span class="number">0.1163</span>,  <span class="number">0.1389</span>,  <span class="number">0.4454</span>, -<span class="number">1.3423</span>]]])</span><br></pre></td></tr></table></figure><p>可以看到BN的计算的mean形状为[2, 1, 1]，并且Norm结果也和上面的两个不一样，这就充分说明了Norm是在对最后一个维度求平均。<br>那么什么又是Instancenorm呢？接下来再来实现一下instancenorm</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">instance_norm = InstanceNorm2d(<span class="number">3</span>, affine=<span class="literal">False</span>)</span><br><span class="line">output = instance_norm(embedding.reshape(<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">1</span>)) <span class="comment">#InstanceNorm2D需要(N,C,H,W)的shape作为输入</span></span><br><span class="line">layer_norm = torch.nn.LayerNorm(<span class="number">4</span>, elementwise_affine = <span class="literal">False</span>)</span><br><span class="line"><span class="built_in">print</span>(layer_norm(embedding))</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tensor([[[ <span class="number">1.1505</span>,  <span class="number">0.5212</span>, -<span class="number">0.1262</span>, -<span class="number">1.5455</span>],</span><br><span class="line">         [-<span class="number">0.6586</span>, -<span class="number">0.2132</span>, -<span class="number">0.8173</span>,  <span class="number">1.6890</span>],</span><br><span class="line">         [ <span class="number">0.6000</span>,  <span class="number">1.2080</span>, -<span class="number">0.3813</span>, -<span class="number">1.4267</span>]],</span><br><span class="line">        [[-<span class="number">0.0861</span>,  <span class="number">1.0145</span>, -<span class="number">1.5895</span>,  <span class="number">0.6610</span>],</span><br><span class="line">         [ <span class="number">0.8724</span>,  <span class="number">0.9047</span>, -<span class="number">1.5371</span>, -<span class="number">0.2400</span>],</span><br><span class="line">         [ <span class="number">0.1507</span>,  <span class="number">0.5268</span>,  <span class="number">0.9785</span>, -<span class="number">1.6560</span>]]])</span><br></pre></td></tr></table></figure><p>可以看出无论是layernorm还是instancenorm，还是我们手动去求平均计算其Norm，结果都是一样的，由此我们可以得出一个结论：Layernorm实际上是在做Instancenorm！</p><h1 id="FeedForward"><a href="#FeedForward" class="headerlink" title="FeedForward"></a>FeedForward</h1><p>接下来是FeedForward，FeedForward是Multi-Head Attention的输出做了残差连接和Norm之后得数据，然后FeedForward做了两次线性线性变换，为的是更加深入的提取特征。<br><img src="https://img-blog.csdnimg.cn/b976d7add795475fac7bbc6c5f01121f.png" alt="在这里插入图片描述"><br>可以看出在每次线性变换都引入了非线性激活函数Relu，在Multi-Head Attention中，主要是进行矩阵乘法，即都是线性变换，而线性变换的学习能力不如非线性变换的学习能力强，FeedForward的计算公式如下：max相当于Relu<br><img src="https://img-blog.csdnimg.cn/43b6886add22435795f3f8a7a889c58e.png" alt="在这里插入图片描述"></p><p>所以FeedForward的作用是：通过线性变换，先将数据映射到高纬度的空间再映射到低纬度的空间，提取了更深层次的特征</p><h1 id="MASK"><a href="#MASK" class="headerlink" title="MASK"></a>MASK</h1><p>最后是MASK介绍，Transformer中的MASK主要分为两部分：Padding Mask和Sequence Mask两部分</p><h2 id="Padding-Masked"><a href="#Padding-Masked" class="headerlink" title="Padding Masked"></a>Padding Masked</h2><p>对于Transformer而言，每次的输入为：[batch_size,seq_length,d_module]结构，由于句子一般是长短不一的，而输入的数据需要是固定的格式，所以要对句子进行处理。<br>通常会把每个句子按照最大长度进行补齐，所以当句子不够长时，需要进行补0操作，以保证输入数据结构的完整性<br>但是在计算注意力机制时的Softmax函数时，就会出现问题，Padding数值为0的话，仍然会影响到Softmax的计算结果，即无效数据参加了运算。<br>为了不让Padding数据产生影响，通常会将Padding数据变为负无穷，这样的话就不会影响Softmax函数了</p><h2 id="Self-Attention-Masked"><a href="#Self-Attention-Masked" class="headerlink" title="Self-Attention Masked"></a>Self-Attention Masked</h2><p>Self-Attention Masked只发生在Decoder操作中，在Decoder中，我们的预测是一个一个进行的，即输入一个token，输出下一个token，在网上看到一个很好的解释如下：<br>假设我们当前在进行机器翻译<br>    输入：我很好<br>    输出：I am fine<br>接下来是Decoder执行步骤<br>第一步：<br>    ·初始输入： 起始符</s> + Positional Encoding（位置编码）<br>    ·中间输入：（我很好）Encoder Embedding<br>    ·最终输出：产生预测“I”<br>第二步：<br>    ·初始输入：起始符</s> + “I”+ Positonal Encoding<br>    ·中间输入：（我很好）Encoder Embedding<br>    ·最终输出：产生预测“am”<br>第三步：<br>    ·初始输入：起始符</s> + “I”+ “am”+ Positonal Encoding<br>    ·中间输入：（我很好）Encoder Embedding<br>    ·最终输出：产生预测“fine”<br>上面就是Decoder的执行过程，在预测出“I”之前，我们是不可能知道‘am’的，所以要将数进行Mask，防止看到当前值后面的值，如下图所示：当我们仅知道start的时候，后面的关系是不知道的，所以start和“I”以及其它单词的Score都为负无穷，当预测出“I”之后，再去预测“am”，最终得到下面第三个得分矩阵。<br><img src="https://img-blog.csdnimg.cn/8df2f100c0a447909a8f9d99cbf86a1d.png"></p><p>最后经过Softmax处理之后，得到最终的得分矩阵<br><img src="https://img-blog.csdnimg.cn/90d840807bf04b89bf8e32dd6bf19e85.png"></p><p>最后不要忘了Decoder中依然采用的是Masked Multi-Head Attention，即多次进行Mask机制</p><p>写在最后：笔者也是刚入门深度学习，对知识也是初步的认识，如果文章有错，请大佬们斧正！</p>]]></content>
      
      
      <categories>
          
          <category> 自然语言处理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> NLP </tag>
            
            <tag> HuggingFace </tag>
            
            <tag> Transformer </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>什么是Warmup</title>
      <link href="/posts/1669.html"/>
      <url>/posts/1669.html</url>
      
        <content type="html"><![CDATA[<p>Warmup可以逐渐地将学习率从一个小的值提升到一个大的值</p><span id="more"></span><h1 id="Warmup"><a href="#Warmup" class="headerlink" title="Warmup"></a>Warmup</h1><h3 id="什么是预热学习率-Warmup-？"><a href="#什么是预热学习率-Warmup-？" class="headerlink" title="什么是预热学习率(Warmup)？"></a>什么是预热学习率(Warmup)？</h3><p>先来看一下预热的定义：预热指的是为防止急热，焊接前先对材料预热。</p><p>而预热学习率指的是对学习率进行控制，使学习率缓慢的变化，而不是直接变为设定值。</p><p>下面我们通过一个具体的例子来展示Warmup：</p><p>设置初始化lr &#x3D; 0.1,假设所有步数num_step &#x3D; 20000,warmup_step &#x3D; 5000，即当步数达到5000时，达到所设置的学习率</p><p>实现代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">warmup_steps = <span class="number">5000</span></span><br><span class="line">init_lr = <span class="number">0.1</span></span><br><span class="line"><span class="comment"># 模拟训练20000步</span></span><br><span class="line">max_steps = <span class="number">20000</span></span><br><span class="line">a = []</span><br><span class="line"><span class="keyword">for</span> train_steps <span class="keyword">in</span> <span class="built_in">range</span>(max_steps):</span><br><span class="line">    <span class="keyword">if</span> warmup_steps <span class="keyword">and</span> train_steps &lt; warmup_steps:</span><br><span class="line">        warmup_percent_done = train_steps / warmup_steps</span><br><span class="line">        warmup_learning_rate = init_lr * warmup_percent_done  <span class="comment">#gradual warmup_lr</span></span><br><span class="line">        learning_rate = warmup_learning_rate</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment">#learning_rate = np.sin(learning_rate)  #预热学习率结束后,学习率呈sin衰减</span></span><br><span class="line">        learning_rate = learning_rate**<span class="number">1.0001</span> <span class="comment">#预热学习率结束后,学习率呈指数衰减(近似模拟指数衰减)</span></span><br><span class="line">    <span class="keyword">if</span> (train_steps+<span class="number">1</span>) % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">             <span class="built_in">print</span>(<span class="string">&quot;train_steps:%.3f--warmup_steps:%.3f--learning_rate:%.3f&quot;</span> % (</span><br><span class="line">                 train_steps+<span class="number">1</span>,warmup_steps,learning_rate))</span><br><span class="line">    a.append(learning_rate)</span><br><span class="line">plt.plot(a)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>可得学习率变化如下：</p><p><img src="https://img-blog.csdnimg.cn/ddd9decebde845009dbf4aad2a84ac4a.png"></p><h3 id="为什么要进行预热学习率"><a href="#为什么要进行预热学习率" class="headerlink" title="为什么要进行预热学习率"></a>为什么要进行预热学习率</h3><p>由于刚开始训练时,模型的权重(weights)是随机初始化的，此时若选择一个较大的学习率,可能带来模型的不稳定(振荡)，选择Warmup预热学习率的方式，可以使得开始训练的几个epoches或者一些steps内学习率较小,在预热的小学习率下，模型可以慢慢趋于稳定,等模型相对稳定后再选择预先设置的学习率进行训练,使得模型收敛速度变得更快，模型效果更佳。</p>]]></content>
      
      
      <categories>
          
          <category> 自然语言处理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>对Transformer中的MASK理解</title>
      <link href="/posts/35596.html"/>
      <url>/posts/35596.html</url>
      
        <content type="html"><![CDATA[<p>Transformer中的MASK主要分为两部分：Padding Mask和Sequence Mask两部分</p><span id="more"></span><p>上一篇文章我们介绍了<a href="https://blog.csdn.net/weixin_51756104/article/details/127250190?spm=1001.2014.3001.5501">对Transformer中FeedForward层的理解</a>，今天我们来介绍一下对MASK的理解<br>老规矩，还是先放一张Transformer的图片<br><img src="https://img-blog.csdnimg.cn/de74182b27f24a84a28fdd5f7204f0cd.png" alt="在这里插入图片描述"><br>Transformer结构主要分为两大部分，一是Encoder层结构，另一个则是Decoder层结构，而所谓的MASK在Encoder和Decoder两个结构中都有使用。</p><p>Transformer中的MASK主要分为两部分：Padding Mask和Sequence Mask两部分</p><h1 id="Padding-Masked"><a href="#Padding-Masked" class="headerlink" title="Padding Masked"></a>Padding Masked</h1><p>对于Transformer而言，每次的输入为：[batch_size,seq_length,d_module]结构，由于句子一般是长短不一的，而输入的数据需要是固定的格式，所以要对句子进行处理。<br>通常会把每个句子按照最大长度进行补齐，所以当句子不够长时，需要进行补0操作，以保证输入数据结构的完整性<br>但是在计算注意力机制时的Softmax函数时，就会出现问题，Padding数值为0的话，仍然会影响到Softmax的计算结果，即无效数据参加了运算。<br>为了不让Padding数据产生影响，通常会将Padding数据变为负无穷，这样的话就不会影响Softmax函数了</p><h1 id="Sequence-Masked"><a href="#Sequence-Masked" class="headerlink" title="Sequence Masked"></a>Sequence Masked</h1><p>Sequence Masked只发生在Decoder操作中，在Decoder中，我们的预测是一个一个进行的，即输入一个token，输出下一个token，在网上看到一个很好的解释如下：<br>假设我们当前在进行机器翻译<br>    输入：我很好<br>    输出：I am fine<br>接下来是Decoder执行步骤<br>第一步：<br>    ·初始输入： 起始符</s> + Positional Encoding（位置编码）<br>    ·中间输入：（我很好）Encoder Embedding<br>    ·最终输出：产生预测“I”<br>第二步：<br>    ·初始输入：起始符</s> + “I”+ Positonal Encoding<br>    ·中间输入：（我很好）Encoder Embedding<br>    ·最终输出：产生预测“am”<br>第三步：<br>    ·初始输入：起始符</s> + “I”+ “am”+ Positonal Encoding<br>    ·中间输入：（我很好）Encoder Embedding<br>    ·最终输出：产生预测“fine”<br>上面就是Decoder的执行过程，在预测出“I”之前，我们是不可能知道‘am’的，所以要将数进行Mask，防止看到当前值后面的值，如下图所示：当我们仅知道start的时候，后面的关系是不知道的，所以start和“I”以及其它单词的Score都为负无穷，当预测出“I”之后，再去预测“am”，最终得到下面第三个得分矩阵。<br><img src="https://img-blog.csdnimg.cn/8df2f100c0a447909a8f9d99cbf86a1d.png"></p><p>最后经过Softmax处理之后，得到最终的得分矩阵<br><img src="https://img-blog.csdnimg.cn/90d840807bf04b89bf8e32dd6bf19e85.png"></p><p>最后不要忘了Decoder中依然采用的是Masked Multi-Head Attention，即多次进行Mask机制</p>]]></content>
      
      
      <categories>
          
          <category> 自然语言处理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> NLP </tag>
            
            <tag> HuggingFace </tag>
            
            <tag> Transformer </tag>
            
            <tag> Mask </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>第五届“泰迪杯”数据分析技能赛</title>
      <link href="/posts/14939.html"/>
      <url>/posts/14939.html</url>
      
        <content type="html"><![CDATA[<p>第五届“泰迪杯”数据分析技能赛复盘</p><span id="more"></span><p>今天刚结束了第五届“泰迪杯”数据分析技能赛，我们选择的B题做，昨天的A题太伤心了，做不出来A题（时间太短，再加上太麻烦，晚上直接跑路去操场看70周年校庆了）</p><p>先上代码：<a href="https://github.com/du2279664786/2022-taidi-competition">https://github.com/du2279664786/2022-taidi-competition</a>，直接在前面仓库可以看到代码和相关数据</p><h1 id="竞赛日程；"><a href="#竞赛日程；" class="headerlink" title="竞赛日程；"></a>竞赛日程；</h1><p>报名起始时间：2022年9月5日-11月10日<br>赛前指导时间：2022年9月13日-11月10日<br>A题竞赛时间：2022年11月12日 8:00-21:00（8:00:00公布赛题）<br>B题竞赛时间：2022年11月13日 8:00-20:00（8:00:00公布赛题）<br>视频答辩时间：2022年12月上旬，具体时间另行通知<br>成绩公示时间：2022年12月中下旬<br>最终成绩公布时间：2022年12月中下旬</p><h1 id="赛题基本情况"><a href="#赛题基本情况" class="headerlink" title="赛题基本情况"></a>赛题基本情况</h1><p>A题基本如下：<br><img src="https://img-blog.csdnimg.cn/fc0e1942da0840e581af2f1a07f92294.png"><br>B题基本如下：<br><img src="https://img-blog.csdnimg.cn/60fe3adf19504c08858bb6e0335dae6c.png"><br><img src="https://img-blog.csdnimg.cn/0bd891ee6bc648db963bbb5be25ff832.png"><br><img src="https://img-blog.csdnimg.cn/32ce46c165fb4f959267a3ee388aa68e.png"><br><img src="https://img-blog.csdnimg.cn/528ac1e435114bd781e6ad1f5de35bb8.png"></p><h1 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h1><p>昨天做A题，今天做B题，每个题的做题时间是8:00-20:00（8:00:00公布赛题），共12个小时的竞赛时间，完成一篇论文</p><p>可以看出，A题和我们人工智能专业相关性不大，所以昨天我和两个队友基本出于摆烂状态，也没有提交论文，基本放弃了A题，而转身去看建校70周年的节目去了</p><p>然后今天早晨又看了B题，发现可以冲，于是我们三个就去201教室开干，一共写了20页，差不多从9点开干，一直到晚上8点，难度不大，但也需要一定的思考逻辑，模型部分如下图展示：<br><img src="https://img-blog.csdnimg.cn/492c0617f3ce49c68980a8c3d4e23b36.png"><br><img src="https://img-blog.csdnimg.cn/4b25af9f99db44c195bb9ce3f6079b28.png"><br><img src="https://img-blog.csdnimg.cn/b7c75b831b574d3fb7c78f100c022287.png"></p><h1 id="感悟"><a href="#感悟" class="headerlink" title="感悟"></a>感悟</h1><p>做的还可以，基本都是按照题目要求做的，美中不足就是正第一页排版不大好，其他的都还可以，希望能够摸一个奖</p>]]></content>
      
      
      <categories>
          
          <category> 竞赛 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 数据挖掘 </tag>
            
            <tag> 竞赛 </tag>
            
            <tag> 数据分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>第三届“大湾区杯”粤港澳金融数学建模竞赛</title>
      <link href="/posts/25176.html"/>
      <url>/posts/25176.html</url>
      
        <content type="html"><![CDATA[<p>2022年第三届“大湾区杯”粤港澳金融数学建模竞赛复盘</p><span id="more"></span><p>老规矩先上代码仓库：<a href="https://github.com/du2279664786/2022-JinRong-Mathematics-modeling">https://github.com/du2279664786/2022-JinRong-Mathematics-modeling</a></p><h1 id="竞赛日程"><a href="#竞赛日程" class="headerlink" title="竞赛日程"></a>竞赛日程</h1><p>报名时间：10月12日10:00:00-10月30日22:00:00<br>竞赛时间：11月1日10:00:00-11月8日14:00:00</p><h1 id="赛题基本情况"><a href="#赛题基本情况" class="headerlink" title="赛题基本情况"></a>赛题基本情况</h1><p>A题如下<br><img src="https://img-blog.csdnimg.cn/4d314192ae304e3ab220fddc93379418.png"><br>B题如下<br><img src="https://img-blog.csdnimg.cn/1c6b8f2fcc844fc891edbf488f9078df.png"><br>AB两个题都是比较偏向金融的（题目就叫‘金融’数学建模）</p><h1 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h1><p>我们三个都是计算机专业的，对金融一窍不通，刚开始选择的是A题，因为我们感觉A比较偏代码，实践性更强一些，但是当我们做了两天之后发现：A题根本没有头绪，对他们所给的数据也是不会处理，11月3号，还是没有思路，于是我们果断换成了B题，容易水论文<br><img src="https://img-blog.csdnimg.cn/83574b6bd9624a229fb935074e4c808a.png"></p><h1 id="感悟"><a href="#感悟" class="headerlink" title="感悟"></a>感悟</h1><p>整体还行，至少尽力做了，对金融领域不大了解，这也是我们的短处，希望能摸一个奖！</p>]]></content>
      
      
      <categories>
          
          <category> 竞赛 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 竞赛 </tag>
            
            <tag> 数学建模 </tag>
            
            <tag> 金融 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>中国大学生计算机设计大赛复盘</title>
      <link href="/posts/194.html"/>
      <url>/posts/194.html</url>
      
        <content type="html"><![CDATA[<p>2022年中国大学生计算机设计大赛-人工智能挑战赛-国家二等奖</p><span id="more"></span><p>此篇文章写于2022年10月27日，为了复盘、回顾上一次的计算机设计大赛<br>中国大学生计算机设计大赛</p><h1 id="日程"><a href="#日程" class="headerlink" title="日程"></a>日程</h1><p>5-6月份开始初赛省赛，我和我的两位队友努力的写文档，整理代码，提交了相关资料，由于初赛（省赛）没有答辩，所以差不多等到六月多收到获得省二的通知<br>7月份多得之进了国赛<br>7月底-8月底就开始修改文档，修改代码，录制相关视频，等待国赛的答辩</p><h1 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h1><p>项目背景：在数字经济蓬勃发展的时代背景下， “数字化”“智慧化”成为了企业管理转型升级的核心引擎。传统建管理模式已不再符合可持续发展的要求，迫切需要利用以信息技术为代表的现代科技手段，实现中国企业管理转型升级与跨越式发展。为了更好的解决时代问题的痛点，并在一定程度上节约人力成本，本项目设计了一个基于云端和硬件的人工智能多场景实时物体监测平台，将多场景实时监测与报警系统进行了融合创新，做到了监控、检测、分类、识别四位一体的平台建设。<br>整体布局：<br><img src="https://img-blog.csdnimg.cn/d652a2b775ee475f951a36c928d2054e.png" alt="在这里插入图片描述"></p><p>算法介绍：<br>移动物体检测：本项目采用OpenCV（Open Source Computer Vision Library）算法，使用灰度转化、图片缩放和高斯滤波等相关操作，对图像进行预处理，增强了移动物体的可检测性。</p><p>物体识别：为提高精确度并且处理时间尽可能短，本项目采用了运算速度比较快的 Yolov3 算法，它是基于深度学习框架Darknet的目标检测开源项目，不仅可以充分发挥多核处理器和 GPU 并行运算的功能，还可以基于预训练模型进行实时目标检测,预期效果如下：<br><img src="https://img-blog.csdnimg.cn/d1d870e51929499fb0637ed6a3ba3703.png" alt="在这里插入图片描述"><br>以及安全帽检测、疲劳监测、口罩检测<br>具体代码仓库如下：<a href="https://github.com/du2279664786/Chinese-undergraduate-computer-design-contest">https://github.com/du2279664786/Chinese-undergraduate-computer-design-contest</a></p><p>最终获得证书：一个省二证书、一个国二证书、外加一枚金匾<br><img src="https://img-blog.csdnimg.cn/736f6b9f339841fc832f0180d06ab5d8.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/99c107c9a863454e8ee0d84169935b90.png" alt="在这里插入图片描述"></p>]]></content>
      
      
      <categories>
          
          <category> 竞赛 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 竞赛 </tag>
            
            <tag> 机器视觉 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数学建模省一思路及其代码</title>
      <link href="/posts/1054.html"/>
      <url>/posts/1054.html</url>
      
        <content type="html"><![CDATA[<p>2022年全国大学生数学建模竞赛山东省一等奖</p><span id="more"></span><p>连肝三天，撸了三天代码，9.17早-9.18晚日夜不停，终于和队友拿下了2022年全国大学生数学建模竞赛山东省一等奖<br>基本思路如下：<br><img src="https://img-blog.csdnimg.cn/c6128ba97db94cf489182b2fe05ee6ec.jpeg"><br>下面是代码部分，仓库连接如下：<a href="https://github.com/du2279664786/CUMCM">https://github.com/du2279664786/CUMCM</a><br><img src="https://img-blog.csdnimg.cn/1b6a9e5ed0054967b790696d20f287ce.png" alt="在这里插入图片描述"></p>]]></content>
      
      
      <categories>
          
          <category> 竞赛 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 竞赛 </tag>
            
            <tag> 数学建模 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>对Transformer中FeedForward层的理解</title>
      <link href="/posts/46858.html"/>
      <url>/posts/46858.html</url>
      
        <content type="html"><![CDATA[<p>在Multi-Head Attention中，主要是进行矩阵乘法，即都是线性变换，而线性变换的学习能力不如非线性变换的学习能力强</p><span id="more"></span><p>上一篇我们介绍了<a href="https://du2279664786.github.io/2022/10/09/2022-10-09%E5%AF%B9Transformer%E4%B8%ADAdd&Norm%E5%B1%82%E7%9A%84%E7%90%86%E8%A7%A3/">对Add&amp;Norm层的理解</a>，有不大熟悉的可以看一下上篇文章。</p><p>今天来说一下Transformer中FeedForward层，首先还是先来回顾一下Transformer的基本结构：首先我们还是先来回顾一下Transformer的结构：Transformer结构主要分为两大部分，一是Encoder层结构，另一个则是Decoder层结构，Encoder 的输入由 Input Embedding 和 Positional Embedding 求和输入Multi-Head-Attention，然后又做了一个ADD&amp;Norm，再通过Feed Forward进行输出。<br><img src="https://img-blog.csdnimg.cn/4af25c021fd14b70aa2648a925fadf54.png"><br>FeedForward的输入是什么呢？是Multi-Head Attention的输出做了残差连接和Norm之后得数据，然后FeedForward做了两次线性线性变换，为的是更加深入的提取特征。<br><img src="https://img-blog.csdnimg.cn/b976d7add795475fac7bbc6c5f01121f.png" alt="在这里插入图片描述"><br>可以看出在每次线性变换都引入了非线性激活函数Relu，在Multi-Head Attention中，主要是进行矩阵乘法，即都是线性变换，而线性变换的学习能力不如非线性变换的学习能力强，FeedForward的计算公式如下：max相当于Relu<br><img src="https://img-blog.csdnimg.cn/43b6886add22435795f3f8a7a889c58e.png" alt="在这里插入图片描述"></p><p>所以FeedForward的作用是：通过线性变换，先将数据映射到高纬度的空间再映射到低纬度的空间，提取了更深层次的特征</p>]]></content>
      
      
      <categories>
          
          <category> 自然语言处理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> NLP </tag>
            
            <tag> HuggingFace </tag>
            
            <tag> Transformer </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>对Transformer中Add&amp;Norm层的理解</title>
      <link href="/posts/34541.html"/>
      <url>/posts/34541.html</url>
      
        <content type="html"><![CDATA[<p>无论是layernorm还是instancenorm，还是我们手动去求平均计算其Norm，结果都是一样的，由此我们可以得出一个结论：Layernorm实际上是在做Instancenorm！</p><span id="more"></span><h1 id="Add操作"><a href="#Add操作" class="headerlink" title="Add操作"></a>Add操作</h1><p>首先我们还是先来回顾一下Transformer的结构：Transformer结构主要分为两大部分，一是Encoder层结构，另一个则是Decoder层结构，Encoder 的输入由 Input Embedding 和 Positional Embedding 求和输入Multi-Head-Attention，再通过Feed Forward进行输出。</p><p>由下图可以看出：在Encoder层和Decoder层中都用到了Add&amp;Norm操作，即残差连接和层归一化操作。<br><img src="https://img-blog.csdnimg.cn/5ef722ad3c5b407482ac132b0883c59c.png" alt="在这里插入图片描述"><br>什么是残差连接呢？残差连接就是把网络的输入和输出相加，即网络的输出为F(x)+x，在网络结构比较深的时候，网络梯度反向传播更新参数时，容易造成梯度消失的问题，但是如果每层的输出都加上一个x的时候，就变成了F(x)+x，对x求导结果为1，所以就相当于每一层求导时都加上了一个常数项‘1’，有效解决了梯度消失问题。</p><h1 id="Norm操作"><a href="#Norm操作" class="headerlink" title="Norm操作"></a>Norm操作</h1><p>首先要明白Norm做了一件什么事，从刚开始接触Transformer开始，我认为所谓的Norm就是BatchNorm，但是有一天我看到了这篇<a href="https://mp.weixin.qq.com/s/HNCl6MPS_hjTVHNt7UkYyw">文章</a>，才明白了Norm是什么。</p><p>假设我们输入的词向量的形状是（2，3，4），2为批次（batch），3为句子长度，4为词向量的维度，生成以下数据：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[[w11, w12, w13, w14], [w21, w22, w23, w24], [w31, w32, w33, w34]</span><br><span class="line">[w41, w42, w43, w44], [w51, w52, w53, w54], [w61, w62, w63, w64]]</span><br></pre></td></tr></table></figure><p>如果是在做BatchNorm（BN）的话，其计算过程如下：BN1&#x3D;(w11+w12+w13+w14+w41+<br>w42+w43+w44)&#x2F;8，同理会得到BN2和BN3，最终得到[BN1,BN2,BN3] 3个mean</p><p>如果是在做LayerNorm（LN）的话，则会进如下计算：LN1&#x3D;(w11+w12+w13+w14+w21+<br>w22+w23+w24+w31+w32+w33+w34)&#x2F;12，同理会得到LN2，最终得到[LN1,LN2]两个mean</p><p>如果是在做InstanceNorm（IN）的话，则会进如下计算：IN1&#x3D;(w11+w12+w13+w14)&#x2F;4，同理会得到IN2，IN3，IN4，IN5，IN6，六个mean，[[IN1，IN2，IN3],[IN4，IN5，IN6]]<br>下图完美的揭示了，这几种Norm<br><img src="https://img-blog.csdnimg.cn/a143d6b41e654fa1849f44580401110c.png" alt="在这里插入图片描述"><br>接下来我们来看一下Transformer中的Norm：首先生成[2,3,4]形状的数据，使用原始的编码方式进行编码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> InstanceNorm2d</span><br><span class="line">random_seed = <span class="number">123</span></span><br><span class="line">torch.manual_seed(random_seed)</span><br><span class="line"></span><br><span class="line">batch_size, seq_size, dim = <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span></span><br><span class="line">embedding = torch.randn(batch_size, seq_size, dim)</span><br><span class="line"></span><br><span class="line">layer_norm = torch.nn.LayerNorm(dim, elementwise_affine = <span class="literal">False</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;y: &quot;</span>, layer_norm(embedding))</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">y:  tensor([[[ <span class="number">1.5524</span>,  <span class="number">0.0155</span>, -<span class="number">0.3596</span>, -<span class="number">1.2083</span>],</span><br><span class="line">         [ <span class="number">0.5851</span>,  <span class="number">1.3263</span>, -<span class="number">0.7660</span>, -<span class="number">1.1453</span>],</span><br><span class="line">         [ <span class="number">0.2864</span>,  <span class="number">0.0185</span>,  <span class="number">1.2388</span>, -<span class="number">1.5437</span>]],</span><br><span class="line">        [[ <span class="number">1.1119</span>, -<span class="number">0.3988</span>,  <span class="number">0.7275</span>, -<span class="number">1.4406</span>],</span><br><span class="line">         [-<span class="number">0.4144</span>, -<span class="number">1.1914</span>,  <span class="number">0.0548</span>,  <span class="number">1.5510</span>],</span><br><span class="line">         [ <span class="number">0.3914</span>, -<span class="number">0.5591</span>,  <span class="number">1.4105</span>, -<span class="number">1.2428</span>]]])</span><br></pre></td></tr></table></figure><p>接下来手动去进行一下编码:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">eps: <span class="built_in">float</span> = <span class="number">0.00001</span></span><br><span class="line">mean = torch.mean(embedding[:, :, :], dim=(-<span class="number">1</span>), keepdim=<span class="literal">True</span>)</span><br><span class="line">var = torch.square(embedding[:, :, :] - mean).mean(dim=(-<span class="number">1</span>), keepdim=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;mean: &quot;</span>, mean.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;y_custom: &quot;</span>, (embedding[:, :, :] - mean) / torch.sqrt(var + eps))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mean:  torch.Size([<span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>])</span><br><span class="line">y_custom:  tensor([[[ <span class="number">1.1505</span>,  <span class="number">0.5212</span>, -<span class="number">0.1262</span>, -<span class="number">1.5455</span>],</span><br><span class="line">         [-<span class="number">0.6586</span>, -<span class="number">0.2132</span>, -<span class="number">0.8173</span>,  <span class="number">1.6890</span>],</span><br><span class="line">         [ <span class="number">0.6000</span>,  <span class="number">1.2080</span>, -<span class="number">0.3813</span>, -<span class="number">1.4267</span>]],</span><br><span class="line">        [[-<span class="number">0.0861</span>,  <span class="number">1.0145</span>, -<span class="number">1.5895</span>,  <span class="number">0.6610</span>],</span><br><span class="line">         [ <span class="number">0.8724</span>,  <span class="number">0.9047</span>, -<span class="number">1.5371</span>, -<span class="number">0.2400</span>],</span><br><span class="line">         [ <span class="number">0.1507</span>,  <span class="number">0.5268</span>,  <span class="number">0.9785</span>, -<span class="number">1.6560</span>]]])</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>可以发现和LayerNorm的结果是一样的，也就是说明Norm是对d_model进行的Norm，会给我们[batch,sqe_length]形状的平均值。<br>加下来进行batch_norm,</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">layer_norm = torch.nn.LayerNorm([seq_size,dim], elementwise_affine = <span class="literal">False</span>)</span><br><span class="line">eps: <span class="built_in">float</span> = <span class="number">0.00001</span></span><br><span class="line">mean = torch.mean(embedding[:, :, :], dim=(-<span class="number">2</span>,-<span class="number">1</span>), keepdim=<span class="literal">True</span>)</span><br><span class="line">var = torch.square(embedding[:, :, :] - mean).mean(dim=(-<span class="number">2</span>,-<span class="number">1</span>), keepdim=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;mean: &quot;</span>, mean.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;y_custom: &quot;</span>, (embedding[:, :, :] - mean) / torch.sqrt(var + eps))</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mean:  torch.Size([<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">y_custom:  tensor([[[ <span class="number">1.1822</span>,  <span class="number">0.4419</span>, -<span class="number">0.3196</span>, -<span class="number">1.9889</span>],</span><br><span class="line">         [-<span class="number">0.6677</span>, -<span class="number">0.2537</span>, -<span class="number">0.8151</span>,  <span class="number">1.5143</span>],</span><br><span class="line">         [ <span class="number">0.7174</span>,  <span class="number">1.2147</span>, -<span class="number">0.0852</span>, -<span class="number">0.9403</span>]],</span><br><span class="line">        [[-<span class="number">0.0138</span>,  <span class="number">1.5666</span>, -<span class="number">2.1726</span>,  <span class="number">1.0590</span>],</span><br><span class="line">         [ <span class="number">0.6646</span>,  <span class="number">0.6852</span>, -<span class="number">0.8706</span>, -<span class="number">0.0442</span>],</span><br><span class="line">         [-<span class="number">0.1163</span>,  <span class="number">0.1389</span>,  <span class="number">0.4454</span>, -<span class="number">1.3423</span>]]])</span><br></pre></td></tr></table></figure><p>可以看到BN的计算的mean形状为[2, 1, 1]，并且Norm结果也和上面的两个不一样，这就充分说明了Norm是在对最后一个维度求平均。<br>那么什么又是Instancenorm呢？接下来再来实现一下instancenorm</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">instance_norm = InstanceNorm2d(<span class="number">3</span>, affine=<span class="literal">False</span>)</span><br><span class="line">output = instance_norm(embedding.reshape(<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">1</span>)) <span class="comment">#InstanceNorm2D需要(N,C,H,W)的shape作为输入</span></span><br><span class="line">layer_norm = torch.nn.LayerNorm(<span class="number">4</span>, elementwise_affine = <span class="literal">False</span>)</span><br><span class="line"><span class="built_in">print</span>(layer_norm(embedding))</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tensor([[[ <span class="number">1.1505</span>,  <span class="number">0.5212</span>, -<span class="number">0.1262</span>, -<span class="number">1.5455</span>],</span><br><span class="line">         [-<span class="number">0.6586</span>, -<span class="number">0.2132</span>, -<span class="number">0.8173</span>,  <span class="number">1.6890</span>],</span><br><span class="line">         [ <span class="number">0.6000</span>,  <span class="number">1.2080</span>, -<span class="number">0.3813</span>, -<span class="number">1.4267</span>]],</span><br><span class="line">        [[-<span class="number">0.0861</span>,  <span class="number">1.0145</span>, -<span class="number">1.5895</span>,  <span class="number">0.6610</span>],</span><br><span class="line">         [ <span class="number">0.8724</span>,  <span class="number">0.9047</span>, -<span class="number">1.5371</span>, -<span class="number">0.2400</span>],</span><br><span class="line">         [ <span class="number">0.1507</span>,  <span class="number">0.5268</span>,  <span class="number">0.9785</span>, -<span class="number">1.6560</span>]]])</span><br></pre></td></tr></table></figure><p>可以看出无论是layernorm还是instancenorm，还是我们手动去求平均计算其Norm，结果都是一样的，由此我们可以得出一个结论：Layernorm实际上是在做Instancenorm！</p><p>如果喜欢文章请点个赞，笔者也是一个刚入门Transformer的小白，一起学习，共同努力。</p>]]></content>
      
      
      <categories>
          
          <category> 自然语言处理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> NLP </tag>
            
            <tag> Transformer </tag>
            
            <tag> Add&amp;Norm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>对Transformer中self-attention的理解</title>
      <link href="/posts/17366.html"/>
      <url>/posts/17366.html</url>
      
        <content type="html"><![CDATA[<p>Q、K点乘之后的方差会随着维度的增大而增大，而大的方差会导致极小的梯度，为了防止梯度消失，所以除以sqrt(dk)来减小方差</p><span id="more"></span><h1 id="什么是self-attention"><a href="#什么是self-attention" class="headerlink" title="什么是self-attention"></a>什么是self-attention</h1><p>首先我们来看一下Transformer架构：对于input输出，首先进行input embedding，然后再进行positional encoding，将两者相加作为Encoder的输入，也就是输如X<img src="https://img-blog.csdnimg.cn/65ef7c5730514e2cac88d332e2588423.png" alt="在这里插入图片描述"><br>何为self-attention？首先我们要明白什么是attention，对于传统的seq2seq任务，例如中-英文翻译，输入中文，得到英文，即source是中文句子（x1 x2 x3）,英文句子是target（y1 y2 y3）<br><img src="https://img-blog.csdnimg.cn/296c379fd77c475ebf77c06fa8e42e59.png" alt="在这里插入图片描述"><br>attention机制发生在target的元素和source中的所有元素之间。简单的将就是attention机制中的权重计算需要target参与，即在上述Encoder-Decoder模型中，Encoder和Decoder两部分都需要参与运算。</p><p>而对于self-attention，它不需要Decoder的参与，而是source内部元素之间发生的运算，对于输入向量X，对其做线性变换，分别得到Q、K、V矩阵<br><img src="https://img-blog.csdnimg.cn/17358bbb1cf641d78117625fb5a00d31.png" alt="在这里插入图片描述"><br>然后去计算attention，Q、K点乘得到初步的权重因子，并对Q、K点乘结果进行放缩，除以sqrt（dk），Q、K点乘之后的方差会随着维度的增大而增大，而大的方差会导致极小的梯度，为了防止梯度消失，所以除以sqrt(dk)来减小方差，最终再加一个softmax就得到了self attention的输出。<br><img src="https://img-blog.csdnimg.cn/07fdbd802d114b7193c70e9fc451ba22.png" alt="在这里插入图片描述"></p><h1 id="Multi–head-attention"><a href="#Multi–head-attention" class="headerlink" title="Multi–head-attention"></a>Multi–head-attention</h1><p>Multi–head-attention使用了多个头进行运算，捕捉到了更多的信息，多头的数量用h表示，一般h&#x3D;8，表示8个头<br><img src="https://img-blog.csdnimg.cn/7cad1e37120b4d40ad64140677452ec1.png" alt="在这里插入图片描述"><br>在输入每个self-attention之前，我们需将输入X均分的分到h个头中，得到Z1-Z7八个头的输出结果。<br><img src="https://img-blog.csdnimg.cn/d5763f726a5c48f292a140f84c0e5200.png" alt="在这里插入图片描述"><br>对于每个头计算相应的attention score，将其进行拼接，再与W0进行一个线性变换，就得到最终输出的Z。<br><img src="https://img-blog.csdnimg.cn/05bfb9eb87bb4f3b8066c8190c0dff0f.png" alt="在这里插入图片描述"></p>]]></content>
      
      
      <categories>
          
          <category> 自然语言处理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> HuggingFace </tag>
            
            <tag> Transformer </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>对Transformer中Positional Encoding的理解</title>
      <link href="/posts/7459.html"/>
      <url>/posts/7459.html</url>
      
        <content type="html"><![CDATA[<p>其中pos表示token在sequence中的位置，d_model表示词嵌入的维度，i则是range(d_model)中的数值</p><span id="more"></span><p>首先来看一下Transformer结构的结构：<br><img src="https://img-blog.csdnimg.cn/c7ce14349b734567a014c4cf679398fe.png" alt="在这里插入图片描述"><br>Transformer是由Encoder和Decoder两大部分组成，首先对于文本特征，需要进行Embedding，由于transformer抛弃了Rnn的结构，不能捕捉到序列的信息，交换单词位置，得到相应的attention也会发生交换，并不会发生数值上的改变，所以要对input进行Positional Encoding。</p><p>Positional encoding和input embedding是同等维度的，所以可以将两者进行相加，的到输入向量<br><img src="https://img-blog.csdnimg.cn/be30b27838dd411c89d793432ff72582.png" alt="在这里插入图片描述"><br>接下来看一些Positional Encoding的计算公式：<br><img src="https://img-blog.csdnimg.cn/6e9a80e756b94a70aeef8a79097eb7a6.png" alt="在这里插入图片描述"><br>其中pos表示token在sequence中的位置，d_model表示词嵌入的维度，i则是range(d_model)中的数值，也就是说：对于单个token的d_model维度的词向量，奇数位置取cos，偶数位置取sin，最终的到一个维度和word embedding维度一样的矩阵，接下来可以看一下代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_positional_encoding</span>(<span class="params">max_seq_len, embed_dim</span>):</span><br><span class="line">    <span class="comment"># 初始化一个positional encoding</span></span><br><span class="line">    <span class="comment"># embed_dim: 字嵌入的维度</span></span><br><span class="line">    <span class="comment"># max_seq_len: 最大的序列长度</span></span><br><span class="line">    positional_encoding = np.array([</span><br><span class="line">        [pos / np.power(<span class="number">10000</span>, <span class="number">2</span> * i / embed_dim) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(embed_dim)] <span class="keyword">if</span> pos != <span class="number">0</span> <span class="keyword">else</span> np.zeros(embed_dim) <span class="keyword">for</span> pos <span class="keyword">in</span> <span class="built_in">range</span>(max_seq_len)])</span><br><span class="line"></span><br><span class="line">    positional_encoding[<span class="number">1</span>:, <span class="number">0</span>::<span class="number">2</span>] = np.sin(positional_encoding[<span class="number">1</span>:, <span class="number">0</span>::<span class="number">2</span>])  <span class="comment"># dim 2i 偶数</span></span><br><span class="line">    positional_encoding[<span class="number">1</span>:, <span class="number">1</span>::<span class="number">2</span>] = np.cos(positional_encoding[<span class="number">1</span>:, <span class="number">1</span>::<span class="number">2</span>])  <span class="comment"># dim 2i+1 奇数</span></span><br><span class="line">    <span class="keyword">return</span> positional_encoding</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">positional_encoding = get_positional_encoding(max_seq_len=<span class="number">100</span>, embed_dim=<span class="number">16</span>)</span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line">sns.heatmap(positional_encoding)</span><br><span class="line">plt.title(<span class="string">&quot;Sinusoidal Function&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;hidden dimension&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;sequence length&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>首先求初始向量：positional_encoding，然后对其奇数列求sin，偶数列求cos：<br><img src="https://img-blog.csdnimg.cn/2da3445d7953426394ab2e46d8820baf.png" alt="在这里插入图片描述"><br>最终得到positional encoding之后的数据可视化：<br><img src="https://img-blog.csdnimg.cn/507cc7ca0ba34f8fb2ec87216689857c.png" alt="在这里插入图片描述"></p>]]></content>
      
      
      <categories>
          
          <category> 自然语言处理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> NLP </tag>
            
            <tag> Positional Encoding </tag>
            
            <tag> Transformer </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>怎么理解预训练模型？</title>
      <link href="/posts/64891.html"/>
      <url>/posts/64891.html</url>
      
        <content type="html"><![CDATA[<p>“预训练“的做法一般是将大量低成本收集的训练数据放在一起，经过某种预训方法去学习其中的共性……</p><span id="more"></span><h1 id="什么是预训练"><a href="#什么是预训练" class="headerlink" title="什么是预训练"></a>什么是预训练</h1><p>“预训练“的做法一般是将大量低成本收集的训练数据放在一起，经过某种预训方法去学习其中的共性，然后将其中的共性“移植”到特定任务的模型中，再使用相关特定领域的少量标注数据进行“微调”，这样的话，模型只需要从”共性“出发，去“学习”该特定任务的“特殊”部分即可。</p><h1 id="预训练的思想"><a href="#预训练的思想" class="headerlink" title="预训练的思想"></a>预训练的思想</h1><p>预训练的思想是：模型的参数不再是随机初始化的，而是通过一些任务进行预先训练，得到一套模型参数，然后用这套参数对模型进行初始化，再进行训练</p><h1 id="CV领域的预训练"><a href="#CV领域的预训练" class="headerlink" title="CV领域的预训练"></a>CV领域的预训练</h1><p>首先对于CV领域图片分类任务，常用的深度学习模型是卷积视神经网络，对于多层的卷积神经网络来说，不同的层学到的特征是不同的，为了捕获更多的特征，浅层的感受野较小，所以浅层学到的特征往往是更加通用的，包含更多的像素点的信息，比如一些细粒度的信息：颜色、纹理、边缘等。<br>通常在大规模图片数据上预先获得‘通用特征’，然后再去做下游任务：<br><img src="https://img-blog.csdnimg.cn/455a209bb08941ff8d390ede716556b4.png" alt="在这里插入图片描述"></p>]]></content>
      
      
      <categories>
          
          <category> 自然语言处理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> NLP </tag>
            
            <tag> HuggingFace </tag>
            
            <tag> 预训练 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HuggingFace的安装和编码</title>
      <link href="/posts/42062.html"/>
      <url>/posts/42062.html</url>
      
        <content type="html"><![CDATA[<p>模型的加载和编码以及基本的使用功能</p><span id="more"></span><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p>使用以下命令安装：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install transformers</span><br></pre></td></tr></table></figure><h1 id="模型的加载"><a href="#模型的加载" class="headerlink" title="模型的加载"></a>模型的加载</h1><p>导入包：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">from transformers import BertTokenizer</span><br></pre></td></tr></table></figure><p>加载预训练模型bert-base-chinese，初次加载可能需要较长的时间。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#加载预训练字典和分词方法</span><br><span class="line">tokenizer = BertTokenizer.from_pretrained(</span><br><span class="line"># 下载或者从本地加载模型</span><br><span class="line">    pretrained_model_name_or_path=&#x27;bert-base-chinese&#x27;,</span><br><span class="line">    force_download=False,</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>接下来就可以看到tokenizer的内容：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tokenizer</span><br><span class="line"></span><br><span class="line">#print:(name_or_path=&#x27;bert-base-chinese&#x27;, vocab_size=21128, model_max_len=512, is_fast=False, padding_side=&#x27;right&#x27;, truncation_side=&#x27;right&#x27;, special_tokens=&#123;&#x27;unk_token&#x27;: &#x27;[UNK]&#x27;, &#x27;sep_token&#x27;: &#x27;[SEP]&#x27;, &#x27;pad_token&#x27;: &#x27;[PAD]&#x27;, &#x27;cls_token&#x27;: &#x27;[CLS]&#x27;, &#x27;mask_token&#x27;: &#x27;[MASK]&#x27;&#125;)</span><br></pre></td></tr></table></figure><h1 id="进行编码"><a href="#进行编码" class="headerlink" title="进行编码"></a>进行编码</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">sents = [</span><br><span class="line">    &#x27;我在一所学院上大三。&#x27;,</span><br><span class="line">    &#x27;今天天气好，我来图书馆学习。&#x27;,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">res= tokenizer.encode(</span><br><span class="line">    # 可以一次编码两个句子，即text和text_pair</span><br><span class="line">    text = sents[0],</span><br><span class="line">    text_pair=sents[1],</span><br><span class="line">    </span><br><span class="line">    # 当句子长度大于max_length是选择截断</span><br><span class="line">    truncation=True,</span><br><span class="line">    </span><br><span class="line">    # 一律补pad到max_length长度</span><br><span class="line">    padding=&#x27;max_length&#x27;,</span><br><span class="line">    add_special_tokens = True,</span><br><span class="line">    max_length=30,</span><br><span class="line">    return_tensors=None,</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>可以打印出res的结果：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 101为CLS    102为SEP    0为PAD</span><br><span class="line">#print(res):[101, 2769, 1762, 671, 2792, 2110, 7368, 677, 1920, 676, 511, 102, 791, 1921, 1921, 3698, 1962, 8024, 2769, 3341, 1745, 741, 7667, 2110, 739, 511, 102, 0, 0, 0]</span><br></pre></td></tr></table></figure><p>也可以查看编码之后的结果:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tokenizer.decode(res)</span><br><span class="line"># [CLS] 我 在 一 所 学 院 上 大 三 。 [SEP] 今 天 天 气 好 ， 我 来 图 书 馆 学 习 。 [SEP] [PAD] [PAD] [PAD]</span><br></pre></td></tr></table></figure><h1 id="多功能编码"><a href="#多功能编码" class="headerlink" title="多功能编码"></a>多功能编码</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">res = tokenizer.encode_plus(</span><br><span class="line">    # 可以一次编码两个句子</span><br><span class="line">    text = sents[0],</span><br><span class="line">    text_pair=sents[1],</span><br><span class="line">    </span><br><span class="line">    # 当句子长度大于max_length是选择截断</span><br><span class="line">    truncation=True,</span><br><span class="line">    </span><br><span class="line">    # 一律补pad到max_length长度</span><br><span class="line">    padding=&#x27;max_length&#x27;,</span><br><span class="line">    add_special_tokens = True,</span><br><span class="line">    max_length=30,</span><br><span class="line">    </span><br><span class="line">    # 返回值的类型：tf  pt  np</span><br><span class="line">    return_tensors=None,</span><br><span class="line">    </span><br><span class="line">    # 返回token_type_ids</span><br><span class="line">    return_token_type_ids=True,</span><br><span class="line">    </span><br><span class="line">    # 返回attention_mask</span><br><span class="line">    return_attention_mask = True,</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    # 返回length标识长度</span><br><span class="line">    return_length = True,</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>查看编码的结果：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">for k,v in res.items():</span><br><span class="line">    print(k,&#x27;:&#x27;,v)</span><br><span class="line">    </span><br><span class="line">tokenizer.decode(res[&#x27;input_ids&#x27;])</span><br><span class="line"></span><br><span class="line"># input_ids:编码后的句子</span><br><span class="line"># token_type_ids:第一个句子和特殊符号的位置是0，第二个句子的位置是1</span><br><span class="line"># attention_mask:pad的位置是0，其它位置是1</span><br><span class="line"># length:返回句子的长度</span><br></pre></td></tr></table></figure><h1 id="将句子批量进行编码"><a href="#将句子批量进行编码" class="headerlink" title="将句子批量进行编码"></a>将句子批量进行编码</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">out = tokenizer.batch_encode_plus(</span><br><span class="line">    batch_text_or_text_pairs=[sents[0],sents[1]],</span><br><span class="line">    </span><br><span class="line">    # 当句子长度大于max_length是选择截断</span><br><span class="line">    truncation=True,</span><br><span class="line">    </span><br><span class="line">    # 一律补pad到max_length长度</span><br><span class="line">    padding=&#x27;max_length&#x27;,</span><br><span class="line">    add_special_tokens = True,</span><br><span class="line">    max_length=30,</span><br><span class="line">    </span><br><span class="line">    # 返回值的类型：tf  pt  np</span><br><span class="line">    return_tensors=None,</span><br><span class="line">    </span><br><span class="line">    # 返回token_type_ids</span><br><span class="line">    return_token_type_ids=True,</span><br><span class="line">    </span><br><span class="line">    # 返回attention_mask</span><br><span class="line">    return_attention_mask = True,</span><br><span class="line">    </span><br><span class="line">    # 返回length标识长度</span><br><span class="line">    return_length = True,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 自然语言处理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> NLP </tag>
            
            <tag> HuggingFace </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习课程回顾</title>
      <link href="/posts/12558.html"/>
      <url>/posts/12558.html</url>
      
        <content type="html"><![CDATA[<p>大二下学期深度学习课程回顾</p><span id="more"></span><h1 id="第1章：深度学习概述"><a href="#第1章：深度学习概述" class="headerlink" title="第1章：深度学习概述"></a>第1章：深度学习概述</h1><p>BP神经网络的反向传播（《深度学习08_小复习.pptx》，链式法则：损失函数，激活函数、信号强度；每多一层多一个sigma符号：也是网络不能太深的原因之一）<br>    参数确定（权值个数和偏置个数）</p><h1 id="第2章：Pytorch简介"><a href="#第2章：Pytorch简介" class="headerlink" title="第2章：Pytorch简介"></a>第2章：Pytorch简介</h1><p>Pytorch安装要点：装python、装CUDA、装gpu版的torch<br>Linux编译安装Python的主要步骤：下载、解压、配置(.&#x2F;configure)、编译安装(make &amp;&amp; make install)<br>Tensor的基本知识：数据方面就是numpy，计算图方面是张量的本质。</p><h1 id="第3章：Pytorch计算图"><a href="#第3章：Pytorch计算图" class="headerlink" title="第3章：Pytorch计算图"></a>第3章：Pytorch计算图</h1><p>《深度学习08_小复习.pptx》<br>给几个公式，可以画出计算图，给计算图，可以复原出公式。<br>给计算图，可以向上算数据，可以算回传梯度<br>Pytorch的计算图结构：1、是否所有的叶子节点都可以设置为需要计算梯度，是否所有的叶子节点都需要计算梯度。2、是否默认所有的计算图都可以回传多次。3、计算图是否一个有向无环图。4、是否默认可以让中间节点保存梯度。5、非叶子节点的导函数是怎么来的？</p><h1 id="第4章：线性回归"><a href="#第4章：线性回归" class="headerlink" title="第4章：线性回归"></a>第4章：线性回归</h1><p>分类与回归，线性回归的基本概念，可用的解法。<br>小批量随机梯度下降法。<br>看网络写方程，看方程画网络。<br>数据加载、损失函数。</p><h1 id="第5章：Softmax回归"><a href="#第5章：Softmax回归" class="headerlink" title="第5章：Softmax回归"></a>第5章：Softmax回归</h1><p>Softmax和交叉熵，代码、计算、业务场景，<br>权值、偏置初始化<br>view()的业务意义</p><h1 id="第6章：多层感知机"><a href="#第6章：多层感知机" class="headerlink" title="第6章：多层感知机"></a>第6章：多层感知机</h1><p>单层和多层的区别（非线性激活函数的意义）<br>权值、偏置初始化，MLP的完备性<br>Relu激活函数</p><h1 id="第7章：模型训练与深度学习计算"><a href="#第7章：模型训练与深度学习计算" class="headerlink" title="第7章：模型训练与深度学习计算"></a>第7章：模型训练与深度学习计算</h1><p>为什么网络不能过深<br>Wd的原因和表现<br>Dropout的原理和实现<br>模型的读写<br>GPU计算的特点和历史<br>常用的框架代码：比如参数初始化、损失函数定义、优化器定义</p><h1 id="第8章：卷积"><a href="#第8章：卷积" class="headerlink" title="第8章：卷积"></a>第8章：卷积</h1><p>卷积的思想基础，能够解释局部性和平移不变性<br>对于某个像素的信息，应当只与其附近的像素有关系，超出一定的距离以后则无关<br>对某个区域进行的特征提取所得到的输出并不会由于平移操作而发生变化<br>卷积、池化的代码、计算<br>步幅、填充、多通道<br>    卷积和池化是否可以用相同的步幅、填充、输入通道、输出通道<br>1*1卷积</p><h1 id="第9章：机器视觉初步"><a href="#第9章：机器视觉初步" class="headerlink" title="第9章：机器视觉初步"></a>第9章：机器视觉初步</h1><p>LeNet、AlexNet、Vgg、NiN、GoogLeNet、ResNet<br>LeNet、典型的VGG块、inception块、Res块<br>过拟与DA，常用的DA技术<br>每个网络的名字的意义，历史脉络、网络深了是更容易过拟还是会减轻过拟。</p><h1 id="第10章：循环神经网络"><a href="#第10章：循环神经网络" class="headerlink" title="第10章：循环神经网络"></a>第10章：循环神经网络</h1><p>N元语法、词向量，两种常用的向量训练方法。<br>二阶马尔可夫展开<br>RNN、LSTM、GRU</p><h1 id="论述："><a href="#论述：" class="headerlink" title="论述："></a>论述：</h1><p>计算图、框架的作用<br>深度学习、卷积神经网络：简史、意义、动力<br>深度学习与机器学习的联系与区别<br>机器学习的核心理念<br>三个以上的观点，可以是自己的合理的观点，言之有物，自圆其说，字数达标，每个关键观点可酌情给予3-4分。<br>纯网络、教材内容不会得到高分。<br>如果有雷同答案，将判为抄袭，本题不得分，不区分抄袭与被抄袭者，欢迎你和同学讨论，但不要将你的完成文稿给别人，如果你已经给了别人，建议你自己再写一份。</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 总结复盘 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习课程回顾</title>
      <link href="/posts/26100.html"/>
      <url>/posts/26100.html</url>
      
        <content type="html"><![CDATA[<p>大二上学期机器学习课程回顾</p><span id="more"></span><h1 id="1-基本概念部分"><a href="#1-基本概念部分" class="headerlink" title="1.基本概念部分"></a>1.基本概念部分</h1><p>1、统计学习方法可以概括如下：……..<br>2、什么是有监督学习、无监督学习、半监督学习<br>3、有监督的学习的三要素两过程<br>4、生成式模型和判别式模型是什么意思，常见的代表模型有哪几个<br>5、什么叫过拟合、欠拟合，常用的减轻拟合的方法<br>6、如果clf是一个模拟的对象，则一般clf.train(X, y), clf.fit(X, y), clf.predict(test)是什么意思，执行后的结果或改变是什么<br>7、Precision, Recall, F1, Accuracy, AUC of ROC。上面这几个概念的定义、意义、计算。给定正负例的信号强度，能画出ROC<br>8、训练集、验证集、测试集的作用是什么，S折交叉验证是怎么回事<br>9、什么叫回归，什么叫聚类，什么叫分类</p><h1 id="2-Knn"><a href="#2-Knn" class="headerlink" title="2.Knn"></a>2.Knn</h1><p>中英文名字、算法理念、算法过程、算法伪代码，算法代码实现</p><h1 id="3-Kmeans"><a href="#3-Kmeans" class="headerlink" title="3.Kmeans"></a>3.Kmeans</h1><p>中英文名字、算法理念、算法过程、算法伪代码，算法代码实现</p><h1 id="4-最优化问题"><a href="#4-最优化问题" class="headerlink" title="4.最优化问题"></a>4.最优化问题</h1><p>最优化问题，迭代最优化问题，梯度下降法都是什么意思。<br>梯度下降法的算法理念、算法过程、算法伪代码、停机条件<br>给定函数、当前自变量、学习率，可算出下一次迭代的自变量<br>给定函数，能求出argmin和min</p><h1 id="5-感知机"><a href="#5-感知机" class="headerlink" title="5.感知机"></a>5.感知机</h1><p>算法理念、算法过程、算法伪代码，算法代码实现<br>感知机解的情况和业务意义，感知机的局限，感知机在机器学习中的地位</p><h1 id="6-线性回归"><a href="#6-线性回归" class="headerlink" title="6.线性回归"></a>6.线性回归</h1><p>线性回归的定义，解法，解的情况，广义线性回归<br>会手算简单的线性回归(单变量)</p><h1 id="7-逻辑回归"><a href="#7-逻辑回归" class="headerlink" title="7.逻辑回归"></a>7.逻辑回归</h1><p>线性回归的定义，解法，解的情况<br>Sigmoid函数及求导，求解最大似然估计</p><h1 id="8-朴素贝叶斯"><a href="#8-朴素贝叶斯" class="headerlink" title="8.朴素贝叶斯"></a>8.朴素贝叶斯</h1><p>给定一个小规模数据集，可以手算朴素贝叶斯</p><h1 id="9-决策树"><a href="#9-决策树" class="headerlink" title="9.决策树"></a>9.决策树</h1><p>决策树的基本算法<br>熵、基尼、熵增益、固有值、熵增益比的定义和业务意义<br>ID3、C4.5、Cart算法基本思路和伪代码</p><h1 id="10-提升方法"><a href="#10-提升方法" class="headerlink" title="10.提升方法"></a>10.提升方法</h1><p>Bagging和随机森林<br>能说清楚GBDT的脉络即：<br>adaboost的理念，加法模型，前向加法模型，提升树，回归树对残差的拟合，以及对梯度的拟合。</p><h1 id="11-SVM"><a href="#11-SVM" class="headerlink" title="11.SVM"></a>11.SVM</h1><p>线性可分支持向量机的基本脉络<br>松弛变量、核函数的业务背景和操作方法<br>SMO算法的大致过程</p><h1 id="12-NN"><a href="#12-NN" class="headerlink" title="12.NN"></a>12.NN</h1><p>说清楚神经网络学习和预测的过程<br>了解常见的神经网络，及中英文名称<br>对于多层神经网络，可以计算其待定参数的个数，并能说明BP算法如何更新网络参数</p><h1 id="13-Numpy"><a href="#13-Numpy" class="headerlink" title="13.Numpy"></a>13.Numpy</h1><p>基本的向量化运算，使用numpy常见的方法</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 总结复盘 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python切换源，快速下载文件</title>
      <link href="/posts/46361.html"/>
      <url>/posts/46361.html</url>
      
        <content type="html"><![CDATA[<p>快速下载文件</p><span id="more"></span><h1 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h1><p>进入电脑路径’C:\Users\user_name\AppData\Roaming\pip’文件夹下，找到pip.ini文件<br><img src="https://img-blog.csdnimg.cn/d02a90ee68bd40248c2b39ea89154681.png" alt="在这里插入图片描述"><br>若没有此文件则可以创建一个pip文件，后缀为ini，，然后打开文件，将文件内容替换为</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[<span class="keyword">global</span>]</span><br><span class="line"></span><br><span class="line">index-url=http://pypi.douban.com/simple</span><br><span class="line"></span><br><span class="line">[install]</span><br><span class="line"></span><br><span class="line">trusted-host=pypi.douban.com</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>保存文件即可<br><img src="https://img-blog.csdnimg.cn/435b149734414ae49fd8cb8cfbe6f124.png" alt="在这里插入图片描述"><br>下载速度惊人<br><img src="https://img-blog.csdnimg.cn/e904985a074142faaab9e22a7e273cc5.png" alt="在这里插入图片描述"><br>如果文章对您有帮助，请点赞+收藏</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SOFTMAX回归模型</title>
      <link href="/posts/21407.html"/>
      <url>/posts/21407.html</url>
      
        <content type="html"><![CDATA[<p>SOFTMAX函数的脉络梳理</p><span id="more"></span><p>2022-05-08SOFTMAX回归模型</p><h2 id="什么是SOFTMAX回归函数"><a href="#什么是SOFTMAX回归函数" class="headerlink" title="什么是SOFTMAX回归函数"></a>什么是SOFTMAX回归函数</h2><p>·softmax回归跟线性回归⼀样将输⼊特征与权᯿做线性叠加<br>·与线性回归的⼀个主要不同在于，softmax回归的输出值个数等于标签⾥的类别数<br>·SOFTMAX是一个单层的神经网络<br>结构图如下：<br><img src="https://img-blog.csdnimg.cn/1eef7cdde9b04e1d866471e374b3a80b.png" alt="在这里插入图片描述"><br>运算过程如下：<br><img src="https://img-blog.csdnimg.cn/4e928316894e4e298b9e71c18598fbd1.png" alt="在这里插入图片描述"><br>即我们通过神经网络预测，然后得到相应的一个分数，此时我们希望我们得到的分数是一个概率：<br><img src="https://img-blog.csdnimg.cn/c16934676c254f119005ddefbb0d5164.png" alt="在这里插入图片描述"><br>此时我们就应该选取一个合适的方案，来将预测的分数来转化为标签的概率，那么最合适的肯定是softmax了，softmax公式：<br><img src="https://img-blog.csdnimg.cn/df4b36ec76f44413b348ad2917c4d399.png" alt="在这里插入图片描述"><br>即将得到的分数都进行exp，然后求每个标签占比(概率)，最终我们得到的是预测概率最大的标签：<br><img src="https://img-blog.csdnimg.cn/656cab1ab05b4020ac06c14f0ea28951.png" alt="在这里插入图片描述"><br>很显然，我们只关注预测概率最大的标签（单标签预测）<br>总结了一下特性：<br>    ·结果都为正数：即将得分为负数的进行转化<br>    ·所有求和为1：所有概率相加等于1<br>    ·平移不变性：所有得分平移得到的结果不受影响<br>    ·最大–&gt;最大：预测得分最大的概率也大</p><h2 id="交叉熵损失函数"><a href="#交叉熵损失函数" class="headerlink" title="交叉熵损失函数"></a>交叉熵损失函数</h2><p>在这里我们使用的是交叉熵损失函数（Cross Entropy）<br><img src="https://img-blog.csdnimg.cn/eded5e651bfd471dada59239dc2b6c9d.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/cf23b1b754ab4f3eae57f49f5f12b0f1.png" alt="其中带下标的是向量 中⾮0即1的元素"></p><h2 id="实现代码："><a href="#实现代码：" class="headerlink" title="实现代码："></a>实现代码：</h2><p>·导入包：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> init</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path.append(<span class="string">&quot;..&quot;</span>)</span><br><span class="line"><span class="keyword">import</span> d2lzh_pytorch <span class="keyword">as</span> d2l</span><br></pre></td></tr></table></figure><p>若出现没有‘d2lzh_pytorch’这个包，<a href="https://blog.csdn.net/weixin_51756104/article/details/124626354?spm=1001.2014.3001.5501">点击此处离线安装</a><br>·导入数据：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">batch_size = <span class="number">256</span></span><br><span class="line">train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)</span><br></pre></td></tr></table></figure><p>·定义网络：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">num_inputs = <span class="number">784</span></span><br><span class="line">num_outputs = <span class="number">10</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LinearNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_inputs, num_outputs</span>):</span><br><span class="line">        <span class="built_in">super</span>(LinearNet, self).__init__()</span><br><span class="line">        self.linear = nn.Linear(num_inputs, num_outputs)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>): <span class="comment"># x shape: (batch, 1, 28, 28)</span></span><br><span class="line">        y = self.linear(x.view(x.shape[<span class="number">0</span>], -<span class="number">1</span>))</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"> </span><br><span class="line">net = LinearNet(num_inputs,num_outputs)</span><br></pre></td></tr></table></figure><p>·初始化模型参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">init.normal_(net.linear.weight, mean=<span class="number">0</span>, std=<span class="number">0.01</span>)</span><br><span class="line">init.constant_(net.linear.bias, val=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>·定义损失函数和优化器：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">loss = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">optimizer = torch.optim.SGD(net.parameters(), lr=<span class="number">0.1</span>)</span><br></pre></td></tr></table></figure><p>·训练：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">num_epochs = <span class="number">5</span></span><br><span class="line">d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs,batch_size, <span class="literal">None</span>, <span class="literal">None</span>, optimizer)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> SOFTMAX </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>d2lzh_pytorch包离线安装</title>
      <link href="/posts/24434.html"/>
      <url>/posts/24434.html</url>
      
        <content type="html"><![CDATA[<p>线上安装经常出错，所以可以选择离线安装</p><span id="more"></span><p>在导入d2lzh_pytorch包时，一般会报错：<br><img src="https://img-blog.csdnimg.cn/56f5ff1ee876479e9707f06a234a04dd.png" alt="在这里插入图片描述"><br>我们可以离线下载包：<br>链接：<a href="https://pan.baidu.com/share/init?surl=iXyFqY8uM5PGhrthL_-9xQ#list/path=/">点击此处</a>，提取码：1314<br>下载后：进入到我们要使用的环境，按照如下位置安放包<br><img src="https://img-blog.csdnimg.cn/79fcfef8196a43c8bb122b712b2dce9d.png" alt="在这里插入图片描述"><br>最后就可以导入了：<br><img src="https://img-blog.csdnimg.cn/4c3b27ce6aa9488494f97a336101d894.png" alt="在这里插入图片描述"></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> d2lzh_pytorch包离线安装 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>线性回归的简洁实现</title>
      <link href="/posts/5133.html"/>
      <url>/posts/5133.html</url>
      
        <content type="html"><![CDATA[<p>创建单层神经网络</p><span id="more"></span><p>线性回归详细实现，<a href="https://blog.csdn.net/weixin_51756104/article/details/124334225">请点击此处</a></p><h3 id="导入包："><a href="#导入包：" class="headerlink" title="导入包："></a>导入包：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> Data    <span class="comment"># 数据读取</span></span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> init     <span class="comment"># 初始化</span></span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim   <span class="comment"># 优化器</span></span><br></pre></td></tr></table></figure><h3 id="数据集的生成"><a href="#数据集的生成" class="headerlink" title="数据集的生成"></a>数据集的生成</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">num_inputs = <span class="number">2</span>     <span class="comment"># 2个维度</span></span><br><span class="line">num_examples = <span class="number">1000</span>     <span class="comment"># 1000调数据</span></span><br><span class="line"><span class="comment"># 标准的参数</span></span><br><span class="line">true_w = [<span class="number">2</span>, -<span class="number">3.4</span>]</span><br><span class="line">true_b = <span class="number">4.2</span></span><br><span class="line">features = torch.tensor(np.random.normal(<span class="number">0</span>, <span class="number">1</span>, (num_examples,num_inputs)), dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">label = true_w[<span class="number">0</span>] * features[:, <span class="number">0</span>] + true_w[<span class="number">1</span>] * features[:, <span class="number">1</span>] +true_b</span><br><span class="line">label += torch.tensor(np.random.normal(<span class="number">0</span>, <span class="number">0.01</span>,size=label.size()), dtype=torch.<span class="built_in">float</span>)</span><br></pre></td></tr></table></figure><h3 id="数据的读取"><a href="#数据的读取" class="headerlink" title="数据的读取"></a>数据的读取</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">batch_size = <span class="number">30</span></span><br><span class="line">dataset = Data.TensorDataset(features,label)</span><br><span class="line">data_it = Data.DataLoader(dataset,batch_size,shuffle =<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><h3 id="定义模型"><a href="#定义模型" class="headerlink" title="定义模型"></a>定义模型</h3><p>定义模型有多种方法：<br>方法一：继承nn.Module</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LinearNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,n_feature</span>):</span><br><span class="line">        <span class="built_in">super</span>(LinearNet, self).__init__()</span><br><span class="line">        self.linear = nn.Linear(n_feature,<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        y = self.linear(x)</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line">net = LinearNet(num_inputs)</span><br><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> net.parameters():</span><br><span class="line">    <span class="built_in">print</span>(param)</span><br></pre></td></tr></table></figure><p>方法二：nn.Sequential</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">net = nn.Sequential(</span><br><span class="line">    nn.Linear(num_inputs, <span class="number">1</span>)</span><br><span class="line"> )</span><br></pre></td></tr></table></figure><p>方法三：nn.Sequential()+add_module</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">net = nn.Sequential()</span><br><span class="line">net.add_module(<span class="string">&#x27;linear&#x27;</span>, nn.Linear(num_inputs, <span class="number">1</span>))</span><br></pre></td></tr></table></figure><p>方法四：导入OrderedDict</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> OrderedDict</span><br><span class="line">net = nn.Sequential(OrderedDict([</span><br><span class="line">    (<span class="string">&#x27;linear&#x27;</span>, nn.Linear(num_inputs, <span class="number">1</span>))]))</span><br></pre></td></tr></table></figure><h3 id="初始化模型参数"><a href="#初始化模型参数" class="headerlink" title="初始化模型参数"></a>初始化模型参数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">init.normal_(net[<span class="number">0</span>].weight, mean=<span class="number">0</span>, std=<span class="number">0.01</span>)</span><br><span class="line">init.constant_(net[<span class="number">0</span>].bias,val=<span class="number">2</span>)</span><br></pre></td></tr></table></figure><h3 id="MSE损失函数"><a href="#MSE损失函数" class="headerlink" title="MSE损失函数"></a>MSE损失函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss = nn.MSELoss()</span><br></pre></td></tr></table></figure><h3 id="定义优化算法"><a href="#定义优化算法" class="headerlink" title="定义优化算法"></a>定义优化算法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">optimizer = optim.SGD(net.parameters(), lr=<span class="number">0.03</span>)</span><br></pre></td></tr></table></figure><h3 id="模型的优化"><a href="#模型的优化" class="headerlink" title="模型的优化"></a>模型的优化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">num_epochs = <span class="number">3</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, num_epochs + <span class="number">1</span>):</span><br><span class="line">    <span class="keyword">for</span> X, y <span class="keyword">in</span> data_it:</span><br><span class="line">        output = net(X)</span><br><span class="line">        l = loss(output, y.view(-<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        optimizer.zero_grad() <span class="comment"># 梯度清零，等价于net.zero_grad()</span></span><br><span class="line">        l.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">    <span class="built_in">print</span>(epoch, l.item())</span><br></pre></td></tr></table></figure><p>最后输出epoch和loss：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span> <span class="number">0.3572668433189392</span></span><br><span class="line"><span class="number">2</span> <span class="number">0.005662666633725166</span></span><br><span class="line"><span class="number">3</span> <span class="number">0.00011592111695790663</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>喜欢文章可以点赞收藏，欢迎关注，如有错误请指正！</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>史上最详细的Pytorch+CUDA+CUDNN的安装(GPU版)</title>
      <link href="/posts/61569.html"/>
      <url>/posts/61569.html</url>
      
        <content type="html"><![CDATA[<p>炒鸡详细的pytorch GPU安装版本，从0搭建！</p><span id="more"></span><p>CPU版本的教程<a href="https://blog.csdn.net/weixin_51756104/article/details/124222546">请点击此处查看</a></p><h3 id="首先看一下自己的驱动："><a href="#首先看一下自己的驱动：" class="headerlink" title="首先看一下自己的驱动："></a>首先看一下自己的驱动：</h3><p>·如果驱动不支持CUDA11的话就要先更新驱动<br>·打开命令行win+r，输入cmd，在命令行输入：nvidia-smi   查看信息<br><img src="https://img-blog.csdnimg.cn/f1d12b1f1cb24e11a5e70143ef5c1195.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rGfIOS4nA==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>这里可以看到我的驱动是512.2，根据下图可以看到驱动只要大于451.22就支持CUDA11，,pytorch最新本已经不支持CUDA10,如果驱动版本低于451,可以升级驱动，<a href="https://www.nvidia.com/en-us/geforce/drivers/">点击此处下载驱动</a>，下面是CUDA和显卡驱动对应的版本：<br><img src="https://img-blog.csdnimg.cn/ea404a8d657e418eaa0ab409ba8386f7.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rGfIOS4nA==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h3 id="安装Pytorch"><a href="#安装Pytorch" class="headerlink" title="安装Pytorch"></a>安装Pytorch</h3><p>此处使用的是本地安装(因为pip安装和conda安装本人都没有成功，可能是网络问题),<a href="https://download.pytorch.org/whl/torch_stable.html">点击此处</a>进行Pytorch的下载：可以看到我的CUDA是11.6版本：<br><img src="https://img-blog.csdnimg.cn/06c6e268cdfa4a2da9224cb2ba7f9b48.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rGfIOS4nA==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>我们进入下载pytorch的网站，发现还没有CUDA11.6版本，我们可以下载CUDA11.5版本，<br>cu115代表CUDA11.5版本，cp38代表python的版本，选择合适的进行下载，我下载的是CUDA11.5版本，Python版本3.8,所以我们选择：<br><img src="https://img-blog.csdnimg.cn/ac64598e145c4b3b943c9516ba7df188.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rGfIOS4nA==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>同理我们再选择torchvison和torchaudio的下载，下载完成后进行本地安装：使用pip install+安装包的路径安装，我的在D盘：<br><img src="https://img-blog.csdnimg.cn/5e018a995bc3415faf2ccdb8be245aa7.png" alt="："><br>此时我们就可以检测一下是否安装成功：<br><img src="https://img-blog.csdnimg.cn/2c27cd5cb5084ae3a502032a12bd7316.png" alt="在这里插入图片描述">可以看到已经成功了！！！</p><h3 id="CUDA安装"><a href="#CUDA安装" class="headerlink" title="CUDA安装"></a>CUDA安装</h3><p><a href="https://developer.nvidia.com/cuda-toolkit-archive">点击此处</a>，进入下载，选择合适自己的版本：<br><img src="https://img-blog.csdnimg.cn/91fb78d977294a21ae0068b7f1eb8234.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rGfIOS4nA==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>选择好信息开始下载：<br><img src="https://img-blog.csdnimg.cn/5b0e8251a48640f9b1490f335f916d84.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rGfIOS4nA==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>点击安装包，一路默认安装就行</p><h3 id="CUDNN安装"><a href="#CUDNN安装" class="headerlink" title="CUDNN安装"></a>CUDNN安装</h3><p><a href="https://developer.nvidia.com/rdp/cudnn-download">点击此处</a>，自行注册账号</p><p><img src="https://img-blog.csdnimg.cn/fcc85c8aeb184e60bf7f1899a3d3e681.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rGfIOS4nA==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>然后点击下载：需要填写调查问卷，点击提交<br><img src="https://img-blog.csdnimg.cn/55be6915942542f2b7e61f587a44e4fa.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rGfIOS4nA==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>找到相应的版本：<br><img src="https://img-blog.csdnimg.cn/84f7be9ba3e74a5bb4566b39b57ea958.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rGfIOS4nA==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>这里我的是windows CUDA11.6，所以我下载windows版本的压缩包<br><img src="https://img-blog.csdnimg.cn/cb5883133ef64418adefffb76c9aebfa.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rGfIOS4nA==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>下载完进行解压：<br><img src="https://img-blog.csdnimg.cn/69864e29e15c46afa22218a9edb63b6e.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rGfIOS4nA==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>然后找到我们CUDA11.6的位置，默认安装的在：C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA<br><img src="https://img-blog.csdnimg.cn/70e4ce0c5ba84be48fd10eecd82524af.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rGfIOS4nA==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>然后我们找到刚刚解压的cudnn文件夹<br><img src="https://img-blog.csdnimg.cn/87f93e9696584e929c591d283fc883c2.png" alt="在这里插入图片描述"><br>将bin，include，lib文件夹下里面的‘文件’分别复制到CUDA相应的文件夹里面（复制的是里面的的文件，不是文件夹）：<br><img src="https://img-blog.csdnimg.cn/69d6624d180c40d999de7c7aa76bc6dc.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rGfIOS4nA==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h3 id="查看是否安装成功"><a href="#查看是否安装成功" class="headerlink" title="查看是否安装成功"></a>查看是否安装成功</h3><p>·查看CUDA，在命令行输入：nvcc -V，出现以下代表成功：<br><img src="https://img-blog.csdnimg.cn/2bf5e7e797224b03aa842149bab8c4cf.png" alt="在这里插入图片描述"><br>·查看cudnn，我们在命令行进入安装cuda的目录，我的是：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11<span class="number">.6</span>\extras\demo_suite</span><br></pre></td></tr></table></figure><p>然后在命令行进入文件夹：<br><img src="https://img-blog.csdnimg.cn/3be6ef8c961743acad34f275013dcd1d.png" alt="在这里插入图片描述"><br>输入：bandwidthTest.exe<br><img src="https://img-blog.csdnimg.cn/c5722a063f564e788682cd13491f759a.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rGfIOS4nA==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>输入：deviceQuery.exe<br><img src="https://img-blog.csdnimg.cn/cc1b0f43a5944f03b12627fd3738dc74.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rGfIOS4nA==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>表示安装成功！！！<br>喜欢文章可以点赞收藏，欢迎关注，如有错误请指正！</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> CUDA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch线性回归的详细实现</title>
      <link href="/posts/45371.html"/>
      <url>/posts/45371.html</url>
      
        <content type="html"><![CDATA[<p>创建单层神经⽹络</p><span id="more"></span><h2 id="线性回归-单层神经网络"><a href="#线性回归-单层神经网络" class="headerlink" title="线性回归-单层神经网络"></a>线性回归-单层神经网络</h2><p>线性回归是⼀个单层神经⽹络<br><img src="https://img-blog.csdnimg.cn/590a40befa164375b9ceb587cda58445.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rGfIOS4nA==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>&amp;emsp;输⼊分别为x1和x2，因此输⼊层的输⼊个数为2,输⼊个数也叫特征数或<br>特征向量维度,输出层的输出个数为1,输出层中的神经元和输⼊层中各个输⼊完全连<br>接,因此，这⾥的输出层⼜叫全连接层,即一个简单地线性回归。<br>&amp;emsp;假设我们有三个预测数据：<br><img src="https://img-blog.csdnimg.cn/e73f69360b1d4f4b90360de495dac343.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rGfIOS4nA==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>转化为矩阵运算：<br><img src="https://img-blog.csdnimg.cn/eec385599fc3439c90c79ebce9737f30.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rGfIOS4nA==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>即<br><img src="https://img-blog.csdnimg.cn/10cf121677624495bc8ad82f4f203933.png" alt="在这里插入图片描述"></p><h2 id="代码实现："><a href="#代码实现：" class="headerlink" title="代码实现："></a>代码实现：</h2><p>首先导入所需要的包：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br></pre></td></tr></table></figure><p>生成数据集：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">num_input = <span class="number">2</span></span><br><span class="line">num_example = <span class="number">1000</span>   <span class="comment"># 1000条样本</span></span><br><span class="line"><span class="comment"># 定义标准的参数</span></span><br><span class="line">true_w = [<span class="number">2</span>, -<span class="number">3.4</span>]   </span><br><span class="line">true_b = <span class="number">4.2</span></span><br><span class="line">np.random.seed(<span class="number">2012</span>)</span><br><span class="line">features = torch.tensor(np.random.normal(<span class="number">0</span>,<span class="number">1</span>,(<span class="number">1000</span>,<span class="number">2</span>)))</span><br><span class="line"><span class="comment"># 构造标签</span></span><br><span class="line">labels = true_w[<span class="number">0</span>] * features[:, <span class="number">0</span>] + true_w[<span class="number">1</span>] * features[:, <span class="number">1</span>] +true_b</span><br><span class="line">labels += torch.from_numpy(np.random.normal(<span class="number">0</span>, <span class="number">0.01</span>,size=labels.size()))</span><br><span class="line"><span class="built_in">print</span>(features,labels)</span><br></pre></td></tr></table></figure><p>数据的读取：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">data_item</span>(<span class="params">bach_size,features,labels</span>):</span><br><span class="line">    num_examples = <span class="built_in">len</span>(features)</span><br><span class="line">    indices = <span class="built_in">list</span>(<span class="built_in">range</span>(num_examples))</span><br><span class="line">    random.shuffle(indices) <span class="comment"># 样本的读取顺序是随机的</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, num_examples, bach_size):</span><br><span class="line">        j = torch.LongTensor(indices[i: <span class="built_in">min</span>(i + bach_size,num_examples)]) <span class="comment"># 最后⼀次可能不⾜⼀个batch</span></span><br><span class="line">        <span class="keyword">yield</span> features.index_select(<span class="number">0</span>, j), labels.index_select(<span class="number">0</span>, j)</span><br></pre></td></tr></table></figure><p>随机初始化模型参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">w = torch.tensor(np.random.normal(<span class="number">0</span>, <span class="number">0.01</span>, (num_input, <span class="number">1</span>)),dtype=torch.double) </span><br><span class="line">b = torch.zeros(<span class="number">1</span>, dtype=torch.double)</span><br><span class="line">w.requires_grad = <span class="literal">True</span>     <span class="comment"># 定义为可求梯度</span></span><br><span class="line">b.requires_grad = <span class="literal">True</span></span><br></pre></td></tr></table></figure><p>定义线性回归函数，使⽤ mm 函数(矩阵相乘)：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">linear</span>(<span class="params">x,w,b</span>):</span><br><span class="line">    <span class="keyword">return</span> torch.mm(x,w)+b</span><br></pre></td></tr></table></figure><p>定义损失函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">loss</span>(<span class="params">y_hat, y</span>): <span class="comment"># 本函数已保存在d2lzh_pytorch包中⽅便以后使⽤</span></span><br><span class="line">    <span class="keyword">return</span> (y_hat - y.view(y_hat.size())) ** <span class="number">2</span> / <span class="number">2</span></span><br></pre></td></tr></table></figure><p>定义优化函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">SGD</span>(<span class="params">params, lr, batch_size</span>): <span class="comment"># 本函数已保存在d2lzh_pytorch包中⽅便以后使⽤</span></span><br><span class="line">    <span class="keyword">for</span> param <span class="keyword">in</span> params:</span><br><span class="line">        param.data -= lr * param.grad / batch_size <span class="comment"># 修改的的param.data</span></span><br></pre></td></tr></table></figure><p>训练模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">lr = <span class="number">0.03</span></span><br><span class="line">bach_size = <span class="number">30</span></span><br><span class="line">net = linear</span><br><span class="line">loss = loss</span><br><span class="line">num_epochs = <span class="number">5</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> x,y <span class="keyword">in</span> data_item(bach_size=bach_size,features=features,labels=labels):</span><br><span class="line">        los = loss(linear(x,w,b),y).<span class="built_in">sum</span>()</span><br><span class="line">        los.backward()</span><br><span class="line">        </span><br><span class="line">        SGD([w,b],lr=lr,batch_size=bach_size)</span><br><span class="line"><span class="comment">#         print(b)</span></span><br><span class="line">        w.grad.zero_()</span><br><span class="line">        b.grad.zero_()</span><br><span class="line">    train_l = loss(net(features, w, b), labels)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;epoch %d, loss %f&#x27;</span> % (epoch + <span class="number">1</span>, train_l.mean().item()))</span><br><span class="line"><span class="built_in">print</span>(true_w, <span class="string">&#x27;\n&#x27;</span>, w)</span><br><span class="line"><span class="built_in">print</span>(true_b, <span class="string">&#x27;\n&#x27;</span>, b)</span><br></pre></td></tr></table></figure><p>喜欢文章可以点赞收藏，欢迎关注，如有错误请指正！</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 线性回归 </tag>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch自动求梯度</title>
      <link href="/posts/18008.html"/>
      <url>/posts/18008.html</url>
      
        <content type="html"><![CDATA[<p>创建Tensor的几种方式</p><span id="more"></span><h1 id="微分"><a href="#微分" class="headerlink" title="微分"></a>微分</h1><p>通常我们见到的微分方法有两种：<br>·符号微分法：<br><img src="https://img-blog.csdnimg.cn/bbaa997b4ed34967a69068ebfa46d97d.png" alt="在这里插入图片描述"><br>·数值微分法：<br><img src="https://img-blog.csdnimg.cn/ac854fda494b48c1825b1c860dc258f8.png" alt="∂f(x)/∂x=lim┬ℎ→0f(x+ℎ)−f(x)/ℎ"></p><h1 id="Pytorch自动微分"><a href="#Pytorch自动微分" class="headerlink" title="Pytorch自动微分"></a>Pytorch自动微分</h1><p>对于一个Tensor，如果它的属性requires_grad 设置为 True，它将开始追<br>踪(track)在其上的所有操作<br>我们定义一个初始的tensor并且requires_grad 设置为 True：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.ones(<span class="number">2</span>, <span class="number">2</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>]], requires_grad=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>此时，我们在x的基础上进行运算：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y = x + <span class="number">2</span></span><br><span class="line"><span class="built_in">print</span>(y)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tensor([[<span class="number">3.</span>, <span class="number">3.</span>],</span><br><span class="line">        [<span class="number">3.</span>, <span class="number">3.</span>]], grad_fn=&lt;AddBackward0&gt;)</span><br><span class="line"><span class="comment"># grad_fn属性代表y是否由运算得来</span></span><br></pre></td></tr></table></figure><p>此时我们就可以进一步运算：out &#x3D;（x+2）**2</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">z = y * y * <span class="number">3</span></span><br><span class="line">out = z.mean()</span><br><span class="line"><span class="built_in">print</span>(z, out)</span><br></pre></td></tr></table></figure><p>反向传播：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">out.backward() <span class="comment"># 等价于 out.backward(torch.tensor(1.))</span></span><br></pre></td></tr></table></figure><p>此时我们就可以输出x的梯度：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(x.grad)</span><br></pre></td></tr></table></figure><p>注意：grad在反向传播过程中是累加的(accumulated)，这意味着每⼀次运⾏反向传播，梯度都会累加之前的梯度，所以⼀般在反向传播之前需把梯度清零</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([[<span class="number">4.5000</span>, <span class="number">4.5000</span>],</span><br><span class="line">        [<span class="number">4.5000</span>, <span class="number">4.5000</span>]])</span><br></pre></td></tr></table></figure><p>为什么会输出这个值呢？接下来看一下过程：<br>我们可以写出out的等式：<br><img src="https://img-blog.csdnimg.cn/8aee7ec7069c4ea5b5e54a8fcaf7d344.png" alt="在这里插入图片描述"><br>此时我们求o关于x的偏导：<br><img src="https://img-blog.csdnimg.cn/d01a2a217b0146faa398d2a078b6f8df.png" alt="在这里插入图片描述"><br>那么我们在在进行求梯度时为什么要求out的梯度呢？为什么最后要z.mean()呢？<br>很显然我们直接y.backward()会报错<img src="https://img-blog.csdnimg.cn/812ca92f731f4290909e9d92c40502a0.png" alt="在这里插入图片描述"></p><p>这是因为：在 y.backward() 时，如果 y 是标量，则不需要为 backward() 传⼊任何参数；否则，需要传⼊⼀个与 y 同形的 Tensor 。<br>在pytorch中：不允许张量对张量求导，只允许标量对张量求导，求导结果是和⾃变量同形的张量。所以必要时我们要把张量通过将所有张量的元素加权求和的方式转换为标量<br>接下来看一个实际的栗子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor([<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>, <span class="number">4.0</span>], requires_grad=<span class="literal">True</span>) </span><br><span class="line">y = <span class="number">2</span> * x </span><br><span class="line"><span class="built_in">print</span>(y)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([<span class="number">2.</span>, <span class="number">4.</span>, <span class="number">6.</span>, <span class="number">8.</span>], grad_fn=&lt;MulBackward0&gt;)</span><br></pre></td></tr></table></figure><p>此时我们直接y.backward()会报错，因为y不是标量，所以我们按照要求应该传入一个同形的张量，作为权重：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">t = torch.tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>])</span><br><span class="line">y.backward(t)</span><br><span class="line"><span class="built_in">print</span>(x.grad)</span><br></pre></td></tr></table></figure><p>d(y) &#x3D; 2<br>求导的同时也应该乘以相应的权重t &#x3D; torch.tensor([1,2,3,4])，所以最后输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([<span class="number">2.</span>, <span class="number">4.</span>, <span class="number">6.</span>, <span class="number">8.</span>])</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>喜欢文章可以点赞收藏，欢迎关注，如有错误请指正！</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 梯度 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch中Tensor的创建</title>
      <link href="/posts/11152.html"/>
      <url>/posts/11152.html</url>
      
        <content type="html"><![CDATA[<p>创建Tensor的几种方式</p><span id="more"></span><h1 id="创建Tensor"><a href="#创建Tensor" class="headerlink" title="创建Tensor"></a>创建Tensor</h1><h3 id="创建一个5行3列未初始化的tensor"><a href="#创建一个5行3列未初始化的tensor" class="headerlink" title="创建一个5行3列未初始化的tensor"></a>创建一个5行3列未初始化的tensor</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.empty(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[<span class="number">1.0194e-38</span>, <span class="number">1.0469e-38</span>, <span class="number">1.0010e-38</span>],</span><br><span class="line">        [<span class="number">8.9081e-39</span>, <span class="number">8.9082e-39</span>, <span class="number">5.9694e-39</span>],</span><br><span class="line">        [<span class="number">8.9082e-39</span>, <span class="number">1.0194e-38</span>, <span class="number">9.1837e-39</span>],</span><br><span class="line">        [<span class="number">4.6837e-39</span>, <span class="number">9.2755e-39</span>, <span class="number">1.0837e-38</span>],</span><br><span class="line">        [<span class="number">8.4490e-39</span>, <span class="number">1.1112e-38</span>, <span class="number">1.0194e-38</span>]])</span><br></pre></td></tr></table></figure><h3 id="创建一个5行3列随机初始化的tensor："><a href="#创建一个5行3列随机初始化的tensor：" class="headerlink" title="创建一个5行3列随机初始化的tensor："></a>创建一个5行3列随机初始化的tensor：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.rand(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[<span class="number">0.5911</span>, <span class="number">0.9191</span>, <span class="number">0.9826</span>],</span><br><span class="line">        [<span class="number">0.4801</span>, <span class="number">0.1648</span>, <span class="number">0.8578</span>],</span><br><span class="line">        [<span class="number">0.9937</span>, <span class="number">0.8051</span>, <span class="number">0.6952</span>],</span><br><span class="line">        [<span class="number">0.9682</span>, <span class="number">0.1975</span>, <span class="number">0.1151</span>],</span><br><span class="line">        [<span class="number">0.2434</span>, <span class="number">0.2917</span>, <span class="number">0.7866</span>]])</span><br></pre></td></tr></table></figure><h3 id="创建Tensor还可以指定数据类型：创建一个5行3列的类型为long的全0数据"><a href="#创建Tensor还可以指定数据类型：创建一个5行3列的类型为long的全0数据" class="headerlink" title="创建Tensor还可以指定数据类型：创建一个5行3列的类型为long的全0数据"></a>创建Tensor还可以指定数据类型：创建一个5行3列的类型为long的全0数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.zeros(<span class="number">5</span>, <span class="number">3</span>, dtype=torch.long)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">        [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">        [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">        [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">        [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]])</span><br></pre></td></tr></table></figure><h3 id="直接输入数据进行创建tensor："><a href="#直接输入数据进行创建tensor：" class="headerlink" title="直接输入数据进行创建tensor："></a>直接输入数据进行创建tensor：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line"><span class="built_in">print</span>(x)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br></pre></td></tr></table></figure><h3 id="根据现有的tensor创建新的tensor："><a href="#根据现有的tensor创建新的tensor：" class="headerlink" title="根据现有的tensor创建新的tensor："></a>根据现有的tensor创建新的tensor：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn_like(x,dtype = torch.float64)</span><br><span class="line">x</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[-<span class="number">0.6669</span>,  <span class="number">0.5308</span>,  <span class="number">1.5981</span>],</span><br><span class="line">        [ <span class="number">1.2061</span>,  <span class="number">0.6624</span>, -<span class="number">0.4535</span>],</span><br><span class="line">        [-<span class="number">0.5667</span>, -<span class="number">0.8755</span>, -<span class="number">2.1078</span>],</span><br><span class="line">        [-<span class="number">3.0560</span>, -<span class="number">0.6035</span>,  <span class="number">0.7990</span>],</span><br><span class="line">        [-<span class="number">0.3979</span>, -<span class="number">1.3582</span>, -<span class="number">0.8427</span>]], dtype=torch.float64)</span><br></pre></td></tr></table></figure><h3 id="2根据numpy创建新的tensor："><a href="#2根据numpy创建新的tensor：" class="headerlink" title="2根据numpy创建新的tensor："></a>2根据numpy创建新的tensor：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># tensor转化为array</span></span><br><span class="line">a = torch.ones(<span class="number">5</span>,<span class="number">3</span>)</span><br><span class="line">b = a.numpy()</span><br><span class="line">b</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">array([[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">       [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">       [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">       [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">       [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>]], dtype=float32)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将array转化为tensor</span></span><br><span class="line">x = torch.from_numpy(b)</span><br><span class="line">x</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>]])</span><br></pre></td></tr></table></figure><p>不过要注意的是：无论是array转化为tensor，还是tensor转化为array，他们都是和原来的数据共享内存的，例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">b+=<span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(b)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">2.</span> <span class="number">2.</span> <span class="number">2.</span>]</span><br><span class="line"> [<span class="number">2.</span> <span class="number">2.</span> <span class="number">2.</span>]</span><br><span class="line"> [<span class="number">2.</span> <span class="number">2.</span> <span class="number">2.</span>]</span><br><span class="line"> [<span class="number">2.</span> <span class="number">2.</span> <span class="number">2.</span>]</span><br><span class="line"> [<span class="number">2.</span> <span class="number">2.</span> <span class="number">2.</span>]]</span><br><span class="line">tensor([[<span class="number">2.</span>, <span class="number">2.</span>, <span class="number">2.</span>],</span><br><span class="line">        [<span class="number">2.</span>, <span class="number">2.</span>, <span class="number">2.</span>],</span><br><span class="line">        [<span class="number">2.</span>, <span class="number">2.</span>, <span class="number">2.</span>],</span><br><span class="line">        [<span class="number">2.</span>, <span class="number">2.</span>, <span class="number">2.</span>],</span><br><span class="line">        [<span class="number">2.</span>, <span class="number">2.</span>, <span class="number">2.</span>]])</span><br><span class="line"><span class="comment"># b的数值发生变化，x的数值也发生变化，需要注意</span></span><br></pre></td></tr></table></figure><p>更多详情请查看<a href="https://pytorch.org/docs/stable/tensors.html">官方文档</a><br>喜欢文章可以点赞收藏，欢迎关注，如有错误请指正！</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用anacond prompt安装pytorch(CPU版)</title>
      <link href="/posts/51014.html"/>
      <url>/posts/51014.html</url>
      
        <content type="html"><![CDATA[<p>利用anaconda搭建一个新环境并安装CPU版本的pytorch</p><span id="more"></span><h1 id="使用anacond-prompt安装pytorch"><a href="#使用anacond-prompt安装pytorch" class="headerlink" title="使用anacond prompt安装pytorch"></a>使用anacond prompt安装pytorch</h1><p>GPU版本的教程<a href="https://blog.csdn.net/weixin_51756104/article/details/124398722?spm=1001.2014.3001.5501">请点击此处查看</a><br>·首先去anaconda<a href="https://www.anaconda.com/">官网</a>安装anaconda，然后打开anaconda prompt（pycharm配置环境略过）：<br>在命令行输入：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Conda create –n pytorch python=<span class="number">3.8</span></span><br></pre></td></tr></table></figure><p>来创建一个关于pytorch的单独环境<br>这里的‘pytorch’是环境名称，python&#x3D;3.8是版本，都可以根据需求自行修改<br>然后就可以进入我们创建好的虚拟环境：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">activate pytorch</span><br></pre></td></tr></table></figure><p>然后我们可以切换一下源：切换源能够更快的下载 包<br>配置清华源，在命令行输入：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/</span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/</span><br><span class="line">conda config --<span class="built_in">set</span> show_channel_urls yes</span><br></pre></td></tr></table></figure><p>然后一切准备工作做好之后，接下来开始安装pytorch，在命令行输入：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install pytorch torchvision torchaudio cpuonly -c pytorch   </span><br></pre></td></tr></table></figure><p>输入之后等待一会再输入‘y’（确认下载）<br>最后在命令行输入：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip <span class="built_in">list</span></span><br></pre></td></tr></table></figure><p>然后会列出这个环境所有的包，可以查看有没有‘torch’<br><img src="https://img-blog.csdnimg.cn/dc71bab57e4141bab8c166d8686d310d.png" alt="休闲就"><br>出现torch就代表成功了！<br>欢迎关注作者，有什么问题可以一起讨论！</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>快速安装python包</title>
      <link href="/posts/28662.html"/>
      <url>/posts/28662.html</url>
      
        <content type="html"><![CDATA[<p>使用源快速安装python包</p><span id="more"></span><p>使用以下代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -i https://pypi.tuna.tsinghua.edu.cn/simple    </span><br></pre></td></tr></table></figure><p>在最后加上你要安装的包，就OK了<br>例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -i https://pypi.tuna.tsinghua.edu.cn/simple pandas</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 逻辑回归 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python修改论文的字体及其大小</title>
      <link href="/posts/56460.html"/>
      <url>/posts/56460.html</url>
      
        <content type="html"><![CDATA[<p>使用python读取数据并修改文章字体相关格式和大小</p><span id="more"></span><h2 id="对标题的格式修改"><a href="#对标题的格式修改" class="headerlink" title="对标题的格式修改"></a>对标题的格式修改</h2><p>·首先是导入包和读取word文档</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> docx <span class="keyword">import</span> Document</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> docx.shared <span class="keyword">import</span> Pt, RGBColor  <span class="comment"># 字号，颜色</span></span><br><span class="line"><span class="keyword">from</span> docx.oxml.ns <span class="keyword">import</span> qn  <span class="comment"># 中文字体</span></span><br><span class="line"></span><br><span class="line">file = Document(<span class="string">&quot;E:\\File\\大一\\大一下学期/马克思.docx&quot;</span>)</span><br></pre></td></tr></table></figure><p>然后对字体进行修改</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> run <span class="keyword">in</span> file.paragraphs:</span><br><span class="line">    <span class="keyword">if</span> re.<span class="keyword">match</span>(<span class="string">&#x27;^Heading \d+$&#x27;</span>, run.style.name):   <span class="comment"># 找出所有标题</span></span><br><span class="line">        <span class="keyword">for</span> kuai <span class="keyword">in</span> run.runs:</span><br><span class="line">            kuai._element.rPr.rFonts.<span class="built_in">set</span>(qn(<span class="string">&#x27;w:eastAsia&#x27;</span>), <span class="string">&#x27;黑体&#x27;</span>)</span><br><span class="line">            kuai.font.size = Pt(<span class="number">42</span>)   <span class="comment"># 修改字号</span></span><br><span class="line">            kuai.font.bold = <span class="literal">True</span>  <span class="comment"># 加粗</span></span><br></pre></td></tr></table></figure><h2 id="对文章内容对修改"><a href="#对文章内容对修改" class="headerlink" title="对文章内容对修改"></a>对文章内容对修改</h2><p>·对正文的修改：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> run <span class="keyword">in</span> file.paragraphs:</span><br><span class="line">    <span class="keyword">if</span> run.style.name == <span class="string">&quot;Normal&quot;</span>:</span><br><span class="line">        <span class="keyword">for</span> kuai <span class="keyword">in</span> run.runs:</span><br><span class="line">            kuai._element.rPr.rFonts.<span class="built_in">set</span>(qn(<span class="string">&#x27;w:eastAsia&#x27;</span>), <span class="string">&#x27;黑体&#x27;</span>)</span><br><span class="line">            kuai.font.size = Pt(<span class="number">42</span>)</span><br><span class="line">            <span class="built_in">print</span>(run.text)</span><br></pre></td></tr></table></figure><p>由于是对整篇论文进行修改，所以又改变了一下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">title = []    <span class="comment"># 存入非段落内容数据</span></span><br><span class="line"><span class="keyword">for</span> run <span class="keyword">in</span> file.paragraphs:</span><br><span class="line">    <span class="keyword">if</span> re.<span class="keyword">match</span>(<span class="string">&#x27;^Heading \d+$&#x27;</span>, run.style.name):</span><br><span class="line">        title.append(run.text)</span><br><span class="line">    <span class="keyword">elif</span> run.style.name == <span class="string">&quot;Normal&quot;</span>:</span><br><span class="line">        title.append(run.text)</span><br><span class="line"><span class="keyword">for</span> run <span class="keyword">in</span> file.paragraphs:</span><br><span class="line">    <span class="keyword">if</span> run.text <span class="keyword">not</span> <span class="keyword">in</span> title:</span><br><span class="line">        <span class="keyword">for</span> kuai <span class="keyword">in</span> run.runs:</span><br><span class="line">            <span class="keyword">if</span> kuai.text <span class="keyword">not</span> <span class="keyword">in</span> title:</span><br><span class="line">                <span class="built_in">print</span>(kuai)</span><br><span class="line">                <span class="comment"># kuai.font.size = Pt(42)</span></span><br><span class="line">                kuai.font.color.rgb = RGBColor(<span class="number">200</span>, <span class="number">100</span> , <span class="number">200</span>)</span><br><span class="line">                <span class="comment"># kuai.font.name = &#x27;Arial&#x27;</span></span><br><span class="line">                <span class="comment"># kuai._element.rPr.rFonts.set(qn(&#x27;w:eastAsia&#x27;),&#x27;黑体&#x27;)</span></span><br></pre></td></tr></table></figure><p>最后不要忘记保存文件</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">file.save(<span class="string">&quot;E:/aa.docx&quot;</span>)</span><br></pre></td></tr></table></figure><p>(在设计全文数据库系统项目中，将论文进行最后的标准化)</p>]]></content>
      
      
      <categories>
          
          <category> Python办公自动化 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python办公自动化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python读取word文档</title>
      <link href="/posts/44024.html"/>
      <url>/posts/44024.html</url>
      
        <content type="html"><![CDATA[<p>读取文章并输出各级标题</p><span id="more"></span><h2 id="读取文件内容"><a href="#读取文件内容" class="headerlink" title="读取文件内容"></a>读取文件内容</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> docx <span class="keyword">import</span> Document</span><br><span class="line">file = Document(<span class="string">&quot;E:\\File\\大一\\大一下学期/马克思.docx&quot;</span>)</span><br></pre></td></tr></table></figure><p>我们直接输出文章内容是不可以的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(file)</span><br><span class="line"><span class="comment"># &lt;docx.document.Document object at 0x000002686EE048C0&gt;</span></span><br></pre></td></tr></table></figure><p>我们可以使用循环的方式进行输出text文本：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 输出内容</span></span><br><span class="line"><span class="keyword">for</span> run <span class="keyword">in</span> file.paragraphs:</span><br><span class="line">    <span class="built_in">print</span>(run.text)</span><br></pre></td></tr></table></figure><h2 id="输出文章的标题"><a href="#输出文章的标题" class="headerlink" title="输出文章的标题"></a>输出文章的标题</h2><h3 id="输出文章的1级标题"><a href="#输出文章的1级标题" class="headerlink" title="输出文章的1级标题"></a>输出文章的1级标题</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> run <span class="keyword">in</span> file.paragraphs:</span><br><span class="line">    <span class="keyword">if</span> run.style.name == <span class="string">&quot;Heading 1&quot;</span>:    <span class="comment"># &#x27;Heading 2&#x27; 表示二级标题...</span></span><br><span class="line">        <span class="built_in">print</span>(run.text)</span><br></pre></td></tr></table></figure><h3 id="输出文章的多级标题"><a href="#输出文章的多级标题" class="headerlink" title="输出文章的多级标题"></a>输出文章的多级标题</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 输出所有标题</span></span><br><span class="line"><span class="keyword">for</span> run <span class="keyword">in</span> file.paragraphs:</span><br><span class="line">    <span class="keyword">if</span> re.<span class="keyword">match</span>(<span class="string">&#x27;^Heading \d+$&#x27;</span>, run.style.name):</span><br><span class="line">        <span class="built_in">print</span>(run.text)</span><br></pre></td></tr></table></figure><h2 id="输出正文"><a href="#输出正文" class="headerlink" title="输出正文"></a>输出正文</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 输出正文</span></span><br><span class="line"><span class="keyword">for</span> run <span class="keyword">in</span> file.paragraphs:</span><br><span class="line">    <span class="keyword">if</span> run.style.name == <span class="string">&quot;Normal&quot;</span>:</span><br><span class="line">        <span class="built_in">print</span>(run.text)</span><br></pre></td></tr></table></figure><h2 id="输出段落内容："><a href="#输出段落内容：" class="headerlink" title="输出段落内容："></a>输出段落内容：</h2><h3 id="输出一段的内容"><a href="#输出一段的内容" class="headerlink" title="输出一段的内容"></a>输出一段的内容</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">file.paragraphs[<span class="number">0</span>].text</span><br><span class="line"><span class="comment"># 如果该段为空格或者其他非段落内容，则输出这一行</span></span><br></pre></td></tr></table></figure><h3 id="输出所有段落的内容"><a href="#输出所有段落的内容" class="headerlink" title="输出所有段落的内容"></a>输出所有段落的内容</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(file.paragraphs)):</span><br><span class="line">    <span class="built_in">print</span>(i, file.paragraphs[<span class="number">0</span>].text)</span><br></pre></td></tr></table></figure><h2 id="保存文章"><a href="#保存文章" class="headerlink" title="保存文章"></a>保存文章</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">file.save(<span class="string">&quot;E:/aa.docx&quot;</span>)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Python办公自动化 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>KNN实现手写字体的识别</title>
      <link href="/posts/12311.html"/>
      <url>/posts/12311.html</url>
      
        <content type="html"><![CDATA[<p>KNN实现对digits数据集分类</p><span id="more"></span><h2 id="KNN算法介绍："><a href="#KNN算法介绍：" class="headerlink" title="KNN算法介绍："></a>KNN算法介绍：</h2><p><a href="http://localhost:4000/2021/09/20/2021-09-20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95-KNN/">点击这里查看KNN算法代码及其介绍</a></p><h2 id="数据的导入："><a href="#数据的导入：" class="headerlink" title="数据的导入："></a>数据的导入：</h2><h3 id="导入包"><a href="#导入包" class="headerlink" title="导入包"></a>导入包</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure><h3 id="导入数据集"><a href="#导入数据集" class="headerlink" title="导入数据集"></a>导入数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 手写字体的数据集导入</span></span><br><span class="line">digtis = datasets.load_digits()</span><br><span class="line">target = digtis.target</span><br><span class="line">data = digtis.data</span><br></pre></td></tr></table></figure><h2 id="数据集介绍："><a href="#数据集介绍：" class="headerlink" title="数据集介绍："></a>数据集介绍：</h2><p>数据集情况：1797条数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data.shape, target.shape</span><br><span class="line"><span class="comment"># (1797, 64), (1797,))</span></span><br></pre></td></tr></table></figure><p>对于导入的数据集data里面的每个数据的形状是(64,)，我们可以将其转化为8X8像素的数据，将第一个数据进行可视化展示：<br>形状转换：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">ima = data[<span class="number">0</span>].reshape(<span class="number">8</span>, <span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">Out：</span><br><span class="line">array([[ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">5.</span>, <span class="number">13.</span>,  <span class="number">9.</span>,  <span class="number">1.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">       [ <span class="number">0.</span>,  <span class="number">0.</span>, <span class="number">13.</span>, <span class="number">15.</span>, <span class="number">10.</span>, <span class="number">15.</span>,  <span class="number">5.</span>,  <span class="number">0.</span>],</span><br><span class="line">       [ <span class="number">0.</span>,  <span class="number">3.</span>, <span class="number">15.</span>,  <span class="number">2.</span>,  <span class="number">0.</span>, <span class="number">11.</span>,  <span class="number">8.</span>,  <span class="number">0.</span>],</span><br><span class="line">       [ <span class="number">0.</span>,  <span class="number">4.</span>, <span class="number">12.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">8.</span>,  <span class="number">8.</span>,  <span class="number">0.</span>],</span><br><span class="line">       [ <span class="number">0.</span>,  <span class="number">5.</span>,  <span class="number">8.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">9.</span>,  <span class="number">8.</span>,  <span class="number">0.</span>],</span><br><span class="line">       [ <span class="number">0.</span>,  <span class="number">4.</span>, <span class="number">11.</span>,  <span class="number">0.</span>,  <span class="number">1.</span>, <span class="number">12.</span>,  <span class="number">7.</span>,  <span class="number">0.</span>],</span><br><span class="line">       [ <span class="number">0.</span>,  <span class="number">2.</span>, <span class="number">14.</span>,  <span class="number">5.</span>, <span class="number">10.</span>, <span class="number">12.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">       [ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">6.</span>, <span class="number">13.</span>, <span class="number">10.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>]])</span><br></pre></td></tr></table></figure><p>可视化：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.imshow(ima)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/9266273c20ce45b6baf6ddc299ce7eb9.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h2 id="数据集的分割："><a href="#数据集的分割：" class="headerlink" title="数据集的分割："></a>数据集的分割：</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x_train, x_test, y_train, y_test = train_test_split(data, target, test_size=<span class="number">0.2</span>, random_state=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><h2 id="定义KNN函数："><a href="#定义KNN函数：" class="headerlink" title="定义KNN函数："></a>定义KNN函数：</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">knn_code</span>(<span class="params">loc, k=<span class="number">5</span>, order=<span class="number">2</span></span>):  <span class="comment"># k order是超参</span></span><br><span class="line">    <span class="comment"># print(order)</span></span><br><span class="line">    diff_loc = x_train - loc</span><br><span class="line">    dis_loc = np.linalg.norm(diff_loc, <span class="built_in">ord</span>=order, axis=<span class="number">1</span>)  <span class="comment"># 没有axis得到一个数，矩阵的泛数。axis=0，得到两个数</span></span><br><span class="line">    knn = y_train[dis_loc.argsort()[:k]]</span><br><span class="line">    counts = np.bincount(knn)</span><br><span class="line">    <span class="keyword">return</span> np.argmax(counts)</span><br></pre></td></tr></table></figure><h2 id="评估准确率："><a href="#评估准确率：" class="headerlink" title="评估准确率："></a>评估准确率：</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">res = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> x_test:</span><br><span class="line">    res.append(knn_code(i))</span><br><span class="line"></span><br><span class="line">acc = ((y_test == pd.Series(res))==<span class="literal">True</span>).<span class="built_in">sum</span>()/<span class="built_in">len</span>(y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;准确率：&quot;</span>, acc)</span><br><span class="line"><span class="comment"># 准确率： 0.9944444444444445</span></span><br></pre></td></tr></table></figure><h2 id="完整代码："><a href="#完整代码：" class="headerlink" title="完整代码："></a>完整代码：</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment"># datetime:2021/11/22 22:54</span></span><br><span class="line"><span class="comment"># software: PyCharm</span></span><br><span class="line"><span class="comment"># 导入包</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 手写字体的数据集导入</span></span><br><span class="line">digtis = datasets.load_digits()</span><br><span class="line">target = digtis.target</span><br><span class="line">data = digtis.data</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化展示</span></span><br><span class="line">ima = data[<span class="number">0</span>].reshape(<span class="number">8</span>, <span class="number">8</span>)</span><br><span class="line">plt.imshow(ima)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据集分割</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(data, target, test_size=<span class="number">0.2</span>, random_state=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># KNN函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">knn_code</span>(<span class="params">loc, k=<span class="number">5</span>, order=<span class="number">2</span></span>):  <span class="comment"># k order是超参</span></span><br><span class="line">    <span class="comment"># print(order)</span></span><br><span class="line">    diff_loc = x_train - loc</span><br><span class="line">    dis_loc = np.linalg.norm(diff_loc, <span class="built_in">ord</span>=order, axis=<span class="number">1</span>)  <span class="comment"># 没有axis得到一个数，矩阵的泛数。axis=0，得到两个数</span></span><br><span class="line">    knn = y_train[dis_loc.argsort()[:k]]</span><br><span class="line">    counts = np.bincount(knn)</span><br><span class="line">    <span class="keyword">return</span> np.argmax(counts)</span><br><span class="line"></span><br><span class="line"><span class="comment"># acc</span></span><br><span class="line">res = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> x_test:</span><br><span class="line">    res.append(knn_code(i))</span><br><span class="line"></span><br><span class="line">acc = ((y_test == pd.Series(res))==<span class="literal">True</span>).<span class="built_in">sum</span>()/<span class="built_in">len</span>(y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;准确率：&quot;</span>, acc)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> KNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>判断两篇文章的相似度</title>
      <link href="/posts/3363.html"/>
      <url>/posts/3363.html</url>
      
        <content type="html"><![CDATA[<p>textrank:将待抽取关键词的文本进行分词,以固定窗口大小，词之间的共现关系，构建图</p><span id="more"></span><h2 id="基于jieba-关键字提取的方法"><a href="#基于jieba-关键字提取的方法" class="headerlink" title="基于jieba 关键字提取的方法"></a>基于jieba 关键字提取的方法</h2><h3 id="textrank"><a href="#textrank" class="headerlink" title="textrank"></a>textrank</h3><p> 1，将待抽取关键词的文本进行分词<br> 2，以固定窗口大小(默认为5，通过span属性调整)，词之间的共现关系，构建图<br> 3，计算图中节点的PageRank，注意是无向带权图</p><h3 id="·关键字的提取代码："><a href="#·关键字的提取代码：" class="headerlink" title="·关键字的提取代码："></a>·关键字的提取代码：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#textrank</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">testRank</span>(<span class="params">corpus1, corpus2</span>):</span><br><span class="line">    keywords_textrank1 = jieba.analyse.textrank(corpus1, <span class="number">15</span>)    <span class="comment"># 提取15个关键字</span></span><br><span class="line">    keywords_textrank2 = jieba.analyse.textrank(corpus2, <span class="number">15</span>)</span><br><span class="line">    <span class="keyword">return</span> keywords_textrank1, keywords_textrank2</span><br></pre></td></tr></table></figure><h3 id="tf-idf"><a href="#tf-idf" class="headerlink" title="tf-idf"></a>tf-idf</h3><p>·词频(term frequency, tf) 指的是某一个给定的词语在该文件中出现的频率<br>·你想文档频率(inverse document frequency, idf)是一个词语普遍的重要性度量，某一特定词语的idf，可以由总文件数目除以包含该词语之文件的数目，再将得到的商取以10底的对数得到<br><img src="https://img-blog.csdnimg.cn/c9ec4584d3de48f6bb3c9976f67fe01b.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/e1888228404c4d06bc1de473cabd0799.png" alt="举例"></p><h3 id="·关键字的提取代码：-1"><a href="#·关键字的提取代码：-1" class="headerlink" title="·关键字的提取代码："></a>·关键字的提取代码：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">Tfidf_extract</span>(<span class="params">corpus1, corpus2</span>):</span><br><span class="line">    <span class="comment"># tf-idf</span></span><br><span class="line">    keywords_tfidf1 = jieba.analyse.extract_tags(corpus1, <span class="number">15</span>)</span><br><span class="line">    keywords_tfidf2 = jieba.analyse.extract_tags(corpus2, <span class="number">15</span>)</span><br><span class="line">    <span class="keyword">return</span> keywords_tfidf1, keywords_tfidf2</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="统计数据"><a href="#统计数据" class="headerlink" title="统计数据"></a>统计数据</h3><p>用两篇文章提取关键字的交集除关键字的并集，得到一个简单的相似度分析</p><h3 id="统计数据的代码："><a href="#统计数据的代码：" class="headerlink" title="统计数据的代码："></a>统计数据的代码：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">count_word</span>(<span class="params">A, B</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">round</span>((<span class="built_in">len</span>(<span class="built_in">set</span>(A).intersection(<span class="built_in">set</span>(B)))/<span class="built_in">len</span>(<span class="built_in">set</span>(A).union(<span class="built_in">set</span>(B)))), <span class="number">4</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="完整代码："><a href="#完整代码：" class="headerlink" title="完整代码："></a>完整代码：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment"># author:小皮</span></span><br><span class="line"><span class="comment"># datetime:2021/11/21 13:06</span></span><br><span class="line"><span class="comment"># software: PyCharm</span></span><br><span class="line"><span class="keyword">import</span> jieba.analyse</span><br><span class="line"></span><br><span class="line"><span class="comment">#准备语料</span></span><br><span class="line">corpus1 = <span class="string">&quot;今天是星期日，中午我买了一个鸡腿&quot;</span></span><br><span class="line">corpus2 = <span class="string">&quot;今天是星期一，中午我买了一杯可乐&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#textrank</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">testRank</span>(<span class="params">corpus1, corpus2</span>):</span><br><span class="line">    keywords_textrank1 = jieba.analyse.textrank(corpus1, <span class="number">15</span>)</span><br><span class="line">    keywords_textrank2 = jieba.analyse.textrank(corpus2, <span class="number">15</span>)</span><br><span class="line">    <span class="keyword">return</span> keywords_textrank1, keywords_textrank2</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Tfidf_extract</span>(<span class="params">corpus1, corpus2</span>):</span><br><span class="line">    <span class="comment"># tf-idf</span></span><br><span class="line">    keywords_tfidf1 = jieba.analyse.extract_tags(corpus1, <span class="number">15</span>)</span><br><span class="line">    keywords_tfidf2 = jieba.analyse.extract_tags(corpus2, <span class="number">15</span>)</span><br><span class="line">    <span class="keyword">return</span> keywords_tfidf1, keywords_tfidf2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">count_word</span>(<span class="params">A, B</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">round</span>((<span class="built_in">len</span>(<span class="built_in">set</span>(A).intersection(<span class="built_in">set</span>(B)))/<span class="built_in">len</span>(<span class="built_in">set</span>(A).union(<span class="built_in">set</span>(B)))), <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">corpus_ran1, corpus_ran2 = testRank(corpus1, corpus2)</span><br><span class="line">corpus_tif1, corpus_tif2 = Tfidf_extract(corpus1, corpus2)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;相似度：&quot;</span>, count_word(corpus1, corpus2))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;相似度：&quot;</span>, count_word(corpus_tif1, corpus_tif2))</span><br><span class="line"><span class="comment"># 相似度： 0.6316</span></span><br><span class="line"><span class="comment"># 相似度： 0.25</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> textrank </tag>
            
            <tag> tf-idf </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DBSCAN聚类算法原理以及代码</title>
      <link href="/posts/37703.html"/>
      <url>/posts/37703.html</url>
      
        <content type="html"><![CDATA[<p>算法里面有两个参数，一个是半径，另一个是数量，根据半径划分范围</p><span id="more"></span><h2 id="简单理解"><a href="#简单理解" class="headerlink" title="简单理解"></a>简单理解</h2><p>算法里面有两个参数，一个是半径，另一个是数量，根据半径划分范围，在这个范围内的数据可以称为直接密度可达，然后取在这个范围内的每个数据根据半径再继续划分范围，从而达到“传播”的效果</p><h2 id="算法优点"><a href="#算法优点" class="headerlink" title="算法优点"></a>算法优点</h2><p>不需要事先知道要形成的簇类的数量。<br>可以发现任意形状的簇类。<br>对噪声敏感，更容易找到噪声</p><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入包</span></span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans   <span class="comment"># 算法</span></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris     <span class="comment"># 数据集</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split    <span class="comment"># 数据集划分</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score     <span class="comment">#评估</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler   <span class="comment"># 标准化</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV   <span class="comment"># 交叉验证网格搜索(没用到）</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">iris = load_iris()    <span class="comment"># 加载数据集</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取特征值和目标值，目标值在这里没什么用</span></span><br><span class="line">X = iris.data[:, <span class="number">1</span>:<span class="number">3</span>]</span><br><span class="line">Y = iris.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据分割，测试集为0.2，随机种子2021</span></span><br><span class="line">X_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=<span class="number">0.2</span>, random_state=<span class="number">2021</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> DBSCAN</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置半径为10，最小样本量为2，训练</span></span><br><span class="line">db = DBSCAN(eps=<span class="number">0.3</span>, min_samples=<span class="number">2</span>).fit(X_train)</span><br><span class="line">labels = db.labels_</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化</span></span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>, <span class="number">8</span>))</span><br><span class="line">plt.scatter(X_train[:, <span class="number">0</span>], X_train[:, <span class="number">1</span>], c=labels, s=<span class="number">100</span>)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/160822b78e04453aa8a18bcb7032f056.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> DBSCAN算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kmeans算法提升</title>
      <link href="/posts/6532.html"/>
      <url>/posts/6532.html</url>
      
        <content type="html"><![CDATA[<p>轮廓系数的值是介于 [-1,1] ，越趋近于1代表内聚度和分离度都相对较优，计算簇内不相似度a(i)</p><span id="more"></span><h1 id="K均值调包"><a href="#K均值调包" class="headerlink" title="K均值调包"></a>K均值调包</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入包</span></span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans   <span class="comment"># 算法</span></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris     <span class="comment"># 数据集</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split    <span class="comment"># 数据集划分</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score     <span class="comment">#评估</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler   <span class="comment"># 标准化</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV   <span class="comment"># 交叉验证网格搜索(没用到）</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">iris = load_iris()    <span class="comment"># 加载数据集</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取特征值和目标值，目标值在这里没什么用</span></span><br><span class="line">X = iris.data[:, <span class="number">1</span>:<span class="number">3</span>]</span><br><span class="line">Y = iris.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据分割，测试集为0.2，随机种子2021</span></span><br><span class="line">X_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=<span class="number">0.2</span>, random_state=<span class="number">2021</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 实例化一个估计器</span></span><br><span class="line">estimator = KMeans(n_clusters=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">estimator.fit(X_train)</span><br><span class="line"></span><br><span class="line">y_pre = estimator.predict(x_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;模型的准确率为：&quot;</span>, accuracy_score(y_test, y_pre))</span><br></pre></td></tr></table></figure><h1 id="可视化展示"><a href="#可视化展示" class="headerlink" title="可视化展示"></a>可视化展示</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入包</span></span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans   <span class="comment"># 算法</span></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris     <span class="comment"># 数据集</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split    <span class="comment"># 数据集划分</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score     <span class="comment">#评估</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler   <span class="comment"># 标准化</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV   <span class="comment"># 交叉验证网格搜索(没用到）</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">iris = load_iris()    <span class="comment"># 加载数据集</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取特征值和目标值，目标值在这里没什么用</span></span><br><span class="line">X = iris.data[:, <span class="number">1</span>:<span class="number">3</span>]</span><br><span class="line">Y = iris.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据分割，测试集为0.2，随机种子2021</span></span><br><span class="line">X_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=<span class="number">0.2</span>, random_state=<span class="number">2021</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义了一个函数进行训练和预测</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Kmeans_fun</span>(<span class="params">k</span>):</span><br><span class="line">    <span class="comment"># 实例化一个估计器</span></span><br><span class="line">    estimator = KMeans(n_clusters=k)</span><br><span class="line">    <span class="comment"># y_pre = KMeans(n_clusters=k, random_state=2021).fit_predict(X)</span></span><br><span class="line">    estimator.fit(X_train)</span><br><span class="line">    y_pre = estimator.predict(X)</span><br><span class="line">    <span class="keyword">return</span> y_pre</span><br><span class="line"></span><br><span class="line">cou = <span class="number">1</span></span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>, <span class="number">8</span>), dpi=<span class="number">100</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">10</span>):</span><br><span class="line">    y_pre = Kmeans_fun(i)</span><br><span class="line">    plt.subplot(<span class="number">330</span> + cou)</span><br><span class="line">    plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=y_pre)</span><br><span class="line">    cou += <span class="number">1</span></span><br><span class="line">    plt.title(<span class="string">&quot;第&#123;0&#125;个中心分类的结果&quot;</span>.<span class="built_in">format</span>(i))</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/a2de566429eb4fde941251eef8b7185e.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h1 id="选取最优K值"><a href="#选取最优K值" class="headerlink" title="选取最优K值"></a>选取最优K值</h1><h2 id="手肘法"><a href="#手肘法" class="headerlink" title="手肘法"></a>手肘法</h2><p>手肘发：肉眼观察K，将每个中心的E进行可视化，选取拐点</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入包</span></span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans   <span class="comment"># 算法</span></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris     <span class="comment"># 数据集</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split    <span class="comment"># 数据集划分</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score     <span class="comment">#评估</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler   <span class="comment"># 标准化</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV   <span class="comment"># 交叉验证网格搜索(没用到）</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">iris = load_iris()    <span class="comment"># 加载数据集</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取特征值和目标值，目标值在这里没什么用</span></span><br><span class="line">X = iris.data[:, <span class="number">1</span>:<span class="number">3</span>]</span><br><span class="line">Y = iris.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据分割，测试集为0.2，随机种子2021</span></span><br><span class="line">X_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=<span class="number">0.2</span>, random_state=<span class="number">2021</span>)</span><br><span class="line"></span><br><span class="line">SSE = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, <span class="number">10</span>):</span><br><span class="line">    estimator = KMeans(n_clusters=i)</span><br><span class="line">    estimator.fit(X_train, y_train)</span><br><span class="line">    SSE.append(estimator.inertia_)</span><br><span class="line"></span><br><span class="line">X = <span class="built_in">range</span>(<span class="number">2</span>,<span class="number">10</span>)</span><br><span class="line">plt.scatter(X, SSE)</span><br><span class="line">plt.plot(X, SSE)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/b7c60a7fd93b49d3aef8bbf24f94bfb4.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h2 id="轮廓系数"><a href="#轮廓系数" class="headerlink" title="轮廓系数"></a>轮廓系数</h2><p>轮廓系数的值是介于 [-1,1] ，越趋近于1代表内聚度和分离度都相对较优，计算簇内不相似度a(i)(所属的簇的其他对象之间的平均距离) ：i向量到同簇内其他点不相似程度的平均值，体现凝聚，计算 簇间不相似度b(i) ：i向量到其他簇的平均不相似程度的最小值，体现分离度<br>si接近1，则说明样本i聚类合理；si接近-1，则说明样本i更应该分类到另外的簇；若si 近似为0，则说明样本i在两个簇的边界上。<br>将所有点的轮廓系数求平均，就是该聚类结果总的轮廓系数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入包</span></span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans   <span class="comment"># 算法</span></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris     <span class="comment"># 数据集</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split    <span class="comment"># 数据集划分</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score     <span class="comment">#评估</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler   <span class="comment"># 标准化</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV   <span class="comment"># 交叉验证网格搜索(没用到）</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">iris = load_iris()    <span class="comment"># 加载数据集</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取特征值和目标值，目标值在这里没什么用</span></span><br><span class="line">X = iris.data[:, <span class="number">1</span>:<span class="number">3</span>]</span><br><span class="line">Y = iris.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据分割，测试集为0.2，随机种子2021</span></span><br><span class="line">X_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=<span class="number">0.2</span>, random_state=<span class="number">2021</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Kmeans_fun</span>(<span class="params">k</span>):</span><br><span class="line">    <span class="comment"># 实例化一个估计器</span></span><br><span class="line">    estimator = KMeans(n_clusters=k)</span><br><span class="line">    <span class="comment"># y_pre = KMeans(n_clusters=k, random_state=2021).fit_predict(X)</span></span><br><span class="line">    estimator.fit(X_train)</span><br><span class="line">    res = estimator.labels_</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line">lis = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, <span class="number">100</span>):</span><br><span class="line">    res_label = Kmeans_fun(i)</span><br><span class="line">    lis.append(metrics.silhouette_score(X_train, res_label, metric=<span class="string">&#x27;euclidean&#x27;</span>, sample_size=<span class="literal">None</span>, random_state=<span class="literal">None</span>))</span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>, <span class="number">8</span>))</span><br><span class="line">plt.plot(<span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">1</span>,<span class="number">99</span>)),lis)</span><br><span class="line">plt.xlabel(<span class="string">&quot;聚类中心的数量&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;轮廓系数&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;轮廓系数和聚类中心的关系&quot;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/0e61749b3ec149e08c450eea1402ae04.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>欢迎大家关注我！！！！</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 手肘法 </tag>
            
            <tag> 轮廓系数 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>爬虫实现百度贴吧的图片爬取</title>
      <link href="/posts/46659.html"/>
      <url>/posts/46659.html</url>
      
        <content type="html"><![CDATA[<p>若想爬取其他的内容，需要将xpath进行修改，以及kw赋值为你想爬取的商品，并确保电脑的目录</p><span id="more"></span><h2 id="基本流程："><a href="#基本流程：" class="headerlink" title="基本流程："></a>基本流程：</h2><p>初始化要爬取的内容，然后使用requests模块进行爬取，使用xpath进行匹配，最后再将图片和详情存入文件夹里面</p><h2 id="代码如下："><a href="#代码如下：" class="headerlink" title="代码如下："></a>代码如下：</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> lxml.etree</span><br><span class="line"><span class="keyword">from</span> lxml.html <span class="keyword">import</span> tostring</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;初始化参数&quot;&quot;&quot;</span></span><br><span class="line">kw = <span class="string">&#x27;篮球&#x27;</span></span><br><span class="line">base_url = <span class="string">&#x27;http://tieba.baidu.com/f&#x27;</span></span><br><span class="line">headers = &#123;<span class="string">&quot;User-Agent&quot;</span>:<span class="string">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.85 Safari/537.36 Edg/90.0.818.46&quot;</span>&#125;</span><br><span class="line">page_num = <span class="number">1</span>  <span class="comment"># 爬取页数</span></span><br><span class="line">title = <span class="string">&#x27;&#x27;</span></span><br><span class="line">path = <span class="string">&#x27;E:\\作业图片\\spider\\&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">parse_text</span>(<span class="params">url, params=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;发送请求，获取响应内容&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 休眠，避免被对方反爬检测到</span></span><br><span class="line">    time.sleep(random.randint(<span class="number">1</span>, <span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">    req = requests.get(url, headers=headers, params=params)</span><br><span class="line">    <span class="keyword">return</span> req.text</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">parse_byte</span>(<span class="params">url, params=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;发送请求，获取响应内容&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    time.sleep(random.random() * <span class="number">2</span>)</span><br><span class="line">    req = requests.get(url, headers=headers, params=params)</span><br><span class="line">    <span class="keyword">return</span> req.content</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">page</span>(<span class="params">content, page_num=<span class="number">1</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;解析每一页&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;第&#123;&#125;页爬取中...&#x27;</span>.<span class="built_in">format</span>(page_num))</span><br><span class="line">    page_num += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 这一句就是为了把每个超链接匹配出来</span></span><br><span class="line">    url_title = re.findall(</span><br><span class="line">        <span class="string">r&#x27;&lt;a rel=&quot;noreferrer&quot; href=&quot;(/p/\d+?)&quot; title=&quot;.+?&quot; target=&quot;_blank&quot; class=&quot;j_th_tit &quot;&gt;(.+?)&lt;/a&gt;&#x27;</span>, content)</span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># html_get = etree.HTML(content)</span></span><br><span class="line">    <span class="comment"># div_ok = html_get.xpath(&#x27;//div[@id=&quot;mw-content-text&quot;]&#x27;)[0]</span></span><br><span class="line">    <span class="comment"># div_content = tostring(div_ok).decode(&#x27;utf-8&#x27;)</span></span><br><span class="line">    url_title1 = lxml.etree.HTML(content)</span><br><span class="line"></span><br><span class="line">    url_title2 = url_title1.xpath(<span class="string">&#x27;//*[@id=&quot;thread_list&quot;]/li/div/div[2]/div[1]/div[1]/a&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># &#x27;//*[@id=&quot;thread_list&quot;]/li[3]/div/div[2]/div[1]/div[1]/a&#x27;</span></span><br><span class="line">    <span class="comment"># &#x27;//*[@id=&quot;thread_list&quot;]/li[5]/div/div[2]/div[1]/div[1]/a&#x27;</span></span><br><span class="line">    <span class="comment"># &#x27;//*[@id=&quot;thread_list&quot;]/li[10]/div/div[2]/div[1]/div[1]/a&#x27;</span></span><br><span class="line">    <span class="comment"># &#x27;//*[@id=&quot;thread_list&quot;]/li[4]/div/div[2]/div[1]/div[1]/a&#x27;</span></span><br><span class="line">    <span class="comment"># &#x27;//*[@id=&quot;thread_list&quot;]/li[6]/div/div[2]/div[1]/div[1]/a&#x27;</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> url_title2:</span><br><span class="line">        <span class="built_in">print</span>(i)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> url, title <span class="keyword">in</span> url_title:</span><br><span class="line">        <span class="comment"># 去掉非中文</span></span><br><span class="line">        title = re.sub(<span class="string">&#x27;[^\u4e00-\u9fa5]+&#x27;</span>, <span class="string">&#x27;&#x27;</span>, title)</span><br><span class="line">        <span class="comment"># 细节处理：其实就是保存每个帖子的图片</span></span><br><span class="line">        detail(<span class="string">&#x27;https://tieba.baidu.com&#x27;</span> + url, title)</span><br><span class="line">        <span class="comment"># 保存标题</span></span><br><span class="line">        save_title(title)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 判断下一页</span></span><br><span class="line">    next_url = re.findall(<span class="string">r&#x27;&lt;a href=&quot;(.*?)&quot; .*?&gt;下一页&amp;gt;&lt;/a&gt;&#x27;</span>, content)</span><br><span class="line">    <span class="keyword">if</span> next_url:</span><br><span class="line">        next_url = <span class="string">&#x27;https:&#x27;</span> + next_url[<span class="number">0</span>]</span><br><span class="line">        content = parse_text(url=next_url)</span><br><span class="line">        page(content, page_num)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;爬虫结束...&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">detail</span>(<span class="params">url, title</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;每一个帖子的详情&quot;&quot;&quot;</span></span><br><span class="line">    content = parse_text(url=url)</span><br><span class="line">    urls = re.findall(<span class="string">r&#x27;&lt;img class=&quot;BDE_Image&quot;.*?src=&quot;(.*?)&quot;.*?&gt;&#x27;</span>, content)</span><br><span class="line">    <span class="keyword">for</span> url <span class="keyword">in</span> urls:</span><br><span class="line">        save_img(url, title)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">save_title</span>(<span class="params">title</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;保存帖子的标题&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(path + <span class="string">&#x27;tieba\\tieba_&#123;&#125;.txt&#x27;</span>.<span class="built_in">format</span>(kw), <span class="string">&#x27;a&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> file:</span><br><span class="line">        file.write(title)</span><br><span class="line">        file.write(<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">save_img</span>(<span class="params">url, title</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;保存图片&quot;&quot;&quot;</span></span><br><span class="line">    content = parse_byte(url=url)</span><br><span class="line">    image_path = path + <span class="string">&#x27;tieba\\images\\&#123;&#125;_&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(title, url[-<span class="number">30</span>:])</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(image_path, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> file:</span><br><span class="line">        file.write(content)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;爬虫开始...&#x27;</span>)</span><br><span class="line">content = parse_text(url=base_url, params=&#123;<span class="string">&#x27;kw&#x27;</span>: kw, <span class="string">&#x27;ie&#x27;</span>: <span class="string">&#x27;utf-8&#x27;</span>, <span class="string">&#x27;fr&#x27;</span>: <span class="string">&#x27;search&#x27;</span>&#125;)</span><br><span class="line">page(content)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>若想爬取其他的内容，需要将xpath进行修改，以及kw赋值为你想爬取的商品，并确保电脑的目录存在方可成功</p>]]></content>
      
      
      <categories>
          
          <category> 爬虫 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 逻辑回归 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>爬虫期末作业：爬虫+基本的天气对话机器人</title>
      <link href="/posts/36179.html"/>
      <url>/posts/36179.html</url>
      
        <content type="html"><![CDATA[<p>使用的是PyAudio库进行录音，存为wav格式的文件，这里使用的是借用科大讯飞API进行语音转文字，然后进行语音播报</p><span id="more"></span><h2 id="基本思路"><a href="#基本思路" class="headerlink" title="基本思路"></a>基本思路</h2><pre><code>    使用selenium模块来进行谷歌驱动，爬取相关的数据，然后将数据进行处理，利用正则分离数据，然后就是把每个功能包装成一个函数，利用得到的数据，实现存入数据库，以及存入csv等相关功能，还有一个就是数据可视化，先后荣立使用的是matplotlib和Pyecharts两个库，相对于matplotlib而言，Pyecharts做出的数据可视化更加的真实，可以动态交互的展现图表，然后对于语音处理方面，主要分为两个方面，一方面是录音转文字，录音的话，使用的是PyAudio库进行录音，存为wav格式的文件，这里使用的是借用科大讯飞API进行语音转文字，然后进行语音播报，使用的是Pyttsx3进行语音播报，然后可以进行死板式聊天，能力有限，并不能搭建出一套完整的人机对话项目。</code></pre><h2 id="关于数据的爬取"><a href="#关于数据的爬取" class="headerlink" title="关于数据的爬取"></a>关于数据的爬取</h2><h3 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h3><pre><code>    爬取是用的谷歌驱动后来又换成了谷歌驱动，爬取前需要安装谷歌驱动[（下载地址)](http://npm.taobao.org/mirrors/chromedriver/)，然后才可以导入，然后就是爬取对应代码里面的spider_jinan()函数和spider_shandong()函数分别爬取</code></pre><h3 id="爬取的过程分析"><a href="#爬取的过程分析" class="headerlink" title="爬取的过程分析"></a>爬取的过程分析</h3><pre><code>    用驱动打开浏览器，打开网页，通过xpath找到想要的数据，然后将数据保存为txt文件，最后关闭浏览器</code></pre><h2 id="数据可视化"><a href="#数据可视化" class="headerlink" title="数据可视化"></a>数据可视化</h2><pre><code>    使用matplotlib和pyecharts两个画图</code></pre><h2 id="数据的保存"><a href="#数据的保存" class="headerlink" title="数据的保存"></a>数据的保存</h2><pre><code>    存入数据库，存入csv</code></pre><h2 id="声音处理"><a href="#声音处理" class="headerlink" title="声音处理"></a>声音处理</h2><h3 id="录音及其转文字"><a href="#录音及其转文字" class="headerlink" title="录音及其转文字"></a>录音及其转文字</h3><pre><code>    使用的是PyAudio库，进行录音，设置的讲话时间为4秒，然后把数据保存下来，存成wav文件，然后使用wave库进行读取wav文件，设置声道数为1，采样宽度为2字节，采样率设为16000，最后将读入的文件传输给speech2text(speech, TOKEN, int(1536))函数，speech是数据，TOKEN是借助的API，int（1536）表示的是普通话，补充一下，也可以说英语，传入1737就是英语，传入1637就是粤语，传入1837就是四川话，可以传入多种数据，这里的语音识别，借助的是科大讯飞转的文字，使用科大讯飞前要进行数据的注册，注册之后会生成相应的数据，base_url,APIKey,SecretKey,这三个数据要保证传入正确才能正确的将语音转化成文字</code></pre><h3 id="关于语音播报"><a href="#关于语音播报" class="headerlink" title="关于语音播报"></a>关于语音播报</h3><pre><code>    使用的是pyttsx3库，这个播报库使用起来非常的方便，首先用pyttsx3.init()函数进行初始化，然后就是用say（）函数写出要说的内容，最后就是使用runAndWait函数进行播报，一共分为这三个步骤</code></pre><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><pre><code>    首先要去[讯飞平台](https://www.xfyun.cn/services/online_tts)注册账号，然后就会获得APIKey和SecretKey，才能进行语音转文字</code></pre><p>需填入方可使用</p><p><img src="https://img-blog.csdnimg.cn/17921d845ceb4f5fa903a091e88e43af.png"><br>代码如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br><span class="line">524</span><br><span class="line">525</span><br><span class="line">526</span><br><span class="line">527</span><br><span class="line">528</span><br><span class="line">529</span><br><span class="line">530</span><br><span class="line">531</span><br><span class="line">532</span><br><span class="line">533</span><br><span class="line">534</span><br><span class="line">535</span><br><span class="line">536</span><br><span class="line">537</span><br><span class="line">538</span><br><span class="line">539</span><br><span class="line">540</span><br><span class="line">541</span><br><span class="line">542</span><br><span class="line">543</span><br><span class="line">544</span><br><span class="line">545</span><br><span class="line">546</span><br><span class="line">547</span><br><span class="line">548</span><br><span class="line">549</span><br><span class="line">550</span><br><span class="line">551</span><br><span class="line">552</span><br><span class="line">553</span><br><span class="line">554</span><br><span class="line">555</span><br><span class="line">556</span><br><span class="line">557</span><br><span class="line">558</span><br><span class="line">559</span><br><span class="line">560</span><br><span class="line">561</span><br><span class="line">562</span><br><span class="line">563</span><br><span class="line">564</span><br><span class="line">565</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment"># author:杜小皮</span></span><br><span class="line"><span class="comment"># datetime:2021/6/23 10:41</span></span><br><span class="line"><span class="comment"># software: PyCharm</span></span><br><span class="line"><span class="keyword">import</span> wave</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> base64</span><br><span class="line"><span class="keyword">from</span> pyaudio <span class="keyword">import</span> PyAudio, paInt16</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> sleep</span><br><span class="line"><span class="keyword">import</span> pyttsx3</span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> wordcloud <span class="keyword">import</span> WordCloud</span><br><span class="line"><span class="keyword">from</span> imageio <span class="keyword">import</span> imread</span><br><span class="line"><span class="keyword">import</span> collections</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pyecharts</span><br><span class="line"><span class="keyword">from</span> sqlalchemy <span class="keyword">import</span> create_engine</span><br><span class="line"></span><br><span class="line"><span class="comment"># from pyecharts import Pie</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">spider_jinan</span>():  <span class="comment"># 爬取所有数据</span></span><br><span class="line">    js = <span class="string">&quot;var q=document.documentElement.scrollTop=100000&quot;</span></span><br><span class="line"></span><br><span class="line">    driver = webdriver.Chrome()  <span class="comment"># 打开浏览器</span></span><br><span class="line">    driver.maximize_window()  <span class="comment"># 最大化窗口</span></span><br><span class="line"></span><br><span class="line">    url = <span class="string">&#x27;https://www.tianqi.com/jinan/&#x27;</span>  <span class="comment"># 打开网页</span></span><br><span class="line">    driver.get(url)</span><br><span class="line">    content = driver.page_source</span><br><span class="line"></span><br><span class="line">    cl = driver.find_elements_by_xpath(<span class="string">&quot;/html/body/div[5]/div/div[2]/div[1]/span[2]/a[2]/h3&quot;</span>)  <span class="comment"># 查看未来30天</span></span><br><span class="line">    cl[<span class="number">0</span>].click()  <span class="comment"># 此处是根据老师讲的京东代码而写</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">list</span> = driver.find_elements_by_xpath(<span class="string">&quot;/html/body/div[6]/div[2]/ul[1]&quot;</span>)  <span class="comment"># 匹配所有数据</span></span><br><span class="line">    result = <span class="built_in">list</span>[<span class="number">0</span>].text.split(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">    driver.close()</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">spider_res_jinan</span>(<span class="params">result</span>):  <span class="comment"># 数据的分离</span></span><br><span class="line">    weather = []</span><br><span class="line">    temp = []</span><br><span class="line">    data = []</span><br><span class="line">    month = []</span><br><span class="line">    day = []</span><br><span class="line">    a = <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> result:</span><br><span class="line">        a += <span class="number">1</span></span><br><span class="line">        <span class="comment"># print(i)</span></span><br><span class="line">        <span class="comment"># print(a)</span></span><br><span class="line">        b = (a % <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (b == <span class="number">0</span>):</span><br><span class="line">            <span class="comment"># print(i)</span></span><br><span class="line">            weather.append(i)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 利用正则表达式找出温度，日期，天气</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> result:</span><br><span class="line">        <span class="comment"># print(i)</span></span><br><span class="line">        lista = re.findall(<span class="string">&quot;\d&#123;2&#125;-\d&#123;2&#125;&quot;</span>, i)</span><br><span class="line">        <span class="comment"># print(data)</span></span><br><span class="line">        <span class="comment"># print(tem)</span></span><br><span class="line">        tem = re.findall(<span class="string">&quot;\d&#123;2&#125;~\d&#123;2&#125;℃&quot;</span>, i)</span><br><span class="line">        <span class="comment"># print(tem)</span></span><br><span class="line">        <span class="keyword">if</span> tem == []:</span><br><span class="line">            <span class="keyword">del</span> tem</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">for</span> iii <span class="keyword">in</span> tem:</span><br><span class="line">                temp.append(iii)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> lista == []:</span><br><span class="line">            <span class="keyword">del</span> lista</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># print(data)</span></span><br><span class="line">            <span class="keyword">for</span> ii <span class="keyword">in</span> lista:</span><br><span class="line">                <span class="comment"># print(ii)</span></span><br><span class="line">                data.append(ii)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> data:</span><br><span class="line">            month.append(i.split(<span class="string">&quot;-&quot;</span>)[<span class="number">0</span>])</span><br><span class="line">            day.append(i.split(<span class="string">&quot;-&quot;</span>)[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> weather, temp, data, month, day</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mean_temp_jinan</span>(<span class="params">temp</span>):  <span class="comment"># 求出未来30天的平均温度</span></span><br><span class="line">    temp_mean = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> temp:</span><br><span class="line">        t = <span class="number">0</span></span><br><span class="line">        <span class="comment"># print(i)</span></span><br><span class="line">        z = re.findall(<span class="string">&quot;\d&#123;2&#125;&quot;</span>, i)</span><br><span class="line">        <span class="keyword">for</span> ii <span class="keyword">in</span> z:</span><br><span class="line">            <span class="comment"># print(ii)</span></span><br><span class="line">            ii = <span class="built_in">int</span>(ii)</span><br><span class="line">            t += ii</span><br><span class="line">        temp_mean.append(t / <span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> temp_mean</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">image_jinan</span>(<span class="params">weather</span>):  <span class="comment"># 画出词云</span></span><br><span class="line">    res = pd.Series()</span><br><span class="line">    res[<span class="string">&quot;weather&quot;</span>] = pd.Series(weather)</span><br><span class="line">    qq = pd.DataFrame(&#123;<span class="string">&quot;天气&quot;</span>: res[<span class="string">&quot;weather&quot;</span>]&#125;)</span><br><span class="line">    qq.to_csv(<span class="string">&quot;E:\\tianqi.txt&quot;</span>, index=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    stop = pd.read_csv(<span class="string">&#x27;E:\\tianqi.txt&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>, engine=<span class="string">&#x27;python&#x27;</span>, sep=<span class="string">&#x27;limh&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    back_pic = imread(<span class="string">&quot;E:\\code\\spider\\week8\\word_cloud\\helle.jpg&quot;</span>)  <span class="comment"># aixin.jpg # 设置背景图片</span></span><br><span class="line">    wc = WordCloud(font_path=<span class="string">&#x27;C:\\Windows\\Fonts\\simkai.TTF&#x27;</span>,  <span class="comment"># 设置字体 使用的 windows 自带的字体</span></span><br><span class="line">                   background_color=<span class="string">&quot;white&quot;</span>,  <span class="comment"># =&quot;white&quot;, #背景颜色</span></span><br><span class="line">                   max_words=<span class="number">2000</span>,  <span class="comment"># 词云显示的最大数</span></span><br><span class="line">                   mask=back_pic,  <span class="comment"># 设置背景图片</span></span><br><span class="line">                   max_font_size=<span class="number">200</span>,  <span class="comment"># =200, #字体最大值</span></span><br><span class="line">                   random_state=<span class="number">42</span>,</span><br><span class="line">                   collocations=<span class="literal">True</span>, )</span><br><span class="line"></span><br><span class="line">    tupian = Image.<span class="built_in">open</span>(<span class="string">&quot;E:\\helle.jpg&quot;</span>)  <span class="comment"># 打开图片路径，形成轮廓</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 绘图</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">16</span>, <span class="number">8</span>))</span><br><span class="line">    plt.imshow(tupian)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">temp_to_csv</span>(<span class="params">weather, temp, data</span>):  <span class="comment"># 将数据转存为csv</span></span><br><span class="line">    results = pd.DataFrame()</span><br><span class="line">    res = pd.Series()</span><br><span class="line">    res[<span class="string">&quot;weather&quot;</span>] = pd.Series(weather)</span><br><span class="line">    res[<span class="string">&quot;temp&quot;</span>] = pd.Series(temp)</span><br><span class="line">    res[<span class="string">&quot;data&quot;</span>] = pd.Series(data)</span><br><span class="line">    results.insert(<span class="number">0</span>, <span class="string">&#x27;天气&#x27;</span>, res[<span class="string">&quot;weather&quot;</span>])</span><br><span class="line">    results.insert(<span class="number">0</span>, <span class="string">&#x27;温度&#x27;</span>, res[<span class="string">&quot;temp&quot;</span>])</span><br><span class="line">    results.insert(<span class="number">0</span>, <span class="string">&#x27;日期&#x27;</span>, res[<span class="string">&quot;data&quot;</span>])</span><br><span class="line">    <span class="comment"># print(results)</span></span><br><span class="line">    results.to_csv(<span class="string">&quot;E:\\weather.csv&quot;</span>, index=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plt_mean_temp_jinan</span>(<span class="params">data, mean__temp</span>):  <span class="comment"># 画平均温度折线图</span></span><br><span class="line">    plt.xlabel(<span class="string">&quot;天气&quot;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&quot;平均温度&quot;</span>)</span><br><span class="line">    plt.title(<span class="string">&quot;温度变化&quot;</span>)</span><br><span class="line">    plt.plot(data, mean__temp)</span><br><span class="line">    plt.grid(<span class="literal">True</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plt_fer_weather</span>(<span class="params">weather</span>):</span><br><span class="line">    tianqi = []</span><br><span class="line">    pinlv = []</span><br><span class="line">    word_counts = collections.Counter(weather)  <span class="comment"># 对分词做词频统计</span></span><br><span class="line">    word_counts_top10 = word_counts.most_common(<span class="number">10</span>)  <span class="comment"># 获取前10最高频的词</span></span><br><span class="line">    <span class="comment"># print(word_counts_top10)  # 输出检查</span></span><br><span class="line">    sun = <span class="number">0</span></span><br><span class="line">    cloud = <span class="number">0</span></span><br><span class="line">    lit_rain = <span class="number">0</span></span><br><span class="line">    mit_rain = <span class="number">0</span></span><br><span class="line">    sail = <span class="number">0</span></span><br><span class="line">    shadom = <span class="number">0</span></span><br><span class="line">    z_rain = <span class="number">0</span></span><br><span class="line">    th_rain = <span class="number">0</span></span><br><span class="line">    xiaoyu = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> word_counts_top10:</span><br><span class="line">        <span class="built_in">print</span>(i[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">if</span> i[<span class="number">0</span>] == <span class="string">&#x27;多云&#x27;</span>:</span><br><span class="line">            sun += <span class="number">1</span></span><br><span class="line">        <span class="keyword">elif</span> i[<span class="number">0</span>] == <span class="string">&#x27;阴转雨&#x27;</span>:</span><br><span class="line">            cloud += <span class="number">1</span></span><br><span class="line">        <span class="keyword">elif</span> i[<span class="number">0</span>] == <span class="string">&#x27;多云转晴&#x27;</span>:</span><br><span class="line">            lit_rain += <span class="number">1</span></span><br><span class="line">        <span class="keyword">elif</span> i[<span class="number">0</span>] == <span class="string">&#x27;小雨到大雨&#x27;</span>:</span><br><span class="line">            mit_rain += <span class="number">1</span></span><br><span class="line">        <span class="keyword">elif</span> i[<span class="number">0</span>] == <span class="string">&#x27;中雨到大雨&#x27;</span>:</span><br><span class="line">            shadom += <span class="number">1</span></span><br><span class="line">        <span class="keyword">elif</span> i[<span class="number">0</span>] == <span class="string">&#x27;多云转雨&#x27;</span>:</span><br><span class="line">            z_rain += <span class="number">1</span></span><br><span class="line">        <span class="keyword">elif</span> i[<span class="number">0</span>] == <span class="string">&#x27;小雨到中雨&#x27;</span>:</span><br><span class="line">            th_rain += <span class="number">1</span></span><br><span class="line">        <span class="keyword">elif</span> i[<span class="number">0</span>] == <span class="string">&#x27;小雨转多云&#x27;</span>:</span><br><span class="line">            sail += <span class="number">1</span></span><br><span class="line">        <span class="keyword">elif</span> i[<span class="number">0</span>] == <span class="string">&#x27;小雨转阴&#x27;</span>:</span><br><span class="line">            xiaoyu += <span class="number">1</span></span><br><span class="line">        <span class="comment"># print(i[0])</span></span><br><span class="line">        tianqi = [<span class="string">&quot;小雨转阴&quot;</span>, <span class="string">&#x27;小雨到大雨&#x27;</span>, <span class="string">&#x27;多云转晴&#x27;</span>, <span class="string">&#x27;小雨转多云&#x27;</span>, <span class="string">&#x27;多云&#x27;</span>, <span class="string">&#x27;小雨到中雨&#x27;</span>, <span class="string">&#x27;阴转雨&#x27;</span>, <span class="string">&#x27;中雨到大雨&#x27;</span>, <span class="string">&#x27;多云转雨&#x27;</span>]</span><br><span class="line">    pie = pyecharts.Pie(<span class="string">&quot;山东天气比例&quot;</span>, <span class="string">&#x27;2020-7-11&#x27;</span>)</span><br><span class="line">    pie.add(<span class="string">&#x27;天气类型&#x27;</span>, tianqi, [xiaoyu, mit_rain, lit_rain, sail, sun, th_rain, cloud, shadom, z_rain], is_label_show=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    pie = pyecharts.Pie(<span class="string">&quot;全国天气类型比例&quot;</span>, <span class="string">&#x27;2018-4-16&#x27;</span>)</span><br><span class="line">    pie.render(<span class="string">&#x27;C:\\Users\\dupeibo\\Desktop\\未来30天天气概况.html&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">spider_shandong</span>():</span><br><span class="line">    city = []</span><br><span class="line">    temp = []</span><br><span class="line">    weather = []</span><br><span class="line">    js = <span class="string">&quot;var q=document.documentElement.scrollTop=100000&quot;</span></span><br><span class="line"></span><br><span class="line">    driver = webdriver.Chrome()  <span class="comment"># 打开浏览器</span></span><br><span class="line">    driver.maximize_window()  <span class="comment"># 最大化窗口</span></span><br><span class="line"></span><br><span class="line">    url = <span class="string">&#x27;https://www.tianqi.com/province/shandong/&#x27;</span>  <span class="comment"># 打开网页</span></span><br><span class="line">    driver.get(url)</span><br><span class="line">    content = driver.page_source</span><br><span class="line"></span><br><span class="line">    <span class="built_in">list</span> = driver.find_elements_by_xpath(<span class="string">&quot;/html/body/div[7]/div[1]/div[5]/ul&quot;</span>)  <span class="comment"># 山东数据</span></span><br><span class="line">    result = <span class="built_in">list</span>[<span class="number">0</span>].text.split(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">    driver.close()</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">shandong_data</span>(<span class="params">result</span>):  <span class="comment"># 爬取山东数据并分离</span></span><br><span class="line">    city = []</span><br><span class="line">    temp = []</span><br><span class="line">    weather = []</span><br><span class="line">    max_temp = []</span><br><span class="line">    min_temp = []</span><br><span class="line">    a = <span class="number">2</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> result:  <span class="comment"># 求出每个城市的天气</span></span><br><span class="line">        a += <span class="number">1</span></span><br><span class="line">        <span class="comment"># print(i)</span></span><br><span class="line">        <span class="comment"># print(a)</span></span><br><span class="line">        b = (a % <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (b == <span class="number">0</span>):</span><br><span class="line">            <span class="comment"># print(i)</span></span><br><span class="line">            weather.append(i)</span><br><span class="line"></span><br><span class="line">    a = <span class="number">3</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> result:  <span class="comment"># 求出山东的城市</span></span><br><span class="line">        a += <span class="number">1</span></span><br><span class="line">        <span class="comment"># print(i)</span></span><br><span class="line">        <span class="comment"># print(a)</span></span><br><span class="line">        b = (a % <span class="number">4</span>)</span><br><span class="line">        <span class="keyword">if</span> (b == <span class="number">0</span>):</span><br><span class="line">            <span class="comment"># print(i)</span></span><br><span class="line">            city.append(i)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> result:  <span class="comment"># 求出每个城市的温度</span></span><br><span class="line">        tem = re.findall(<span class="string">&#x27;\d&#123;2&#125; ~ \d&#123;2&#125;℃&#x27;</span>, i)</span><br><span class="line">        <span class="comment"># print(tem)</span></span><br><span class="line">        <span class="keyword">if</span> tem == []:</span><br><span class="line">            <span class="keyword">del</span> tem</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">for</span> iii <span class="keyword">in</span> tem:</span><br><span class="line">                temp.append(iii)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> temp:  <span class="comment"># 求出温度的最大值和最小值</span></span><br><span class="line">        t = <span class="number">0</span></span><br><span class="line">        <span class="comment"># print(i)</span></span><br><span class="line">        z = re.findall(<span class="string">&quot;\d&#123;2&#125;&quot;</span>, i)</span><br><span class="line">        <span class="comment"># print(z[0])</span></span><br><span class="line">        min_temp.append(z[<span class="number">0</span>])</span><br><span class="line">        max_temp.append(z[<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">return</span> city, temp, weather, max_temp, min_temp</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">shandong_Parallel</span>(<span class="params">city, max_temp, min_temp</span>):</span><br><span class="line">    parallel = pyecharts.Parallel(<span class="string">&quot;高低温度的平行坐标系图&quot;</span>, <span class="string">&quot;2021-7-13&quot;</span>, width=<span class="number">1200</span>,</span><br><span class="line">                                  height=<span class="number">600</span>)</span><br><span class="line">    parallel.config(city)</span><br><span class="line">    parallel.add(<span class="string">&quot;高低温&quot;</span>, [max_temp, min_temp], is_random=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    parallel.render(<span class="string">&#x27;C:\\Users\\dupeibo\\Desktop\\山东温度分析.html&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">jinan_to_sql</span>(<span class="params">weather, temp, data</span>):</span><br><span class="line">    <span class="comment"># result = spider_jinan()</span></span><br><span class="line">    <span class="comment"># weather, temp, data = spider_res_jinan(result)</span></span><br><span class="line">    results = pd.DataFrame()</span><br><span class="line">    res = pd.Series()</span><br><span class="line">    res[<span class="string">&quot;weather&quot;</span>] = pd.Series(weather)</span><br><span class="line">    res[<span class="string">&quot;temp&quot;</span>] = pd.Series(temp)</span><br><span class="line">    res[<span class="string">&quot;data&quot;</span>] = pd.Series(data)</span><br><span class="line">    results.insert(<span class="number">0</span>, <span class="string">&#x27;天气&#x27;</span>, res[<span class="string">&quot;weather&quot;</span>])</span><br><span class="line">    results.insert(<span class="number">0</span>, <span class="string">&#x27;温度&#x27;</span>, res[<span class="string">&quot;temp&quot;</span>])</span><br><span class="line">    results.insert(<span class="number">0</span>, <span class="string">&#x27;日期&#x27;</span>, res[<span class="string">&quot;data&quot;</span>])</span><br><span class="line">    <span class="comment"># print(results)</span></span><br><span class="line">    conn = create_engine(<span class="string">&#x27;mysql+pymysql://root:dpb238031@localhost:3306/weather?charset=utf8&#x27;</span>)</span><br><span class="line">    sql = <span class="string">&#x27;select * from runoob_tbl&#x27;</span></span><br><span class="line">    rub = pd.read_sql(sql, conn)</span><br><span class="line">    results.to_sql(name=<span class="string">&#x27;jinan_weather&#x27;</span>, con=conn, if_exists=<span class="string">&#x27;append&#x27;</span>, index=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">shandong_to_sql</span>(<span class="params">city, weather, min_temp, max_temp</span>):</span><br><span class="line">    <span class="comment"># result = spider_shandong()</span></span><br><span class="line">    <span class="comment"># city, temp, weather, max_temp, min_temp = shandong_data(result)</span></span><br><span class="line">    results = pd.DataFrame()</span><br><span class="line">    res = pd.Series()</span><br><span class="line">    res[<span class="string">&quot;city&quot;</span>] = pd.Series(city)</span><br><span class="line">    res[<span class="string">&quot;weather&quot;</span>] = pd.Series(weather)</span><br><span class="line">    res[<span class="string">&quot;max_temp&quot;</span>] = pd.Series(max_temp)</span><br><span class="line">    res[<span class="string">&quot;min_temp&quot;</span>] = pd.Series(min_temp)</span><br><span class="line">    results.insert(<span class="number">0</span>, <span class="string">&#x27;城市&#x27;</span>, res[<span class="string">&quot;city&quot;</span>])</span><br><span class="line">    results.insert(<span class="number">0</span>, <span class="string">&#x27;天气&#x27;</span>, res[<span class="string">&quot;weather&quot;</span>])</span><br><span class="line">    results.insert(<span class="number">0</span>, <span class="string">&#x27;最低温&#x27;</span>, res[<span class="string">&quot;min_temp&quot;</span>])</span><br><span class="line">    results.insert(<span class="number">0</span>, <span class="string">&#x27;最高温&#x27;</span>, res[<span class="string">&quot;max_temp&quot;</span>])</span><br><span class="line">    conn = create_engine(<span class="string">&#x27;mysql+pymysql://root:dpb238031@localhost:3306/weather?charset=utf8&#x27;</span>)</span><br><span class="line">    <span class="comment"># sql = &#x27;select * from runoob_tbl&#x27;</span></span><br><span class="line">    <span class="comment"># rub = pd.read_sql(sql, conn)</span></span><br><span class="line">    results.to_sql(name=<span class="string">&#x27;shandong_weather&#x27;</span>, con=conn, if_exists=<span class="string">&#x27;append&#x27;</span>, index=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">audio</span>(<span class="params">exam, weather, temp, month, day</span>):</span><br><span class="line">    <span class="comment"># put = input(&quot;请输入要查看的信息，例如：今天，明天，后天&quot;)</span></span><br><span class="line">    <span class="keyword">if</span> exam == <span class="string">&quot;今天&quot;</span>:</span><br><span class="line">        pt = pyttsx3.init()</span><br><span class="line">        pt.say(<span class="string">&quot;今天是：&quot;</span> + month[<span class="number">0</span>] + <span class="string">&quot;月&quot;</span> + day[<span class="number">1</span>] + <span class="string">&quot;日\n\n&quot;</span> + <span class="string">&quot;今天的天气是\n&quot;</span> + weather[<span class="number">0</span>] + <span class="string">&quot;\n\n今天的气温是&quot;</span> + temp[<span class="number">0</span>])</span><br><span class="line">        pt.runAndWait()</span><br><span class="line">        <span class="comment"># print(&quot;天气：&quot; + weather[0] + &quot; ，温度为：&quot; + temp[0] + &quot; ，日期：&quot; + data[0])</span></span><br><span class="line">    <span class="keyword">elif</span> exam == <span class="string">&quot;明天&quot;</span>:</span><br><span class="line">        pt = pyttsx3.init()</span><br><span class="line">        pt.say(<span class="string">&quot;明天是：&quot;</span> + month[<span class="number">1</span>] + <span class="string">&quot;月&quot;</span> + day[<span class="number">1</span>] + <span class="string">&quot;日\n\n&quot;</span> + <span class="string">&quot;明天的天气是\n&quot;</span> + weather[<span class="number">1</span>] + <span class="string">&quot;\n\n明天的气温是&quot;</span> + temp[<span class="number">1</span>])</span><br><span class="line">        pt.runAndWait()</span><br><span class="line">    <span class="keyword">elif</span> exam == <span class="string">&quot;后天&quot;</span>:</span><br><span class="line">        pt = pyttsx3.init()</span><br><span class="line">        pt.say(<span class="string">&quot;后天是：&quot;</span> + month[<span class="number">2</span>] + <span class="string">&quot;月&quot;</span> + day[<span class="number">1</span>] + <span class="string">&quot;日\n\n&quot;</span> + <span class="string">&quot;后天的天气是\n&quot;</span> + weather[<span class="number">2</span>] + <span class="string">&quot;\n\n后天的气温是&quot;</span> + temp[<span class="number">2</span>])</span><br><span class="line">        pt.runAndWait()</span><br><span class="line">    <span class="keyword">elif</span> exam == <span class="string">&quot;大后天&quot;</span>:</span><br><span class="line">        pt = pyttsx3.init()</span><br><span class="line">        pt.say(<span class="string">&quot;大后天是：&quot;</span> + month[<span class="number">3</span>] + <span class="string">&quot;月&quot;</span> + day[<span class="number">1</span>] + <span class="string">&quot;日\n\n&quot;</span> + <span class="string">&quot;大后天的天气是\n&quot;</span> + weather[<span class="number">3</span>] + <span class="string">&quot;\n\n大后天的气温是&quot;</span> + temp[<span class="number">3</span>])</span><br><span class="line">        pt.runAndWait()</span><br><span class="line"></span><br><span class="line">framerate = <span class="number">16000</span>  <span class="comment"># 采样率</span></span><br><span class="line">num_samples = <span class="number">2000</span>  <span class="comment"># 采样点</span></span><br><span class="line">channels = <span class="number">1</span>  <span class="comment"># 声道</span></span><br><span class="line">sampwidth = <span class="number">2</span>  <span class="comment"># 采样宽度2bytes</span></span><br><span class="line">FILEPATH = <span class="string">&#x27;speech.wav&#x27;</span></span><br><span class="line"></span><br><span class="line">base_url = <span class="string">&quot;https://openapi.baidu.com/oauth/2.0/token?grant_type=client_credentials&amp;client_id=%s&amp;client_secret=%s&quot;</span></span><br><span class="line">APIKey = <span class="string">&quot;注册的APIKey&quot;</span></span><br><span class="line">SecretKey = <span class="string">&quot;注册的SecretKey&quot;</span></span><br><span class="line"></span><br><span class="line">HOST = base_url % (APIKey, SecretKey)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getToken</span>(<span class="params">host</span>):</span><br><span class="line">    res = requests.post(host)</span><br><span class="line">    <span class="keyword">return</span> res.json()[<span class="string">&#x27;access_token&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">save_wave_file</span>(<span class="params">filepath, data</span>):</span><br><span class="line">    wf = wave.<span class="built_in">open</span>(filepath, <span class="string">&#x27;wb&#x27;</span>)</span><br><span class="line">    wf.setnchannels(channels)   <span class="comment">#声道数</span></span><br><span class="line">    wf.setsampwidth(sampwidth)    <span class="comment">#采样宽度2bytes</span></span><br><span class="line">    wf.setframerate(framerate)    <span class="comment"># 采样率</span></span><br><span class="line">    wf.writeframes(<span class="string">b&#x27;&#x27;</span>.join(data))</span><br><span class="line">    wf.close()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">my_record</span>():     <span class="comment">#录音函数</span></span><br><span class="line">    pa = PyAudio()</span><br><span class="line">    stream = pa.<span class="built_in">open</span>(<span class="built_in">format</span>=paInt16, channels=channels,</span><br><span class="line">                     rate=framerate, <span class="built_in">input</span>=<span class="literal">True</span>, frames_per_buffer=num_samples)</span><br><span class="line">    my_buf = []</span><br><span class="line">    <span class="comment"># count = 0</span></span><br><span class="line">    t = time.time()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;请讲话...&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> time.time() &lt; t + <span class="number">4</span>:  <span class="comment"># 秒</span></span><br><span class="line">        string_audio_data = stream.read(num_samples)</span><br><span class="line">        my_buf.append(string_audio_data)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;录音结束.&#x27;</span>)</span><br><span class="line">    save_wave_file(FILEPATH, my_buf)</span><br><span class="line">    stream.close()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_audio</span>(<span class="params">file</span>):</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(file, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        data = f.read()</span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">speech2text</span>(<span class="params">speech_data, token, dev_pid=<span class="number">1537</span></span>):</span><br><span class="line">    FORMAT = <span class="string">&#x27;wav&#x27;</span></span><br><span class="line">    RATE = <span class="string">&#x27;16000&#x27;</span></span><br><span class="line">    CHANNEL = <span class="number">1</span></span><br><span class="line">    CUID = <span class="string">&#x27;24422381&#x27;</span></span><br><span class="line">    SPEECH = base64.b64encode(speech_data).decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    data = &#123;</span><br><span class="line">        <span class="string">&#x27;format&#x27;</span>: FORMAT,</span><br><span class="line">        <span class="string">&#x27;rate&#x27;</span>: RATE,</span><br><span class="line">        <span class="string">&#x27;channel&#x27;</span>: CHANNEL,</span><br><span class="line">        <span class="string">&#x27;cuid&#x27;</span>: CUID,</span><br><span class="line">        <span class="string">&#x27;len&#x27;</span>: <span class="built_in">len</span>(speech_data),</span><br><span class="line">        <span class="string">&#x27;speech&#x27;</span>: SPEECH,</span><br><span class="line">        <span class="string">&#x27;token&#x27;</span>: token,</span><br><span class="line">        <span class="string">&#x27;dev_pid&#x27;</span>: dev_pid</span><br><span class="line">    &#125;</span><br><span class="line">    url = <span class="string">&#x27;https://vop.baidu.com/server_api&#x27;</span></span><br><span class="line">    headers = &#123;<span class="string">&#x27;Content-Type&#x27;</span>: <span class="string">&#x27;application/json&#x27;</span>&#125;</span><br><span class="line">    <span class="comment"># r=requests.post(url,data=json.dumps(data),headers=headers)</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;正在识别...&#x27;</span>)</span><br><span class="line">    r = requests.post(url, json=data, headers=headers)</span><br><span class="line">    Result = r.json()</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;result&#x27;</span> <span class="keyword">in</span> Result:</span><br><span class="line">        <span class="keyword">return</span> Result[<span class="string">&#x27;result&#x27;</span>][<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> Result</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    flag = <span class="string">&#x27;重新开始&#x27;</span></span><br><span class="line">    <span class="keyword">while</span> flag.lower() == <span class="string">&#x27;重新开始&#x27;</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;您是要查看&#x27;济南天气&#x27;还是&#x27;山东所有城市的天气&#x27;？&quot;</span>)</span><br><span class="line">        pt = pyttsx3.init()</span><br><span class="line">        pt.say(<span class="string">&quot;您是要查看济南天气还是山东所有城市的天气？&quot;</span>)</span><br><span class="line">        pt.runAndWait()</span><br><span class="line">        sleep(<span class="number">2</span>)</span><br><span class="line">        <span class="comment"># print(&#x27;请输入数字选择语言：&#x27;)</span></span><br><span class="line">        <span class="comment"># devpid = input(&#x27;1536：普通话(简单英文),1537:普通话(有标点),1737:英语,1637:粤语,1837:四川话\n&#x27;)</span></span><br><span class="line">        my_record()</span><br><span class="line">        TOKEN = getToken(HOST)</span><br><span class="line">        speech = get_audio(FILEPATH)</span><br><span class="line">        result = speech2text(speech, TOKEN, <span class="built_in">int</span>(<span class="number">1536</span>))</span><br><span class="line">        sleep(<span class="number">2</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;识别结果：&quot;</span> + result)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;开始收集数据....&quot;</span>)</span><br><span class="line">        sleep(<span class="number">2</span>)</span><br><span class="line">        <span class="comment"># abc = &quot;返回上一级&quot;</span></span><br><span class="line">        <span class="keyword">if</span> result == <span class="string">&quot;济南天气&quot;</span>:</span><br><span class="line">            <span class="comment"># while abc == &quot;返回上一级&quot;:</span></span><br><span class="line">            result = spider_jinan()</span><br><span class="line">            weather, temp, data, month, day = spider_res_jinan(result)</span><br><span class="line">            mean__temp = mean_temp_jinan(temp)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;目前有的功能\n\n查看最近天气\n查看未来30天的温度\n画出天气词云\n平均温度折线图\n保存数据\n查看未来天气类型\n将数据存入数据库\n\n请选择你要使用的功能&quot;</span>)</span><br><span class="line">            <span class="comment"># print(&quot;查看最近天气\n查看未来30天的温度\n画出天气词云\n画平均温度折线图\n保存数据\n画出柱状图&quot;)</span></span><br><span class="line">            pt = pyttsx3.init()</span><br><span class="line">            pt.say(<span class="string">&quot;\n\n\n\n\n\n\n目前有的功能\n\n查看最近天气\n查看未来30天的温度\n画出天气词云\n平均温度折线图\n保存数据\n查看未来天气类型\n将数据存入数据库\n\n请选择你要使用的功能&quot;</span>)</span><br><span class="line">            pt.runAndWait()</span><br><span class="line">            my_record()</span><br><span class="line">            <span class="comment"># sleep(2)</span></span><br><span class="line">            TOKEN = getToken(HOST)</span><br><span class="line">            speech = get_audio(FILEPATH)</span><br><span class="line">            func = speech2text(speech, TOKEN, <span class="built_in">int</span>(<span class="number">1536</span>))</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;识别结果:&quot;</span> + func)</span><br><span class="line">            sleep(<span class="number">2</span>)</span><br><span class="line">            <span class="comment"># func = input()</span></span><br><span class="line">            <span class="keyword">if</span> func == <span class="string">&quot;查看最近天气&quot;</span>:</span><br><span class="line">                <span class="comment"># exam = input(&quot;请输入要查看的信息，例如：今天，明天，后天，大后天&quot;)</span></span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;请输入要查看的信息，例如：今天，明天，后天，大后天&quot;</span>)</span><br><span class="line">                pt = pyttsx3.init()</span><br><span class="line">                pt.say(<span class="string">&quot;请输入要查看的信息，例如：今天，明天，后天，大后天&quot;</span>)</span><br><span class="line">                pt.runAndWait()</span><br><span class="line">                my_record()</span><br><span class="line">                TOKEN = getToken(HOST)</span><br><span class="line">                speech = get_audio(FILEPATH)</span><br><span class="line">                apple = speech2text(speech, TOKEN, <span class="built_in">int</span>(<span class="number">1536</span>))</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;识别结果：&quot;</span> + apple)</span><br><span class="line">                audio(apple, weather, temp, month, day)</span><br><span class="line">                pt1 = pyttsx3.init()</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;重新开始还是退出？&quot;</span>)</span><br><span class="line">                pt1.say(<span class="string">&quot;是否重新开始还是退出？&quot;</span>)</span><br><span class="line">                pt1.runAndWait()</span><br><span class="line">                my_record()</span><br><span class="line">                <span class="comment"># sleep(2)</span></span><br><span class="line">                TOKEN = getToken(HOST)</span><br><span class="line">                speech = get_audio(FILEPATH)</span><br><span class="line">                flag = speech2text(speech, TOKEN, <span class="built_in">int</span>(<span class="number">1536</span>))</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;识别结果：&quot;</span> + flag)</span><br><span class="line">            <span class="keyword">elif</span> func == <span class="string">&quot;查看未来三十天的温度&quot;</span>:</span><br><span class="line">                mean__temp = mean_temp_jinan(temp)</span><br><span class="line">                plt_mean_temp_jinan(data, mean__temp)</span><br><span class="line">                pt = pyttsx3.init()</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;重新开始还是退出？&quot;</span>)</span><br><span class="line">                pt.say(<span class="string">&quot;是否重新开始还是退出？&quot;</span>)</span><br><span class="line">                pt.runAndWait()</span><br><span class="line">                my_record()</span><br><span class="line">                <span class="comment"># sleep(2)</span></span><br><span class="line">                TOKEN = getToken(HOST)</span><br><span class="line">                speech = get_audio(FILEPATH)</span><br><span class="line">                flag = speech2text(speech, TOKEN, <span class="built_in">int</span>(<span class="number">1536</span>))</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;识别结果：&quot;</span> + flag)</span><br><span class="line">            <span class="keyword">elif</span> func == <span class="string">&quot;画出天气词云&quot;</span>:</span><br><span class="line">                image_jinan(weather)</span><br><span class="line">                <span class="comment"># os.system(&quot;E:\\code\\spider\\week8\\word_cloud\\bodies.png&quot;)</span></span><br><span class="line">                pt = pyttsx3.init()</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;重新开始还是退出？&quot;</span>)</span><br><span class="line">                pt.say(<span class="string">&quot;是否重新开始还是退出？&quot;</span>)</span><br><span class="line">                pt.runAndWait()</span><br><span class="line">                my_record()</span><br><span class="line">                <span class="comment"># sleep(2)</span></span><br><span class="line">                TOKEN = getToken(HOST)</span><br><span class="line">                speech = get_audio(FILEPATH)</span><br><span class="line">                flag = speech2text(speech, TOKEN, <span class="built_in">int</span>(<span class="number">1536</span>))</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;识别结果：&quot;</span> + flag)</span><br><span class="line">            <span class="keyword">elif</span> func == <span class="string">&quot;平均温度折线图&quot;</span>:</span><br><span class="line">                plt_mean_temp_jinan(data, mean__temp)</span><br><span class="line">                pt = pyttsx3.init()</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;重新开始还是退出？&quot;</span>)</span><br><span class="line">                pt.say(<span class="string">&quot;重新开始还是退出？&quot;</span>)</span><br><span class="line">                pt.runAndWait()</span><br><span class="line">                my_record()</span><br><span class="line">                <span class="comment"># sleep(2)</span></span><br><span class="line">                TOKEN = getToken(HOST)</span><br><span class="line">                speech = get_audio(FILEPATH)</span><br><span class="line">                flag = speech2text(speech, TOKEN, <span class="built_in">int</span>(<span class="number">1536</span>))</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;识别结果：&quot;</span> + flag)</span><br><span class="line">            <span class="keyword">elif</span> func == <span class="string">&quot;保存数据&quot;</span>:</span><br><span class="line">                temp_to_csv(weather, temp, data)</span><br><span class="line">                <span class="comment"># print(&quot;csv文件保存成功&quot;)</span></span><br><span class="line">                pt = pyttsx3.init()</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;重新开始还是退出？&quot;</span>)</span><br><span class="line">                pt.say(<span class="string">&quot;重新开始还是退出？&quot;</span>)</span><br><span class="line">                pt.runAndWait()</span><br><span class="line">                my_record()</span><br><span class="line">                <span class="comment"># sleep(2)</span></span><br><span class="line">                TOKEN = getToken(HOST)</span><br><span class="line">                speech = get_audio(FILEPATH)</span><br><span class="line">                flag = speech2text(speech, TOKEN, <span class="built_in">int</span>(<span class="number">1536</span>))</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;识别结果：&quot;</span> + flag)</span><br><span class="line">            <span class="keyword">elif</span> func == <span class="string">&quot;查看未来天气类型&quot;</span>:</span><br><span class="line">                plt_fer_weather(weather)</span><br><span class="line">                os.system(<span class="string">&#x27;C:\\Users\\dupeibo\\Desktop\\未来30天天气概况.html&#x27;</span>)</span><br><span class="line">                pt = pyttsx3.init()</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;重新开始还是退出？&quot;</span>)</span><br><span class="line">                pt.say(<span class="string">&quot;重新开始还是退出？&quot;</span>)</span><br><span class="line">                pt.runAndWait()</span><br><span class="line">                my_record()</span><br><span class="line">                <span class="comment"># sleep(2)</span></span><br><span class="line">                TOKEN = getToken(HOST)</span><br><span class="line">                speech = get_audio(FILEPATH)</span><br><span class="line">                flag = speech2text(speech, TOKEN, <span class="built_in">int</span>(<span class="number">1536</span>))</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;识别结果：&quot;</span> + flag)</span><br><span class="line">            <span class="keyword">elif</span> func == <span class="string">&quot;将数据存入数据库&quot;</span>:</span><br><span class="line">                jinan_to_sql(weather, temp, data)</span><br><span class="line">                pt = pyttsx3.init()</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;重新开始还是退出？&quot;</span>)</span><br><span class="line">                pt.say(<span class="string">&quot;数据库保存成功\n\n重新开始还是退出？&quot;</span>)</span><br><span class="line">                pt.runAndWait()</span><br><span class="line">                my_record()</span><br><span class="line">                <span class="comment"># sleep(2)</span></span><br><span class="line">                TOKEN = getToken(HOST)</span><br><span class="line">                speech = get_audio(FILEPATH)</span><br><span class="line">                flag = speech2text(speech, TOKEN, <span class="built_in">int</span>(<span class="number">1536</span>))</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;识别结果：&quot;</span> + flag)</span><br><span class="line">                <span class="comment"># print(&quot;数据库保存成功&quot;)</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">elif</span> result == <span class="string">&quot;山东所有城市的天气&quot;</span>:</span><br><span class="line">            result = spider_shandong()</span><br><span class="line">            city, temp, weather, max_temp, min_temp = shandong_data(result)</span><br><span class="line">            pt = pyttsx3.init()</span><br><span class="line">            sleep(<span class="number">3</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;目前有的功能\n\n\n查看各城市天气状况\n将数据存入数据库&quot;</span>)</span><br><span class="line">            pt.say(<span class="string">&quot;目前有的功能\n\n\n查看各城市天气状况\n将数据存入数据库&quot;</span>)</span><br><span class="line">            pt.runAndWait()</span><br><span class="line">            my_record()</span><br><span class="line">            sleep(<span class="number">2</span>)</span><br><span class="line">            TOKEN = getToken(HOST)</span><br><span class="line">            speech = get_audio(FILEPATH)</span><br><span class="line">            fun2 = speech2text(speech, TOKEN, <span class="built_in">int</span>(<span class="number">1536</span>))</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;识别结果：&quot;</span> + fun2)</span><br><span class="line">            <span class="keyword">if</span> fun2 == <span class="string">&quot;查看各城市天气状况&quot;</span>:</span><br><span class="line">                <span class="comment"># shandong_Parallel(city, max_temp, min_temp)</span></span><br><span class="line">                os.system(<span class="string">&quot;C:\\Users\\dupeibo\\Desktop\\山东温度分析.html&quot;</span>)</span><br><span class="line">                pt = pyttsx3.init()</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;重新开始还是退出？&quot;</span>)</span><br><span class="line">                pt.say(<span class="string">&quot;重新开始还是退出？&quot;</span>)</span><br><span class="line">                pt.runAndWait()</span><br><span class="line">                my_record()</span><br><span class="line">                <span class="comment"># sleep(2)</span></span><br><span class="line">                TOKEN = getToken(HOST)</span><br><span class="line">                speech = get_audio(FILEPATH)</span><br><span class="line">                flag = speech2text(speech, TOKEN, <span class="built_in">int</span>(<span class="number">1536</span>))</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;识别结果：&quot;</span> + flag)</span><br><span class="line">            <span class="keyword">elif</span> fun2 == <span class="string">&quot;将数据存入数据库&quot;</span>:</span><br><span class="line">                shandong_to_sql(city, weather, min_temp, max_temp)</span><br><span class="line">                pt = pyttsx3.init()</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;重新开始还是退出？&quot;</span>)</span><br><span class="line">                pt.say(<span class="string">&quot;重新开始还是退出？&quot;</span>)</span><br><span class="line">                pt.runAndWait()</span><br><span class="line">                my_record()</span><br><span class="line">                <span class="comment"># sleep(2)</span></span><br><span class="line">                TOKEN = getToken(HOST)</span><br><span class="line">                speech = get_audio(FILEPATH)</span><br><span class="line">                flag = speech2text(speech, TOKEN, <span class="built_in">int</span>(<span class="number">1536</span>))</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;识别结果：&quot;</span> + flag)</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 爬虫 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 爬虫 </tag>
            
            <tag> 对话机器人 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>爬虫动态爬取京东商品的数据</title>
      <link href="/posts/37678.html"/>
      <url>/posts/37678.html</url>
      
        <content type="html"><![CDATA[<p>根据xpath进行定位分析，提取信息、翻页等操作</p><span id="more"></span><h2 id="导入包"><a href="#导入包" class="headerlink" title="导入包"></a>导入包</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> sleep</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> quote</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br></pre></td></tr></table></figure><h2 id="对DataFrame处理"><a href="#对DataFrame处理" class="headerlink" title="对DataFrame处理"></a>对DataFrame处理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pd.set_option(<span class="string">&#x27;display.max_columns&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line">pd.set_option(<span class="string">&#x27;display.width&#x27;</span>, <span class="number">150</span>)</span><br></pre></td></tr></table></figure><h2 id="评论处理"><a href="#评论处理" class="headerlink" title="评论处理"></a>评论处理</h2><p>如果含有“万”，则进行分割处理，将评论转化为int类型</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">com_count</span>(<span class="params">text</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;万&#x27;</span> <span class="keyword">in</span> text:</span><br><span class="line">        num = <span class="built_in">float</span>(text.split(<span class="string">&#x27;万&#x27;</span>)[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">int</span>(num * <span class="number">10000</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">int</span>(re.<span class="keyword">match</span>(<span class="string">&#x27;\d+&#x27;</span>, text).group())</span><br></pre></td></tr></table></figure><p>浏览器初始化</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">driver = webdriver.Chrome()  <span class="comment"># 打开浏览器</span></span><br><span class="line">driver.maximize_window()  <span class="comment"># 最大化窗口</span></span><br></pre></td></tr></table></figure><h2 id="查询的网页"><a href="#查询的网页" class="headerlink" title="查询的网页"></a>查询的网页</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">key = <span class="string">&#x27;红酒&#x27;</span>  <span class="comment"># 设置搜索商品关键词</span></span><br><span class="line">url = <span class="string">&#x27;https://search.jd.com/Search?keyword=&#x27;</span> + quote(key) + <span class="string">&#x27;&amp;enc=utf-8&#x27;</span>  <span class="comment"># 构造url</span></span><br><span class="line">driver.get(url)  <span class="comment"># 打开url</span></span><br><span class="line">driver.implicitly_wait(<span class="number">3</span>)  <span class="comment"># 等待</span></span><br></pre></td></tr></table></figure><h2 id="爬取过程"><a href="#爬取过程" class="headerlink" title="爬取过程"></a>爬取过程</h2><p>&amp;emsp;&amp;emsp;分析过程如下：根据xpath进行定位分析，首先是找到价格的xpath，然后提取数据，对于商品名称，提取之后根据换行进行分割，然后保存， 然后就是分别找到商品的链接和编号，根据for遍历先储存商品名称和价格，评论的话就是调用上面的评论修正函数最有就是把数据进行保存，保存之后就进行翻页，继续爬取下一页的数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">page_crawl</span>(<span class="params">results</span>):</span><br><span class="line">    res = pd.Series()  <span class="comment"># 记录单条商品信息</span></span><br><span class="line">    prices = driver.find_elements_by_xpath(<span class="string">&#x27;//*[@id=&quot;J_goodsList&quot;]/ul/li/div/div[2]/strong/i&#x27;</span>)</span><br><span class="line">    prices = [<span class="built_in">float</span>(price.text) <span class="keyword">for</span> price <span class="keyword">in</span> prices]</span><br><span class="line">    goods = driver.find_elements_by_xpath(<span class="string">&#x27;//*[@id=&quot;J_goodsList&quot;]/ul/li/div/div[3]/a/em&#x27;</span>)</span><br><span class="line">    goods = [good.text.replace(<span class="string">&#x27;\n&#x27;</span>, <span class="string">&#x27;&#x27;</span>) <span class="keyword">for</span> good <span class="keyword">in</span> goods]</span><br><span class="line">    links = driver.find_elements_by_xpath(<span class="string">&#x27;//*[@id=&quot;J_goodsList&quot;]/ul/li/div/div[3]/a&#x27;</span>)  <span class="comment"># 查找当前页面的商品链接</span></span><br><span class="line">    urls = [l.get_attribute(<span class="string">&#x27;href&#x27;</span>) <span class="keyword">for</span> l <span class="keyword">in</span> links]</span><br><span class="line">    codes = [re.search(<span class="string">&#x27;\d+&#x27;</span>, url).group() <span class="keyword">for</span> url <span class="keyword">in</span> urls]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> ii <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(prices)):</span><br><span class="line">        <span class="comment"># print(len(prices))</span></span><br><span class="line">        res.name = codes[ii]  <span class="comment"># 这个name是Series的名字</span></span><br><span class="line">        res[<span class="string">&#x27;good_name&#x27;</span>] = goods[ii]</span><br><span class="line">        res[<span class="string">&#x27;good_price&#x27;</span>] = prices[ii]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 评论数的抽取稍微复杂一些</span></span><br><span class="line">        <span class="comment"># 1、他的xpath不再是排序的，而是J_comment_商品编号</span></span><br><span class="line">        <span class="comment"># 2、有的单位是条，有单位是万条</span></span><br><span class="line">        com = driver.find_elements_by_xpath(<span class="string">&#x27;//*[@id=&quot;J_comment_&#123;&#125;&quot;]&#x27;</span>.<span class="built_in">format</span>(codes[ii]))</span><br><span class="line">        <span class="comment"># print(com)</span></span><br><span class="line">        res[<span class="string">&#x27;com_count&#x27;</span>] = com_count(com[<span class="number">0</span>].text)  <span class="comment"># 调用上面的万条评论的修正的函数</span></span><br><span class="line">        <span class="built_in">print</span>(res[<span class="string">&#x27;com_count&#x27;</span>])</span><br><span class="line"></span><br><span class="line">        results = results.append(res)  <span class="comment"># 各商品记录</span></span><br><span class="line">    <span class="comment"># 翻页</span></span><br><span class="line">    cl = driver.find_elements_by_xpath(<span class="string">&#x27;//*[@id=&quot;J_bottomPage&quot;]/span[1]/a[9]&#x27;</span>)</span><br><span class="line">    cl[<span class="number">0</span>].click()  <span class="comment"># 点击“下一页”</span></span><br><span class="line">    sleep(<span class="number">5</span>)  <span class="comment"># 等待</span></span><br><span class="line">    <span class="keyword">return</span> results</span><br><span class="line"></span><br><span class="line">results = pd.DataFrame()</span><br></pre></td></tr></table></figure><h2 id="关闭浏览器"><a href="#关闭浏览器" class="headerlink" title="关闭浏览器"></a>关闭浏览器</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> ii <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">    <span class="built_in">print</span>(datetime.now(), ii)</span><br><span class="line">    results = page_crawl(results)</span><br><span class="line"></span><br><span class="line">driver.close()</span><br></pre></td></tr></table></figure><p>本文和爬取苏宁的代码相似，如有不明白的请看<a href="https://blog.csdn.net/weixin_51756104/article/details/121286518?spm=1001.2014.3001.5502">爬取苏宁</a>这个文章</p>]]></content>
      
      
      <categories>
          
          <category> 爬虫 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> selenium </tag>
            
            <tag> 爬虫 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>动态爬取苏宁的商品信息</title>
      <link href="/posts/37514.html"/>
      <url>/posts/37514.html</url>
      
        <content type="html"><![CDATA[<p>爬虫动态爬取苏宁的商品名称、评论数、价格</p><span id="more"></span><p>&amp;emsp;&amp;emsp;·爬取苏宁的商品信息我们需要使用chrome浏览器，需要下载相应版本的去驱动，然后将驱动放在解释器的根目录下面，驱动版本要和浏览器的版本一致，下面是下载驱动的链接：<br><a href="http://npm.taobao.org/mirrors/chromedriver/">http://npm.taobao.org/mirrors/chromedriver/</a><br>下面就是爬取的代码以及详细的解释：</p><h2 id="导入包"><a href="#导入包" class="headerlink" title="导入包"></a>导入包</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> sleep</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br></pre></td></tr></table></figure><h2 id="对DataFrame进行基本的处理"><a href="#对DataFrame进行基本的处理" class="headerlink" title="对DataFrame进行基本的处理"></a>对DataFrame进行基本的处理</h2><p>   ·第一个是设置最大的列数，如果超过特定数值就会显示省略号，输入参数为None就显示所有的数据<br>    ·第二行是设置宽度，横向最多显示150个字符</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pd.set_option(<span class="string">&#x27;display.max_columns&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line">pd.set_option(<span class="string">&#x27;display.width&#x27;</span>, <span class="number">150</span>)</span><br></pre></td></tr></table></figure><h2 id="设置网页的像素"><a href="#设置网页的像素" class="headerlink" title="设置网页的像素"></a>设置网页的像素</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">js = <span class="string">&quot;var q=document.documentElement.scrollTop=100000&quot;</span></span><br></pre></td></tr></table></figure><h2 id="处理评论"><a href="#处理评论" class="headerlink" title="处理评论"></a>处理评论</h2><p>如果评论中含有“万”，则使用split进行分割，转换成int型的评论，如果不含有“万”，则可以直接提取出来评论数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">com_count</span>(<span class="params">text</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;万&#x27;</span> <span class="keyword">in</span> text:</span><br><span class="line">        num = <span class="built_in">float</span>(text.split(<span class="string">&#x27;万&#x27;</span>)[<span class="number">0</span>])</span><br><span class="line">        <span class="built_in">print</span>(num)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">int</span>(num * <span class="number">10000</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        a = re.<span class="keyword">match</span>(<span class="string">&#x27;\d+&#x27;</span>, text)</span><br><span class="line">        <span class="keyword">if</span> a:</span><br><span class="line">            <span class="keyword">return</span> a.group()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br></pre></td></tr></table></figure><h2 id="浏览器初始化"><a href="#浏览器初始化" class="headerlink" title="浏览器初始化"></a>浏览器初始化</h2><p>Python模块selenium中的webdriver对Chrome的调用，从而进行初始化</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">driver = webdriver.Chrome()  <span class="comment"># 打开浏览器</span></span><br><span class="line">driver.maximize_window()  <span class="comment"># 最大化窗口</span></span><br></pre></td></tr></table></figure><h2 id="爬取过程"><a href="#爬取过程" class="headerlink" title="爬取过程"></a>爬取过程</h2><p>&amp;emsp;&amp;emsp;接下来就是最主要的爬取数据的函数：第一部分：先定义一个Series一维的数组，然后根据xpath找到正在浏览网页的所有内容，prouduct_list是一个list，然后将list转化为str，就是product_text，然后根据特使符号进行分割，得到的是一个list，每个商品的所有数据作为列表中的一个元素，然后删除空字符串，查看一下列表的长度。第二部分：由分析得出，正常状态下，每页得到的数据应该为120个，有的含有超级会员的商品会有两个价格，这样的话就会导致数据大于120，不准确，然后就进行翻页，此页的数据不要，提取下一页的数据。如果是超级会员的话，进行分析，每个商品看成一个列表，进行分析，不难发现，每个列表的第一个数据是price，第二个数据是名称，第三个数据是评论，然后就可以进行处理了。第三部分：将每个商品的名称，价格，评论数通过遍历存入一个DataFrame二位结构的表中，然后利用append添加进去数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">results = pd.DataFrame()</span><br><span class="line"><span class="comment"># 爬取功能主函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">page_crawl</span>(<span class="params">results</span>):</span><br><span class="line">    res = pd.Series()</span><br><span class="line">    product_list = driver.find_elements_by_xpath(<span class="string">&#x27;//*[@id=&quot;product-list&quot;]&#x27;</span>)</span><br><span class="line">    product_text = product_list[<span class="number">0</span>].text</span><br><span class="line">    text_list = product_text.split(<span class="string">&#x27;¥&#x27;</span>)</span><br><span class="line">    <span class="keyword">del</span> text_list[<span class="number">0</span>]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;len(text_list):&#x27;</span>, <span class="built_in">len</span>(text_list))</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(text_list) != <span class="number">120</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;超级会员异常，放弃！&#x27;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;没有超级会员异常，进行取数！&#x27;</span>)</span><br><span class="line">        text_list_split = [ii.split(<span class="string">&#x27;\n&#x27;</span>) <span class="keyword">for</span> ii <span class="keyword">in</span> text_list]</span><br><span class="line">        prices = [ii[<span class="number">0</span>] <span class="keyword">for</span> ii <span class="keyword">in</span> text_list_split]</span><br><span class="line">        goods = [ii[<span class="number">1</span>] <span class="keyword">for</span> ii <span class="keyword">in</span> text_list_split]</span><br><span class="line">        counts = [com_count(ii[<span class="number">2</span>]) <span class="keyword">for</span> ii <span class="keyword">in</span> text_list_split]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 如果有错误，可以拥入这段代码，具体定位问题</span></span><br><span class="line">        <span class="comment"># for ii in text_list_split:</span></span><br><span class="line">        <span class="comment">#     print(ii[0], ii[1], ii[2])</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> ii <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(prices)):</span><br><span class="line">            res.name = goods[ii]</span><br><span class="line">            res[<span class="string">&#x27;good_name&#x27;</span>] = goods[ii]</span><br><span class="line">            res[<span class="string">&#x27;good_price&#x27;</span>] = prices[ii]</span><br><span class="line">            res[<span class="string">&#x27;com_count&#x27;</span>] = counts[ii]</span><br><span class="line"></span><br><span class="line">            results = results.append(res)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> results</span><br></pre></td></tr></table></figure><h2 id="浏览器的操作"><a href="#浏览器的操作" class="headerlink" title="浏览器的操作"></a>浏览器的操作</h2><p>&amp;emsp;&amp;emsp;自己找出url的规律，然后format格式化字符串进行连接，打开浏览器，进行翻页等操作，最后关闭浏览器</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> ii <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    <span class="built_in">print</span>(datetime.now(), ii)</span><br><span class="line">    url = <span class="string">&#x27;https://search.suning.com/%E5%8F%A3%E7%BD%A9/&amp;iy=0&amp;isNoResult=0&amp;cp=&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(ii)</span><br><span class="line">    driver.get(url)  <span class="comment"># 打开url</span></span><br><span class="line">    sleep(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 下翻页</span></span><br><span class="line">    driver.execute_script(js)</span><br><span class="line">    sleep(<span class="number">3</span>)</span><br><span class="line">    driver.execute_script(js)</span><br><span class="line">    sleep(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    results = page_crawl(results)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(results.shape)</span><br><span class="line"></span><br><span class="line">driver.close()</span><br></pre></td></tr></table></figure><h2 id="写入数据库或存入CSV文件"><a href="#写入数据库或存入CSV文件" class="headerlink" title="写入数据库或存入CSV文件"></a>写入数据库或存入CSV文件</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sqlalchemy <span class="keyword">import</span> create_engine</span><br><span class="line"></span><br><span class="line">conn = create_engine(<span class="string">&#x27;mysql+pymysql://root:dpb238031@localhost:3306/data?charset=utf8&#x27;</span>)</span><br><span class="line">results.to_sql(<span class="string">&#x27;data&#x27;</span>, conn, index=<span class="literal">False</span>, if_exists=<span class="string">&#x27;replace&#x27;</span>)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/66cb1a1021fd4ad997a4fddf40a698a7.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p>]]></content>
      
      
      <categories>
          
          <category> 爬虫 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 爬虫，selenium </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>线性回归模型损失和优化</title>
      <link href="/posts/52177.html"/>
      <url>/posts/52177.html</url>
      
        <content type="html"><![CDATA[<p>对线性回归优化：正规方程、梯度下降</p><span id="more"></span><h2 id="学习任务"><a href="#学习任务" class="headerlink" title="学习任务"></a>学习任务</h2><pre><code>使用正规方程对损失函数优化的过程使用梯度下降法对损失函数优化的过程</code></pre><p><img src="https://img-blog.csdnimg.cn/279852910ca94e70aa3875194d21da4c.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h2 id="优化方法"><a href="#优化方法" class="headerlink" title="优化方法"></a>优化方法</h2><h3 id="正规方程"><a href="#正规方程" class="headerlink" title="正规方程"></a>正规方程</h3><p>正规方程,一次就可以求得最合适的值<br><img src="https://img-blog.csdnimg.cn/bea457e1c05740e79ab02e08c9702a07.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>理解：X为特征矩阵，y为目标值矩阵。直接求得最好的结果<br>缺点：当特征值过多复杂时，求解速度太慢并且得不到结果。</p><h3 id="正规方程推导过程"><a href="#正规方程推导过程" class="headerlink" title="正规方程推导过程"></a>正规方程推导过程</h3><p><img src="https://img-blog.csdnimg.cn/2f904d9a8ce04b0d83c6287634edd3c8.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h3 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h3><p>&amp;nbsp;&amp;nbsp;   &amp;nbsp;&amp;nbsp;梯度是微积分中一个很重要的概念，在单变量的函数中，梯度其实就是函数的微分，代表着函数在某个给定点的切线的斜率;在多变量函数中，梯度是一一个向量，向量有方向，梯度的方向就指出了函数在给定点的上升最快的方向;<br>&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;这也就说明了为什么我们需要千方百计的求取梯度!我们需要到达山底，就需要在每一步观测到此时最陡峭的地方，梯度就恰巧告诉了我们这个方向。梯度的方向是函数在给定点上升最快的方向，那么梯度的反方向<br>&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;    就是函数在给定点下降最快的方向，这正是我们所需要的。所以我们只要沿着梯度的反方向一直走，就能走到局部的最低点!</p><p><img src="https://img-blog.csdnimg.cn/5daee055a9cb4e79a8fc69a3c15e8851.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/dca48bc4ec2b40a2bae83ad7562bfe2d.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h3 id="梯度下降公式"><a href="#梯度下降公式" class="headerlink" title="梯度下降公式"></a>梯度下降公式</h3><p><img src="https://img-blog.csdnimg.cn/38c388038fe0440486f4f790227f1b73.png" alt="在这里插入图片描述"></p><h2 id="两者的对比"><a href="#两者的对比" class="headerlink" title="两者的对比"></a>两者的对比</h2><p><img src="https://img-blog.csdnimg.cn/03152e4dfab7449ebc03ce73bca8574d.png" alt="在这里插入图片描述"></p><h2 id="如何选择"><a href="#如何选择" class="headerlink" title="如何选择"></a>如何选择</h2><h3 id="小规模数据"><a href="#小规模数据" class="headerlink" title="小规模数据"></a>小规模数据</h3><pre><code>    ·正规方程：LinearRegression（不能解决拟合问题）    ·岭回归</code></pre><h3 id="大规模数据"><a href="#大规模数据" class="headerlink" title="大规模数据"></a>大规模数据</h3><pre><code>·梯度下降法：SGDRegressor</code></pre>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 线性回归 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>第一次搭建成功MySQL数据库</title>
      <link href="/posts/48436.html"/>
      <url>/posts/48436.html</url>
      
        <content type="html"><![CDATA[<p>MySQL的安装以及使用Python连接数据库</p><span id="more"></span><h3 id="首先了解一下MySQL"><a href="#首先了解一下MySQL" class="headerlink" title="首先了解一下MySQL"></a>首先了解一下MySQL</h3><pre><code>数据库：    简单理解，就是好多表，类似Excel的工作簿    操作系统看来：文件是文件的整体，文件内容不关心    数据库系统看来：每一条记录才是问题的关键，比文件更细数据表：    二维的数据结构，有行有列，有一个略显奇怪的名字：关系    一行叫一条记录，代表一个交易、一个数据条目：机器学习中叫“样本”    一列叫一个字段，代表记录的性情：机器学习中叫“特征”</code></pre><h3 id="关于MySQL的安装"><a href="#关于MySQL的安装" class="headerlink" title="关于MySQL的安装"></a>关于MySQL的安装</h3><p>安装过程略，安装完成需要配置环境变量，把bin目录的路径添加上去，在cmd中输入where mysql或者输入path查看是否安装成功<br><img src="https://img-blog.csdnimg.cn/07ad101621b14695ab275b27f613857c.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h3 id="启动服务"><a href="#启动服务" class="headerlink" title="启动服务"></a>启动服务</h3><pre><code>以管理员身份启动cmd：    初始化数据库 mysqld  --initialize    安装服务 mysqld --install  mysql56    启动服务 net start mysql56    连接root用户：mysql -uroot mysql    查看用户情况：select host,user,password from mysql.user;</code></pre><p>·Database：一个数据库相当于一个excel的工作簿，一个table相当于一个工作表</p><pre><code>查看当前数据库：select database();查看所有数据库：show databases;</code></pre><h3 id="创建数据库"><a href="#创建数据库" class="headerlink" title="创建数据库"></a>创建数据库</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create database spider2 DEFAULT CHARACTER SET utf8;  // 中文支持</span><br></pre></td></tr></table></figure><h3 id="删除数据库"><a href="#删除数据库" class="headerlink" title="删除数据库"></a>删除数据库</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">drop database &lt;数据库名&gt;;</span><br></pre></td></tr></table></figure><h3 id="关于tables"><a href="#关于tables" class="headerlink" title="关于tables"></a>关于tables</h3><pre><code>查看tables：show() tables;删除数据表：DROP TABLE table_name;</code></pre><h3 id="使用python连接数据库"><a href="#使用python连接数据库" class="headerlink" title="使用python连接数据库"></a>使用python连接数据库</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pymysql</span><br><span class="line"></span><br><span class="line"><span class="comment"># 简单的查找  # 连接数据库</span></span><br><span class="line">conn = pymysql.connect(host=<span class="string">&#x27;localhost&#x27;</span>, port=<span class="number">3306</span>, charset=<span class="string">&quot;UTF8&quot;</span>, user=<span class="string">&#x27;root&#x27;</span>, password=<span class="string">&#x27;dpb238031&#x27;</span>, database=<span class="string">&#x27;mysql&#x27;</span>)</span><br><span class="line">cursor = conn.cursor(cursor=pymysql.cursors.DictCursor)</span><br><span class="line"></span><br><span class="line">sql = <span class="string">&#x27;select * from runoob_tbl&#x27;</span></span><br><span class="line">row = cursor.execute(sql)</span><br><span class="line">result = cursor.fetchall()</span><br></pre></td></tr></table></figure><h3 id="python实现增删改"><a href="#python实现增删改" class="headerlink" title="python实现增删改"></a>python实现增删改</h3><p>增</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sql = <span class="string">&quot;&quot;&quot;INSERT INTO runoob_tbl (runoob_title, runoob_author, submission_date)</span></span><br><span class="line"><span class="string">      VALUES  (&quot;JAVA 教程&quot;, &quot;RUNOOB.COM&quot;, &#x27;2016-09-06&#x27;)&quot;&quot;&quot;</span></span><br><span class="line">cursor.execute(sql)</span><br><span class="line">conn.commit()   <span class="comment">#提交事务，如果不提交，更新不生效</span></span><br></pre></td></tr></table></figure><p>删</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sql = <span class="string">&quot;&quot;&quot;delete from  runoob_tbl where runoob_id = 7 &quot;&quot;&quot;</span></span><br><span class="line">cursor.execute(sql)</span><br><span class="line">conn.commit()</span><br></pre></td></tr></table></figure><p>改</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sql = <span class="string">&quot;&quot;&quot;UPDATE runoob_tbl SET runoob_title = &#x27;我爱学习&#x27;,</span></span><br><span class="line"><span class="string">                        runoob_author = &#x27;杜培博&#x27;,submission_date = &#x27;2021-05-08&#x27; WHERE  runoob_id = 7&quot;&quot;&quot;</span></span><br><span class="line">cursor.execute(sql)</span><br><span class="line">conn.commit()</span><br></pre></td></tr></table></figure><p>最后不要忘了关闭</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cursor.close()</span><br><span class="line">conn.close()</span><br></pre></td></tr></table></figure><p>使用pandas向已有mysql表格中写入数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sqlalchemy <span class="keyword">import</span> create_engine</span><br><span class="line"></span><br><span class="line">conn3 = create_engine(<span class="string">&#x27;mysql+pymysql://root:dpb238031@localhost:3306/mysql?charset=utf8&#x27;</span>)</span><br><span class="line">sql = <span class="string">&#x27;select * from runoob_tbl&#x27;</span></span><br><span class="line">rub = pd.read_sql(sql, conn3)</span><br><span class="line"></span><br><span class="line">df = pd.DataFrame(&#123;<span class="string">&#x27;runoob_id&#x27;</span>: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], <span class="string">&#x27;runoob_title&#x27;</span>: [<span class="string">&#x27;zhangsan&#x27;</span>, <span class="string">&#x27;lisi&#x27;</span>, <span class="string">&#x27;wangwu&#x27;</span>],</span><br><span class="line">                   <span class="string">&#x27;runoob_author&#x27;</span>: [<span class="number">6</span>, <span class="number">8</span>, <span class="number">9</span>], <span class="string">&#x27;submission_date&#x27;</span>: [<span class="string">&#x27;2016-09-06&#x27;</span>, <span class="string">&#x27;2016-09-06&#x27;</span>, <span class="string">&#x27;2016-09-06&#x27;</span>]&#125;)</span><br><span class="line"></span><br><span class="line">df.to_sql(name=<span class="string">&#x27;aaaa&#x27;</span>, con=conn3, if_exists=<span class="string">&#x27;append&#x27;</span>, index=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> MySQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>关于python中的类，很详细</title>
      <link href="/posts/12968.html"/>
      <url>/posts/12968.html</url>
      
        <content type="html"><![CDATA[<p>Python中的类的学习</p><span id="more"></span><h3 id="类的组成"><a href="#类的组成" class="headerlink" title="类的组成"></a>类的组成</h3><pre><code>·类属性·实例方法·静态方法·类方法</code></pre><h3 id="创建类的语法（基本模板）"><a href="#创建类的语法（基本模板）" class="headerlink" title="创建类的语法（基本模板）"></a>创建类的语法（基本模板）</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Student</span>:    <span class="comment">#Student为类的名字，</span></span><br><span class="line">    native_place=<span class="string">&#x27;吉林&#x27;</span>   <span class="comment">#类属性</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,name,age</span>):    <span class="comment">#name,age为实例属性,直接写在类里的变量，称为类属性</span></span><br><span class="line">        self.name=name  <span class="comment">#self.name为实例属性，进行了一个赋值操作，将局部变量name赋值给实例属性</span></span><br><span class="line">        self.age=age</span><br><span class="line"></span><br><span class="line">    <span class="comment">#实例方法</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">info</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;我的名字叫：&#x27;</span>,self.name,<span class="string">&#x27;年龄是：&#x27;</span>,self.age)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#类方法</span></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sm</span>(<span class="params">cls</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;类方法&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#静态方法</span></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sm</span>():</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;静态方法&#x27;</span>)</span><br></pre></td></tr></table></figure><h3 id="对象的创建"><a href="#对象的创建" class="headerlink" title="对象的创建"></a>对象的创建</h3><pre><code>·语法：    实例名=类名（）·意义：有了实例，就可以调用类的内容·创建Student类的实例对象：</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">stu1=Student(<span class="string">&#x27;Jack&#x27;</span>,<span class="number">20</span>)</span><br><span class="line"><span class="built_in">print</span>(stu1.name)</span><br><span class="line"><span class="built_in">print</span>(stu1.age)</span><br><span class="line">stu1.info()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/67240d5f053f40e4b2d7bc753e601d55.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h3 id="方法的调用"><a href="#方法的调用" class="headerlink" title="方法的调用"></a>方法的调用</h3><pre><code>··方法一：stu1.eat()   #对象名.方法名··方法二：Student.eat(stu1)    #类名.方法名(类的对象)</code></pre><h3 id="类属性，类方法，静态方法"><a href="#类属性，类方法，静态方法" class="headerlink" title="类属性，类方法，静态方法"></a>类属性，类方法，静态方法</h3><pre><code>·类属性:类中方法外的变量称为类属性，被该类的所有对象所共享 ·类方法:使用@classmethod修饰的方法， 使用类名直接访问的方法 ·静态方法:使用@staticmethod修饰的主法， 使用类名直接访问的方法</code></pre><p>   ·使用方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;---------类属性的使用方法-----------&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(Student.native_place)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;---------类方法的使用方式-----------&#x27;</span>)</span><br><span class="line">Student.cm()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;---------静态方法的使用方式-----------&#x27;</span>)</span><br><span class="line">Student.sm()</span><br></pre></td></tr></table></figure><h3 id="动态绑定属性和方法"><a href="#动态绑定属性和方法" class="headerlink" title="动态绑定属性和方法"></a>动态绑定属性和方法</h3><p> ·一个Student类可以创建N多个Student类的实例对象，每个实例对象的属性值不同。</p><pre><code>·Python是一门动态语言，在创建对象之后，可以动态的绑定属性和方法·动态绑定属性：</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stu1.gender=<span class="string">&#x27;女&#x27;</span>    <span class="comment">#此属性只允许stu1使用，stu2不可使</span></span><br></pre></td></tr></table></figure><pre><code>·动态的绑定方法：</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#为stu1单独绑定show()方法</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">shou</span>():</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line">stu1.shou=shou</span><br><span class="line">stu1.shou()</span><br></pre></td></tr></table></figure><h3 id="知识点总结"><a href="#知识点总结" class="headerlink" title="知识点总结"></a>知识点总结</h3><p><img src="https://img-blog.csdnimg.cn/6d00a63130104bf0ab0493854e6e87fd.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>学生信息管理系统</title>
      <link href="/posts/13452.html"/>
      <url>/posts/13452.html</url>
      
        <content type="html"><![CDATA[<p>学生信息管理系统可分为七大模块来讲解</p><span id="more"></span><h2 id="学生信息管理系统基本理解"><a href="#学生信息管理系统基本理解" class="headerlink" title="学生信息管理系统基本理解"></a>学生信息管理系统基本理解</h2><p><img src="https://img-blog.csdnimg.cn/688f084d3b8547a693e62662a609fa57.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h2 id="系统业务流程"><a href="#系统业务流程" class="headerlink" title="系统业务流程"></a>系统业务流程</h2><p><img src="https://img-blog.csdnimg.cn/74ed0681d0a044ae812168531472b515.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h2 id="系统开发环境"><a href="#系统开发环境" class="headerlink" title="系统开发环境"></a>系统开发环境</h2><pre><code>·操作系统：Win10·Python解释器版本：Python3.8·开发工具：PyCharm·Python内置模块：os，re</code></pre><p>·系统主界面运行效果图如下：</p><p><img src="https://img-blog.csdnimg.cn/433f1d210ccc4470b080e3d84dfa2728.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h2 id="主函数数设计流程"><a href="#主函数数设计流程" class="headerlink" title="主函数数设计流程"></a>主函数数设计流程</h2><p><img src="https://img-blog.csdnimg.cn/10dbd83ef8254f07b2ad11f23827540b.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h2 id="由函数图得出函数基本骨架"><a href="#由函数图得出函数基本骨架" class="headerlink" title="由函数图得出函数基本骨架"></a>由函数图得出函数基本骨架</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        menm()</span><br><span class="line">        choice = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&quot;请输入&quot;</span>))</span><br><span class="line">        <span class="keyword">if</span> choice <span class="keyword">in</span> [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>]:</span><br><span class="line">            <span class="keyword">if</span> choice == <span class="number">0</span>:</span><br><span class="line">                answer = <span class="built_in">input</span>(<span class="string">&quot;您确定退出系统吗？y/n&quot;</span>)</span><br><span class="line">                <span class="keyword">if</span> answer == <span class="string">&quot;y&quot;</span> <span class="keyword">or</span> answer == <span class="string">&quot;Y&quot;</span>:</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">&quot;谢谢使用&quot;</span>)</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">elif</span> choice == <span class="number">1</span>:</span><br><span class="line">                insert()  <span class="comment"># 录入学生信息</span></span><br><span class="line">            <span class="keyword">elif</span> choice == <span class="number">2</span>:</span><br><span class="line">                search()</span><br><span class="line">            <span class="keyword">elif</span> choice == <span class="number">3</span>:</span><br><span class="line">                delete()</span><br><span class="line">            <span class="keyword">elif</span> choice == <span class="number">4</span>:</span><br><span class="line">                modify</span><br><span class="line">            <span class="keyword">elif</span> choice == <span class="number">5</span>:</span><br><span class="line">                sort()</span><br><span class="line">            <span class="keyword">elif</span> choice == <span class="number">6</span>:</span><br><span class="line">                total()</span><br><span class="line">            <span class="keyword">elif</span> choice == <span class="number">7</span>:</span><br><span class="line">                show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">menm</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;=======================学生信息管理系统=====================&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;=======================功能菜单===========================&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\t\t\t\t\t1.录入学生信息&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\t\t\t\t\t2.查找学生信息&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\t\t\t\t\t3.删除学生信息&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\t\t\t\t\t4.修改学生信息&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\t\t\t\t\t5.排序&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\t\t\t\t\t6.统计学生总人数&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\t\t\t\t\t7.显示所有学生信息&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\t\t\t\t\t0.退出&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">insert</span>():</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">search</span>():</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">delete</span>():</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">modify</span>():</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sort</span>():</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">total</span>():</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">show</span>():</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><h2 id="录入学生信息"><a href="#录入学生信息" class="headerlink" title="录入学生信息"></a>录入学生信息</h2><h3 id="业务流程"><a href="#业务流程" class="headerlink" title="业务流程"></a>业务流程</h3><p><img src="https://img-blog.csdnimg.cn/1c7f0b67b4bd43a48b8a35b1cfe6351f.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h3 id="代码如下"><a href="#代码如下" class="headerlink" title="代码如下"></a>代码如下</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">insert</span>():</span><br><span class="line">    student_list = []</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="built_in">id</span> = <span class="built_in">input</span>(<span class="string">&quot;请输入id：&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">id</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        name = <span class="built_in">input</span>(<span class="string">&quot;请输入姓名：&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> name:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            english = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&quot;请输入英语成绩&quot;</span>))</span><br><span class="line">            python = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&quot;请输入python成绩：&quot;</span>))</span><br><span class="line">            java = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&quot;请输入java成绩：&quot;</span>))</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;输入无效，不是整数类型，请重新输入：&quot;</span>)</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="comment"># 将录入的成绩保存到字典中</span></span><br><span class="line">        student = &#123;<span class="string">&quot;id&quot;</span>: <span class="built_in">id</span>, <span class="string">&quot;name&quot;</span>: name, <span class="string">&quot;english&quot;</span>: english, <span class="string">&quot;python&quot;</span>: python, <span class="string">&quot;java&quot;</span>: java&#125;</span><br><span class="line">        <span class="comment"># 将学生信息添加到列表中</span></span><br><span class="line">        student_list.append(student)</span><br><span class="line">        answer = <span class="built_in">input</span>(<span class="string">&quot;是否继续相加&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> answer == <span class="string">&quot;y&quot;</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="comment"># 调用save函数</span></span><br><span class="line">    save(student_list)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;学生信息录入完毕！！！！&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">save</span>(<span class="params">lst</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        stu_txt = <span class="built_in">open</span>(filename, <span class="string">&quot;a&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        stu_txt = <span class="built_in">open</span>(filename, <span class="string">&quot;w&quot;</span>, encoding = <span class="string">&quot;utf-8&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> lst:</span><br><span class="line">        stu_txt.write(<span class="built_in">str</span>(item) + <span class="string">&quot;\n&quot;</span>)</span><br><span class="line">    stu_txt.close()</span><br></pre></td></tr></table></figure><h2 id="删除学生信息"><a href="#删除学生信息" class="headerlink" title="删除学生信息"></a>删除学生信息</h2><h3 id="业务流程-1"><a href="#业务流程-1" class="headerlink" title="业务流程"></a>业务流程</h3><p><img src="https://img-blog.csdnimg.cn/d285b8250739481e97a3a389d02011c3.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h3 id="代码如下-1"><a href="#代码如下-1" class="headerlink" title="代码如下"></a>代码如下</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">delete</span>():</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        student_id=<span class="built_in">input</span>(<span class="string">&quot;请输入要删除学生的id：&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> student_id!=<span class="string">&quot;&quot;</span>:</span><br><span class="line">            <span class="keyword">if</span> os.path.exists(filename):</span><br><span class="line">                <span class="keyword">with</span> <span class="built_in">open</span>(filename,<span class="string">&quot;r&quot;</span>,encoding=<span class="string">&quot;utf-8&quot;</span>)<span class="keyword">as</span> file:</span><br><span class="line">                    student_old=file.readlines()</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                student_old=[]</span><br><span class="line">            flag=<span class="literal">False</span>   <span class="comment">#标记是否删除</span></span><br><span class="line">            <span class="keyword">if</span> student_old:</span><br><span class="line">                <span class="keyword">with</span> <span class="built_in">open</span>(filename,<span class="string">&quot;w&quot;</span>,encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> wfile:</span><br><span class="line">                    d=&#123;&#125;</span><br><span class="line">                    <span class="keyword">for</span> item <span class="keyword">in</span> student_old:</span><br><span class="line">                        d=<span class="built_in">dict</span>(<span class="built_in">eval</span>(item))   <span class="comment">#将字符串转换为字典</span></span><br><span class="line">                        <span class="keyword">if</span> d[<span class="string">&quot;id&quot;</span>]!=student_id:</span><br><span class="line">                            wfile.write(<span class="built_in">str</span>(d)+<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">                        <span class="keyword">else</span>:</span><br><span class="line">                            flag=<span class="literal">True</span></span><br><span class="line">                    <span class="keyword">if</span> flag:</span><br><span class="line">                        <span class="built_in">print</span>(<span class="string">f&quot;id为<span class="subst">&#123;student_id&#125;</span>的学生信息已被删除&quot;</span>)</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        <span class="built_in">print</span>(<span class="string">f&quot;没有找到id为<span class="subst">&#123;student_id&#125;</span>的学生信息&quot;</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;无学生信息&quot;</span>)</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            show()    <span class="comment">#删除之后要重新显示学生信息</span></span><br><span class="line">            answer=<span class="built_in">input</span>(<span class="string">&quot;是否继续删除？y/n&quot;</span>)</span><br><span class="line">            <span class="keyword">if</span> answer==<span class="string">&quot;y&quot;</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br></pre></td></tr></table></figure><h2 id="修改学生信息"><a href="#修改学生信息" class="headerlink" title="修改学生信息"></a>修改学生信息</h2><h3 id="业务流程图"><a href="#业务流程图" class="headerlink" title="业务流程图"></a>业务流程图</h3><p><img src="https://img-blog.csdnimg.cn/9b5c868041e745d3ad0527d6e30a3d10.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h3 id="代码如下-2"><a href="#代码如下-2" class="headerlink" title="代码如下"></a>代码如下</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">modify</span>():</span><br><span class="line">    show()</span><br><span class="line">    <span class="keyword">if</span> os.path.exists(filename):</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(filename,<span class="string">&quot;r&quot;</span>,encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> rfile:</span><br><span class="line">            student_old=rfile.readlines()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    student_id=<span class="built_in">input</span>(<span class="string">&quot;请输入要修改学生的id：&quot;</span>)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(filename,<span class="string">&quot;w&quot;</span>,encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> wfile:</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> student_old:</span><br><span class="line">            d=<span class="built_in">dict</span>(<span class="built_in">eval</span>(item))</span><br><span class="line">            <span class="keyword">if</span> d[<span class="string">&quot;id&quot;</span>]==student_id:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;找到学生信息了，可以修改相关信息了！&quot;</span>)</span><br><span class="line">                <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">                    <span class="keyword">try</span>:</span><br><span class="line">                        d[<span class="string">&quot;name&quot;</span>]=<span class="built_in">input</span>(<span class="string">&quot;请输入姓名：&quot;</span>)</span><br><span class="line">                        d[<span class="string">&quot;english&quot;</span>]=<span class="built_in">input</span>(<span class="string">&quot;请输入英语成绩:&quot;</span>)</span><br><span class="line">                        d[<span class="string">&quot;python&quot;</span>]=<span class="built_in">input</span>(<span class="string">&quot;请输入Python成绩：&quot;</span>)</span><br><span class="line">                        d[<span class="string">&quot;java&quot;</span>]=<span class="built_in">input</span>(<span class="string">&quot;请输入java成绩：&quot;</span>)</span><br><span class="line">                    <span class="keyword">except</span>:</span><br><span class="line">                        <span class="built_in">print</span>(<span class="string">&quot;您输入有误，请重新输入！！！&quot;</span>)</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        <span class="keyword">break</span></span><br><span class="line">                wfile.write(<span class="built_in">str</span>(d)+<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;修改成功！！！&quot;</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                wfile.write(<span class="built_in">str</span>(d)+<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">        answer=<span class="built_in">input</span>(<span class="string">&quot;是否要继续修改其他学生信息？y/n&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> answer==<span class="string">&quot;y&quot;</span>:</span><br><span class="line">            modify()</span><br></pre></td></tr></table></figure><h2 id="查找学生信息功能"><a href="#查找学生信息功能" class="headerlink" title="查找学生信息功能"></a>查找学生信息功能</h2><h3 id="业务流程图-1"><a href="#业务流程图-1" class="headerlink" title="业务流程图"></a>业务流程图</h3><p><img src="https://img-blog.csdnimg.cn/19cbff28edd84fc89bc374115b9170d2.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h3 id="代码如下-3"><a href="#代码如下-3" class="headerlink" title="代码如下"></a>代码如下</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">search</span>():</span><br><span class="line">    student_query = []</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="built_in">id</span> = <span class="string">&quot;&quot;</span></span><br><span class="line">        name = <span class="string">&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> os.path.exists(filename):</span><br><span class="line">            mode = <span class="built_in">input</span>(<span class="string">&quot;按id查找请输入1，按姓名查找请输入2：&quot;</span>)</span><br><span class="line">            <span class="keyword">if</span> mode == <span class="string">&quot;1&quot;</span>:</span><br><span class="line">                <span class="built_in">id</span> = <span class="built_in">input</span>(<span class="string">&quot;请输入学生id：&quot;</span>)</span><br><span class="line">            <span class="keyword">elif</span> mode == <span class="string">&quot;2&quot;</span>:</span><br><span class="line">                name = <span class="built_in">input</span>(<span class="string">&quot;请输入学生的姓名：&quot;</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;您的输入有误，请重新输入&quot;</span>)</span><br><span class="line">                search()</span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(filename, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> rfile:</span><br><span class="line">                student = rfile.readlines()</span><br><span class="line">                <span class="keyword">for</span> item <span class="keyword">in</span> student:</span><br><span class="line">                    d = <span class="built_in">dict</span>(<span class="built_in">eval</span>(item))</span><br><span class="line">                    <span class="keyword">if</span> <span class="built_in">id</span> != <span class="string">&quot;&quot;</span>:</span><br><span class="line">                        <span class="keyword">if</span> d[<span class="string">&quot;id&quot;</span>] == <span class="built_in">id</span>:</span><br><span class="line">                            student_query.append(d)</span><br><span class="line">                    <span class="keyword">elif</span> name != <span class="string">&quot;&quot;</span>:</span><br><span class="line">                        <span class="keyword">if</span> d[<span class="string">&quot;name&quot;</span>] == name:</span><br><span class="line">                            student_query.append(d)</span><br><span class="line">            <span class="comment"># 显示查询结果</span></span><br><span class="line">            show_student(student_query)</span><br><span class="line">            <span class="comment"># 清空列表</span></span><br><span class="line">            student_query.clear()</span><br><span class="line">            anser = <span class="built_in">input</span>(<span class="string">&quot;是否要继续查询？y/n\n&quot;</span>)</span><br><span class="line">            <span class="keyword">if</span> anser == <span class="string">&quot;y&quot;</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;暂未保存学员信息&quot;</span>)</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">show_student</span>(<span class="params">lst</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(lst) == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;没查到学生信息，无数据显示！！！&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    <span class="comment"># 定义标准的显示格式</span></span><br><span class="line">    format_title = <span class="string">&quot;&#123;:^6&#125;\t&#123;:^12&#125;\t&#123;:^8&#125;\t&#123;:^01&#125;\t&#123;:^10&#125;\t&#123;:^8&#125;&quot;</span></span><br><span class="line">    <span class="built_in">print</span>(format_title.<span class="built_in">format</span>(<span class="string">&quot;ID&quot;</span>, <span class="string">&quot;姓名&quot;</span>, <span class="string">&quot;英语成绩&quot;</span>,<span class="string">&quot;python成绩&quot;</span>, <span class="string">&quot;java成绩&quot;</span>, <span class="string">&quot;总成绩&quot;</span>))</span><br><span class="line">    <span class="comment"># 定义内容的显示格式</span></span><br><span class="line">    format_data = <span class="string">&quot;&#123;:^6&#125;\t&#123;:^12&#125;\t&#123;:^8&#125;\t&#123;:^10&#125;\t&#123;:^10&#125;\t&#123;:^8&#125;&quot;</span></span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> lst:</span><br><span class="line">        <span class="built_in">print</span>(format_data.<span class="built_in">format</span>(item.get(<span class="string">&quot;id&quot;</span>),</span><br><span class="line">                                 item.get(<span class="string">&quot;name&quot;</span>),</span><br><span class="line">                                 item.get(<span class="string">&quot;english&quot;</span>),</span><br><span class="line">                                 item.get(<span class="string">&quot;python&quot;</span>),</span><br><span class="line">                                 item.get(<span class="string">&quot;java&quot;</span>),</span><br><span class="line">                                 <span class="built_in">int</span>(item.get(<span class="string">&quot;english&quot;</span>)) + <span class="built_in">int</span>(item.get(<span class="string">&quot;python&quot;</span>)) + <span class="built_in">int</span>(item.get(<span class="string">&quot;java&quot;</span>))</span><br><span class="line">                                 ))</span><br></pre></td></tr></table></figure><h2 id="统计学生总人数"><a href="#统计学生总人数" class="headerlink" title="统计学生总人数"></a>统计学生总人数</h2><h3 id="业务流程图-2"><a href="#业务流程图-2" class="headerlink" title="业务流程图"></a>业务流程图</h3><p><img src="https://img-blog.csdnimg.cn/5c5fbfd4affe45d6b381756c554a47a4.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h3 id="代码如下-4"><a href="#代码如下-4" class="headerlink" title="代码如下"></a>代码如下</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">total</span>():</span><br><span class="line">    <span class="keyword">if</span> os.path.exists(filename):</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(filename,<span class="string">&quot;r&quot;</span>,encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> rfile:</span><br><span class="line">            student=rfile.readlines()</span><br><span class="line">            <span class="keyword">if</span> student:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;一共有<span class="subst">&#123;<span class="built_in">len</span>(student)&#125;</span>名学生&quot;</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;还没有录入学生信息&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;暂未保存数据信息.....&quot;</span>)</span><br></pre></td></tr></table></figure><h2 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h2><h3 id="业务流程图-3"><a href="#业务流程图-3" class="headerlink" title="业务流程图"></a>业务流程图</h3><p><img src="https://img-blog.csdnimg.cn/2d68573e293d48aea0ac593baa998f46.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h3 id="代码如下-5"><a href="#代码如下-5" class="headerlink" title="代码如下"></a>代码如下</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">sort</span>():</span><br><span class="line">    show()</span><br><span class="line">    <span class="keyword">if</span> os.path.exists(filename):</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(filename,<span class="string">&quot;r&quot;</span>,encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> rfile:</span><br><span class="line">            student_list=rfile.readlines()</span><br><span class="line">        student_new=[]</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> student_list:</span><br><span class="line">            d=<span class="built_in">dict</span>(<span class="built_in">eval</span>(item))</span><br><span class="line">            student_new.append(d)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    asc_or_desc=<span class="built_in">input</span>(<span class="string">&quot;请选择（0.升序  1.降序）：&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> asc_or_desc==<span class="string">&quot;0&quot;</span>:</span><br><span class="line">        asc_or_desc_bool=<span class="literal">False</span></span><br><span class="line">    <span class="keyword">elif</span> asc_or_desc==<span class="string">&quot;1&quot;</span>:</span><br><span class="line">        asc_or_desc_bool=<span class="literal">True</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;您的输入有误，请重新输入&quot;</span>)</span><br><span class="line">        sort()</span><br><span class="line">    mode=<span class="built_in">input</span>(<span class="string">&quot;请选择排序方式（1，按英语成绩排序  2，按python程序排序  3，按Java程序排序  0，按照总程序排序）&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> mode==<span class="string">&quot;1&quot;</span>:</span><br><span class="line">        student_new.sort(key=<span class="keyword">lambda</span> x:<span class="built_in">int</span>(x[<span class="string">&quot;english&quot;</span>]),reverse=asc_or_desc_bool)</span><br><span class="line">    <span class="keyword">elif</span> mode==<span class="string">&quot;2&quot;</span>:</span><br><span class="line">        student_new.sort(key=<span class="keyword">lambda</span> x:<span class="built_in">int</span>(x[<span class="string">&quot;python&quot;</span>]),reverse=asc_or_desc_bool)</span><br><span class="line">    <span class="keyword">elif</span> mode==<span class="string">&quot;3&quot;</span>:</span><br><span class="line">        student_new.sort(key=<span class="keyword">lambda</span> x:<span class="built_in">int</span>(x[<span class="string">&quot;java&quot;</span>]),reverse=asc_or_desc_bool)</span><br><span class="line">    <span class="keyword">elif</span> mode==<span class="string">&quot;0&quot;</span>:</span><br><span class="line">        student_new.sort(key=<span class="keyword">lambda</span> x: <span class="built_in">int</span>(x[<span class="string">&quot;english&quot;</span>])+<span class="built_in">int</span>(x[<span class="string">&quot;python&quot;</span>])+<span class="built_in">int</span>(x[<span class="string">&quot;java&quot;</span>]),reverse=asc_or_desc_bool)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;您的输入有误，请从新输入：&quot;</span>)</span><br><span class="line">        sort()</span><br><span class="line">    show_student(student_new)</span><br></pre></td></tr></table></figure><h2 id="显示所有学生信息"><a href="#显示所有学生信息" class="headerlink" title="显示所有学生信息"></a>显示所有学生信息</h2><h3 id="业务图"><a href="#业务图" class="headerlink" title="业务图"></a>业务图</h3><p><img src="https://img-blog.csdnimg.cn/57b8ce9b6c594087bded1a67c09785db.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h3 id="代码如下-6"><a href="#代码如下-6" class="headerlink" title="代码如下"></a>代码如下</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">show</span>():</span><br><span class="line">    student_lst=[]</span><br><span class="line">    <span class="keyword">if</span> os.path.exists(filename):</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(filename,<span class="string">&quot;r&quot;</span>,encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> rfile:</span><br><span class="line">            student=rfile.readlines()</span><br><span class="line">            <span class="keyword">for</span> item <span class="keyword">in</span> student:</span><br><span class="line">                student_lst.append(<span class="built_in">eval</span>(item))</span><br><span class="line">                <span class="keyword">if</span> student_lst:</span><br><span class="line">                    show_student(student_lst)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;暂未保存过数据！！&quot;</span>)</span><br></pre></td></tr></table></figure><h2 id="最后得出这个工程完整的代码"><a href="#最后得出这个工程完整的代码" class="headerlink" title="最后得出这个工程完整的代码"></a>最后得出这个工程完整的代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment"># author:杜小皮</span></span><br><span class="line"><span class="comment"># datetime:2021/1/30 10:12</span></span><br><span class="line"><span class="comment"># software: PyCharm</span></span><br><span class="line"><span class="keyword">import</span> os  <span class="comment"># 删除操作导入os模块</span></span><br><span class="line"></span><br><span class="line">filename = <span class="string">&quot;student.txt&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        menm()</span><br><span class="line">        choice = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&quot;请输入&quot;</span>))</span><br><span class="line">        <span class="keyword">if</span> choice <span class="keyword">in</span> [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>]:</span><br><span class="line">            <span class="keyword">if</span> choice == <span class="number">0</span>:</span><br><span class="line">                answer = <span class="built_in">input</span>(<span class="string">&quot;您确定退出系统吗？y/n&quot;</span>)</span><br><span class="line">                <span class="keyword">if</span> answer == <span class="string">&quot;y&quot;</span> <span class="keyword">or</span> answer == <span class="string">&quot;Y&quot;</span>:</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">&quot;谢谢使用&quot;</span>)</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">elif</span> choice == <span class="number">1</span>:</span><br><span class="line">                insert()  <span class="comment"># 录入学生信息</span></span><br><span class="line">            <span class="keyword">elif</span> choice == <span class="number">2</span>:</span><br><span class="line">                search()</span><br><span class="line">            <span class="keyword">elif</span> choice == <span class="number">3</span>:</span><br><span class="line">                delete()</span><br><span class="line">            <span class="keyword">elif</span> choice == <span class="number">4</span>:</span><br><span class="line">                modify()</span><br><span class="line">            <span class="keyword">elif</span> choice == <span class="number">5</span>:</span><br><span class="line">                sort()</span><br><span class="line">            <span class="keyword">elif</span> choice == <span class="number">6</span>:</span><br><span class="line">                total()</span><br><span class="line">            <span class="keyword">elif</span> choice == <span class="number">7</span>:</span><br><span class="line">                show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">menm</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;=======================学生信息管理系统=====================&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;=======================功能菜单===========================&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\t\t\t\t\t1.录入学生信息&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\t\t\t\t\t2.查找学生信息&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\t\t\t\t\t3.删除学生信息&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\t\t\t\t\t4.修改学生信息&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\t\t\t\t\t5.排序&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\t\t\t\t\t6.统计学生总人数&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\t\t\t\t\t7.显示所有学生信息&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\t\t\t\t\t0.退出&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">insert</span>():</span><br><span class="line">    student_list = []</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="built_in">id</span> = <span class="built_in">input</span>(<span class="string">&quot;请输入id：&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">id</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        name = <span class="built_in">input</span>(<span class="string">&quot;请输入姓名：&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> name:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            english = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&quot;请输入英语成绩&quot;</span>))</span><br><span class="line">            python = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&quot;请输入python成绩：&quot;</span>))</span><br><span class="line">            java = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&quot;请输入java成绩：&quot;</span>))</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;输入无效，不是整数类型，请重新输入：&quot;</span>)</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="comment"># 将录入的成绩保存到字典中</span></span><br><span class="line">        student = &#123;<span class="string">&quot;id&quot;</span>: <span class="built_in">id</span>, <span class="string">&quot;name&quot;</span>: name, <span class="string">&quot;english&quot;</span>: english, <span class="string">&quot;python&quot;</span>: python, <span class="string">&quot;java&quot;</span>: java&#125;</span><br><span class="line">        <span class="comment"># 将学生信息添加到列表中</span></span><br><span class="line">        student_list.append(student)</span><br><span class="line">        answer = <span class="built_in">input</span>(<span class="string">&quot;是否继续相加&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> answer == <span class="string">&quot;y&quot;</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="comment"># 调用save函数</span></span><br><span class="line">    save(student_list)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;学生信息录入完毕！！！！&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">save</span>(<span class="params">lst</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        stu_txt = <span class="built_in">open</span>(filename, <span class="string">&quot;a&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        stu_txt = <span class="built_in">open</span>(filename, <span class="string">&quot;w&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> lst:</span><br><span class="line">        stu_txt.write(<span class="built_in">str</span>(item) + <span class="string">&quot;\n&quot;</span>)</span><br><span class="line">    stu_txt.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">search</span>():</span><br><span class="line">    student_query = []</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="built_in">id</span> = <span class="string">&quot;&quot;</span></span><br><span class="line">        name = <span class="string">&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> os.path.exists(filename):</span><br><span class="line">            mode = <span class="built_in">input</span>(<span class="string">&quot;按id查找请输入1，按姓名查找请输入2：&quot;</span>)</span><br><span class="line">            <span class="keyword">if</span> mode == <span class="string">&quot;1&quot;</span>:</span><br><span class="line">                <span class="built_in">id</span> = <span class="built_in">input</span>(<span class="string">&quot;请输入学生id：&quot;</span>)</span><br><span class="line">            <span class="keyword">elif</span> mode == <span class="string">&quot;2&quot;</span>:</span><br><span class="line">                name = <span class="built_in">input</span>(<span class="string">&quot;请输入学生的姓名：&quot;</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;您的输入有误，请重新输入&quot;</span>)</span><br><span class="line">                search()</span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(filename, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> rfile:</span><br><span class="line">                student = rfile.readlines()</span><br><span class="line">                <span class="keyword">for</span> item <span class="keyword">in</span> student:</span><br><span class="line">                    d = <span class="built_in">dict</span>(<span class="built_in">eval</span>(item))</span><br><span class="line">                    <span class="keyword">if</span> <span class="built_in">id</span> != <span class="string">&quot;&quot;</span>:</span><br><span class="line">                        <span class="keyword">if</span> d[<span class="string">&quot;id&quot;</span>] == <span class="built_in">id</span>:</span><br><span class="line">                            student_query.append(d)</span><br><span class="line">                    <span class="keyword">elif</span> name != <span class="string">&quot;&quot;</span>:</span><br><span class="line">                        <span class="keyword">if</span> d[<span class="string">&quot;name&quot;</span>] == name:</span><br><span class="line">                            student_query.append(d)</span><br><span class="line">            <span class="comment"># 显示查询结果</span></span><br><span class="line">            show_student(student_query)</span><br><span class="line">            <span class="comment"># 清空列表</span></span><br><span class="line">            student_query.clear()</span><br><span class="line">            anser = <span class="built_in">input</span>(<span class="string">&quot;是否要继续查询？y/n\n&quot;</span>)</span><br><span class="line">            <span class="keyword">if</span> anser == <span class="string">&quot;y&quot;</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;暂未保存学员信息&quot;</span>)</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">show_student</span>(<span class="params">lst</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(lst) == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;没查到学生信息，无数据显示！！！&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    <span class="comment"># 定义标准的显示格式</span></span><br><span class="line">    format_title = <span class="string">&quot;&#123;:^6&#125;\t&#123;:^12&#125;\t&#123;:^8&#125;\t&#123;:^01&#125;\t&#123;:^10&#125;\t&#123;:^8&#125;&quot;</span></span><br><span class="line">    <span class="built_in">print</span>(format_title.<span class="built_in">format</span>(<span class="string">&quot;ID&quot;</span>, <span class="string">&quot;姓名&quot;</span>, <span class="string">&quot;英语成绩&quot;</span>,<span class="string">&quot;python成绩&quot;</span>, <span class="string">&quot;java成绩&quot;</span>, <span class="string">&quot;总成绩&quot;</span>))</span><br><span class="line">    <span class="comment"># 定义内容的显示格式</span></span><br><span class="line">    format_data = <span class="string">&quot;&#123;:^6&#125;\t&#123;:^12&#125;\t&#123;:^8&#125;\t&#123;:^10&#125;\t&#123;:^10&#125;\t&#123;:^8&#125;&quot;</span></span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> lst:</span><br><span class="line">        <span class="built_in">print</span>(format_data.<span class="built_in">format</span>(item.get(<span class="string">&quot;id&quot;</span>),</span><br><span class="line">                                 item.get(<span class="string">&quot;name&quot;</span>),</span><br><span class="line">                                 item.get(<span class="string">&quot;english&quot;</span>),</span><br><span class="line">                                 item.get(<span class="string">&quot;python&quot;</span>),</span><br><span class="line">                                 item.get(<span class="string">&quot;java&quot;</span>),</span><br><span class="line">                                 <span class="built_in">int</span>(item.get(<span class="string">&quot;english&quot;</span>)) + <span class="built_in">int</span>(item.get(<span class="string">&quot;python&quot;</span>)) + <span class="built_in">int</span>(item.get(<span class="string">&quot;java&quot;</span>))</span><br><span class="line">                                 ))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">delete</span>():</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        student_id = <span class="built_in">input</span>(<span class="string">&quot;请输入要删除学生的id：&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> student_id != <span class="string">&quot;&quot;</span>:</span><br><span class="line">            <span class="keyword">if</span> os.path.exists(filename):</span><br><span class="line">                <span class="keyword">with</span> <span class="built_in">open</span>(filename, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>)<span class="keyword">as</span> file:</span><br><span class="line">                    student_old = file.readlines()</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                student_old = []</span><br><span class="line">            flag = <span class="literal">False</span>  <span class="comment"># 标记是否删除</span></span><br><span class="line">            <span class="keyword">if</span> student_old:</span><br><span class="line">                <span class="keyword">with</span> <span class="built_in">open</span>(filename, <span class="string">&quot;w&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> wfile:</span><br><span class="line">                    d = &#123;&#125;</span><br><span class="line">                    <span class="keyword">for</span> item <span class="keyword">in</span> student_old:</span><br><span class="line">                        d = <span class="built_in">dict</span>(<span class="built_in">eval</span>(item))  <span class="comment"># 将字符串转换为字典</span></span><br><span class="line">                        <span class="keyword">if</span> d[<span class="string">&quot;id&quot;</span>] != student_id:</span><br><span class="line">                            wfile.write(<span class="built_in">str</span>(d) + <span class="string">&quot;\n&quot;</span>)</span><br><span class="line">                        <span class="keyword">else</span>:</span><br><span class="line">                            flag = <span class="literal">True</span></span><br><span class="line">                    <span class="keyword">if</span> flag:</span><br><span class="line">                        <span class="built_in">print</span>(<span class="string">f&quot;id为<span class="subst">&#123;student_id&#125;</span>的学生信息已被删除&quot;</span>)</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        <span class="built_in">print</span>(<span class="string">f&quot;没有找到id为<span class="subst">&#123;student_id&#125;</span>的学生信息&quot;</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;无学生信息&quot;</span>)</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            show()  <span class="comment"># 删除之后要重新显示学生信息</span></span><br><span class="line">            answer = <span class="built_in">input</span>(<span class="string">&quot;是否继续删除？y/n&quot;</span>)</span><br><span class="line">            <span class="keyword">if</span> answer == <span class="string">&quot;y&quot;</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">modify</span>():</span><br><span class="line">    show()</span><br><span class="line">    <span class="keyword">if</span> os.path.exists(filename):</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(filename, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> rfile:</span><br><span class="line">            student_old = rfile.readlines()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    student_id = <span class="built_in">input</span>(<span class="string">&quot;请输入要修改学生的id：&quot;</span>)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(filename, <span class="string">&quot;w&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> wfile:</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> student_old:</span><br><span class="line">            d = <span class="built_in">dict</span>(<span class="built_in">eval</span>(item))</span><br><span class="line">            <span class="keyword">if</span> d[<span class="string">&quot;id&quot;</span>] == student_id:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;找到学生信息了，可以修改相关信息了！&quot;</span>)</span><br><span class="line">                <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">                    <span class="keyword">try</span>:</span><br><span class="line">                        d[<span class="string">&quot;name&quot;</span>] = <span class="built_in">input</span>(<span class="string">&quot;请输入姓名：&quot;</span>)</span><br><span class="line">                        d[<span class="string">&quot;english&quot;</span>] = <span class="built_in">input</span>(<span class="string">&quot;请输入英语成绩:&quot;</span>)</span><br><span class="line">                        d[<span class="string">&quot;python&quot;</span>] = <span class="built_in">input</span>(<span class="string">&quot;请输入Python成绩：&quot;</span>)</span><br><span class="line">                        d[<span class="string">&quot;java&quot;</span>] = <span class="built_in">input</span>(<span class="string">&quot;请输入java成绩：&quot;</span>)</span><br><span class="line">                    <span class="keyword">except</span>:</span><br><span class="line">                        <span class="built_in">print</span>(<span class="string">&quot;您输入有误，请重新输入！！！&quot;</span>)</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        <span class="keyword">break</span></span><br><span class="line">                wfile.write(<span class="built_in">str</span>(d) + <span class="string">&quot;\n&quot;</span>)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;修改成功！！！&quot;</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                wfile.write(<span class="built_in">str</span>(d) + <span class="string">&quot;\n&quot;</span>)</span><br><span class="line">        answer = <span class="built_in">input</span>(<span class="string">&quot;是否要继续修改其他学生信息？y/n&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> answer == <span class="string">&quot;y&quot;</span>:</span><br><span class="line">            modify()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sort</span>():</span><br><span class="line">    show()</span><br><span class="line">    <span class="keyword">if</span> os.path.exists(filename):</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(filename,<span class="string">&quot;r&quot;</span>,encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> rfile:</span><br><span class="line">            student_list=rfile.readlines()</span><br><span class="line">        student_new=[]</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> student_list:</span><br><span class="line">            d=<span class="built_in">dict</span>(<span class="built_in">eval</span>(item))</span><br><span class="line">            student_new.append(d)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    asc_or_desc=<span class="built_in">input</span>(<span class="string">&quot;请选择（0.升序  1.降序）：&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> asc_or_desc==<span class="string">&quot;0&quot;</span>:</span><br><span class="line">        asc_or_desc_bool=<span class="literal">False</span></span><br><span class="line">    <span class="keyword">elif</span> asc_or_desc==<span class="string">&quot;1&quot;</span>:</span><br><span class="line">        asc_or_desc_bool=<span class="literal">True</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;您的输入有误，请重新输入&quot;</span>)</span><br><span class="line">        sort()</span><br><span class="line">    mode=<span class="built_in">input</span>(<span class="string">&quot;请选择排序方式（1，按英语成绩排序  2，按python程序排序  3，按Java程序排序  0，按照总程序排序）&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> mode==<span class="string">&quot;1&quot;</span>:</span><br><span class="line">        student_new.sort(key=<span class="keyword">lambda</span> x:<span class="built_in">int</span>(x[<span class="string">&quot;english&quot;</span>]),reverse=asc_or_desc_bool)</span><br><span class="line">    <span class="keyword">elif</span> mode==<span class="string">&quot;2&quot;</span>:</span><br><span class="line">        student_new.sort(key=<span class="keyword">lambda</span> x:<span class="built_in">int</span>(x[<span class="string">&quot;python&quot;</span>]),reverse=asc_or_desc_bool)</span><br><span class="line">    <span class="keyword">elif</span> mode==<span class="string">&quot;3&quot;</span>:</span><br><span class="line">        student_new.sort(key=<span class="keyword">lambda</span> x:<span class="built_in">int</span>(x[<span class="string">&quot;java&quot;</span>]),reverse=asc_or_desc_bool)</span><br><span class="line">    <span class="keyword">elif</span> mode==<span class="string">&quot;0&quot;</span>:</span><br><span class="line">        student_new.sort(key=<span class="keyword">lambda</span> x: <span class="built_in">int</span>(x[<span class="string">&quot;english&quot;</span>])+<span class="built_in">int</span>(x[<span class="string">&quot;python&quot;</span>])+<span class="built_in">int</span>(x[<span class="string">&quot;java&quot;</span>]),reverse=asc_or_desc_bool)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;您的输入有误，请从新输入：&quot;</span>)</span><br><span class="line">        sort()</span><br><span class="line">    show_student(student_new)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">total</span>():</span><br><span class="line">    <span class="keyword">if</span> os.path.exists(filename):</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(filename,<span class="string">&quot;r&quot;</span>,encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> rfile:</span><br><span class="line">            student=rfile.readlines()</span><br><span class="line">            <span class="keyword">if</span> student:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;一共有<span class="subst">&#123;<span class="built_in">len</span>(student)&#125;</span>名学生&quot;</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;还没有录入学生信息&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;暂未保存数据信息.....&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">show</span>():</span><br><span class="line">    student_lst=[]</span><br><span class="line">    <span class="keyword">if</span> os.path.exists(filename):</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(filename,<span class="string">&quot;r&quot;</span>,encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> rfile:</span><br><span class="line">            student=rfile.readlines()</span><br><span class="line">            <span class="keyword">for</span> item <span class="keyword">in</span> student:</span><br><span class="line">                student_lst.append(<span class="built_in">eval</span>(item))</span><br><span class="line">                <span class="keyword">if</span> student_lst:</span><br><span class="line">                    show_student(student_lst)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;暂未保存过数据！！&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 项目 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Matplotlib第三弹</title>
      <link href="/posts/1234.html"/>
      <url>/posts/1234.html</url>
      
        <content type="html"><![CDATA[<p>Matplotlib从零开始画图(三)</p><span id="more"></span><p>matplotlib.pyplot.subplots(nrows&#x3D;1, ncols&#x3D;1, **fig_ kw)创建一个 带有多个axes(坐标系&#x2F;绘图区)的图</p><h3 id="基本参数"><a href="#基本参数" class="headerlink" title="基本参数"></a>基本参数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Parameters:</span><br><span class="line">nrows, ncols :设置有几行几列坐标系</span><br><span class="line"><span class="built_in">int</span>, optional, default: <span class="number">1</span>, Number of rows/columns of the subplot grid.</span><br><span class="line">Returns:</span><br><span class="line">fig :图对象</span><br><span class="line">axes :返回相应数量的坐标系</span><br><span class="line">设置标题等方法不同:</span><br><span class="line">set_ xticks</span><br><span class="line">set_ _yticks</span><br><span class="line">set_ xlabel</span><br><span class="line">set_ ylabel</span><br></pre></td></tr></table></figure><h3 id="代码如下："><a href="#代码如下：" class="headerlink" title="代码如下："></a>代码如下：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="comment"># 0.准备数据</span></span><br><span class="line">x = <span class="built_in">range</span>(<span class="number">60</span>)</span><br><span class="line">y_shanghai = [random.uniform(<span class="number">45</span>, <span class="number">18</span>) <span class="keyword">for</span> i <span class="keyword">in</span> x]</span><br><span class="line">y_beijing = [random.uniform(<span class="number">1</span>, <span class="number">5</span>) <span class="keyword">for</span> i <span class="keyword">in</span> x]</span><br><span class="line"><span class="comment"># 1.创建画布</span></span><br><span class="line"><span class="comment"># plt.figure(figsize=(20, 8), dpi=100)</span></span><br><span class="line">fig, axes = plt. subplots (nrows=<span class="number">1</span>, ncols=<span class="number">2</span>, figsize=(<span class="number">20</span>, <span class="number">8</span>),dpi=<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.绘制图像</span></span><br><span class="line"><span class="comment"># plt.plot(x, y_ shanghai, label=&quot; 上海&quot;)</span></span><br><span class="line"><span class="comment"># plt.plot(x, y_ beijing, color=&quot;r&quot;, linestyle=&quot;--&quot;, label=&quot;北京&quot;)</span></span><br><span class="line">axes [<span class="number">0</span>].plot(x, y_shanghai, label=<span class="string">&quot; 上海&quot;</span>)</span><br><span class="line">axes[<span class="number">1</span>].plot(x, y_beijing, color=<span class="string">&quot;r&quot;</span>, linestyle=<span class="string">&quot;--&quot;</span>, label=<span class="string">&quot;北京&quot;</span>)</span><br><span class="line"><span class="comment"># 2.1添加x，y轴刻度</span></span><br><span class="line"><span class="comment">#构造x,y轴刻度标签</span></span><br><span class="line">x_ticks_label = [<span class="string">&quot;11点&#123;&#125;分&quot;</span> . <span class="built_in">format</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> x]</span><br><span class="line">y_ticks = <span class="built_in">range</span>(<span class="number">40</span>)</span><br><span class="line"><span class="comment">#刻度显示</span></span><br><span class="line"><span class="comment"># plt.xticks(x[::5], x_ ticks_ label[::5])</span></span><br><span class="line"><span class="comment"># plt.yticks(y_ ticks[::5])</span></span><br><span class="line">axes[<span class="number">0</span>].set_xticks(x[::<span class="number">5</span>])</span><br><span class="line">axes[<span class="number">0</span>].set_yticks(y_ticks[::<span class="number">5</span>])</span><br><span class="line">axes[<span class="number">0</span>].set_xticklabels(x_ticks_label[::<span class="number">5</span>])</span><br><span class="line">axes[<span class="number">1</span>].set_xticks(x[::<span class="number">5</span>])</span><br><span class="line">axes[<span class="number">1</span>].set_yticks(y_ticks[::<span class="number">5</span>])</span><br><span class="line">axes [<span class="number">1</span>].set_xticklabels(x_ticks_label[::<span class="number">5</span>])</span><br><span class="line"><span class="comment"># 2.2添加网格显示</span></span><br><span class="line"><span class="comment"># plt.grid(True, linestyle=&quot;--&quot;, alpha=0.5)</span></span><br><span class="line">axes [<span class="number">0</span>]. grid(<span class="literal">True</span>, linestyle=<span class="string">&quot;--&quot;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">axes [<span class="number">1</span>]. grid(<span class="literal">True</span>, linestyle=<span class="string">&quot;--&quot;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.3添加描述信息</span></span><br><span class="line"><span class="comment"># plt.xlabel(&quot;时间&quot;)</span></span><br><span class="line"><span class="comment"># plt.ylabel(&quot;温度&quot;)</span></span><br><span class="line"><span class="comment"># plt.title(&quot;中午11点--12点某城市温度变化图&quot;， fontsize=20)</span></span><br><span class="line">axes [<span class="number">0</span>].set_xlabel(<span class="string">&quot;时间&quot;</span>)</span><br><span class="line">axes [<span class="number">0</span>].set_ylabel(<span class="string">&quot;温度&quot;</span>)</span><br><span class="line">axes[<span class="number">0</span>].set_title(<span class="string">&quot;中午11点--12点某城市温度变化图&quot;</span>,fontsize=<span class="number">20</span>)</span><br><span class="line">axes[<span class="number">1</span>].set_xlabel(<span class="string">&quot;时间&quot;</span> )</span><br><span class="line">axes[<span class="number">1</span>].set_ylabel(<span class="string">&quot;温度&quot;</span> )</span><br><span class="line">axes [<span class="number">1</span>].set_title(<span class="string">&quot;中午11点--12点某城市温度变化图&quot;</span>,fontsize=<span class="number">20</span>)</span><br><span class="line"><span class="comment"># #2.4图像保存</span></span><br><span class="line"><span class="comment"># plt. savefig(&quot;./test. png&quot;)</span></span><br><span class="line"><span class="comment"># #2.5添加图例</span></span><br><span class="line"><span class="comment"># plt. legend(loc=0)</span></span><br><span class="line">axes [<span class="number">0</span>]. legend(loc=<span class="number">0</span>)</span><br><span class="line">axes [<span class="number">1</span>]. legend(loc=<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 3.图像显示</span></span><br><span class="line">plt. show()</span><br></pre></td></tr></table></figure><h3 id="画图结果"><a href="#画图结果" class="headerlink" title="画图结果"></a>画图结果</h3><p><img src="https://img-blog.csdnimg.cn/170afc88ffc14bc9b5b4023b56ca634b.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h3 id="数学函数绘图"><a href="#数学函数绘图" class="headerlink" title="数学函数绘图"></a>数学函数绘图</h3><p>导入包：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure><p>画图代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 0.准备数据</span></span><br><span class="line">x = np.linspace(-<span class="number">10</span>,<span class="number">10</span>,<span class="number">1000</span>)   <span class="comment">#生成-10到10的1000个数</span></span><br><span class="line">y = np.sin(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.创建画布</span></span><br><span class="line">plt.figure(figsize = (<span class="number">20</span>,<span class="number">8</span>),dpi = <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.绘制函数图像</span></span><br><span class="line">plt.plot(x,y)</span><br><span class="line"><span class="comment"># 2.1添加网格</span></span><br><span class="line">plt.grid()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.显示图像</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>画图结果：<br><img src="https://img-blog.csdnimg.cn/a58395bf74464d42bd2ef2d2ccf687c2.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h3 id="画图小结："><a href="#画图小结：" class="headerlink" title="画图小结："></a>画图小结：</h3><p>·添加x,y轴刻度</p><pre><code>plt.xticks()plt.yticks()</code></pre><p>注意:在传递进去的第一个参数必须是数字不能是字符串,如果是字符,需要进行替换操作</p><p>添加网格显示</p><pre><code>plt.grid(inestyle=&quot;--&quot; ，alpha=0.5)</code></pre><p>·添加描述信息</p><pre><code>plt.xlabel()plt.ylabel()plt.title()</code></pre><p>·图像保存</p><pre><code>plt.savefig(&quot;路径&quot;)</code></pre><p>显示图例</p><pre><code>plt.legend(loc=&quot;best&quot;)</code></pre><p>注意:一定要在plt.plot()里面设置-个label,如果不设置,没法显示</p><p>·多个坐标系显示</p><pre><code>plt.subplots(nrows=, ncols=)</code></pre>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> Matplotlib </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Matplotlib第二弹</title>
      <link href="/posts/2219.html"/>
      <url>/posts/2219.html</url>
      
        <content type="html"><![CDATA[<p>Matplotlib从零开始画图(二)</p><span id="more"></span><p>@<a href="%E5%9C%A8%E4%B8%80%E4%B8%AA%E5%9D%90%E6%A0%87%E7%B3%BB%E6%B7%BB%E5%8A%A0%E5%A4%9A%E4%B8%AA%E5%9B%BE%E5%83%8F">TOC</a></p><h3 id="绘制一个图像"><a href="#绘制一个图像" class="headerlink" title="绘制一个图像"></a>绘制一个图像</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#画出温度变化图</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>]=[<span class="string">&#x27;SimHei&#x27;</span>] <span class="comment">#显示中文标签</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>]=<span class="literal">False</span></span><br><span class="line"><span class="comment"># 0.准备数据</span></span><br><span class="line">x = <span class="built_in">range</span>(<span class="number">60</span>)</span><br><span class="line">y_shanghai = [ random. uniform(<span class="number">15</span>,<span class="number">18</span>) <span class="keyword">for</span> i <span class="keyword">in</span> x]</span><br><span class="line"><span class="comment"># 1.创建画布</span></span><br><span class="line">plt. figure(figsize=(<span class="number">20</span>, <span class="number">8</span>),dpi=<span class="number">100</span>)</span><br><span class="line"><span class="comment"># 2.绘制图像</span></span><br><span class="line">plt.plot(x, y_shanghai)</span><br><span class="line"><span class="comment"># 2.1 A加x, y轴刻度</span></span><br><span class="line"><span class="comment">#设置x,y轴刻度</span></span><br><span class="line">x_ticks_label = [<span class="string">&quot;11点&#123;&#125;分&quot;</span> . <span class="built_in">format</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> x]</span><br><span class="line">y_ticks = <span class="built_in">range</span>(<span class="number">40</span>)</span><br><span class="line"><span class="comment">#修改x, y轴坐标刻度显示</span></span><br><span class="line"><span class="comment"># plt.xticks(x_ticks_label[::5]) #坐标刻度不可以直接通过字符串进行修改</span></span><br><span class="line">plt.xticks(x[::<span class="number">5</span>], x_ticks_label[::<span class="number">5</span>])</span><br><span class="line">plt.yticks(y_ticks[::<span class="number">5</span>])<span class="comment"># 从头到尾间隔五个</span></span><br><span class="line"><span class="comment"># 添加网格</span></span><br><span class="line">plt.grid(<span class="literal">True</span>, linestyle=<span class="string">&quot;--&quot;</span>, alpha=<span class="number">1</span>)</span><br><span class="line"><span class="comment">#添加描述信息</span></span><br><span class="line">plt.xlabel(<span class="string">&quot;时间&quot;</span>, fontsize=<span class="number">20</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;温度&quot;</span>, fontsize=<span class="number">20</span>)</span><br><span class="line">plt.title(<span class="string">&quot;中午11点到12点某城市温度变化&quot;</span>, fontsize=<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.图像显示</span></span><br><span class="line">plt. show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/4495a96653664e95a5580bb30f810c3b.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h3 id="绘制两个图像"><a href="#绘制两个图像" class="headerlink" title="绘制两个图像"></a>绘制两个图像</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="comment">#画出温度变化图</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>]=[<span class="string">&#x27;SimHei&#x27;</span>] <span class="comment">#显示中文标签</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>]=<span class="literal">False</span></span><br><span class="line"><span class="comment"># 0.准备数据</span></span><br><span class="line">x = <span class="built_in">range</span>(<span class="number">60</span>)</span><br><span class="line">y_shanghai = [random.uniform(<span class="number">15</span>,<span class="number">18</span>) <span class="keyword">for</span> i <span class="keyword">in</span> x]</span><br><span class="line">y_beijing = [ random.uniform(<span class="number">1</span>,<span class="number">3</span>) <span class="keyword">for</span> i <span class="keyword">in</span> x]</span><br><span class="line"><span class="comment"># 1.创建画布</span></span><br><span class="line">plt. figure(figsize=(<span class="number">10</span>, <span class="number">4</span>),dpi=<span class="number">100</span>)</span><br><span class="line"><span class="comment"># 2.绘制图像</span></span><br><span class="line">plt.plot(x, y_shanghai)</span><br><span class="line">plt.plot(x, y_beijing,color=<span class="string">&#x27;r&#x27;</span>,linestyle = <span class="string">&#x27;--&#x27;</span>)  <span class="comment">#设置颜色和风格字符</span></span><br><span class="line"><span class="comment"># 2.1 A加x, y轴刻度</span></span><br><span class="line"><span class="comment">#设置x,y轴刻度</span></span><br><span class="line">x_ticks_label = [<span class="string">&quot;11点&#123;&#125;分&quot;</span> . <span class="built_in">format</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> x]</span><br><span class="line">y_ticks = <span class="built_in">range</span>(<span class="number">40</span>)</span><br><span class="line"><span class="comment">#修改x, y轴坐标刻度显示</span></span><br><span class="line"><span class="comment"># plt.xticks(x_ticks_label[::5]) #坐标刻度不可以直接通过字符串进行修改</span></span><br><span class="line">plt.xticks(x[::<span class="number">5</span>], x_ticks_label[::<span class="number">5</span>])</span><br><span class="line">plt.yticks(y_ticks[::<span class="number">5</span>])<span class="comment"># 从头到尾间隔五个</span></span><br><span class="line"><span class="comment"># 添加网格</span></span><br><span class="line">plt.grid(<span class="literal">True</span>, linestyle=<span class="string">&quot;--&quot;</span>, alpha=<span class="number">1</span>)</span><br><span class="line"><span class="comment">#添加描述信息</span></span><br><span class="line">plt.xlabel(<span class="string">&quot;时间&quot;</span>, fontsize=<span class="number">20</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;温度&quot;</span>, fontsize=<span class="number">20</span>)</span><br><span class="line">plt.title(<span class="string">&quot;中午11点到12点某城市温度变化&quot;</span>, fontsize=<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.图像显示</span></span><br><span class="line">plt. show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/0bbd1a8d5de14ded9759b579b5fa2492.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h3 id="风格设置"><a href="#风格设置" class="headerlink" title="风格设置"></a>风格设置</h3><p><img src="https://img-blog.csdnimg.cn/e351c59ac12648a88be9916c613cdbb8.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h3 id="显示图例"><a href="#显示图例" class="headerlink" title="显示图例"></a>显示图例</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#绘制折线图</span></span><br><span class="line">plt.plot(x, y_shanghai, label=<span class="string">&quot;. 上海&quot;</span>)</span><br><span class="line"><span class="comment">#使用多次plot可以画多个折线</span></span><br><span class="line">plt.plot(x, y_beijing, color=<span class="string">&#x27;r&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>, label=<span class="string">&quot;北京&quot;</span>)</span><br><span class="line"><span class="comment">#显示图例</span></span><br><span class="line">plt. Legend(loc=<span class="string">&quot;best&quot;</span>)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/a589cb992f45476182e3119fb9b0d213.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h3 id="图例的位置："><a href="#图例的位置：" class="headerlink" title="图例的位置："></a>图例的位置：</h3><p><img src="https://img-blog.csdnimg.cn/08c4f97b21fc4c3dac435b3878a5a8c5.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> Matplotlib </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Matplotlib第一弹</title>
      <link href="/posts/39121.html"/>
      <url>/posts/39121.html</url>
      
        <content type="html"><![CDATA[<p>Matplotlib从零开始画图(一)</p><span id="more"></span><h3 id="什么是matplotlib？"><a href="#什么是matplotlib？" class="headerlink" title="什么是matplotlib？"></a>什么是matplotlib？</h3><pre><code>·专门用于开发2D（3D）图表的包</code></pre><h3 id="matplotlib-pyplot模块"><a href="#matplotlib-pyplot模块" class="headerlink" title="matplotlib.pyplot模块"></a>matplotlib.pyplot模块</h3><pre><code>·matplotlib.pyplot包含了一系列类似于matlab的画图函数</code></pre><h3 id="图形绘制流程："><a href="#图形绘制流程：" class="headerlink" title="图形绘制流程："></a>图形绘制流程：</h3><pre><code>·1.创建画布-- plt.figure()    plt. figure(figsize=(), dpi=)    figsize:指定图的长宽    dpi:图像的清晰度    返回fig对象·2.绘制图像- plt.plot(x, y)    以折线图为例·3.显示图像-- plt.show()</code></pre><h3 id="画出温度折线图"><a href="#画出温度折线图" class="headerlink" title="画出温度折线图"></a>画出温度折线图</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="comment"># 画出温度变化图</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]  <span class="comment"># 显示中文标签</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>  <span class="comment"># 显示中文标签</span></span><br><span class="line"><span class="comment"># 0.准备数据</span></span><br><span class="line">x = <span class="built_in">range</span>(<span class="number">60</span>)</span><br><span class="line">y_shanghai = [random.uniform(<span class="number">15</span>, <span class="number">18</span>) <span class="keyword">for</span> i <span class="keyword">in</span> x]</span><br><span class="line"><span class="comment"># 1.创建画布</span></span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>, <span class="number">8</span>), dpi=<span class="number">100</span>)</span><br><span class="line"><span class="comment"># 2.绘制图像</span></span><br><span class="line">plt.plot(x, y_shanghai)</span><br><span class="line"><span class="comment"># A加x, y轴刻度</span></span><br><span class="line"><span class="comment"># 设置x,y轴刻度</span></span><br><span class="line">x_ticks_label = [<span class="string">&quot;11点&#123;&#125;分&quot;</span>.<span class="built_in">format</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> x]</span><br><span class="line">y_ticks = <span class="built_in">range</span>(<span class="number">40</span>)</span><br><span class="line"><span class="comment"># 修改x, y轴坐标刻度显示</span></span><br><span class="line"><span class="comment"># plt.xticks(x_ticks_label[::5]) #坐标刻度不可以直接通过字符串进行修改</span></span><br><span class="line">plt.xticks(x[::<span class="number">5</span>], x_ticks_label[::<span class="number">5</span>])</span><br><span class="line">plt.yticks(y_ticks[::<span class="number">5</span>])  <span class="comment"># 从头到尾间隔五个</span></span><br><span class="line"><span class="comment"># 3.图像显示</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h3 id="画出来的结果"><a href="#画出来的结果" class="headerlink" title="画出来的结果"></a>画出来的结果</h3><p><img src="https://img-blog.csdnimg.cn/1d494f5cac4c46f78dd738c0b3404883.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h3 id="添加网格"><a href="#添加网格" class="headerlink" title="添加网格"></a>添加网格</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.grid(<span class="literal">True</span>, linestyle=<span class="string">&quot;--&quot;</span>, alpha=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/cddc4eb203724875b2f426802d6a7ab8.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h3 id="添加描述信息："><a href="#添加描述信息：" class="headerlink" title="添加描述信息："></a>添加描述信息：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.xlabel(<span class="string">&quot;时间&quot;</span>, fontsize=<span class="number">20</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;温度&quot;</span>, fontsize=<span class="number">20</span>)</span><br><span class="line">plt.title(<span class="string">&quot;中午11点到12点某城市温度变化&quot;</span>, fontsize=<span class="number">20</span>)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/372a47fd349b43e5b7160f05527d8a72.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h3 id="保存图片到指定路径"><a href="#保存图片到指定路径" class="headerlink" title="保存图片到指定路径"></a>保存图片到指定路径</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.savefig(<span class="string">&quot;E:/image.png&quot;</span>)</span><br></pre></td></tr></table></figure><p>·注意: plt.show0会释放figure资源，如果在显示图像之后保存图片将只能保存空图片。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> Matplotlib </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>朴素贝叶斯+拉普拉斯平滑代码实现-方法二</title>
      <link href="/posts/63154.html"/>
      <url>/posts/63154.html</url>
      
        <content type="html"><![CDATA[<p>朴素贝叶斯有多种实现方式，这是另一种实现方式！</p><span id="more"></span><h2 id="首先导入包："><a href="#首先导入包：" class="headerlink" title="首先导入包："></a>首先导入包：</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> scorer</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure><h2 id="数据的读取："><a href="#数据的读取：" class="headerlink" title="数据的读取："></a>数据的读取：</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">datasets = pd.DataFrame([[<span class="string">&quot;青绿&quot;</span>, <span class="string">&quot;蜷缩&quot;</span>, <span class="string">&quot;浊响&quot;</span>, <span class="string">&quot;清晰&quot;</span>, <span class="string">&quot;凹陷&quot;</span>, <span class="string">&quot;硬滑&quot;</span>, <span class="string">&quot;是&quot;</span>],</span><br><span class="line">                         [<span class="string">&quot;乌黑&quot;</span>, <span class="string">&quot;蜷缩&quot;</span>, <span class="string">&quot;沉闷&quot;</span>, <span class="string">&quot;清晰&quot;</span>, <span class="string">&quot;凹陷&quot;</span>, <span class="string">&quot;硬滑&quot;</span>, <span class="string">&quot;是&quot;</span>],</span><br><span class="line">                         [<span class="string">&quot;乌黑&quot;</span>, <span class="string">&quot;蜷缩&quot;</span>, <span class="string">&quot;浊响&quot;</span>, <span class="string">&quot;清晰&quot;</span>, <span class="string">&quot;凹陷&quot;</span>, <span class="string">&quot;硬滑&quot;</span>, <span class="string">&quot;是&quot;</span>],</span><br><span class="line">                         [<span class="string">&quot;青绿&quot;</span>, <span class="string">&quot;蜷缩&quot;</span>, <span class="string">&quot;沉闷&quot;</span>, <span class="string">&quot;清晰&quot;</span>, <span class="string">&quot;凹陷&quot;</span>, <span class="string">&quot;硬滑&quot;</span>, <span class="string">&quot;是&quot;</span>],</span><br><span class="line">                         [<span class="string">&quot;浅白&quot;</span>, <span class="string">&quot;蜷缩&quot;</span>, <span class="string">&quot;浊响&quot;</span>, <span class="string">&quot;清晰&quot;</span>, <span class="string">&quot;凹陷&quot;</span>, <span class="string">&quot;硬滑&quot;</span>, <span class="string">&quot;是&quot;</span>],</span><br><span class="line">                         [<span class="string">&quot;青绿&quot;</span>, <span class="string">&quot;稍蜷&quot;</span>, <span class="string">&quot;浊响&quot;</span>, <span class="string">&quot;清晰&quot;</span>, <span class="string">&quot;稍凹&quot;</span>, <span class="string">&quot;软粘&quot;</span>, <span class="string">&quot;是&quot;</span>],</span><br><span class="line">                         [<span class="string">&quot;乌黑&quot;</span>, <span class="string">&quot;稍蜷&quot;</span>, <span class="string">&quot;浊响&quot;</span>, <span class="string">&quot;稍糊&quot;</span>, <span class="string">&quot;稍凹&quot;</span>, <span class="string">&quot;软粘&quot;</span>, <span class="string">&quot;是&quot;</span>],</span><br><span class="line">                         [<span class="string">&quot;乌黑&quot;</span>, <span class="string">&quot;稍蜷&quot;</span>, <span class="string">&quot;浊响&quot;</span>, <span class="string">&quot;清晰&quot;</span>, <span class="string">&quot;稍凹&quot;</span>, <span class="string">&quot;硬滑&quot;</span>, <span class="string">&quot;是&quot;</span>],</span><br><span class="line">                         [<span class="string">&quot;乌黑&quot;</span>, <span class="string">&quot;稍蜷&quot;</span>, <span class="string">&quot;沉闷&quot;</span>, <span class="string">&quot;稍糊&quot;</span>, <span class="string">&quot;稍凹&quot;</span>, <span class="string">&quot;硬滑&quot;</span>, <span class="string">&quot;否&quot;</span>],</span><br><span class="line">                         [<span class="string">&quot;青绿&quot;</span>, <span class="string">&quot;硬挺&quot;</span>, <span class="string">&quot;清脆&quot;</span>, <span class="string">&quot;清晰&quot;</span>, <span class="string">&quot;平坦&quot;</span>, <span class="string">&quot;软粘&quot;</span>, <span class="string">&quot;否&quot;</span>],</span><br><span class="line">                         [<span class="string">&quot;浅白&quot;</span>, <span class="string">&quot;硬挺&quot;</span>, <span class="string">&quot;清脆&quot;</span>, <span class="string">&quot;模糊&quot;</span>, <span class="string">&quot;平坦&quot;</span>, <span class="string">&quot;硬滑&quot;</span>, <span class="string">&quot;否&quot;</span>],</span><br><span class="line">                         [<span class="string">&quot;浅白&quot;</span>, <span class="string">&quot;蜷缩&quot;</span>, <span class="string">&quot;浊响&quot;</span>, <span class="string">&quot;模糊&quot;</span>, <span class="string">&quot;平坦&quot;</span>, <span class="string">&quot;软粘&quot;</span>, <span class="string">&quot;否&quot;</span>],</span><br><span class="line">                         [<span class="string">&quot;青绿&quot;</span>, <span class="string">&quot;稍蜷&quot;</span>, <span class="string">&quot;浊响&quot;</span>, <span class="string">&quot;稍糊&quot;</span>, <span class="string">&quot;凹陷&quot;</span>, <span class="string">&quot;硬滑&quot;</span>, <span class="string">&quot;否&quot;</span>],</span><br><span class="line">                         [<span class="string">&quot;浅白&quot;</span>, <span class="string">&quot;稍蜷&quot;</span>, <span class="string">&quot;沉闷&quot;</span>, <span class="string">&quot;稍糊&quot;</span>, <span class="string">&quot;凹陷&quot;</span>, <span class="string">&quot;硬滑&quot;</span>, <span class="string">&quot;否&quot;</span>],</span><br><span class="line">                         [<span class="string">&quot;乌黑&quot;</span>, <span class="string">&quot;稍蜷&quot;</span>, <span class="string">&quot;浊响&quot;</span>, <span class="string">&quot;清晰&quot;</span>, <span class="string">&quot;稍凹&quot;</span>, <span class="string">&quot;软粘&quot;</span>, <span class="string">&quot;否&quot;</span>],</span><br><span class="line">                         [<span class="string">&quot;浅白&quot;</span>, <span class="string">&quot;蜷缩&quot;</span>, <span class="string">&quot;浊响&quot;</span>, <span class="string">&quot;模糊&quot;</span>, <span class="string">&quot;平坦&quot;</span>, <span class="string">&quot;硬滑&quot;</span>, <span class="string">&quot;否&quot;</span>],</span><br><span class="line">                         [<span class="string">&quot;青绿&quot;</span>, <span class="string">&quot;蜷缩&quot;</span>, <span class="string">&quot;沉闷&quot;</span>, <span class="string">&quot;稍糊&quot;</span>, <span class="string">&quot;稍凹&quot;</span>, <span class="string">&quot;硬滑&quot;</span>, <span class="string">&quot;否&quot;</span>]],</span><br><span class="line">                        columns=[<span class="string">&quot;色泽&quot;</span>, <span class="string">&quot;根蒂&quot;</span>, <span class="string">&quot;敲声&quot;</span>, <span class="string">&quot;纹理&quot;</span>, <span class="string">&quot;脐部&quot;</span>, <span class="string">&quot;触感&quot;</span>, <span class="string">&quot;好瓜&quot;</span>])</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="计算出好瓜的概率："><a href="#计算出好瓜的概率：" class="headerlink" title="计算出好瓜的概率："></a>计算出好瓜的概率：</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">fit_fun</span>(<span class="params">datasets</span>):</span><br><span class="line">    good_el_dic = &#123;&#125;   <span class="comment"># P(*|好瓜)</span></span><br><span class="line">    bad_el_dic = &#123;&#125;   <span class="comment"># P(*|坏瓜)</span></span><br><span class="line">    P_dic = &#123;&#125;   <span class="comment"># P(*)</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> datasets.columns.to_list()[<span class="number">0</span>:-<span class="number">1</span>]:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> datasets[j].unique():</span><br><span class="line"><span class="comment">#             P_dic[i] = round((datasets[j].value_counts()[i]+1)/(len(datasets)+len(datasets[j].unique())), 2)</span></span><br><span class="line">            <span class="keyword">if</span> <span class="string">&quot;是&quot;</span> <span class="keyword">in</span> datasets.groupby(j)[<span class="string">&quot;好瓜&quot;</span>].value_counts()[i]:</span><br><span class="line">                good_el_dic[i] = <span class="built_in">round</span>((datasets.groupby(j)[<span class="string">&quot;好瓜&quot;</span>].value_counts()[i][<span class="string">&quot;是&quot;</span>]+<span class="number">1</span>)/(<span class="built_in">len</span>(datasets[datasets[<span class="string">&quot;好瓜&quot;</span>] == <span class="string">&quot;是&quot;</span>])+<span class="built_in">len</span>(datasets[j].unique())), <span class="number">3</span>)      <span class="comment"># 拉普拉斯</span></span><br><span class="line"><span class="comment">#                 good_el_dic[i] = round((datasets.groupby(j)[&quot;好瓜&quot;].value_counts()[i][&quot;是&quot;]+1)/(datasets[j].value_counts()[i]+len(datasets[j].unique())), 2)      # 拉普拉斯</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line"><span class="comment">#                 good_el_dic[i] = round(1/(datasets[j].value_counts()[i]+len(datasets[j].unique())), 2)    # 拉普拉斯</span></span><br><span class="line">                good_el_dic[i] = <span class="built_in">round</span>(<span class="number">1</span>/(<span class="built_in">len</span>(datasets[datasets[<span class="string">&quot;好瓜&quot;</span>] == <span class="string">&quot;是&quot;</span>])+<span class="built_in">len</span>(datasets[j].unique())), <span class="number">3</span>)    <span class="comment"># 拉普拉斯</span></span><br><span class="line">    P_good = <span class="built_in">round</span>((<span class="built_in">len</span>(datasets[datasets[<span class="string">&quot;好瓜&quot;</span>] == <span class="string">&quot;是&quot;</span>])+<span class="number">1</span>)/(<span class="built_in">len</span>(datasets)+<span class="number">2</span>), <span class="number">2</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;P(*|好瓜):&quot;</span>, good_el_dic)</span><br><span class="line"><span class="comment">#     print(&quot;\nP(*):&quot;, P_dic)</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\nP:&quot;</span>, P_good)</span><br><span class="line">    <span class="keyword">return</span> good_el_dic, P_dic, P_good</span><br><span class="line">good_el_dic, P_dic, P = fit_fun(datasets)</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">P(*|好瓜): &#123;<span class="string">&#x27;青绿&#x27;</span>: <span class="number">0.364</span>, <span class="string">&#x27;乌黑&#x27;</span>: <span class="number">0.455</span>, <span class="string">&#x27;浅白&#x27;</span>: <span class="number">0.182</span>, <span class="string">&#x27;蜷缩&#x27;</span>: <span class="number">0.545</span>, <span class="string">&#x27;稍蜷&#x27;</span>: <span class="number">0.364</span>, <span class="string">&#x27;硬挺&#x27;</span>: <span class="number">0.091</span>, <span class="string">&#x27;浊响&#x27;</span>: <span class="number">0.636</span>, <span class="string">&#x27;沉闷&#x27;</span>: <span class="number">0.273</span>, <span class="string">&#x27;清脆&#x27;</span>: <span class="number">0.091</span>, <span class="string">&#x27;清晰&#x27;</span>: <span class="number">0.727</span>, <span class="string">&#x27;稍糊&#x27;</span>: <span class="number">0.182</span>, <span class="string">&#x27;模糊&#x27;</span>: <span class="number">0.091</span>, <span class="string">&#x27;凹陷&#x27;</span>: <span class="number">0.545</span>, <span class="string">&#x27;稍凹&#x27;</span>: <span class="number">0.364</span>, <span class="string">&#x27;平坦&#x27;</span>: <span class="number">0.091</span>, <span class="string">&#x27;硬滑&#x27;</span>: <span class="number">0.7</span>, <span class="string">&#x27;软粘&#x27;</span>: <span class="number">0.3</span>&#125;</span><br><span class="line"></span><br><span class="line">P: <span class="number">0.47</span></span><br></pre></td></tr></table></figure><h2 id="计算坏瓜的概率："><a href="#计算坏瓜的概率：" class="headerlink" title="计算坏瓜的概率："></a>计算坏瓜的概率：</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">fit_fun</span>(<span class="params">datasets</span>):</span><br><span class="line"><span class="comment">#     good_el_dic = &#123;&#125;   # P(*|好瓜)</span></span><br><span class="line">    bad_el_dic = &#123;&#125;   <span class="comment"># P(*|坏瓜)</span></span><br><span class="line"><span class="comment">#     P_dic = &#123;&#125;   # P(*)</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> datasets.columns.to_list()[<span class="number">0</span>:-<span class="number">1</span>]:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> datasets[j].unique():</span><br><span class="line">            <span class="keyword">if</span> <span class="string">&quot;否&quot;</span> <span class="keyword">in</span> datasets.groupby(j)[<span class="string">&quot;好瓜&quot;</span>].value_counts()[i]:</span><br><span class="line"><span class="comment">#                 bad_el_dic[i] = round((datasets.groupby(j)[&quot;好瓜&quot;].value_counts()[i][&quot;否&quot;]+1)/(datasets[j].value_counts()[i]+len(datasets[j].unique())), 2)    # 平滑</span></span><br><span class="line">               bad_el_dic[i] = <span class="built_in">round</span>((datasets.groupby(j)[<span class="string">&quot;好瓜&quot;</span>].value_counts()[i][<span class="string">&quot;否&quot;</span>]+<span class="number">1</span>)/(<span class="built_in">len</span>(datasets[datasets[<span class="string">&quot;好瓜&quot;</span>] == <span class="string">&quot;否&quot;</span>])+<span class="built_in">len</span>(datasets[j].unique())), <span class="number">3</span>) </span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line"><span class="comment">#                 P_bad[i] = round(1/(datasets[j].value_counts()[i]+len(datasets[j].unique())), 2)      # 平滑</span></span><br><span class="line">                P_bad[i] = <span class="built_in">round</span>(<span class="number">1</span>/(<span class="built_in">len</span>(datasets[datasets[<span class="string">&quot;好瓜&quot;</span>] == <span class="string">&quot;否&quot;</span>])+<span class="built_in">len</span>(datasets[j].unique())), <span class="number">3</span>)      <span class="comment"># 平滑</span></span><br><span class="line">    P_bad = <span class="built_in">round</span>((<span class="built_in">len</span>(datasets[datasets[<span class="string">&quot;好瓜&quot;</span>] == <span class="string">&quot;否&quot;</span>])+<span class="number">1</span>)/(<span class="built_in">len</span>(datasets)+<span class="number">2</span>), <span class="number">3</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;P(*|坏瓜):&quot;</span>, bad_el_dic)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\nP_bad:&quot;</span>, P_bad)</span><br><span class="line">    <span class="keyword">return</span> bad_el_dic, P_bad</span><br><span class="line">bad_el_dic, P_bad = fit_fun(datasets)</span><br><span class="line">P_ = <span class="number">1</span>-P</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">P(*|坏瓜): &#123;<span class="string">&#x27;青绿&#x27;</span>: <span class="number">0.333</span>, <span class="string">&#x27;乌黑&#x27;</span>: <span class="number">0.25</span>, <span class="string">&#x27;浅白&#x27;</span>: <span class="number">0.417</span>, <span class="string">&#x27;蜷缩&#x27;</span>: <span class="number">0.333</span>, <span class="string">&#x27;稍蜷&#x27;</span>: <span class="number">0.417</span>, <span class="string">&#x27;硬挺&#x27;</span>: <span class="number">0.25</span>, <span class="string">&#x27;浊响&#x27;</span>: <span class="number">0.417</span>, <span class="string">&#x27;沉闷&#x27;</span>: <span class="number">0.333</span>, <span class="string">&#x27;清脆&#x27;</span>: <span class="number">0.25</span>, <span class="string">&#x27;清晰&#x27;</span>: <span class="number">0.25</span>, <span class="string">&#x27;稍糊&#x27;</span>: <span class="number">0.417</span>, <span class="string">&#x27;模糊&#x27;</span>: <span class="number">0.333</span>, <span class="string">&#x27;凹陷&#x27;</span>: <span class="number">0.25</span>, <span class="string">&#x27;稍凹&#x27;</span>: <span class="number">0.333</span>, <span class="string">&#x27;平坦&#x27;</span>: <span class="number">0.417</span>, <span class="string">&#x27;硬滑&#x27;</span>: <span class="number">0.636</span>, <span class="string">&#x27;软粘&#x27;</span>: <span class="number">0.364</span>&#125;</span><br><span class="line"></span><br><span class="line">P_bad: <span class="number">0.526</span></span><br></pre></td></tr></table></figure><h2 id="单个数据的预测："><a href="#单个数据的预测：" class="headerlink" title="单个数据的预测："></a>单个数据的预测：</h2><p>好瓜概率预测：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">test = [<span class="string">&quot;乌黑&quot;</span>, <span class="string">&quot;稍蜷&quot;</span>, <span class="string">&quot;浊响&quot;</span>, <span class="string">&quot;清晰&quot;</span>, <span class="string">&quot;稍凹&quot;</span>, <span class="string">&quot;软粘&quot;</span>]</span><br><span class="line">P_good = P</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> test:</span><br><span class="line"><span class="comment">#     P_good = P_good*good_el_dic[i]*P_dic[i]/P</span></span><br><span class="line">    P_good = P_good*good_el_dic[i]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;预测为好瓜的概率：&quot;</span>, P_good )</span><br><span class="line"><span class="comment"># 预测为坏瓜的概率： 0.0006981899836275</span></span><br></pre></td></tr></table></figure><p>坏瓜概率预测：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">P_bad = P_</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> test:</span><br><span class="line"><span class="comment">#     P_bad = P_bad*bad_el_dic[i]*P_dic[i]/P_</span></span><br><span class="line">    P_bad = P_bad*bad_el_dic[i]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;预测为坏瓜的概率：&quot;</span>, P_bad)</span><br><span class="line"><span class="comment"># 预测为坏瓜的概率： 0.0006981899836275</span></span><br></pre></td></tr></table></figure><h2 id="整体预测："><a href="#整体预测：" class="headerlink" title="整体预测："></a>整体预测：</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">y_pre = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(datasets)):</span><br><span class="line">    test = datasets.iloc[i, :<span class="number">0</span>-<span class="number">1</span>].to_list()</span><br><span class="line">    P_g = P</span><br><span class="line">    P_b = P_</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> test:</span><br><span class="line"><span class="comment">#         P_g = P_g*good_el_dic[i]*P_dic[i]/P</span></span><br><span class="line">        P_g = P_g*good_el_dic[i]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> test:</span><br><span class="line"><span class="comment">#         P_b = P_b*bad_el_dic[i]*P_dic[i]/P_</span></span><br><span class="line">        P_b = P_b*bad_el_dic[i]</span><br><span class="line">    <span class="keyword">if</span> P_g&gt;P_b:</span><br><span class="line">        y_pre.append(<span class="string">&quot;是&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        y_pre.append(<span class="string">&quot;否&quot;</span>)</span><br><span class="line">y_test = datasets[<span class="string">&quot;好瓜&quot;</span>]</span><br><span class="line">y_test==pd.Series(y_pre)</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>      <span class="literal">True</span></span><br><span class="line"><span class="number">1</span>      <span class="literal">True</span></span><br><span class="line"><span class="number">2</span>      <span class="literal">True</span></span><br><span class="line"><span class="number">3</span>      <span class="literal">True</span></span><br><span class="line"><span class="number">4</span>      <span class="literal">True</span></span><br><span class="line"><span class="number">5</span>      <span class="literal">True</span></span><br><span class="line"><span class="number">6</span>     <span class="literal">False</span></span><br><span class="line"><span class="number">7</span>      <span class="literal">True</span></span><br><span class="line"><span class="number">8</span>      <span class="literal">True</span></span><br><span class="line"><span class="number">9</span>      <span class="literal">True</span></span><br><span class="line"><span class="number">10</span>     <span class="literal">True</span></span><br><span class="line"><span class="number">11</span>     <span class="literal">True</span></span><br><span class="line"><span class="number">12</span>    <span class="literal">False</span></span><br><span class="line"><span class="number">13</span>     <span class="literal">True</span></span><br><span class="line"><span class="number">14</span>    <span class="literal">False</span></span><br><span class="line"><span class="number">15</span>     <span class="literal">True</span></span><br><span class="line"><span class="number">16</span>     <span class="literal">True</span></span><br><span class="line">dtype: <span class="built_in">bool</span></span><br></pre></td></tr></table></figure><p>如有大佬看出错误，请指正。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 朴素贝叶斯 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>手撕代码：朴素贝叶斯+拉普拉斯平滑代码实现</title>
      <link href="/posts/56073.html"/>
      <url>/posts/56073.html</url>
      
        <content type="html"><![CDATA[<p>通过底层逻辑去复现贝叶斯代码</p><span id="more"></span><h3 id="计算步骤："><a href="#计算步骤：" class="headerlink" title="计算步骤："></a>计算步骤：</h3><p>P(好瓜) &#x3D; P(好瓜)P(色泽|好瓜)P(根蒂|好瓜)P(敲声|好瓜)P(纹理|好瓜)P(脐部|好瓜)P(触感|好瓜)<br>P(坏瓜) &#x3D; P(坏瓜)P(色泽|坏瓜)P(根蒂|坏瓜)P(敲声|坏瓜)P(纹理|坏瓜)P(脐部|坏瓜)P(触感|坏瓜)<br>例：P(色泽|好瓜) &#x3D; P(好瓜|色泽)*P(色泽)&#x2F;P(好瓜)</p><h3 id="数据的读取"><a href="#数据的读取" class="headerlink" title="数据的读取"></a>数据的读取</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># melon2 = pd.read_csv(&#x27;E:\\work\ml\\Python_Project_01\\sklearn_week\\week_10\\melon2.0.csv&#x27;, index_col=&#x27;编号&#x27;)</span></span><br><span class="line"></span><br><span class="line">melon2 = pd.DataFrame([[<span class="string">&quot;青绿&quot;</span>, <span class="string">&quot;蜷缩&quot;</span>, <span class="string">&quot;浊响&quot;</span>, <span class="string">&quot;清晰&quot;</span>, <span class="string">&quot;凹陷&quot;</span>, <span class="string">&quot;硬滑&quot;</span>, <span class="string">&quot;是&quot;</span>],</span><br><span class="line">                         [<span class="string">&quot;乌黑&quot;</span>, <span class="string">&quot;蜷缩&quot;</span>, <span class="string">&quot;沉闷&quot;</span>, <span class="string">&quot;清晰&quot;</span>, <span class="string">&quot;凹陷&quot;</span>, <span class="string">&quot;硬滑&quot;</span>, <span class="string">&quot;是&quot;</span>],</span><br><span class="line">                         [<span class="string">&quot;乌黑&quot;</span>, <span class="string">&quot;蜷缩&quot;</span>, <span class="string">&quot;浊响&quot;</span>, <span class="string">&quot;清晰&quot;</span>, <span class="string">&quot;凹陷&quot;</span>, <span class="string">&quot;硬滑&quot;</span>, <span class="string">&quot;是&quot;</span>],</span><br><span class="line">                         [<span class="string">&quot;青绿&quot;</span>, <span class="string">&quot;蜷缩&quot;</span>, <span class="string">&quot;沉闷&quot;</span>, <span class="string">&quot;清晰&quot;</span>, <span class="string">&quot;凹陷&quot;</span>, <span class="string">&quot;硬滑&quot;</span>, <span class="string">&quot;是&quot;</span>],</span><br><span class="line">                         [<span class="string">&quot;浅白&quot;</span>, <span class="string">&quot;蜷缩&quot;</span>, <span class="string">&quot;浊响&quot;</span>, <span class="string">&quot;清晰&quot;</span>, <span class="string">&quot;凹陷&quot;</span>, <span class="string">&quot;硬滑&quot;</span>, <span class="string">&quot;是&quot;</span>],</span><br><span class="line">                         [<span class="string">&quot;青绿&quot;</span>, <span class="string">&quot;稍蜷&quot;</span>, <span class="string">&quot;浊响&quot;</span>, <span class="string">&quot;清晰&quot;</span>, <span class="string">&quot;稍凹&quot;</span>, <span class="string">&quot;软粘&quot;</span>, <span class="string">&quot;是&quot;</span>],</span><br><span class="line">                         [<span class="string">&quot;乌黑&quot;</span>, <span class="string">&quot;稍蜷&quot;</span>, <span class="string">&quot;浊响&quot;</span>, <span class="string">&quot;稍糊&quot;</span>, <span class="string">&quot;稍凹&quot;</span>, <span class="string">&quot;软粘&quot;</span>, <span class="string">&quot;是&quot;</span>],</span><br><span class="line">                         [<span class="string">&quot;乌黑&quot;</span>, <span class="string">&quot;稍蜷&quot;</span>, <span class="string">&quot;浊响&quot;</span>, <span class="string">&quot;清晰&quot;</span>, <span class="string">&quot;稍凹&quot;</span>, <span class="string">&quot;硬滑&quot;</span>, <span class="string">&quot;是&quot;</span>],</span><br><span class="line">                         [<span class="string">&quot;乌黑&quot;</span>, <span class="string">&quot;稍蜷&quot;</span>, <span class="string">&quot;沉闷&quot;</span>, <span class="string">&quot;稍糊&quot;</span>, <span class="string">&quot;稍凹&quot;</span>, <span class="string">&quot;硬滑&quot;</span>, <span class="string">&quot;否&quot;</span>],</span><br><span class="line">                         [<span class="string">&quot;青绿&quot;</span>, <span class="string">&quot;硬挺&quot;</span>, <span class="string">&quot;清脆&quot;</span>, <span class="string">&quot;清晰&quot;</span>, <span class="string">&quot;平坦&quot;</span>, <span class="string">&quot;软粘&quot;</span>, <span class="string">&quot;否&quot;</span>],</span><br><span class="line">                         [<span class="string">&quot;浅白&quot;</span>, <span class="string">&quot;硬挺&quot;</span>, <span class="string">&quot;清脆&quot;</span>, <span class="string">&quot;模糊&quot;</span>, <span class="string">&quot;平坦&quot;</span>, <span class="string">&quot;硬滑&quot;</span>, <span class="string">&quot;否&quot;</span>],</span><br><span class="line">                         [<span class="string">&quot;浅白&quot;</span>, <span class="string">&quot;蜷缩&quot;</span>, <span class="string">&quot;浊响&quot;</span>, <span class="string">&quot;模糊&quot;</span>, <span class="string">&quot;平坦&quot;</span>, <span class="string">&quot;软粘&quot;</span>, <span class="string">&quot;否&quot;</span>],</span><br><span class="line">                         [<span class="string">&quot;青绿&quot;</span>, <span class="string">&quot;稍蜷&quot;</span>, <span class="string">&quot;浊响&quot;</span>, <span class="string">&quot;稍糊&quot;</span>, <span class="string">&quot;凹陷&quot;</span>, <span class="string">&quot;硬滑&quot;</span>, <span class="string">&quot;否&quot;</span>],</span><br><span class="line">                         [<span class="string">&quot;浅白&quot;</span>, <span class="string">&quot;稍蜷&quot;</span>, <span class="string">&quot;沉闷&quot;</span>, <span class="string">&quot;稍糊&quot;</span>, <span class="string">&quot;凹陷&quot;</span>, <span class="string">&quot;硬滑&quot;</span>, <span class="string">&quot;否&quot;</span>],</span><br><span class="line">                         [<span class="string">&quot;乌黑&quot;</span>, <span class="string">&quot;稍蜷&quot;</span>, <span class="string">&quot;浊响&quot;</span>, <span class="string">&quot;清晰&quot;</span>, <span class="string">&quot;稍凹&quot;</span>, <span class="string">&quot;软粘&quot;</span>, <span class="string">&quot;否&quot;</span>],</span><br><span class="line">                         [<span class="string">&quot;浅白&quot;</span>, <span class="string">&quot;蜷缩&quot;</span>, <span class="string">&quot;浊响&quot;</span>, <span class="string">&quot;模糊&quot;</span>, <span class="string">&quot;平坦&quot;</span>, <span class="string">&quot;硬滑&quot;</span>, <span class="string">&quot;否&quot;</span>],</span><br><span class="line">                         [<span class="string">&quot;青绿&quot;</span>, <span class="string">&quot;蜷缩&quot;</span>, <span class="string">&quot;沉闷&quot;</span>, <span class="string">&quot;稍糊&quot;</span>, <span class="string">&quot;稍凹&quot;</span>, <span class="string">&quot;硬滑&quot;</span>, <span class="string">&quot;否&quot;</span>]],</span><br><span class="line">                        columns=[<span class="string">&quot;色泽&quot;</span>, <span class="string">&quot;根蒂&quot;</span>, <span class="string">&quot;敲声&quot;</span>, <span class="string">&quot;纹理&quot;</span>, <span class="string">&quot;脐部&quot;</span>, <span class="string">&quot;触感&quot;</span>, <span class="string">&quot;好瓜&quot;</span>])</span><br></pre></td></tr></table></figure><h3 id="取好坏瓜："><a href="#取好坏瓜：" class="headerlink" title="取好坏瓜："></a>取好坏瓜：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">m2_bad = melon2[melon2[<span class="string">&#x27;好瓜&#x27;</span>] == <span class="string">&#x27;否&#x27;</span>]</span><br><span class="line">m2_good = melon2[melon2[<span class="string">&#x27;好瓜&#x27;</span>] == <span class="string">&#x27;是&#x27;</span>]</span><br></pre></td></tr></table></figure><h3 id="求先验："><a href="#求先验：" class="headerlink" title="求先验："></a>求先验：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># # 好不好的先验</span></span><br><span class="line">p_good_priori = (<span class="built_in">len</span>(m2_good) + <span class="number">1</span>) / (<span class="built_in">len</span>(melon2) + <span class="number">2</span>)</span><br><span class="line">p_bad_priori = (<span class="built_in">len</span>(m2_bad) + <span class="number">1</span>) / (<span class="built_in">len</span>(melon2) + <span class="number">2</span>)</span><br></pre></td></tr></table></figure><h3 id="特征提取："><a href="#特征提取：" class="headerlink" title="特征提取："></a>特征提取：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># # 各个特征的好、不好的拉普拉斯平滑：使用列表作为整体，每个特征实现一个字典</span></span><br><span class="line"><span class="comment"># 计数每个特征的值类别数</span></span><br><span class="line">feature_num = melon2.shape[-<span class="number">1</span>] - <span class="number">1</span>  <span class="comment"># 全局性隐含特征序一致</span></span><br><span class="line">features_name = []  <span class="comment"># 特征的值的集合，这里一致，然后防止好瓜、坏瓜中没有相关的特征值</span></span><br><span class="line">features_counts = []  <span class="comment"># 特征的个数，可以拉普拉斯平滑的分母修正项</span></span><br><span class="line"><span class="keyword">for</span> ii <span class="keyword">in</span> <span class="built_in">range</span>(feature_num):</span><br><span class="line">    features_name.append(<span class="built_in">set</span>(melon2.iloc[:, ii]))</span><br><span class="line">    features_counts.append(<span class="built_in">len</span>(<span class="built_in">set</span>(melon2.iloc[:, ii]))</span><br><span class="line">  </span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">features_name</span><br><span class="line">[&#123;<span class="string">&#x27;乌黑&#x27;</span>, <span class="string">&#x27;浅白&#x27;</span>, <span class="string">&#x27;青绿&#x27;</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;硬挺&#x27;</span>, <span class="string">&#x27;稍蜷&#x27;</span>, <span class="string">&#x27;蜷缩&#x27;</span>&#125;,</span><br><span class="line">  &#123;<span class="string">&#x27;沉闷&#x27;</span>, <span class="string">&#x27;浊响&#x27;</span>, <span class="string">&#x27;清脆&#x27;</span>&#125;,</span><br><span class="line">  &#123;<span class="string">&#x27;模糊&#x27;</span>, <span class="string">&#x27;清晰&#x27;</span>, <span class="string">&#x27;稍糊&#x27;</span>&#125;,</span><br><span class="line">  &#123;<span class="string">&#x27;凹陷&#x27;</span>, <span class="string">&#x27;平坦&#x27;</span>, <span class="string">&#x27;稍凹&#x27;</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;硬滑&#x27;</span>, <span class="string">&#x27;软粘&#x27;</span>&#125;]</span><br><span class="line"> </span><br><span class="line">features_counts：[<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="求P-好瓜-："><a href="#求P-好瓜-：" class="headerlink" title="求P(*|好瓜)："></a>求P(*|好瓜)：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 好瓜部分</span></span><br><span class="line">ps_feature_good = []</span><br><span class="line"><span class="comment"># 先对特征计数</span></span><br><span class="line"><span class="keyword">for</span> ii <span class="keyword">in</span> <span class="built_in">range</span>(feature_num):</span><br><span class="line">    ps_feature_good.append(<span class="built_in">dict</span>(m2_good.iloc[:, ii].value_counts()))  <span class="comment"># Series本质上就是字典</span></span><br><span class="line"><span class="comment"># 然后用拉普拉斯计算条件概率</span></span><br><span class="line"><span class="keyword">for</span> ii <span class="keyword">in</span> <span class="built_in">range</span>(feature_num):</span><br><span class="line">    <span class="keyword">for</span> ff <span class="keyword">in</span> features_name[ii]:  <span class="comment"># 下一行的get防止出空</span></span><br><span class="line">        ps_feature_good[ii][ff] = (ps_feature_good[ii].get(ff, <span class="number">0</span>) + <span class="number">1</span>) / (<span class="built_in">len</span>(m2_good) + features_counts[ii])</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="求P-坏瓜-："><a href="#求P-坏瓜-：" class="headerlink" title="求P(*|坏瓜)："></a>求P(*|坏瓜)：</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 坏瓜部分</span><br><span class="line">ps_feature_bad = []</span><br><span class="line"># 先对特征计数</span><br><span class="line">for ii in range(feature_num):</span><br><span class="line">    ps_feature_bad.append(dict(m2_bad.iloc[:, ii].value_counts()))</span><br><span class="line"># 然后用拉普拉斯计算条件概率</span><br><span class="line">for ii in range(feature_num):</span><br><span class="line">    for ff in features_name[ii]:</span><br><span class="line">        ps_feature_bad[ii][ff] = (ps_feature_bad[ii].get(ff, 0) + 1) / (len(m2_bad) + features_counts[ii])</span><br></pre></td></tr></table></figure><h3 id="预测好坏瓜的函数："><a href="#预测好坏瓜的函数：" class="headerlink" title="预测好坏瓜的函数："></a>预测好坏瓜的函数：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># # 预测的函数 好坏分开，连乘比大小</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">features</span>):</span><br><span class="line">    p_good = p_good_priori</span><br><span class="line">    <span class="keyword">for</span> ii <span class="keyword">in</span> <span class="built_in">range</span>(feature_num):</span><br><span class="line">        p_good *= ps_feature_good[ii][features[ii]]</span><br><span class="line"></span><br><span class="line">    p_bad = p_bad_priori</span><br><span class="line">    <span class="keyword">for</span> ii <span class="keyword">in</span> <span class="built_in">range</span>(feature_num):</span><br><span class="line">        p_bad *= ps_feature_bad[ii][features[ii]]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;是&#x27;</span> <span class="keyword">if</span> p_good &gt; p_bad <span class="keyword">else</span> <span class="string">&#x27;否&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="验证结果："><a href="#验证结果：" class="headerlink" title="验证结果："></a>验证结果：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 验证结果</span></span><br><span class="line"><span class="keyword">for</span> idx <span class="keyword">in</span> melon2.index:</span><br><span class="line">    <span class="built_in">print</span>(predict(melon2.loc[idx]), melon2.loc[idx][-<span class="number">1</span>],</span><br><span class="line">          predict(melon2.loc[idx]) == melon2.loc[idx][-<span class="number">1</span>])</span><br></pre></td></tr></table></figure><h3 id="输出："><a href="#输出：" class="headerlink" title="输出："></a>输出：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">是 是 <span class="literal">True</span></span><br><span class="line">是 是 <span class="literal">True</span></span><br><span class="line">是 是 <span class="literal">True</span></span><br><span class="line">是 是 <span class="literal">True</span></span><br><span class="line">是 是 <span class="literal">True</span></span><br><span class="line">是 是 <span class="literal">True</span></span><br><span class="line">否 是 <span class="literal">False</span></span><br><span class="line">是 是 <span class="literal">True</span></span><br><span class="line">否 否 <span class="literal">True</span></span><br><span class="line">否 否 <span class="literal">True</span></span><br><span class="line">否 否 <span class="literal">True</span></span><br><span class="line">否 否 <span class="literal">True</span></span><br><span class="line">是 否 <span class="literal">False</span></span><br><span class="line">否 否 <span class="literal">True</span></span><br><span class="line">是 否 <span class="literal">False</span></span><br><span class="line">否 否 <span class="literal">True</span></span><br><span class="line">否 否 <span class="literal">True</span></span><br></pre></td></tr></table></figure><p>这是老师给的代码，下一篇文章介绍本人自己的写的代码，欢迎阅读</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 朴素贝叶斯 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>感知机对偶形式</title>
      <link href="/posts/60166.html"/>
      <url>/posts/60166.html</url>
      
        <content type="html"><![CDATA[<p>对偶形式的学习</p><span id="more"></span><h1 id="感知机："><a href="#感知机：" class="headerlink" title="感知机："></a>感知机：</h1><p><img src="https://img-blog.csdnimg.cn/8bc509286c3641a7844f284216f720c5.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>符号函数：<br><img src="https://img-blog.csdnimg.cn/70e40fdefc484089b822a8efec34ef22.png" alt="在这里插入图片描述"><br>选择误分类点到超平面的总距离作为损失函数：<br>距离：<br><img src="https://img-blog.csdnimg.cn/b1e8233735eb44b099e77ebd0fbd5039.png" alt="在这里插入图片描述"><br>误分类点：<br><img src="https://img-blog.csdnimg.cn/c6ba2a3255ed4545a2ad4ebef007366c.png" alt="在这里插入图片描述"><br>误分类点距离<br><img src="https://img-blog.csdnimg.cn/d5e075fd4b8a4e07b2c1d9a32085a4cd.png" alt="在这里插入图片描述"><br>总距离<br><img src="https://img-blog.csdnimg.cn/e602a94564984d83b108933a75d65d56.png" alt="在这里插入图片描述"></p><h1 id="感知机对偶形式"><a href="#感知机对偶形式" class="headerlink" title="感知机对偶形式"></a>感知机对偶形式</h1><p><img src="https://img-blog.csdnimg.cn/ef771d364c0a4ff88c004cfda93efa9b.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/226ce69ae78345b89b95eba252209fb2.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>过程<br><img src="https://img-blog.csdnimg.cn/96b18946a7994e6cb89953132231d9bf.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>例题：<br><img src="https://img-blog.csdnimg.cn/4c91b3714bf44ecb9aa30e3a28050ab7.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/71b991ddbe554e1cadcacac1591c4a3e.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>动态可视化代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 以半动画的方式展示感知识机对偶问题的操作的合理性</span></span><br><span class="line"><span class="comment"># 给定初始点， 初始直线</span></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> ListedColormap</span><br><span class="line"></span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;font.family&#x27;</span>]=<span class="string">&#x27;sans-serif&#x27;</span></span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cmap_light = ListedColormap([<span class="string">&#x27;#FFAAAA&#x27;</span>, <span class="string">&#x27;#AAFFAA&#x27;</span>, <span class="string">&#x27;#AAAAFF&#x27;</span>])</span><br><span class="line">cmap_bold = ListedColormap([<span class="string">&#x27;#FF0000&#x27;</span>, <span class="string">&#x27;#00FF00&#x27;</span>, <span class="string">&#x27;#0000FF&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化展示</span></span><br><span class="line">point_coordinates = np.array([<span class="number">2.</span>, <span class="number">2.</span>])  <span class="comment"># 关键点坐标</span></span><br><span class="line"></span><br><span class="line">line_a, line_b = <span class="number">7</span>, <span class="number">9</span>  <span class="comment"># 初始线方程</span></span><br><span class="line">line_c = - line_b * line_a  <span class="comment"># 注意负号</span></span><br><span class="line"></span><br><span class="line">bottom, up = -<span class="number">5</span>, <span class="number">10</span>  <span class="comment"># 视窗</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 关键点对应的“基线”的方程的分类，以平面展示</span></span><br><span class="line">xx_plane = np.linspace(bottom - <span class="number">0.5</span>, up + <span class="number">0.5</span>, <span class="number">300</span>)</span><br><span class="line">yy_plane = np.linspace(bottom - <span class="number">0.5</span>, up + <span class="number">0.5</span>, <span class="number">300</span>)</span><br><span class="line">xx_plane, yy_plane = np.meshgrid(xx_plane, yy_plane)</span><br><span class="line">class_plane = np.array([<span class="number">1</span> <span class="keyword">if</span> np.dot(xi, point_coordinates) + <span class="number">1</span> &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> xi <span class="keyword">in</span> <span class="built_in">zip</span>(</span><br><span class="line">    xx_plane.ravel(), yy_plane.ravel())]).reshape(xx_plane.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 优化方程对应的分类，以整数点展示</span></span><br><span class="line">dots = np.array([np.array([ii, jj]) <span class="keyword">for</span> ii <span class="keyword">in</span> <span class="built_in">range</span>(bottom, up + <span class="number">1</span>) <span class="keyword">for</span> jj <span class="keyword">in</span> <span class="built_in">range</span>(bottom, up + <span class="number">1</span>)</span><br><span class="line">                 <span class="keyword">if</span> ii != point_coordinates[<span class="number">0</span>] <span class="keyword">or</span> jj != point_coordinates[<span class="number">1</span>]])</span><br><span class="line">class_dots = np.array([<span class="number">1</span> <span class="keyword">if</span> np.dot(xi, [line_a, line_b]) + line_c &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> xi <span class="keyword">in</span> dots])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 找到直线在视窗内的两个顶点  直线与视窗四线的交点的中间的两个</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">window_cross</span>(<span class="params">line_a, line_b, line_c</span>):</span><br><span class="line">    <span class="keyword">if</span> line_a == <span class="number">0</span> <span class="keyword">and</span> line_b ==<span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> (<span class="number">0</span>, <span class="number">0</span>), (<span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">elif</span> line_a == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> (bottom, -line_c / line_b), (up,  -line_c / line_b)</span><br><span class="line">    <span class="keyword">elif</span> line_b == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> (-line_c / line_a, bottom), (-line_c / line_a, up)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        c1 = bottom, - <span class="number">1</span> / line_b * (line_c + line_a * bottom)</span><br><span class="line">        c2 = up, - <span class="number">1</span> / line_b * (line_c + line_a * up)</span><br><span class="line">        c3 = -<span class="number">1</span> / line_a * (line_c + line_b * bottom), bottom</span><br><span class="line">        c4 = -<span class="number">1</span> / line_a * (line_c + line_b * up), up</span><br><span class="line">        cross_points = [c1, c2, c3, c4]</span><br><span class="line">        cross_points.sort()</span><br><span class="line">        <span class="keyword">return</span> cross_points[<span class="number">1</span>:<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始状态展示</span></span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>, <span class="number">6</span>))</span><br><span class="line">plt.title(<span class="string">&#x27;起始状态 同向&#x27;</span>)</span><br><span class="line">plt.pcolormesh(xx_plane, yy_plane, class_plane, cmap=cmap_light)</span><br><span class="line">plt.scatter(dots[:, <span class="number">0</span>], dots[:, <span class="number">1</span>], c=class_dots, cmap=cmap_bold)</span><br><span class="line">color_point = <span class="string">&#x27;b&#x27;</span> <span class="keyword">if</span> point_coordinates[<span class="number">0</span>] * line_a + point_coordinates[<span class="number">1</span>] * line_b + line_c &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="string">&#x27;r&#x27;</span></span><br><span class="line">plt.scatter(point_coordinates[<span class="number">0</span>], point_coordinates[<span class="number">1</span>], c=color_point, marker=<span class="string">&quot;v&quot;</span>, s=<span class="number">100</span>)</span><br><span class="line"><span class="comment"># plt.grid()</span></span><br><span class="line">plt.plot([bottom - <span class="number">0.5</span>, up + <span class="number">0.5</span>], [<span class="number">0</span>, <span class="number">0</span>], c=<span class="string">&#x27;k&#x27;</span>)</span><br><span class="line">plt.plot([<span class="number">0</span>, <span class="number">0</span>], [bottom - <span class="number">0.5</span>, up + <span class="number">0.5</span>], c=<span class="string">&#x27;k&#x27;</span>)</span><br><span class="line">cross = window_cross(line_a, line_b, line_c)</span><br><span class="line">plt.plot([cross[<span class="number">0</span>][<span class="number">0</span>], cross[<span class="number">1</span>][<span class="number">0</span>]], [cross[<span class="number">0</span>][<span class="number">1</span>], cross[<span class="number">1</span>][<span class="number">1</span>]], c=<span class="string">&#x27;g&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 迭代过程的动态展示</span></span><br><span class="line">plt.close(<span class="string">&#x27;all&#x27;</span>)</span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>, <span class="number">6</span>))</span><br><span class="line">plt.ion()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> ii <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">200</span>):</span><br><span class="line">    plt.cla()</span><br><span class="line">    plt.title(<span class="string">f&#x27;epoch=<span class="subst">&#123;ii+<span class="number">1</span>&#125;</span>: (<span class="subst">&#123;line_a&#125;</span>) * x + (<span class="subst">&#123;line_b&#125;</span>) * y + (<span class="subst">&#123;line_c&#125;</span>) = 0&#x27;</span>, fontsize=<span class="number">20</span>)</span><br><span class="line">    <span class="keyword">if</span> ii &lt; <span class="number">8</span>:</span><br><span class="line">        time.sleep(<span class="number">0.4</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        time.sleep(<span class="number">0.02</span>)</span><br><span class="line">    plt.pcolormesh(xx_plane, yy_plane, class_plane, cmap=cmap_light)</span><br><span class="line">    plt.scatter(dots[:, <span class="number">0</span>], dots[:, <span class="number">1</span>], c=class_dots, cmap=cmap_bold)</span><br><span class="line">    color_point = <span class="string">&#x27;b&#x27;</span> <span class="keyword">if</span> point_coordinates[<span class="number">0</span>] * line_a + point_coordinates[<span class="number">1</span>] * line_b + line_c &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="string">&#x27;r&#x27;</span></span><br><span class="line">    plt.scatter(point_coordinates[<span class="number">0</span>], point_coordinates[<span class="number">1</span>], c=color_point, marker=<span class="string">&quot;v&quot;</span>, s=<span class="number">100</span>)</span><br><span class="line">    plt.grid()</span><br><span class="line">    plt.plot([bottom - <span class="number">0.5</span>, up + <span class="number">0.5</span>], [<span class="number">0</span>, <span class="number">0</span>], c=<span class="string">&#x27;k&#x27;</span>)</span><br><span class="line">    plt.plot([<span class="number">0</span>, <span class="number">0</span>], [bottom - <span class="number">0.5</span>, up + <span class="number">0.5</span>], c=<span class="string">&#x27;k&#x27;</span>)</span><br><span class="line">    cross = window_cross(line_a, line_b, line_c)</span><br><span class="line">    plt.plot([cross[<span class="number">0</span>][<span class="number">0</span>], cross[<span class="number">1</span>][<span class="number">0</span>]], [cross[<span class="number">0</span>][<span class="number">1</span>], cross[<span class="number">1</span>][<span class="number">1</span>]], c=<span class="string">&#x27;g&#x27;</span>)</span><br><span class="line">    <span class="comment"># 暂停</span></span><br><span class="line">    <span class="keyword">if</span> ii &lt; <span class="number">8</span>:</span><br><span class="line">        time.sleep(<span class="number">0.3</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        time.sleep(<span class="number">0.02</span>)</span><br><span class="line">    plt.pause(<span class="number">0.01</span>)</span><br><span class="line">    <span class="comment"># 迭代更新</span></span><br><span class="line">    line_a, line_b, line_c = line_a+point_coordinates[<span class="number">0</span>], line_b+point_coordinates[<span class="number">0</span>], line_c + <span class="number">1</span></span><br><span class="line">    class_dots = np.array([<span class="number">1</span> <span class="keyword">if</span> np.dot(xi, [line_a, line_b]) + line_c &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> xi <span class="keyword">in</span> dots])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 关闭交互模式</span></span><br><span class="line">plt.ioff()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 图形显示</span></span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 感知机 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>随机 梯度下降--感知机实现</title>
      <link href="/posts/1964.html"/>
      <url>/posts/1964.html</url>
      
        <content type="html"><![CDATA[<p>要理解梯度下降和“随机”梯度下降的区别。</p><span id="more"></span><h2 id="随机梯度下降特点："><a href="#随机梯度下降特点：" class="headerlink" title="随机梯度下降特点："></a>随机梯度下降特点：</h2><p> ·每次更新数据只选取一个样本</p><h2 id="优点"><a href="#优点" class="headerlink" title="优点:"></a>优点:</h2><p>   ·相比于批量梯度，这样的方法更快，更快收敛，虽然不是全局最优，但很多时候是我们可以接受的</p><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><p>首先导入包</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure><p>数据的准备</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># x = np.array([[-1., 2.], [0., 0.], [0., 2.], [1., 0]])</span></span><br><span class="line">x = np.array([[<span class="number">0.</span>, <span class="number">2.</span>], [<span class="number">1.</span>, <span class="number">0</span>], [-<span class="number">1.</span>, <span class="number">2.</span>], [<span class="number">0.</span>, <span class="number">0.</span>]])</span><br><span class="line"><span class="comment"># y = np.array([1, 1, -1, -1])</span></span><br><span class="line">y = np.array([-<span class="number">1</span>, -<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br></pre></td></tr></table></figure><p>可视化函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">plot_plot</span>(<span class="params">x, omega, b</span>):</span><br><span class="line">    xx = np.linspace(-<span class="number">5</span>, <span class="number">5</span>, <span class="number">100</span>)</span><br><span class="line">    yy = - <span class="number">1</span> / omega[<span class="number">1</span>] * (omega[<span class="number">0</span>] * xx + b)</span><br><span class="line">    plt.figure()</span><br><span class="line">    plt.scatter(x[:, <span class="number">0</span>], x[:, <span class="number">1</span>], c=y)</span><br><span class="line">    plt.plot(xx, yy)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;x1&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;x2&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;(&#123;&#125;) * x1 + (&#123;&#125;) * x2 + (&#123;&#125;) = 0&#x27;</span>.<span class="built_in">format</span>(*omega, b))</span><br><span class="line">    plt.xlim(-<span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">    plt.ylim(-<span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">    plt.grid()</span><br></pre></td></tr></table></figure><p>随机初始化</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">omega = np.array([<span class="number">0.</span>, <span class="number">0.</span>])</span><br><span class="line">b = <span class="number">0.0</span></span><br><span class="line">eta = <span class="number">1.0</span></span><br></pre></td></tr></table></figure><p>感知机函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">sign</span>(<span class="params">pp, b, omega</span>):</span><br><span class="line">    <span class="keyword">return</span> np.sign(np.dot(pp, omega) + b)</span><br></pre></td></tr></table></figure><p>定义判断感知机分类对错的函数（选取错的点来优化）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">error_value</span>(<span class="params">x, y</span>):</span><br><span class="line">    x_f = []</span><br><span class="line">    y_f = []</span><br><span class="line"></span><br><span class="line">    check = <span class="literal">False</span></span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">not</span> check:</span><br><span class="line">        check = <span class="literal">True</span></span><br><span class="line">        <span class="keyword">for</span> xi, yi <span class="keyword">in</span> <span class="built_in">zip</span>(x, y):</span><br><span class="line">            <span class="keyword">if</span> sign(xi, b, omega) * yi &lt;= <span class="number">0</span>:</span><br><span class="line">                x_f.append(xi)</span><br><span class="line">                y_f.append(yi)</span><br><span class="line">    <span class="keyword">return</span> x_f, y_f</span><br></pre></td></tr></table></figure><p>进行判断和优化</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">i = <span class="number">1</span></span><br><span class="line">check = <span class="literal">False</span></span><br><span class="line"><span class="keyword">while</span> <span class="keyword">not</span> check:</span><br><span class="line">    x_f, y_f = error_value(x, y)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(x_f) == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;最终梯度下降得到的omega和b分别是：&quot;</span>, omega, b)</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    index = np.random.randint(<span class="number">0</span>, <span class="built_in">len</span>(x_f), <span class="number">1</span>)[<span class="number">0</span>]   <span class="comment"># 体现出&quot;随机&quot;</span></span><br><span class="line">    x_tem = x_f[index]</span><br><span class="line">    y_tem = y_f[index]</span><br><span class="line">    omega = omega - eta * (-np.dot(x_tem, y_tem))   <span class="comment"># 体现出&quot;梯度下降&quot;</span></span><br><span class="line">    b = b - eta * (-y_tem)</span><br><span class="line"><span class="comment">#     print(omega)</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;第&#123;0&#125;此迭代分错的样本为:&quot;</span>.<span class="built_in">format</span>(i), x_f)</span><br><span class="line">    i+=<span class="number">1</span></span><br></pre></td></tr></table></figure><p>Out</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">第<span class="number">1</span>此迭代分错的样本为: [array([<span class="number">0.</span>, <span class="number">2.</span>]), array([<span class="number">1.</span>, <span class="number">0.</span>]), array([-<span class="number">1.</span>,  <span class="number">2.</span>]), array([<span class="number">0.</span>, <span class="number">0.</span>])]</span><br><span class="line">第<span class="number">2</span>此迭代分错的样本为: [array([<span class="number">0.</span>, <span class="number">2.</span>]), array([<span class="number">1.</span>, <span class="number">0.</span>])]</span><br><span class="line">第<span class="number">3</span>此迭代分错的样本为: [array([<span class="number">0.</span>, <span class="number">2.</span>]), array([<span class="number">0.</span>, <span class="number">0.</span>])]</span><br><span class="line">第<span class="number">4</span>此迭代分错的样本为: [array([<span class="number">0.</span>, <span class="number">0.</span>])]</span><br><span class="line">第<span class="number">5</span>此迭代分错的样本为: [array([<span class="number">0.</span>, <span class="number">2.</span>]), array([<span class="number">0.</span>, <span class="number">0.</span>])]</span><br><span class="line">第<span class="number">6</span>此迭代分错的样本为: [array([-<span class="number">1.</span>,  <span class="number">2.</span>]), array([<span class="number">0.</span>, <span class="number">0.</span>])]</span><br><span class="line">第<span class="number">7</span>此迭代分错的样本为: [array([<span class="number">0.</span>, <span class="number">2.</span>]), array([<span class="number">0.</span>, <span class="number">0.</span>])]</span><br><span class="line">第<span class="number">8</span>此迭代分错的样本为: [array([<span class="number">0.</span>, <span class="number">2.</span>])]</span><br><span class="line">第<span class="number">9</span>此迭代分错的样本为: [array([-<span class="number">1.</span>,  <span class="number">2.</span>]), array([<span class="number">0.</span>, <span class="number">0.</span>])]</span><br><span class="line">第<span class="number">10</span>此迭代分错的样本为: [array([<span class="number">0.</span>, <span class="number">2.</span>])]</span><br><span class="line">第<span class="number">11</span>此迭代分错的样本为: [array([-<span class="number">1.</span>,  <span class="number">2.</span>]), array([<span class="number">0.</span>, <span class="number">0.</span>])]</span><br><span class="line">第<span class="number">12</span>此迭代分错的样本为: [array([<span class="number">0.</span>, <span class="number">2.</span>])]</span><br><span class="line">第<span class="number">13</span>此迭代分错的样本为: [array([<span class="number">0.</span>, <span class="number">0.</span>])]</span><br><span class="line">最终梯度下降得到的omega和b分别是： [-<span class="number">5.</span> -<span class="number">2.</span>] <span class="number">1.0</span></span><br></pre></td></tr></table></figure><p>可视化</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plot_plot(x, omega, b)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/37ff5d54542c4c749d50568d6533d110.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_16,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>可改进之处：在“进行判断和优化”的代码里面直接打乱数据的顺序，使得能够随机选取一个数进行优化</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 感知机 </tag>
            
            <tag> 梯度下降 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>梯度下降--感知机实现</title>
      <link href="/posts/1300.html"/>
      <url>/posts/1300.html</url>
      
        <content type="html"><![CDATA[<p>用梯度下降法来优化感知机模型</p><span id="more"></span><h1 id="任务：用梯度下降的方法优化感知机"><a href="#任务：用梯度下降的方法优化感知机" class="headerlink" title="任务：用梯度下降的方法优化感知机"></a>任务：用梯度下降的方法优化感知机</h1><p>首先导入包</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 首先导入包：</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure><p>数据的准备</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># x = np.array([[-1., 2.], [0., 0.], [0., 2.], [1., 0]])</span></span><br><span class="line">x = np.array([[<span class="number">0.</span>, <span class="number">2.</span>], [<span class="number">1.</span>, <span class="number">0</span>], [-<span class="number">1.</span>, <span class="number">2.</span>], [<span class="number">0.</span>, <span class="number">0.</span>]])</span><br><span class="line"><span class="comment"># y = np.array([1, 1, -1, -1])</span></span><br><span class="line">y = np.array([-<span class="number">1</span>, -<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br></pre></td></tr></table></figure><p>可视化函数的定义</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">plot_plot</span>(<span class="params">x, omega, b</span>):</span><br><span class="line">    xx = np.linspace(-<span class="number">5</span>, <span class="number">5</span>, <span class="number">100</span>)</span><br><span class="line">    yy = - <span class="number">1</span> / omega[<span class="number">1</span>] * (omega[<span class="number">0</span>] * xx + b)</span><br><span class="line">    plt.figure()</span><br><span class="line">    plt.scatter(x[:, <span class="number">0</span>], x[:, <span class="number">1</span>], c=y)</span><br><span class="line">    plt.plot(xx, yy)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;x1&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;x2&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;(&#123;&#125;) * x1 + (&#123;&#125;) * x2 + (&#123;&#125;) = 0&#x27;</span>.<span class="built_in">format</span>(*omega, b))</span><br><span class="line">    plt.xlim(-<span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">    plt.ylim(-<span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">    plt.grid()</span><br></pre></td></tr></table></figure><p>随机初始化</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">omega = np.array([<span class="number">0.</span>, <span class="number">0.</span>])</span><br><span class="line">b = <span class="number">0.0</span></span><br><span class="line">eta = <span class="number">1.0</span></span><br></pre></td></tr></table></figure><p>感知机函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">sign</span>(<span class="params">pp, b, omega</span>):</span><br><span class="line">    <span class="keyword">return</span> np.sign(np.dot(pp, omega) + b)</span><br></pre></td></tr></table></figure><p>实现梯度下降</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">check = <span class="literal">False</span></span><br><span class="line"><span class="keyword">while</span> <span class="keyword">not</span> check:</span><br><span class="line">    check = <span class="literal">True</span></span><br><span class="line">    ter = <span class="built_in">list</span>(<span class="built_in">zip</span>(x, y))</span><br><span class="line">    np.random.shuffle(ter)</span><br><span class="line">    np.random.seed(<span class="number">10</span>)</span><br><span class="line">    <span class="built_in">print</span>(ter)</span><br><span class="line">    <span class="keyword">for</span> xi, yi <span class="keyword">in</span> ter:</span><br><span class="line">        <span class="keyword">if</span> sign(xi, b, omega) * yi &lt;= <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(xi)</span><br><span class="line">            <span class="built_in">print</span>(omega, b)</span><br><span class="line">            omega += eta * xi * yi</span><br><span class="line">            b += eta * yi</span><br><span class="line">            <span class="built_in">print</span>(omega, b)</span><br><span class="line">            check = <span class="literal">False</span></span><br><span class="line">            <span class="built_in">print</span>()</span><br><span class="line">plot_plot(x, omega, b)</span><br></pre></td></tr></table></figure><p>最终优化的曲结果<img src="https://img-blog.csdnimg.cn/855b3b90f7904984b9d4527a24b37493.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 感知机 </tag>
            
            <tag> 梯度下降 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>系统认证风险预测-Baseline</title>
      <link href="/posts/9548.html"/>
      <url>/posts/9548.html</url>
      
        <content type="html"><![CDATA[<p>构建用户认证行为特征模型和风险异常评估模型，利用风险评估模型去判断当前用户认证行为是否存在风险</p><span id="more"></span><h1 id="比赛任务"><a href="#比赛任务" class="headerlink" title="比赛任务"></a>比赛任务</h1><p>本赛题中，参赛团队将基于用户认证行为数据及风险异常标记结构，构建用户认证行为特征模型和风险异常评估模型，利用风险评估模型去判断当前用户认证行为是否存在风险</p><pre><code>利用用户认证数据构建行为基采用监督学习模型，基于用户认证行为特征，构建风险异常评估模型，判断当前用户认证行为是否存在风险</code></pre><h1 id="比赛数据集"><a href="#比赛数据集" class="headerlink" title="比赛数据集"></a>比赛数据集</h1><p><a href="https://www.heywhale.com/mw/dataset/6189288bebdfaf0017562059/file">https://www.heywhale.com/mw/dataset/6189288bebdfaf0017562059/file</a></p><h1 id="赛题baseline："><a href="#赛题baseline：" class="headerlink" title="赛题baseline："></a>赛题baseline：</h1><p>导入包</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.simplefilter(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> gc</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">pd.set_option(<span class="string">&#x27;max_columns&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line">pd.set_option(<span class="string">&#x27;max_rows&#x27;</span>, <span class="number">200</span>)</span><br><span class="line">pd.set_option(<span class="string">&#x27;float_format&#x27;</span>, <span class="keyword">lambda</span> x: <span class="string">&#x27;%.3f&#x27;</span> % x)</span><br><span class="line"><span class="keyword">from</span> tqdm.notebook <span class="keyword">import</span> tqdm </span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold, StratifiedKFold</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler, MinMaxScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br><span class="line"><span class="keyword">import</span> lightgbm <span class="keyword">as</span> lgb</span><br></pre></td></tr></table></figure><p>合并数据集</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">train = pd.read_csv(<span class="string">&quot;E://data//DF//CCK-系统认证风险预测/train_dataset.csv&quot;</span>, sep=<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line">test = pd.read_csv(<span class="string">&#x27;E://data//DF//CCK-系统认证风险预测/test_dataset.csv&#x27;</span>, sep=<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line">data = pd.concat([train, test])</span><br></pre></td></tr></table></figure><p>特征转换</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">data[<span class="string">&#x27;location_first_lvl&#x27;</span>] = data[<span class="string">&#x27;location&#x27;</span>].astype(<span class="built_in">str</span>).apply(<span class="keyword">lambda</span> x: json.loads(x)[<span class="string">&#x27;first_lvl&#x27;</span>])</span><br><span class="line">data[<span class="string">&#x27;location_sec_lvl&#x27;</span>] = data[<span class="string">&#x27;location&#x27;</span>].astype(<span class="built_in">str</span>).apply(<span class="keyword">lambda</span> x: json.loads(x)[<span class="string">&#x27;sec_lvl&#x27;</span>])</span><br><span class="line">data[<span class="string">&#x27;location_third_lvl&#x27;</span>] = data[<span class="string">&#x27;location&#x27;</span>].astype(<span class="built_in">str</span>).apply(<span class="keyword">lambda</span> x: json.loads(x)[<span class="string">&#x27;third_lvl&#x27;</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">data[<span class="string">&#x27;auth_type&#x27;</span>].fillna(<span class="string">&#x27;__NaN__&#x27;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> tqdm([<span class="string">&#x27;user_name&#x27;</span>, <span class="string">&#x27;action&#x27;</span>, <span class="string">&#x27;auth_type&#x27;</span>, <span class="string">&#x27;ip&#x27;</span>, </span><br><span class="line">                 <span class="string">&#x27;ip_location_type_keyword&#x27;</span>, <span class="string">&#x27;ip_risk_level&#x27;</span>, <span class="string">&#x27;location&#x27;</span>, <span class="string">&#x27;device_model&#x27;</span>,</span><br><span class="line">                 <span class="string">&#x27;os_type&#x27;</span>, <span class="string">&#x27;os_version&#x27;</span>, <span class="string">&#x27;browser_type&#x27;</span>, <span class="string">&#x27;browser_version&#x27;</span>,</span><br><span class="line">                 <span class="string">&#x27;bus_system_code&#x27;</span>, <span class="string">&#x27;op_target&#x27;</span>, <span class="string">&#x27;location_first_lvl&#x27;</span>, <span class="string">&#x27;location_sec_lvl&#x27;</span>, </span><br><span class="line">                 <span class="string">&#x27;location_third_lvl&#x27;</span>]):</span><br><span class="line">    lbl = LabelEncoder()</span><br><span class="line">    data[col] = lbl.fit_transform(data[col])</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>时间的处理</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">data[<span class="string">&#x27;op_date&#x27;</span>] = pd.to_datetime(data[<span class="string">&#x27;op_date&#x27;</span>])</span><br><span class="line">data[<span class="string">&#x27;op_ts&#x27;</span>] = data[<span class="string">&quot;op_date&quot;</span>].values.astype(np.int64) // <span class="number">10</span> ** <span class="number">9</span></span><br><span class="line"><span class="comment"># data[&quot;op_date&quot;].values.astype(np.int64)</span></span><br><span class="line"><span class="comment"># data = data.sort_values(by=[&#x27;user_name&#x27;, &#x27;op_ts&#x27;, &quot;action&quot;]).reset_index(drop=True)</span></span><br><span class="line">data = data.sort_values(by=[<span class="string">&#x27;user_name&#x27;</span>, <span class="string">&#x27;op_ts&#x27;</span>, <span class="string">&quot;action&quot;</span>]).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># data[&#x27;last_ts&#x27;] = data.groupby([&#x27;user_name&#x27;,&quot;action&quot;])[&#x27;op_ts&#x27;].shift(1)</span></span><br><span class="line">data[<span class="string">&#x27;last_ts&#x27;</span>] = data.groupby([<span class="string">&#x27;user_name&#x27;</span>])[<span class="string">&#x27;op_ts&#x27;</span>].shift(<span class="number">1</span>)</span><br><span class="line">data[<span class="string">&#x27;ts_diff1&#x27;</span>] = data[<span class="string">&#x27;op_ts&#x27;</span>] - data[<span class="string">&#x27;last_ts&#x27;</span>]</span><br><span class="line">data[<span class="string">&quot;weekday&quot;</span>] = data[<span class="string">&quot;op_date&quot;</span>].dt.dayofweek+<span class="number">1</span></span><br><span class="line"><span class="comment"># data.groupby(&quot;weekday&quot;)[&quot;ts_diff1&quot;].sum()</span></span><br><span class="line">data[<span class="string">&quot;year&quot;</span>] = data[<span class="string">&quot;op_date&quot;</span>].dt.year</span><br><span class="line">data[<span class="string">&quot;year&quot;</span>] = data[<span class="string">&quot;year&quot;</span>].<span class="built_in">map</span>(&#123;<span class="number">2018</span>:<span class="number">0</span>, <span class="number">2019</span>:<span class="number">1</span>, <span class="number">2020</span>:<span class="number">2</span>&#125;)</span><br><span class="line">data[<span class="string">&quot;month&quot;</span>] = data[<span class="string">&quot;op_date&quot;</span>].dt.month</span><br><span class="line">data[<span class="string">&quot;day&quot;</span>] = data[<span class="string">&quot;op_date&quot;</span>].dt.day</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>特征构建：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">data[<span class="string">&quot;ts_diff1_log&quot;</span>] = data[<span class="string">&quot;ts_diff1&quot;</span>].apply(np.log)</span><br><span class="line">data[<span class="string">&quot;ts_diff1_log_log&quot;</span>] = data[<span class="string">&quot;ts_diff1&quot;</span>].apply(np.log).apply(np.log)</span><br><span class="line"><span class="keyword">for</span> f <span class="keyword">in</span> [<span class="string">&#x27;ip&#x27;</span>, <span class="string">&#x27;location&#x27;</span>, <span class="string">&#x27;device_model&#x27;</span>, <span class="string">&#x27;os_version&#x27;</span>]:</span><br><span class="line">    data[<span class="string">f&#x27;user_<span class="subst">&#123;f&#125;</span>_nunique&#x27;</span>] = data.groupby([<span class="string">&#x27;user_name&#x27;</span>,<span class="string">&quot;action&quot;</span>])[f].transform(<span class="string">&#x27;nunique&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> method <span class="keyword">in</span> [<span class="string">&#x27;mean&#x27;</span>, <span class="string">&#x27;max&#x27;</span>, <span class="string">&#x27;min&#x27;</span>, <span class="string">&#x27;std&#x27;</span>,<span class="string">&quot;prod&quot;</span>]:</span><br><span class="line">    data[<span class="string">f&#x27;ts_diff1_<span class="subst">&#123;method&#125;</span>&#x27;</span>] = data.groupby([<span class="string">&#x27;user_name&#x27;</span>,<span class="string">&quot;action&quot;</span>])[<span class="string">&#x27;ts_diff1&#x27;</span>].transform(method)</span><br><span class="line"></span><br><span class="line">=```</span><br><span class="line">构建与标签相关性高的数据（但是并没有业务意义）</span><br><span class="line"></span><br><span class="line">```python</span><br><span class="line">data[<span class="string">&quot;auth_type//ip_risk_level&quot;</span>] = data[<span class="string">&quot;auth_type&quot;</span>]/data[<span class="string">&quot;ip_risk_level&quot;</span>]</span><br><span class="line">data[<span class="string">&quot;ip_risk_level//auth_type&quot;</span>] = data[<span class="string">&quot;ip_risk_level&quot;</span>]/data[<span class="string">&quot;auth_type&quot;</span>]</span><br><span class="line">data[<span class="string">&quot;browser_type//auth_type&quot;</span>] = data[<span class="string">&quot;browser_type&quot;</span>]/data[<span class="string">&quot;auth_type&quot;</span>]</span><br><span class="line">data[<span class="string">&quot;browser_version//auth_type&quot;</span>] = data[<span class="string">&quot;browser_version&quot;</span>]/data[<span class="string">&quot;auth_type&quot;</span>]</span><br></pre></td></tr></table></figure><p>查看相关性</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">data.corr()[<span class="string">&quot;risk_label&quot;</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 与标签的相关性</span></span><br><span class="line">ip_risk_level//auth_type     -<span class="number">0.032</span></span><br><span class="line">auth_type//ip_risk_level     -<span class="number">0.028</span></span><br><span class="line">browser_type//auth_type      -<span class="number">0.025</span></span><br><span class="line">browser_version//auth_type   -<span class="number">0.021</span></span><br><span class="line">op_ts                        -<span class="number">0.021</span></span><br><span class="line">last_ts                      -<span class="number">0.021</span></span><br><span class="line">year                         -<span class="number">0.017</span></span><br><span class="line">browser_version              -<span class="number">0.009</span></span><br><span class="line">browser_type                 -<span class="number">0.009</span></span><br><span class="line">weekday                      -<span class="number">0.009</span></span><br><span class="line">day                          -<span class="number">0.008</span></span><br><span class="line">month                        -<span class="number">0.008</span></span><br><span class="line">ip_risk_level                -<span class="number">0.007</span></span><br><span class="line">auth_type                    -<span class="number">0.006</span></span><br></pre></td></tr></table></figure><p>删除没用的特征</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">data.drop([<span class="string">&#x27;client_type&#x27;</span>, <span class="string">&#x27;browser_source&#x27;</span>, <span class="string">&quot;user_name&quot;</span>, <span class="string">&quot;bus_system_code&quot;</span>], axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># data.drop([&#x27;client_type&#x27;, &#x27;browser_source&#x27;, &quot;browser_type&quot;], axis=1, inplace=True)</span></span><br><span class="line">train = data[data[<span class="string">&#x27;risk_label&#x27;</span>].notna()]</span><br><span class="line">test = data[data[<span class="string">&#x27;risk_label&#x27;</span>].isna()]</span><br></pre></td></tr></table></figure><p>查看相关性热力图<br><img src="https://img-blog.csdnimg.cn/b43c525d72b94d4a91f3acf38d98410a.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>选取feature_names</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ycol = <span class="string">&#x27;risk_label&#x27;</span></span><br><span class="line">feature_names = <span class="built_in">list</span>(</span><br><span class="line">    <span class="built_in">filter</span>(<span class="keyword">lambda</span> x: x <span class="keyword">not</span> <span class="keyword">in</span> [ycol, <span class="string">&#x27;session_id&#x27;</span>, <span class="string">&#x27;op_date&#x27;</span>, <span class="string">&#x27;last_ts&#x27;</span>], train.columns))</span><br></pre></td></tr></table></figure><p>训练模型</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line">model = lgb.LGBMClassifier(objective=<span class="string">&#x27;binary&#x27;</span>,</span><br><span class="line">                           boosting_type=<span class="string">&#x27;gbdt&#x27;</span>,</span><br><span class="line">                           tree_learner=<span class="string">&#x27;serial&#x27;</span>,</span><br><span class="line">                           num_leaves=<span class="number">32</span>,</span><br><span class="line">                           max_depth=<span class="number">6</span>,</span><br><span class="line">                           learning_rate=<span class="number">0.05</span>,</span><br><span class="line">                           n_estimators=<span class="number">3000</span>,</span><br><span class="line">                           subsample=<span class="number">0.8</span>,</span><br><span class="line">                           feature_fraction=<span class="number">0.6</span>,</span><br><span class="line">                           reg_alpha=<span class="number">0.</span>,</span><br><span class="line">                           reg_lambda=<span class="number">0.</span>,</span><br><span class="line">                           random_state=<span class="number">1983</span>,</span><br><span class="line">                           is_unbalance=<span class="literal">True</span>,</span><br><span class="line">                           metric=<span class="string">&#x27;auc&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">oof = []</span><br><span class="line">prediction = test[[<span class="string">&#x27;session_id&#x27;</span>]]</span><br><span class="line">prediction[ycol] = <span class="number">0</span></span><br><span class="line">df_importance_list = []</span><br><span class="line"></span><br><span class="line">kfold = StratifiedKFold(n_splits=<span class="number">5</span>, shuffle=<span class="literal">True</span>, random_state=<span class="number">1983</span>)</span><br><span class="line"><span class="keyword">for</span> fold_id, (trn_idx, val_idx) <span class="keyword">in</span> <span class="built_in">enumerate</span>(kfold.split(train[feature_names], train[ycol])):</span><br><span class="line">    X_train = train.iloc[trn_idx][feature_names]</span><br><span class="line">    Y_train = train.iloc[trn_idx][ycol]</span><br><span class="line"></span><br><span class="line">    X_val = train.iloc[val_idx][feature_names]</span><br><span class="line">    Y_val = train.iloc[val_idx][ycol]</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\nFold_&#123;&#125; Training ================================\n&#x27;</span>.<span class="built_in">format</span>(fold_id+<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    lgb_model = model.fit(X_train,</span><br><span class="line">                          Y_train,</span><br><span class="line">                          eval_names=[<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;valid&#x27;</span>],</span><br><span class="line">                          eval_set=[(X_train, Y_train), (X_val, Y_val)],</span><br><span class="line">                          verbose=<span class="number">500</span>,</span><br><span class="line">                          eval_metric=<span class="string">&#x27;auc&#x27;</span>,</span><br><span class="line">                          early_stopping_rounds=<span class="number">50</span>)</span><br><span class="line"></span><br><span class="line">    pred_val = lgb_model.predict_proba(</span><br><span class="line">        X_val, num_iteration=lgb_model.best_iteration_)</span><br><span class="line">    df_oof = train.iloc[val_idx][[<span class="string">&#x27;session_id&#x27;</span>, ycol]].copy()</span><br><span class="line">    df_oof[<span class="string">&#x27;pred&#x27;</span>] = pred_val[:, <span class="number">1</span>]</span><br><span class="line">    oof.append(df_oof)</span><br><span class="line"></span><br><span class="line">    pred_test = lgb_model.predict_proba(</span><br><span class="line">        test[feature_names], num_iteration=lgb_model.best_iteration_)</span><br><span class="line">    prediction[ycol] += pred_test[:, <span class="number">1</span>] / kfold.n_splits</span><br><span class="line"></span><br><span class="line">    df_importance = pd.DataFrame(&#123;</span><br><span class="line">        <span class="string">&#x27;column&#x27;</span>: feature_names,</span><br><span class="line">        <span class="string">&#x27;importance&#x27;</span>: lgb_model.feature_importances_,</span><br><span class="line">    &#125;)</span><br><span class="line">    df_importance_list.append(df_importance)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">del</span> lgb_model, pred_val, pred_test, X_train, Y_train, X_val, Y_val</span><br><span class="line">    gc.collect()</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">df_importance = pd.concat(df_importance_list)</span><br><span class="line">df_importance = df_importance.groupby([<span class="string">&#x27;column&#x27;</span>])[<span class="string">&#x27;importance&#x27;</span>].agg(</span><br><span class="line">    <span class="string">&#x27;mean&#x27;</span>).sort_values(ascending=<span class="literal">False</span>).reset_index()</span><br><span class="line">df_oof = pd.concat(oof)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;roc_auc_score&#x27;</span>, roc_auc_score(df_oof[ycol], df_oof[<span class="string">&#x27;pred&#x27;</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment">## roc_auc_score 0.5131761316649879</span></span><br><span class="line"></span><br><span class="line">prediction[<span class="string">&#x27;id&#x27;</span>] = <span class="built_in">range</span>(<span class="built_in">len</span>(prediction))</span><br><span class="line">prediction[<span class="string">&#x27;id&#x27;</span>] = prediction[<span class="string">&#x27;id&#x27;</span>] + <span class="number">1</span></span><br><span class="line">prediction = prediction[[<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;risk_label&#x27;</span>]].copy()</span><br><span class="line">prediction.columns = [<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;ret&#x27;</span>]</span><br><span class="line">prediction.head()</span><br><span class="line"></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">id</span> ret</span><br><span class="line"><span class="number">6147</span> <span class="number">1</span> <span class="number">0.378</span></span><br><span class="line"><span class="number">6148</span> <span class="number">2</span> <span class="number">0.488</span></span><br><span class="line"><span class="number">6149</span> <span class="number">3</span> <span class="number">0.502</span></span><br><span class="line"><span class="number">6150</span> <span class="number">4</span> <span class="number">0.509</span></span><br><span class="line"><span class="number">6151</span> <span class="number">5</span> <span class="number">0.480</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 竞赛 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 数据挖掘 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>梯度下降算介绍以及代码详解</title>
      <link href="/posts/3325.html"/>
      <url>/posts/3325.html</url>
      
        <content type="html"><![CDATA[<p>梯度下降法是一个一阶最优化算法。 要使用梯度下降法找到一个函数的局部极小值，必须向函数上当前点对应梯度（或者是近似梯度）的反方向的规定步长距离点进行迭代搜索。 </p><span id="more"></span><h2 id="什么是梯度下降："><a href="#什么是梯度下降：" class="headerlink" title="什么是梯度下降："></a>什么是梯度下降：</h2><p>首先来看看梯度下降的一个直观的解释。比如我们在一座大山上的某处位置，由于我们不知道怎么下山，于是决定走一步算一步，也就是在每走到一个位置的时候，求解当前位置的梯度，沿着梯度的负方向，也就是当前最陡峭的位置向下走一步，然后继续求解当前位置梯度，向这一步所在位置沿着最陡峭最易下山的位置走一步。这样一步步的走下去，一直走到觉得我们已经到了山脚。当然这样走下去，有可能我们不能走到山脚，而是到了某一个局部的山峰低处</p><h2 id="理论部分："><a href="#理论部分：" class="headerlink" title="理论部分："></a>理论部分：</h2><p><img src="https://img-blog.csdnimg.cn/0b195a289c0e40118074af94f03035ba.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/6eebb019bdbe4786a9937003481a98d4.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h2 id="梯度下降伪代码-个人感觉第-5-步应该转第-2-步-："><a href="#梯度下降伪代码-个人感觉第-5-步应该转第-2-步-：" class="headerlink" title="梯度下降伪代码(个人感觉第(5)步应该转第(2)步)："></a>梯度下降伪代码(个人感觉第(5)步应该转第(2)步)：</h2><p><img src="https://img-blog.csdnimg.cn/b226c05dafef44488d551d507a378622.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h2 id="代码："><a href="#代码：" class="headerlink" title="代码："></a>代码：</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 首先初始化函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">f</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> x ** <span class="number">2</span> + <span class="number">10</span> * np.sin(x)</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="comment"># 然后初始化梯度函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">df</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="number">2</span> * x + <span class="number">10</span> * np.cos(x)</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个阈值</span></span><br><span class="line">value = <span class="number">10e-8</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化起始点</span></span><br><span class="line">k = <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    grad = df(k)</span><br><span class="line"><span class="comment">#     print(grad)</span></span><br><span class="line">    <span class="keyword">if</span> np.<span class="built_in">abs</span>(df(k)) &lt; value:</span><br><span class="line">        x_mark = k</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 找出最合适的学习率</span></span><br><span class="line">        Lambda = np.linspace(<span class="number">0</span>, <span class="number">12</span>, <span class="number">10000000</span>)</span><br><span class="line">        tem = k-Lambda * grad       <span class="comment"># 直接减去的梯度的方向，</span></span><br><span class="line">        base_Lambda = Lambda[np.argmin(f(tem))]</span><br><span class="line"><span class="comment">#         print(&quot;最佳的学习率为&quot;, Lambda[np.argmin(f(tem))])</span></span><br><span class="line">    <span class="keyword">if</span> np.<span class="built_in">abs</span>(k - (k-base_Lambda * grad)) &lt; value <span class="keyword">or</span> np.<span class="built_in">abs</span>(f(k) - f(k-base_Lambda * grad)) &lt; value:</span><br><span class="line">        x_mark = k-base_Lambda * grad</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    k = k-base_Lambda * grad</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;局部最优的坐标X值为：&quot;</span>,x_mark)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;局部最优的学习率为：&quot;</span>, base_Lambda)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Out：</span><br><span class="line">局部最优的坐标X值为： <span class="number">3.837467103051607</span></span><br><span class="line">局部最优的学习率为： <span class="number">11.37973433797343</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 梯度下降算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kmeans实战-实现二维的bolo分析</title>
      <link href="/posts/8244.html"/>
      <url>/posts/8244.html</url>
      
        <content type="html"><![CDATA[<p>对二维的bolo数据集分析与可视化</p><span id="more"></span><h1 id="首先导入包："><a href="#首先导入包：" class="headerlink" title="首先导入包："></a>首先导入包：</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入包</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt     <span class="comment"># 画图的包</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np     </span><br><span class="line"><span class="keyword">import</span> pylab <span class="keyword">as</span> mpl  <span class="comment"># import matplotlib as mpl</span></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs   <span class="comment"># 产生数据集</span></span><br></pre></td></tr></table></figure><h1 id="默认设置："><a href="#默认设置：" class="headerlink" title="默认设置："></a>默认设置：</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mpl.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;FangSong&#x27;</span>]  <span class="comment"># 指定默认字体</span></span><br><span class="line">mpl.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>  <span class="comment"># 解决保存图像是负号&#x27;-&#x27;显示为方块的问题</span></span><br></pre></td></tr></table></figure><h1 id="进行初始化："><a href="#进行初始化：" class="headerlink" title="进行初始化："></a>进行初始化：</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">n_samples = <span class="number">1500</span>  <span class="comment"># 生成1500个数据集</span></span><br><span class="line">random_state = <span class="number">170</span>  <span class="comment"># 170这个是随机种子</span></span><br><span class="line">k = <span class="number">3</span>  <span class="comment"># 超参数</span></span><br><span class="line">np.random.seed(<span class="number">26</span>)    <span class="comment">#给numpy设置一个随机种子，保证每次都能产生相同的值</span></span><br><span class="line">X, y = make_blobs(n_samples=n_samples, random_state=random_state)    <span class="comment"># 生成数据集，包括1500个样本</span></span><br><span class="line">ages = np.vstack((X[y == <span class="number">0</span>][:<span class="number">500</span>], X[y == <span class="number">1</span>][:<span class="number">500</span>], X[y == <span class="number">2</span>][:<span class="number">500</span>]))   <span class="comment"># 将数据进行堆叠，shape为(1500, 2)</span></span><br><span class="line">y = np.array(([<span class="number">0</span>] * <span class="number">500</span> + [<span class="number">1</span>] * <span class="number">500</span> + [<span class="number">2</span>] * <span class="number">500</span>))  <span class="comment">#生成0 1 2 各500个</span></span><br></pre></td></tr></table></figure><h1 id="迭代初始化："><a href="#迭代初始化：" class="headerlink" title="迭代初始化："></a>迭代初始化：</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">centers = np.zeros([<span class="number">3</span>, <span class="number">2</span>])    <span class="comment"># 生成0矩阵</span></span><br><span class="line">centers_random = np.random.choice(<span class="built_in">range</span>(<span class="built_in">len</span>(y)), <span class="number">3</span>)  <span class="comment"># 迭代起点</span></span><br><span class="line">centers_new = ages[centers_random]   <span class="comment"># 随机选取中心</span></span><br><span class="line">dis_to_cent = np.zeros((k, <span class="built_in">len</span>(ages)))  <span class="comment"># 一个二维数据，相当于一个空的容器</span></span><br></pre></td></tr></table></figure><h1 id="实现预测："><a href="#实现预测：" class="headerlink" title="实现预测："></a>实现预测：</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> <span class="keyword">not</span> (centers_new == centers).<span class="built_in">all</span>():</span><br><span class="line">    centers = centers_new.copy()  <span class="comment"># 注意python的赋值过程，进行展开讲解，== is 和复制方式</span></span><br><span class="line">    <span class="keyword">for</span> ii <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">        dis_to_cent[ii] = np.linalg.norm(ages - centers[ii], axis=<span class="number">1</span>)    <span class="comment"># 计算每个数值到中心的距离</span></span><br><span class="line"></span><br><span class="line">    clusters = dis_to_cent.argmin(axis=<span class="number">0</span>)   <span class="comment"># 划分出每个类别</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> ii <span class="keyword">in</span> <span class="built_in">range</span>(k):   <span class="comment"># 重新计算中心</span></span><br><span class="line">        cluster = ages[clusters == ii]</span><br><span class="line">        centers_new[ii] = ages[clusters == ii].mean(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(centers, centers_new)</span><br><span class="line">    <span class="built_in">print</span>(centers_new)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;centers_new==centers?&#x27;</span>, (centers_new == centers).<span class="built_in">all</span>())</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> Kmeans可视化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>KMeans算法分析以及可视化展示</title>
      <link href="/posts/65480.html"/>
      <url>/posts/65480.html</url>
      
        <content type="html"><![CDATA[<p>手动生成数据集并进行可视化</p><span id="more"></span><h1 id="基本流程："><a href="#基本流程：" class="headerlink" title="基本流程："></a>基本流程：</h1><h2 id="导入包"><a href="#导入包" class="headerlink" title="导入包"></a>导入包</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pylab <span class="keyword">as</span> mpl  <span class="comment"># import matplotlib as mpl</span></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</span><br></pre></td></tr></table></figure><h2 id="画图问题："><a href="#画图问题：" class="headerlink" title="画图问题："></a>画图问题：</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mpl.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;FangSong&#x27;</span>]  <span class="comment"># 指定默认字体</span></span><br><span class="line">mpl.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>  <span class="comment"># 解决保存图像是负号&#x27;-&#x27;显示为方块的问题</span></span><br></pre></td></tr></table></figure><h2 id="数据集的生成"><a href="#数据集的生成" class="headerlink" title="数据集的生成"></a>数据集的生成</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">n_samples = 1500  # 生成1500个数据集</span><br><span class="line">random_state = 170  # 170这个是随机种子</span><br><span class="line">X, y = make_blobs(n_samples=n_samples, random_state=random_state)    # 生成数据集，包括1500个样本</span><br><span class="line">ages = np.vstack((X[y == 0][:500], X[y == 1][:500], X[y == 2][:500]))   # 将数据进行堆叠，shape为(1500, 2)</span><br><span class="line">y = np.array(([0] * 500 + [1] * 500 + [2] * 500))  #生成0 1 2 各500个</span><br></pre></td></tr></table></figure><h2 id="定义聚类中心："><a href="#定义聚类中心：" class="headerlink" title="定义聚类中心："></a>定义聚类中心：</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">k = <span class="number">3</span>  <span class="comment"># 超参数</span></span><br></pre></td></tr></table></figure><h2 id="随机种子"><a href="#随机种子" class="headerlink" title="随机种子"></a>随机种子</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(<span class="number">26</span>)    <span class="comment">#给numpy设置一个随机种子，保证每次都能产生相同的值</span></span><br></pre></td></tr></table></figure><h2 id="初始化："><a href="#初始化：" class="headerlink" title="初始化："></a>初始化：</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">centers = np.zeros([<span class="number">3</span>, <span class="number">2</span>])    <span class="comment"># 生成0矩阵</span></span><br><span class="line">centers_random = np.random.choice(<span class="built_in">range</span>(<span class="built_in">len</span>(y)), <span class="number">3</span>)  <span class="comment"># 迭代起点</span></span><br><span class="line">centers_new = ages[centers_random]   <span class="comment"># 随机选取中心</span></span><br><span class="line">dis_to_cent = np.zeros((k, <span class="built_in">len</span>(ages)))  <span class="comment"># 一个二维数据，相当于一个空的容器</span></span><br></pre></td></tr></table></figure><h2 id="进行聚类中心的判断："><a href="#进行聚类中心的判断：" class="headerlink" title="进行聚类中心的判断："></a>进行聚类中心的判断：</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> <span class="keyword">not</span> (centers_new == centers).<span class="built_in">all</span>():</span><br><span class="line">    centers = centers_new.copy()  <span class="comment"># 注意python的赋值过程，进行展开讲解，== is 和复制方式，这里是浅拷贝</span></span><br><span class="line">    <span class="keyword">for</span> ii <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">        dis_to_cent[ii] = np.linalg.norm(ages - centers[ii], axis=<span class="number">1</span>)    <span class="comment"># 计算每个数值到中心的距离</span></span><br><span class="line"></span><br><span class="line">    clusters = dis_to_cent.argmin(axis=<span class="number">0</span>)   <span class="comment"># 划分出每个类别</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> ii <span class="keyword">in</span> <span class="built_in">range</span>(k):   <span class="comment"># 重新计算中心</span></span><br><span class="line">        cluster = ages[clusters == ii]</span><br><span class="line">        centers_new[ii] = ages[clusters == ii].mean(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(centers, centers_new)</span><br><span class="line">    <span class="built_in">print</span>(centers_new)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;centers_new==centers?&#x27;</span>, (centers_new == centers).<span class="built_in">all</span>())</span><br><span class="line">    <span class="built_in">print</span>()</span><br></pre></td></tr></table></figure><h2 id="最后实现可视化的展示："><a href="#最后实现可视化的展示：" class="headerlink" title="最后实现可视化的展示："></a>最后实现可视化的展示：</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">**plt.figure(figsize=(<span class="number">8</span>, <span class="number">4</span>))   <span class="comment">#创建画布</span></span><br><span class="line">ax = plt.subplot(<span class="number">121</span>)  <span class="comment"># 几行，几列，第几个，先按行数</span></span><br><span class="line">ax.scatter(ages[:, <span class="number">0</span>], ages[:, <span class="number">1</span>], c=y)  <span class="comment"># x, y, 颜色，系统有基本的选择机制，不用写得太细</span></span><br><span class="line"></span><br><span class="line">ax.set_title(<span class="string">&#x27;数据本身的标签&#x27;</span>)</span><br><span class="line"></span><br><span class="line">ax = plt.subplot(<span class="number">122</span>)  <span class="comment"># 几行，几列，第几个，先按行数</span></span><br><span class="line">ax.scatter(ages[:, <span class="number">0</span>], ages[:, <span class="number">1</span>], c=clusters)  <span class="comment"># x, y, 颜色，系统有基本的选择机制，不用写得太细</span></span><br><span class="line"></span><br><span class="line">ax.set_title(<span class="string">&#x27;聚类的结果&#x27;</span>)**</span><br></pre></td></tr></table></figure><h2 id="可视化的结果："><a href="#可视化的结果：" class="headerlink" title="可视化的结果："></a>可视化的结果：</h2><p><img src="https://img-blog.csdnimg.cn/43e3ae4a0ea548ffb2550a154cfca28b.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> Kmeans </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>KNN实现鸢尾花数据集的可视化</title>
      <link href="/posts/38838.html"/>
      <url>/posts/38838.html</url>
      
        <content type="html"><![CDATA[<p>kNN实现鸢尾花可视化代码</p><span id="more"></span><h1 id="首先导入包："><a href="#首先导入包：" class="headerlink" title="首先导入包："></a>首先导入包：</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> ListedColormap</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br></pre></td></tr></table></figure><h1 id="获取数据："><a href="#获取数据：" class="headerlink" title="获取数据："></a>获取数据：</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">iris = load_iris()  <span class="comment"># 加载数据</span></span><br><span class="line">X = iris.data[:, (<span class="number">1</span>, <span class="number">3</span>)]  <span class="comment"># 为方便画图，仅采用数据的其中两个特征</span></span><br><span class="line">y = iris.target</span><br></pre></td></tr></table></figure><h1 id="设置画图的颜色深浅："><a href="#设置画图的颜色深浅：" class="headerlink" title="设置画图的颜色深浅："></a>设置画图的颜色深浅：</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cmap_light = ListedColormap([<span class="string">&#x27;#FFAAAA&#x27;</span>, <span class="string">&#x27;#AAFFAA&#x27;</span>, <span class="string">&#x27;#AAAAFF&#x27;</span>])</span><br><span class="line">cmap_bold = ListedColormap([<span class="string">&#x27;#FF0000&#x27;</span>, <span class="string">&#x27;#00FF00&#x27;</span>, <span class="string">&#x27;#0000FF&#x27;</span>]</span><br></pre></td></tr></table></figure><h1 id="决策边界，用不同的颜色表示："><a href="#决策边界，用不同的颜色表示：" class="headerlink" title="决策边界，用不同的颜色表示："></a>决策边界，用不同的颜色表示：</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x_min, x_max = X[:, <span class="number">0</span>].<span class="built_in">min</span>() - <span class="number">0.1</span>, X[:, <span class="number">0</span>].<span class="built_in">max</span>() + <span class="number">0.1</span></span><br><span class="line">y_min, y_max = X[:, <span class="number">1</span>].<span class="built_in">min</span>() - <span class="number">0.1</span>, X[:, <span class="number">1</span>].<span class="built_in">max</span>() + <span class="number">0.1</span></span><br><span class="line">xx, yy = np.meshgrid(np.arange(x_min, x_max, <span class="number">0.02</span>),</span><br><span class="line">                     np.arange(y_min, y_max, <span class="number">0.02</span>))</span><br></pre></td></tr></table></figure><h1 id="KNN原理："><a href="#KNN原理：" class="headerlink" title="KNN原理："></a>KNN原理：</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">knn_code</span>(<span class="params">loc, k=<span class="number">5</span>, order=<span class="number">2</span> </span>):  <span class="comment"># k order是超参</span></span><br><span class="line">    diff_loc = X - loc</span><br><span class="line">    dis_loc = np.linalg.norm(diff_loc, <span class="built_in">ord</span>=order, axis=<span class="number">1</span>) <span class="comment"># 没有axis得到一个数，矩阵的泛数。axis=0，得到两个数</span></span><br><span class="line">    knn = y[dis_loc.argsort()[:k]]</span><br><span class="line">    counts = np.bincount(knn)</span><br><span class="line">    <span class="keyword">return</span> np.argmax(counts</span><br></pre></td></tr></table></figure><h1 id="将数据合并："><a href="#将数据合并：" class="headerlink" title="将数据合并："></a>将数据合并：</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">line_loc = np.array(<span class="built_in">list</span>(<span class="built_in">zip</span>(xx.ravel(), yy.ravel())))</span><br></pre></td></tr></table></figure><h1 id="进行画图："><a href="#进行画图：" class="headerlink" title="进行画图："></a>进行画图：</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">15</span>, <span class="number">12</span>))  <span class="comment"># 图的尺寸</span></span><br><span class="line"></span><br><span class="line">pos = <span class="number">1</span>  <span class="comment"># 位置计数器</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> [<span class="number">2</span>, <span class="number">6</span>]:</span><br><span class="line">    <span class="keyword">for</span> order <span class="keyword">in</span> [<span class="number">1</span>, <span class="number">2</span>]:</span><br><span class="line"></span><br><span class="line">        Z = np.array([knn_code(ii, k, order) <span class="keyword">for</span> ii <span class="keyword">in</span> line_loc]).reshape(xx.shape)  <span class="comment"># 这个是不支持向量化运算的</span></span><br><span class="line">        ax = plt.subplot(<span class="number">220</span> + pos)  <span class="comment"># 几行，几列，第几个，先按行数</span></span><br><span class="line">        ax.pcolormesh(xx, yy, Z, cmap=cmap_light, shading=<span class="string">&#x27;auto&#x27;</span>)  <span class="comment"># 绘制预测结果图</span></span><br><span class="line">        ax.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=y, cmap=cmap_bold)  <span class="comment"># 补充训练数据点</span></span><br><span class="line">        ax.set_title(<span class="string">f&#x27;k: <span class="subst">&#123;k&#125;</span>, distance order: <span class="subst">&#123;order&#125;</span>&#x27;</span>)</span><br><span class="line">        pos += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">plt.suptitle(<span class="string">&#x27;I am a tuner!&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h1 id="可视化展示"><a href="#可视化展示" class="headerlink" title="可视化展示:"></a>可视化展示:</h1><p><img src="https://img-blog.csdnimg.cn/895a06844b024714835b82441349e3f4.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16" alt="可视化"></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> KNN可视化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>查找list中出现次数最多的元素</title>
      <link href="/posts/55034.html"/>
      <url>/posts/55034.html</url>
      
        <content type="html"><![CDATA[<p>用三种方法来查看列表中出现次数最多的元素</p><span id="more"></span><h1 id="·步骤一首先将元素存入词典"><a href="#·步骤一首先将元素存入词典" class="headerlink" title="·步骤一首先将元素存入词典"></a>·步骤一首先将元素存入词典</h1><h3 id="方法一"><a href="#方法一" class="headerlink" title="方法一"></a>方法一</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">data = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>]</span><br><span class="line">dic = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> data:</span><br><span class="line">    <span class="keyword">if</span> i <span class="keyword">in</span> dic.keys():</span><br><span class="line">        dic[i] += <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        dic[i] = <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(dic)</span><br></pre></td></tr></table></figure><h3 id="方法二："><a href="#方法二：" class="headerlink" title="方法二："></a>方法二：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 方法二 </span></span><br><span class="line">data = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>]</span><br><span class="line">dic = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> data:</span><br><span class="line">    i = <span class="built_in">str</span>(i)</span><br><span class="line">    dic[i] = dic.get(i, <span class="number">0</span>) + <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(dic)</span><br></pre></td></tr></table></figure><h3 id="方法三："><a href="#方法三：" class="headerlink" title="方法三："></a>方法三：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"></span><br><span class="line">data = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>]</span><br><span class="line">dic = Counter(data)</span><br></pre></td></tr></table></figure><h1 id="·步骤二：统计次数："><a href="#·步骤二：统计次数：" class="headerlink" title="·步骤二：统计次数："></a>·步骤二：统计次数：</h1><h3 id="方法一：argman函数"><a href="#方法一：argman函数" class="headerlink" title="方法一：argman函数"></a>方法一：argman函数</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"># 添加数据</span><br><span class="line">lis = []</span><br><span class="line">for i in dic:</span><br><span class="line">    lis.append(dic[i])</span><br><span class="line">    </span><br><span class="line">tem = np.array(lis)</span><br><span class="line">print(&quot;在列表中出现最多的那个数是：&quot;,list(dic.keys())[tem.argmax()])</span><br></pre></td></tr></table></figure><h3 id="方法二：argsort方法"><a href="#方法二：argsort方法" class="headerlink" title="方法二：argsort方法"></a>方法二：argsort方法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># 添加数据</span></span><br><span class="line">lis = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> dic:</span><br><span class="line">    lis.append(dic[i])</span><br><span class="line">    </span><br><span class="line">tem = np.array(lis)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;在列表中出现最多的那个数是：&quot;</span>,<span class="built_in">list</span>(dic.keys())[tem.argsort()[-<span class="number">1</span>]])</span><br></pre></td></tr></table></figure><h3 id="方法三：打擂台法"><a href="#方法三：打擂台法" class="headerlink" title="方法三：打擂台法"></a>方法三：打擂台法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">lis = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> dic:</span><br><span class="line">    lis.append(dic[i])</span><br><span class="line"></span><br><span class="line">diff = lis[<span class="number">0</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> lis:</span><br><span class="line">    <span class="keyword">if</span> i &gt; diff:</span><br><span class="line">        diff = i</span><br><span class="line">        inde = lis.index(i)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;在列表中出现最多的那个数是：&quot;</span>, <span class="built_in">list</span>(dic.keys())[inde])</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习算法-KNN</title>
      <link href="/posts/43912.html"/>
      <url>/posts/43912.html</url>
      
        <content type="html"><![CDATA[<p>根据knn的步骤写出knn的代码并画出决策边界</p><span id="more"></span><h1 id="·KNN算法的基本过程："><a href="#·KNN算法的基本过程：" class="headerlink" title="·KNN算法的基本过程："></a>·KNN算法的基本过程：</h1><p>1）计算测试数据与各个训练数据之间的距离<br>2）按照距离的递增关系进行排序</p><p>3）选取距离最小的K个点<br>4）确定前K个点所在类别的出现频率<br>5）返回前K个点中出现频率最高的类别作为测试数据的预测分类</p><h1 id="·算法的优缺点"><a href="#·算法的优缺点" class="headerlink" title="·算法的优缺点"></a>·算法的优缺点</h1><p>优点：精度高、对异常值不敏<br>缺点：计算复杂度高、空间复杂度高</p><p>基本实现流程：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入包</span></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据集</span></span><br><span class="line">iris = load_iris()</span><br><span class="line"><span class="comment"># 数据集的划分</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=<span class="number">666</span>, test_size=<span class="number">0.2</span>)</span><br><span class="line"><span class="comment"># 设置邻居数，即n_neighbors的大小</span></span><br><span class="line">knn = KNeighborsClassifier(n_neighbors=<span class="number">5</span>)</span><br><span class="line">knn.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line">y_pre = knn.predict(x_test)</span><br><span class="line"><span class="comment"># print(y_pre=y_test)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;准确率为：\n&quot;</span>, knn.score(x_test, y_pre))</span><br></pre></td></tr></table></figure><h1 id="·手撕KNN代码，刨析KNN原理"><a href="#·手撕KNN代码，刨析KNN原理" class="headerlink" title="·手撕KNN代码，刨析KNN原理"></a>·手撕KNN代码，刨析KNN原理</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> ListedColormap</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"></span><br><span class="line"><span class="comment"># %matplotlib inline</span></span><br><span class="line"></span><br><span class="line">iris = load_iris()  <span class="comment"># 加载数据</span></span><br><span class="line">X = iris.data[:, (<span class="number">1</span>, <span class="number">3</span>)]  <span class="comment"># 为方便画图，仅采用数据的其中两个特征</span></span><br><span class="line">y = iris.target</span><br><span class="line"></span><br><span class="line">cmap_light = ListedColormap([<span class="string">&#x27;#FFAAAA&#x27;</span>, <span class="string">&#x27;#AAFFAA&#x27;</span>, <span class="string">&#x27;#AAAAFF&#x27;</span>])</span><br><span class="line">cmap_bold = ListedColormap([<span class="string">&#x27;#FF0000&#x27;</span>, <span class="string">&#x27;#00FF00&#x27;</span>, <span class="string">&#x27;#0000FF&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 决策边界，用不同颜色表示</span></span><br><span class="line">x_min, x_max = X[:, <span class="number">0</span>].<span class="built_in">min</span>() - <span class="number">0.1</span>, X[:, <span class="number">0</span>].<span class="built_in">max</span>() + <span class="number">0.1</span></span><br><span class="line">y_min, y_max = X[:, <span class="number">1</span>].<span class="built_in">min</span>() - <span class="number">0.1</span>, X[:, <span class="number">1</span>].<span class="built_in">max</span>() + <span class="number">0.1</span></span><br><span class="line">xx, yy = np.meshgrid(np.arange(x_min, x_max, <span class="number">0.02</span>),</span><br><span class="line">                     np.arange(y_min, y_max, <span class="number">0.02</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">knn_code</span>(<span class="params">loc, k=<span class="number">5</span>, order=<span class="number">2</span> </span>):  <span class="comment"># k order是超参</span></span><br><span class="line">    <span class="comment"># print(order)</span></span><br><span class="line">    diff_loc = X - loc</span><br><span class="line">    dis_loc = np.linalg.norm(diff_loc, <span class="built_in">ord</span>=order, axis=<span class="number">1</span>) <span class="comment"># 没有axis得到一个数，矩阵的泛数。axis=0，得到两个数</span></span><br><span class="line">    knn = y[dis_loc.argsort()[:k]]</span><br><span class="line">    counts = np.bincount(knn)</span><br><span class="line">    <span class="keyword">return</span> np.argmax(counts)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">line_loc = np.array(<span class="built_in">list</span>(<span class="built_in">zip</span>(xx.ravel(), yy.ravel())))</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">15</span>, <span class="number">12</span>))  <span class="comment"># 图的尺寸</span></span><br><span class="line"></span><br><span class="line">pos = <span class="number">1</span>  <span class="comment"># 位置计数器</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> [<span class="number">2</span>, <span class="number">6</span>]:</span><br><span class="line">    <span class="keyword">for</span> order <span class="keyword">in</span> [<span class="number">1</span>, <span class="number">2</span>]:</span><br><span class="line">        Z = np.array([knn_code(ii, k, order) <span class="keyword">for</span> ii <span class="keyword">in</span> line_loc]).reshape(xx.shape)  <span class="comment"># 这个是不支持向量化运算的</span></span><br><span class="line">        ax = plt.subplot(<span class="number">220</span> + pos)  <span class="comment"># 几行，几列，第几个，先按行数</span></span><br><span class="line">        ax.pcolormesh(xx, yy, Z, cmap=cmap_light, shading=<span class="string">&#x27;auto&#x27;</span>)  <span class="comment"># 绘制预测结果图</span></span><br><span class="line">        ax.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=y, cmap=cmap_bold)  <span class="comment"># 补充训练数据点</span></span><br><span class="line">        ax.set_title(<span class="string">f&#x27;k: <span class="subst">&#123;k&#125;</span>, distance order: <span class="subst">&#123;order&#125;</span>&#x27;</span>)</span><br><span class="line">        pos += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">plt.suptitle(<span class="string">&#x27;I am a tuner!&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>KNN实现鸢尾花可视化<img src="https://img-blog.csdnimg.cn/0e791c3af82341aa966760e72856e78c.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center"></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> KNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习算法-Logistic Regressi</title>
      <link href="/posts/62659.html"/>
      <url>/posts/62659.html</url>
      
        <content type="html"><![CDATA[<p>逻辑回归并不是一个回归算法，它是一个分类算法；通过拟合一个逻辑函数来预测一个离散型因变量的值（预测一个概率值，基于0与1）</p><span id="more"></span><h1 id="·逻辑回归"><a href="#·逻辑回归" class="headerlink" title="·逻辑回归"></a>·逻辑回归</h1><ul><li>与线性回归不同的是，逻辑回归并不是一个回归算法，它是一个分类算法；通过拟合一个逻辑函数来预测一个离散型因变量的值（预测一个概率值，基于0与1），来描述自变量对因变量的影响程度。</li></ul><p>自变量可以有一个，也可以有多个。其中，一个自变量被称为一元逻辑回归，而多个自变量被称为多元逻辑回归。以实例而言，逻辑回归可以预测一封邮件是垃圾邮件的概率是多少。同时，因为结果是概率值，它同样可以对点击率等结果做排名模型预测</p><ul><li>基本代码实现：</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># 关于逻辑回</span><br></pre></td></tr></table></figure><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//# 首先导入包：</span></span><br><span class="line"><span class="keyword">from</span> sklearn.<span class="property">datasets</span> <span class="keyword">import</span> load_iris</span><br><span class="line"></span><br><span class="line">iris = <span class="title function_">load_iris</span>()</span><br><span class="line"></span><br><span class="line"># 前两列数据（花萼长度与宽度）进行回归分类</span><br><span class="line">X = iris.<span class="property">data</span>[:, :<span class="number">2</span>]</span><br><span class="line">Y = iris.<span class="property">target</span></span><br><span class="line"></span><br><span class="line"># 分割数据集：</span><br><span class="line"><span class="keyword">from</span> sklearn.<span class="property">model_selection</span> <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">x_train, x_test, y_train, y_test = <span class="title function_">train_test_split</span>(X, Y, random_state=<span class="number">66</span>, test_size=<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line"># 导入模型， 调佣逻辑回归函数<span class="title class_">LogisticRegrssion</span>()函数</span><br><span class="line"><span class="keyword">from</span> sklearn.<span class="property">linear_model</span> <span class="keyword">import</span> <span class="title class_">LogisticRegression</span></span><br><span class="line"></span><br><span class="line"># 训练模型</span><br><span class="line">lr = <span class="title class_">LogisticRegression</span>(penalty=<span class="string">&quot;l2&quot;</span>, solver=<span class="string">&#x27;newton-cg&#x27;</span>, multi_class=<span class="string">&#x27;multinomial&#x27;</span>)</span><br><span class="line">lr.<span class="title function_">fit</span>(x_train, y_train)</span><br><span class="line"># 关于模型的参数：</span><br><span class="line"># penalty：正则化选择参数，默认方式为 <span class="variable constant_">L2</span> 正则化</span><br><span class="line"># solver：优化算法选择参数，有&#123;‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’&#125;四种参数，如果你是用的是 <span class="variable constant_">L1</span> 正则化，则只能使用 libinear，这是因为 <span class="variable constant_">L1</span> 正则化并不是一个连续可导的损失函数。</span><br><span class="line"># muti_class：分类方式选择参数，包括&#123;‘ovr’, ‘multinomial’&#125;两种参数。简单来说，<span class="title class_">OvR</span> 相对简单，但分类效果相对略差（这里指大多数样本分布情况，某些样本分布下 <span class="title class_">OvR</span> 可能更好）。而 <span class="title class_">MvM</span> 分类相对精确，但是分类速度没有 <span class="title class_">OvR</span> 快。</span><br><span class="line"></span><br><span class="line"># 预测数据</span><br><span class="line">y_pre = lr.<span class="title function_">predict</span>(x_test)</span><br><span class="line"></span><br><span class="line"># 准确率的评估</span><br><span class="line"><span class="title function_">print</span>(<span class="string">&quot;逻辑回归训练集数据的准确率为\n&quot;</span>, lr.<span class="title function_">score</span>(x_train, y_train))</span><br><span class="line"><span class="title function_">print</span>(<span class="string">&quot;逻辑回归测试集数据的准确率为\n&quot;</span>, lr.<span class="title function_">score</span>(x_test, y_test))</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line">accuracy = metrics.<span class="title function_">accuracy_score</span>(y_pre, y_test)</span><br><span class="line"><span class="title function_">print</span>(<span class="string">&#x27;逻辑回归模型准确率：%.3f&#x27;</span>% accuracy)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>公众号：欢迎转发和关注本公众号，经常分享一些基础的学习知识。欢迎关注！！！</p><p><img src="https://img-blog.csdnimg.cn/b45ed81227604d569a2ca4f50cfee1aa.jpg?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP55qu6bq76Iqx,size_20,color_FFFFFF,t_70,g_se,x_16" alt="请添加图片描述"></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 逻辑回归 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>什么是机器学习？</title>
      <link href="/posts/53265.html"/>
      <url>/posts/53265.html</url>
      
        <content type="html"><![CDATA[<p>对机器学习的初步理解</p><span id="more"></span><h3 id="什么是机器学习？"><a href="#什么是机器学习？" class="headerlink" title="什么是机器学习？"></a>什么是机器学习？</h3><p>;官方解释：<br>&amp;emsp;&amp;emsp;·机器学习就是从“数据”中自动分析获得规律，利用规律对未知的数据进行预测。<br>        - 模型：算法模型，是一个特殊的对象，该算法模型对象中已经集成了或封装好了某种形式的算法&#x2F;方程（还没有求出解）<br>    - 模型的作用：<br>      &amp;emsp;&amp;emsp;  - 预测：可以通过方程或者算法产生一个新的位置的数据&#x2F;事物<br>   &amp;emsp;&amp;emsp;     - 分类：可以将一个未知归类的事物给其归属到一个已有的类群中<br>   &amp;emsp;&amp;emsp;     - 注意：算法模型对应的算法或者方程求出的解就是预测或者分类的结果<br>    - 样本数据：<br>  &amp;emsp;&amp;emsp;      - 模型的训练，将样本数据带入到模型中，对其进行训练（给方程进行求解），模型训练好了后，则模型方程就有唯一解或者最优解。有解后则模型就可以实现分类或者预测功能<br>        - 构成：<br>         &amp;emsp;&amp;emsp;   - 特征数据：自变量<br>        &amp;emsp;&amp;emsp;    - 标签&#x2F;目标数据：因变量<br>    - 模型的分类：<br>       &amp;emsp;&amp;emsp; - 有监督学习<br>         &amp;emsp;&amp;emsp;   - 如果模型需要的样本数据必须包含特征数据和标签数据，则该模型为有监督学习分类<br>        - 无监督学习<br>            &amp;emsp;&amp;emsp;- 模型样本只需要要特征数据即可，目标数据有或者无都可以<br>    - 数据集的获取途径：<br>     &amp;emsp;&amp;emsp;   - kaggle：数据竞赛平台<br>     &amp;emsp;&amp;emsp;   - UCI数据集<br>      &amp;emsp;&amp;emsp;  - sklearn<br>机器学习工作流程：<br>&amp;emsp;&amp;emsp;    ·获取数据<br>&amp;emsp;&amp;emsp;    ·数据基本处理<br>  &amp;emsp;&amp;emsp;  ·特征工程<br>  &amp;emsp;&amp;emsp;  ·机器学习<br> &amp;emsp;&amp;emsp;   ·模型评估<br>特征工程：<br>  &amp;emsp;&amp;emsp;  ·定义：把数据转换为机器更容易识别的数据<br>&amp;emsp;&amp;emsp;    ·特征抽取<br> &amp;emsp;&amp;emsp;   ·数据特征预处理–特征降维<br>&amp;emsp;&amp;emsp;    ·选择特征<br>    ·为什么需要特征工程？<br>      &amp;emsp;&amp;emsp;  - 样本数据中的特征工程可能会存在缺失值，异常值等等，那么我们是需要对特征工程中的相关的噪点进行数据处理的，那么处理的目的就是为了营造出一个更纯净的样本，让模型基于这个数组可以有更好的预测能力，当然特征工程不是单单只是处理上述操作。<br>    特征工程的意义：<br>       &amp;emsp;&amp;emsp; ·直接影响模型预测的结果<br>    如何实现特征工程？<br>      &amp;emsp;&amp;emsp;  ·工具：sk-learn</p><h3 id="sklearn介绍："><a href="#sklearn介绍：" class="headerlink" title="sklearn介绍："></a>sklearn介绍：</h3><p>   &amp;emsp;&amp;emsp; - 是python语言中机器学习的工具，包含了许多知名的机器学习算法的实现，其文档完善，容易上手。</p><p>  &amp;emsp;&amp;emsp;      - 功能：<br>      &amp;emsp;&amp;emsp;    &amp;emsp;&amp;emsp;  ·分类模型<br>     &amp;emsp;&amp;emsp;      &amp;emsp;&amp;emsp; ·回归模型<br>       &amp;emsp;&amp;emsp;   &amp;emsp;&amp;emsp;  ·聚类模型<br>       &amp;emsp;&amp;emsp;    &amp;emsp;&amp;emsp; ·特征工程<br>·特征抽取目的：<br>     &amp;emsp;&amp;emsp;    ·我们所采集到样本中的特征往往是字符串或者其他类型的数据，而我们知道电脑只能识别二进制数值型的数据，如果把字符串给电脑，电脑是看不懂的。<br>·机器学习算法分类：<br>   &amp;emsp;&amp;emsp;      ·监督学习<br>   &amp;emsp;&amp;emsp;      ·无监督学习<br>    &amp;emsp;&amp;emsp;     ·半监督学习<br>    &amp;emsp;&amp;emsp;     ·强化学习<br>    ·监督学习：输入的数据由目标值和特征值组成<br>     &amp;emsp;&amp;emsp;  &amp;emsp;&amp;emsp;   ·回归：函数的输入可以是一个连续的值<br>    &amp;emsp;&amp;emsp;   &amp;emsp;&amp;emsp;   ·分类：输出是有限个离散值<br>    ·半监督学习：有特征值，但是一部分数据有目标值，一部分没有<br>    ·无监督学习：仅有特征值<br>    ·强化学习：agent  action  environment  rewaed<br>·模型评估：<br>    ·分类模型评估<br>        &amp;emsp;&amp;emsp; ·准确率：<br>            &amp;emsp;&amp;emsp; &amp;emsp;&amp;emsp; ·预测正确的数占样本总数的比例<br>     &amp;emsp;&amp;emsp;    ·精确率<br>            &amp;emsp;&amp;emsp; &amp;emsp;&amp;emsp; ·正确预测为正确占全部预测为正的比例<br>      &amp;emsp;&amp;emsp;   ·召回率<br>           &amp;emsp;&amp;emsp; &amp;emsp;&amp;emsp;  ·正确预测为正占全部样本的比例<br>      &amp;emsp;&amp;emsp;   ·F1-score<br>           &amp;emsp;&amp;emsp; &amp;emsp;&amp;emsp;  ·主要用于评估模型的稳健性<br>        &amp;emsp;&amp;emsp; ·AUC指标<br>            &amp;emsp;&amp;emsp; &amp;emsp;&amp;emsp; ·主要用于评估样本不均衡的情况<br>    ·回归模型评估<br>      &amp;emsp;&amp;emsp;   均方根误差<br>      &amp;emsp;&amp;emsp;   相对平方误差<br>    &amp;emsp;&amp;emsp;     平均结对误差<br>     &amp;emsp;&amp;emsp;    相对绝对误差<br>    &amp;emsp;&amp;emsp;     决定系数<br>    ·拟合：<br>     &amp;emsp;&amp;emsp;    欠拟合：机器学习的特征太少了，区分标准粗糙，不能准确识别<br>     &amp;emsp;&amp;emsp;    过拟合：机器学习的特征太多了，验证数据及其测试数据中表现不佳</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 逻辑回归 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pandas基础</title>
      <link href="/posts/41256.html"/>
      <url>/posts/41256.html</url>
      
        <content type="html"><![CDATA[<p>DataFrame是一个表格型的数据结构，它含有一组 有序 的列，每列可以是不同的值类型</p><span id="more"></span><p>DataFrame介绍：</p><p>DataFrame是一个表格型的数据结构，它含有一组 有序 的列，每列可以是不同的值类型（数值、字符串、布尔值等）。</p><p>导入包：</p><p><img src="https://img-blog.csdnimg.cn/20210502192544593.png" alt="在这里插入图片描述"></p><p>  1.将字典转化为DataFrame</p><p>  定义字典：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data = &#123;<span class="string">&quot;grammer&quot;</span>:[<span class="string">&quot;Python&quot;</span>,<span class="string">&quot;C&quot;</span>,<span class="string">&quot;Java&quot;</span>,<span class="string">&quot;GO&quot;</span>,np.nan,<span class="string">&quot;SQL&quot;</span>,<span class="string">&quot;PHP&quot;</span>,<span class="string">&quot;Python&quot;</span>],</span><br><span class="line">       <span class="string">&quot;score&quot;</span>:[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">10</span>]&#125;</span><br></pre></td></tr></table></figure><p>   将字典转化为DataFrame：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df = pd.DataFrame(data)</span><br></pre></td></tr></table></figure><pre><code>得到：</code></pre><p> <img src="https://img-blog.csdnimg.cn/20210502192739302.png" alt="在这里插入图片描述"></p><p>2.提取含有字符串“Python”行：</p><p>方法一：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">df[df[<span class="string">&#x27;grammer&#x27;</span>] == <span class="string">&#x27;Python&#x27;</span>]</span><br></pre></td></tr></table></figure><p>方法二：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">results = df[<span class="string">&#x27;grammer&#x27;</span>].<span class="built_in">str</span>.contains(<span class="string">&quot;Python&quot;</span>)</span><br><span class="line">results.fillna(value=<span class="literal">False</span>,inplace = <span class="literal">True</span>)</span><br><span class="line">df[results]</span><br></pre></td></tr></table></figure><p>得到的结果：<br><img src="https://img-blog.csdnimg.cn/20210502192812667.png" alt="在这里插入图片描述"></p><p>3.输出列名：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(df.columns)</span><br></pre></td></tr></table></figure><p>得到的结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Out[<span class="number">28</span>]: Index([<span class="string">&#x27;grammer&#x27;</span>, <span class="string">&#x27;score&#x27;</span>], dtype=<span class="string">&#x27;object&#x27;</span>)</span><br></pre></td></tr></table></figure><p>4.将第二列改成“popularity”:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">df.rename(columns = &#123;<span class="string">&#x27;score&#x27;</span>:<span class="string">&#x27;popularity&#x27;</span>&#125;, inplace = <span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>输出df：</p><p><img src="https://img-blog.csdnimg.cn/20210502192842315.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl81MTc1NjEwNA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p>5.统计grammer每一列中编程语言出现的次数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">&#x27;grammer&#x27;</span>].value_counts()</span><br></pre></td></tr></table></figure><p>结果：</p><p><img src="https://img-blog.csdnimg.cn/20210502192858266.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl81MTc1NjEwNA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p>6.提取popularity中大于三的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[df[<span class="string">&#x27;score&#x27;</span>]&gt;<span class="number">3</span>]</span><br></pre></td></tr></table></figure><p>结果：</p><p><img src="https://img-blog.csdnimg.cn/20210502192910111.png" alt="在这里插入图片描述"></p><p>7.按照grammer列进行去除重复值：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">df.drop_duplicates([<span class="string">&#x27;grammer&#x27;</span>])</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/20210502192948980.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl81MTc1NjEwNA==,size_16,color_FFFFFF,t_70" alt="图片"></p><p>8.计算popularity列的平均值：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">&#x27;score&#x27;</span>].mean()</span><br></pre></td></tr></table></figure><p>9.将grammer列转化为list：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">df[<span class="string">&#x27;grammer&#x27;</span>].tolist()</span><br></pre></td></tr></table></figure><p>10.将DataFrame保存为csv</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.to_csv(<span class="string">&quot;text.csv&quot;</span>)</span><br></pre></td></tr></table></figure><p>结果得到了一个csv文件：</p><p><img src="https://img-blog.csdnimg.cn/20210502192956593.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl81MTc1NjEwNA==,size_16,color_FFFFFF,t_70" alt="图片"></p><p><a href="https://www.heywhale.com/mw/project/6047189c89c874001524f6c9?token=43ba0f12bfd74662">task来源于和鲸训练营</a></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 数据处理 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
