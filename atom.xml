<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>江东的笔记</title>
  
  <subtitle>Be overcome difficulties is victory</subtitle>
  <link href="https://du2279664786.github.io/atom.xml" rel="self"/>
  
  <link href="https://du2279664786.github.io/"/>
  <updated>2022-12-15T03:42:30.683Z</updated>
  <id>https://du2279664786.github.io/</id>
  
  <author>
    <name>江东</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>机器视觉期末-第18章</title>
    <link href="https://du2279664786.github.io/posts/d7e527bc.html"/>
    <id>https://du2279664786.github.io/posts/d7e527bc.html</id>
    <published>2022-12-15T14:55:10.000Z</published>
    <updated>2022-12-15T03:42:30.683Z</updated>
    
    <content type="html"><![CDATA[<p>机器视觉期末知识点整理</p><span id="more"></span><h1 id="机器视觉期末知识点整理"><a href="#机器视觉期末知识点整理" class="headerlink" title="机器视觉期末知识点整理"></a>机器视觉期末知识点整理</h1><h2 id="第18章-通用图像处理系统ImageSys"><a href="#第18章-通用图像处理系统ImageSys" class="headerlink" title="第18章　通用图像处理系统ImageSys"></a>第18章　通用图像处理系统ImageSys</h2><h3 id="一．总体功能介绍"><a href="#一．总体功能介绍" class="headerlink" title="一．总体功能介绍"></a>一．总体功能介绍</h3><pre><code>    图像信息处理是当今信息时代的重要组成部分，现在几乎所有专业都在研究和利用图像信息技术。    lmageSys是一部大型通用图像处理系统，它是图像信息研究和教学的重要工具,在大学和研究开发机构有着广阔的应用前景。主要内容包括图像/多媒体文件操作、图像捕捉、图像数据分析、颜色测量、颜色变换、几何变换、频率域变换、图像间变换、图像滤波、图像分割、2值图像运算、参数测量与统计、图像编辑、多媒体播放等，汇聚了现代图像处理技术的绝大多数功能，而且伴随这些功能给用户提供了大量可利用的函数。研究者可以用本系统提供的功能简单地进行各种试验，快速找到最佳方案，用提供的函数简单地编出自己的处理程序。在实际应用上，ImageSys 也可以代替使用者自动测量多种数学统计数据，可以利用提供的函数组合各种功能用于机器人的视觉判断。ImageSys还给用户提供了一个框架源程序，用户可以简单地在框架程序上追加自己的程序。</code></pre><h3 id="二-ImageSys的4大特点"><a href="#二-ImageSys的4大特点" class="headerlink" title="二. ImageSys的4大特点"></a>二. ImageSys的4大特点</h3><pre><code>    1.兼容国际标准的 IEEE1394接口和USB接口以及专用图像采集卡的图像采集。可使用的摄像装置包括数码、模拟、民用、工业、一般速率和高速等各种摄像机。    2．可处理目前流行的大多数图像/多媒体文件格式，包括BMP、JPG、JPEG、TIF、TIFF、GIF、TXT、AVI、DAT、MPG、MPEG、MOV、vOB等。    3.大量的特征参数测量与统计功能。    4.具有开发平台功能的源程序以及多功能函数库。</code></pre><h3 id="三-ImageSys的具体各种功能介绍"><a href="#三-ImageSys的具体各种功能介绍" class="headerlink" title="三.ImageSys的具体各种功能介绍"></a>三.ImageSys的具体各种功能介绍</h3><p>1静动两用的图像文件操作:</p><p>可读入和保存单幅图像文件（bmp、jpg、jpeg、tif、tiff、gif、txt等30多种文件格式);也可读入和保存连续图像文件，产生动态效果。可读入多媒体图像文件(avi、dat、mpg、mpeg、mov、vob等绝大多数流行的文件格式）和保存视频图像文件，保存时可以选择MPEG4等多种压缩格式，能从多媒体文件中取出某段或某幅图像。各种文件之间可以自由变换。彩色图像文件可以变换成灰度图像读入和保存。附带有多媒体文件播放器功能。</p><p>2完美的表示功能:</p><p>图像表示:彩色图像表示，彩色图像的R、G、B各个单色分量表示;彩色图像的H、S、l各个单色分量表示;灰度图像表示，灰度图像的伪彩色表示;图像的透视、自由放大和缩小表示;可以表示静态图像和动态图像，动态图像表示时可以设定表示速度。</p><p>像素值表示:鼠标周围像素值的自动表示，区域像素分布直方图表示，区域像素的立体分布图表示，鼠标所画直线上像素值的分布图表示，区域像素的纵向和横向累加值分布图表示。各种分布图都给出平均值、最大值、最小值、标准偏差等参数，分布图能够被打印、复制、数据文件保存等。<br>图像变换、参数测量的图像表示:仿射变换、透视变换、HSI变换、亮度变换、图像分割、细线化…等都可以预览处理结果，判断后再处理;2值图像自动测量、手动测量、圆形分离等结果可在图像上表示。<br>频率域表示:小波变换的高频、低频表示;傅立叶变换的频率表示、环特性分布表示、楔特性分布表示。<br>频数分布表示:2值图像自动测量、圆形分离等结果的频数分布表示。<br>数据文件表示:所有的分布图数据、测量数据都可以以数据文件的形式表示、保存、读取和打印。</p><p>3丰富的图像变换功能:</p><p>仿射变换:包括平移、旋转、膨胀、收缩等。<br>透视变换:包括扩大率、回转度、视点位置、屏幕位置等。HSI变换:包括基准色选择、HSI及各分量图像、色差图像。<br>自由变换:包括移动、90度旋转、亮度轮廓线、马赛克、窗口涂抹、积分平均等。<br>小波变换:可以进行行、列的单向和双向的多级变换，可以去掉任意频率成分后</p><p>进行图像恢复，可以进行基于小波变换的图像放大。<br>傅立叶变换:可以进行傅立叶变换和逆变换，可以选择多种通用滤波模式，可以用画笔自由设定滤波模式，可以查看环特征和锲特征的频数分布图谱。</p><p>颜色亮度变换:包括像素提取、像素范围移动、N值化、Log变换、y变换、动态范围变换、用户自定义、反色、直方图平滑化等。<br>图像间变换:包括图像间的算术运算（加、减、乘、除）和逻辑运算(AND, OR,XOR,XNOR）。可以两幅图像间运算，也可以多幅图像间同时运算。<br>动态图像校正:通过把动态图像的每一幅分解为奇数场和偶数场，得到两幅图像，修正动态图像因场交叉而产生的模糊。</p><p>4多种滤波增强功能:<br>通过对图像施加某种滤波运算，达到增强图像的某些特征或改善画质的目的。可选择的滤波器类型有:简单均值，加权均值，4方向锐化，4方向增强，8方向锐化，8方向增强，平滑增强，中值，排序，用户自定义等。滤波器的尺寸可选择:3x 3,5x 5,7 x7,9x9像素。<br>5直观灵活的2值化处理功能:<br>在图像处理中,往往需要通过2值化处理(图像分割）的手段提取某些特征，以便判断或参数测量。本系统可以自由直观地设定2值化的阈值，灰度图像可以实行自动2值化处理，彩色图像可以通过鼠标点击的方式自动提取图像的某一部分。</p><p>6多功能的2值运算功能:<br>2值化处理后的图像，一般具有许多不尽人意的地方，在进行参数测量前往往需要进行各种加工。<br>基本运算:去噪声，补洞，膨胀，收缩，排它膨胀，细线化，去毛刺，清除窗口。特殊提取:提取满足条件的像素。可同时设定4个项目，逻辑关系可选AND或OR。可选的条件项目有面积、周长、周长&#x2F;面积、面积比、圆形度…等26项。<br>7庞大的参数测量统计功能:颜色测量:根据R、G、B的亮度值以及国际照明委员会（CIE）倡导的[XYZ颜色空间]、[HSI颜色空间]、[L<em>a</em>b*颜色空间]、[uCS颜色空间]的坐标计算、测量色差等等。<br>2值图像参数的自动测量:自动测量各个区域（物体）的参数，标定测量序号，可设定比例尺，测量结果可以</p><p>文字表示、频数分布表示。可供选择的测量项目有49项:物体的面积，周长，周长2，孔洞数，孔洞面积，总面积，面积比，周长&#x2F;面积，NCI比（周长除总面积的平方根），圆形度，等价圆直径，球体体积，圆的形状系数，线段长度，重心横坐标，重心纵坐标，水平投影径，垂直投影存,投影径角，占有率，最大径，最大径端点x1，最大径端点y1，最大径端点x2，最大径端点y2，最大径角，直径的形状系数，长径，短径，长径角，水平投影径始点横坐标,水平投影径终点横坐标,垂直投影径始点纵坐标，垂直投影径终点纵坐标，图形始点×座标,图形始y座标,椭圆长轴，椭圆短轴，椭圆方向角，椭圆长短轴比，椭圆体体积，椭圆形状系数，О阶矩，1阶矩X，1阶矩Y，2阶矩×，2阶矩Y，惯性矩，极惯性矩，等等。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;机器视觉期末知识点整理&lt;/p&gt;</summary>
    
    
    
    <category term="机器视觉" scheme="https://du2279664786.github.io/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    
    <category term="机器视觉" scheme="https://du2279664786.github.io/tags/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    <category term="期末考试" scheme="https://du2279664786.github.io/tags/%E6%9C%9F%E6%9C%AB%E8%80%83%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>第3章 图像处理</title>
    <link href="https://du2279664786.github.io/posts/1f485563.html"/>
    <id>https://du2279664786.github.io/posts/1f485563.html</id>
    <published>2022-12-15T14:55:10.000Z</published>
    <updated>2022-12-15T08:37:29.188Z</updated>
    
    <content type="html"><![CDATA[<p>机器视觉期末复习的整理 第3章 图像处理</p><span id="more"></span><h1 id="第三章-图像处理"><a href="#第三章-图像处理" class="headerlink" title="第三章 图像处理"></a>第三章 图像处理</h1><h2 id="1-数字图像的计算机表述"><a href="#1-数字图像的计算机表述" class="headerlink" title="1. 数字图像的计算机表述"></a>1. 数字图像的计算机表述</h2><p> 图中显示了局部放大后的图像，放大后可以看见图中的各个小方块即为像素。<br><img src="https://img-blog.csdnimg.cn/15fd17fdd10341bf828be22c6a947deb.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/17a52477ccf14d648f1b15677c39e9a3.png" alt="在这里插入图片描述"></p><h2 id="2-常用图像处理算法及其通用性问题"><a href="#2-常用图像处理算法及其通用性问题" class="headerlink" title="2.常用图像处理算法及其通用性问题"></a>2.常用图像处理算法及其通用性问题</h2><p>图像处理的基本算法包括：图像增强、去噪声处理、图像分割、边缘检测、特征提取、几何变换等；经典算法有：Hough（哈夫）变换、傅里叶变换（FFT）、小波（wavelet）变换、模式识别、神经网络、遗传算法等。<br>图像处理最大的难点在于，没有任何一种算法能够独立完成千差万别的图像处理，针对不同的处理对象，需要对多种图像处理算法进行组合和修改。不同的处理对象和环境，图像处理的难点不同。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;机器视觉期末复习的整理 第3章 图像处理&lt;/p&gt;</summary>
    
    
    
    <category term="机器视觉" scheme="https://du2279664786.github.io/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    
    <category term="机器视觉" scheme="https://du2279664786.github.io/tags/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    <category term="期末考试" scheme="https://du2279664786.github.io/tags/%E6%9C%9F%E6%9C%AB%E8%80%83%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>第5章 图像平滑处理</title>
    <link href="https://du2279664786.github.io/posts/ed305aa6.html"/>
    <id>https://du2279664786.github.io/posts/ed305aa6.html</id>
    <published>2022-12-15T14:55:10.000Z</published>
    <updated>2022-12-15T08:37:29.194Z</updated>
    
    <content type="html"><![CDATA[<p>机器视觉期末复习的整理 第5章 图像平滑处理</p><span id="more"></span><h1 id="机器视觉期末复习的整理"><a href="#机器视觉期末复习的整理" class="headerlink" title="机器视觉期末复习的整理"></a>机器视觉期末复习的整理</h1><h2 id="图像平滑"><a href="#图像平滑" class="headerlink" title="图像平滑"></a>图像平滑</h2><h3 id="1-图像增强"><a href="#1-图像增强" class="headerlink" title="1.图像增强"></a>1.图像增强</h3><p>图像增强是对图像进行处理，使其比原始图像更适合于特定的应用，它需要与实际应用相结合.对于图像的某些特征如边缘、轮廓、对比度等，图像增强是进行强调或锐化，以便于显示、观察或进一步分析与处理。图像增强的方法是因应用不同而不同的，研究内容包括: (参考课件和左飞的《数字图像处理》)<br><img src="https://img-blog.csdnimg.cn/4e95f876b62c4a209f127fc61d0bc736.png" alt="在这里插入图片描述"></p><h3 id="2-图像平滑"><a href="#2-图像平滑" class="headerlink" title="2.图像平滑"></a>2.图像平滑</h3><p>图像平滑是一种区域增强的算法，平滑算法有邻域平均法、中指滤波、边界保持类滤波等.在<br>图像产生、传输和复制过程中，常常会因为多方面原因而被噪声干扰或出现数据丢失，降低了<br>像的质量(某- -像素，如果它与周围像素点相比有明显的不同，则该点被噪声所感染)。这就需要对图像进行一定的增强处理以减小这 些缺陷带来的影响。</p><p>简单平滑-邻域平均法</p><h3 id="3-邻域平均法"><a href="#3-邻域平均法" class="headerlink" title="3.邻域平均法"></a>3.邻域平均法</h3><p>图像简单平滑是指通过邻域简单平均对图像进行平滑处理的方法，用这种方法在一定程度上消除原始图像中的噪声、降低原始图像对比度的作用.它利用卷积运算对图像邻域的像素灰度进行平均，从而达到减小图像中噪声影响、降低图像对比度的目的.但邻域平均值主要缺点是在降低噪声的同时使图像变得模糊，特别在边缘和细节处，而且邻域越大，在去噪能力增强的同时模糊程度越严重.</p><p><img src="https://img-blog.csdnimg.cn/bac3f71c3dfc4d9a87a883daa41d7f7c.png" alt="[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-qGJOFKDV-1671088442726)(C:\Users\xiaopi\AppData\Roaming\Typora\typora-user-images\1671083701723.png)]"><br><img src="https://img-blog.csdnimg.cn/b73e4dbcabaa44d1a2e74b6b7000c5f2.png" alt="在这里插入图片描述"></p><h2 id="均值滤波"><a href="#均值滤波" class="headerlink" title="均值滤波"></a>均值滤波</h2><h3 id="1-原理"><a href="#1-原理" class="headerlink" title="1.原理"></a>1.原理</h3><p>均值滤波是指任意一点的像素值，都是周围N<em>M个像素值的均值.例如下图中，红色点的像素<br>值为蓝色背景区域像素值之和除25.<br><img src="https://img-blog.csdnimg.cn/a1d85a49aa6f4e33804814c13a676f12.png" alt="在这里插入图片描述"><br>其中红色区域的像素值均值滤波处理过程为：(197+25+106+156+159)+(149+40+107+5+71)+(163+198+<em>226</em></em>+223+156)+(222+37+68+193+157)+(42+72+250+41+75)&#x2F;25<br>其中5*5的矩阵称为核，针对原始图像内的像素点，采用核进行处理，得到结果图像.<br><img src="https://img-blog.csdnimg.cn/07a7e7c6fe1843e3a1aef811235c0170.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/3c22d5ffa8394f7d8e02026885545051.png" alt="在这里插入图片描述"></p><h3 id="2-代码"><a href="#2-代码" class="headerlink" title="2.代码"></a>2.代码</h3><p>PythonOpenCV调用实现均值滤波的核心函数如下：<br>result&#x3D;cv2.blur(原始图像，和大小)<br>其中，核大小是以(宽度，高度)表示的元祖形式.常见的形式包括:核大小(3，3)和(5，5)。<br><img src="https://img-blog.csdnimg.cn/55b93a313b5d4ec3adeb8f61fc98c7f8.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/e0b133bcaa23484f99916efedf324f07.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/edcf0b84e0d2478599d801f2e6c0e537.png" alt="在这里插入图片描述"></p><h2 id="中值滤波"><a href="#中值滤波" class="headerlink" title="中值滤波"></a>中值滤波</h2><h3 id="1-概念"><a href="#1-概念" class="headerlink" title="1.概念"></a>1.概念</h3><p>在使用邻域平均法去噪的同时也使得边界变得模糊.而中值滤波是非线性的图像处理方法，在去噪的时可以兼顾到边界信息的保留.选一个含有奇数点的窗口W，将这个窗口在图像上扫描，把窗口中所含的像素点按灰度级的升或降序排列，取位于中间的灰度值来代替该点的灰度值.例如选择滤波的窗口如下图，是一个–维的窗口，待处理像素的灰度取这个模板中灰度的中值，滤波过程如下：<img src="https://img-blog.csdnimg.cn/8f5d39376eb842559ba823c12eeba636.png"><br>如下图所示，将临近像素按照大小排列，取排序像素中位于中间位置的值作为中值滤波的像素值.</p><h3 id="2-代码-1"><a href="#2-代码-1" class="headerlink" title="2.代码"></a>2.代码</h3><p>主要调用medianBlur()函数实现中值滤波。图像平滑里中值滤波的效果好.dst&#x3D;cv2.medianBlur(src，ksize)其中，src表示源文件，ksize表示核大小.核必须是大于1的奇数，如3、5、7等.<br><img src="https://img-blog.csdnimg.cn/f9452d58ac86435a9840ab2c35ec0319.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/ad97f271a27e4ad980b301f933333cf4.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/d3dfb9290b3945349c21c670a1be07de.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/c7122fc401ec4b69b02917895ab5f7bb.png" alt="在这里插入图片描述"></p><h2 id="高斯滤波"><a href="#高斯滤波" class="headerlink" title="高斯滤波"></a>高斯滤波</h2><p>1.概念</p><p>为了克服简单局部平均法的弊端(图像模糊)，目前已提出许多保持边缘、细节的局部平滑算法.它们的出发点都集中在如何选择邻域的大小、形状和方向、参数加平均及邻域各店的权重系数等.<br>图像高斯平滑也是邻域平均的思想对图像进行平滑的-种方法，在图像高斯平滑中，对图像进行平均时，不同位置的像素被赋予了不同的权重.高斯平滑与简单平滑不同，它在对邻域内像素进行平均时，给予不同位置的像素不同的权值，下图的所示的3<em>3和5</em>5领域的高斯模板.<br><img src="https://img-blog.csdnimg.cn/6a04890378f64300a071213fc94c74aa.png" alt="在这里插入图片描述"></p><p>高斯滤波让临近的像素具有更高的重要度，对周围像素计算加权平均值，较近的像素具有较大的权重值.如下图所示，中心位置权重最高为0.4.<br><img src="https://img-blog.csdnimg.cn/72851d23233a441fb91a09f5c96e1b95.png" alt="在这里插入图片描述"></p><h3 id="2-代码-2"><a href="#2-代码-2" class="headerlink" title="2.代码"></a>2.代码</h3><p>Python中OpenCV主要调用GaussianBlur函数，如下：<br>dst&#x3D;cv2.GaussianBlur(src，ksize，sigmaX)<br>其中，src表示原始图像，ksize表示核大小，sigmaX表示X方向方差.注意，核大小(N，N)必须是奇数，X方向方差主要控制权重.<br><img src="https://img-blog.csdnimg.cn/c5bd030fc02a4175b117788eca2f857f.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/554fbfa3c58c45f38611696a95b7fd7a.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/0a63d9116ce84638b873e9d7c8806b31.png" alt="在这里插入图片描述"></p><h2 id="直方图均衡化"><a href="#直方图均衡化" class="headerlink" title="直方图均衡化"></a>直方图均衡化</h2><p>1&gt;.希望一幅图像的像素占有全部可能的灰度级且分布均匀，能够具有高对比度；<br>2&gt;.基本思想是把原始图的直方图变换为均匀分布的形式，这样就增加了像素灰度值的动态范围，从而达到增强图像整体对比度的效果<br>3&gt;.直方图均衡化的前提条件是图像是灰度图<br>4&gt;.全局直方图均衡化<br><img src="https://img-blog.csdnimg.cn/8cbdc88f26c54b4a8944f888f6688e41.png" alt="在这里插入图片描述"></p><h2 id="二值图像的平滑处理–消除噪声的腐蚀处理"><a href="#二值图像的平滑处理–消除噪声的腐蚀处理" class="headerlink" title="二值图像的平滑处理–消除噪声的腐蚀处理"></a>二值图像的平滑处理–消除噪声的腐蚀处理</h2><p>假设有一个模板B(就是一个红色的3x3的框，没有任何值，出于简化的考虑)这个模板在一个图像P.中进行移动.那么模板和图像的运算规则就决定了输出图像是被腐蚀还是被膨胀了.<br>考虑下面的图像，1表示白色区域，0表示黑色区域，现在对图像P和模板B的计算制定一条规则：<br>选取红色方框内的最小值作为新图像的中心值.那么红色方框中最小值是0，也就是新图像对应方框中心位置的像素值是0.<br><img src="https://img-blog.csdnimg.cn/b9e8c97e94b44add9ed4170db231bc71.png" alt="在这里插入图片描述"><br>想象一下就会发现红色框在移动中，框里面的最小值大多数都是0，也就是说新图片大多数都是0的像素值(即黑色)。那么什么情况下能得到1呢(白色)？仅仅当模板在下面这张图的位置能得到1，也就是只有在框内数值均为1时才能使得最小值是1.<br><img src="https://img-blog.csdnimg.cn/520bb51f26b7448197baf125f59fcc40.png" alt="在这里插入图片描述"></p><p>综上，新的图像只有一处像素值为1(白色)，其它位置都是0(黑色)，即这张图像被“腐蚀了.<br><img src="https://img-blog.csdnimg.cn/9e583c8fd57e4c00b843d06013cf6462.png" alt="在这里插入图片描述"></p><p>上述代码实现的就是卷积操作，其中第一个if语句用来判断卷积核尺寸是不是奇数并且正整数，第二个if用来判断输入图像是不是灰度图像，如果不满足这两者就会抛出错误。接下来的双层循环是模板在图像以步长为1进行移动，并选取最小值过程.用来调用函数并绘图的代码如下：<br><img src="https://img-blog.csdnimg.cn/07312b881b24438d87282acbe2d5e074.png" alt="在这里插入图片描述"></p><h2 id="二值图像的平滑处理–消除噪声的膨胀处理"><a href="#二值图像的平滑处理–消除噪声的膨胀处理" class="headerlink" title="二值图像的平滑处理–消除噪声的膨胀处理"></a>二值图像的平滑处理–消除噪声的膨胀处理</h2><p>膨胀和腐蚀是两个相反的过程，上一节讲“选取红色方框内最小值”改为“选取红色方框内最大值“即可.选取框内最小值造成了1大量减少，那么选取框内最大值就会造成1大量增加，这里不再累述.代码如下：<br><img src="https://img-blog.csdnimg.cn/074c28936bbd4c8da66f16bf83786071.png" alt="在这里插入图片描述"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;机器视觉期末复习的整理 第5章 图像平滑处理&lt;/p&gt;</summary>
    
    
    
    <category term="机器视觉" scheme="https://du2279664786.github.io/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    
    <category term="机器视觉" scheme="https://du2279664786.github.io/tags/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    <category term="期末考试" scheme="https://du2279664786.github.io/tags/%E6%9C%9F%E6%9C%AB%E8%80%83%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>第八章 几何变换</title>
    <link href="https://du2279664786.github.io/posts/8f02966d.html"/>
    <id>https://du2279664786.github.io/posts/8f02966d.html</id>
    <published>2022-12-15T14:55:10.000Z</published>
    <updated>2022-12-15T12:51:23.273Z</updated>
    
    <content type="html"><![CDATA[<p>第八章 几何变换</p><span id="more"></span><h1 id="第八章-几何变换"><a href="#第八章-几何变换" class="headerlink" title="第八章 几何变换"></a>第八章 几何变换</h1><h2 id="1-几何变换"><a href="#1-几何变换" class="headerlink" title="1.几何变换"></a>1.几何变换</h2><pre><code>   图像几何变换不改变图像的像素值，在图像平面上进行像素变换。适当的几何变换可以最大程度地消除由于成像角度、透视关系乃至镜头自身原因所造成的几何失真所产生的负面影响。几何变换常常作为图像处理应用的预处理步骤，是图像归一化的核心工作之一。  一个几何变换需要两部分运算：空间变换、灰度插值算法。</code></pre><p><img src="https://img-blog.csdnimg.cn/1af9ae54de8f4cf4993092d8e2b69b52.png" alt="在这里插入图片描述"></p><h2 id="2-图像放大缩小"><a href="#2-图像放大缩小" class="headerlink" title="2.图像放大缩小"></a>2.图像放大缩小</h2><pre><code>  图像缩放（image scaling）是指对数字图像的大小进行调整的过程。在Python中，图像缩放主要调用resize()函数实现，函数原型如下：</code></pre><p>result &#x3D; cv2.resize(src, dsize[, result[. fx[, fy[, interpolation]]]])<br><img src="https://img-blog.csdnimg.cn/18dfd532912642f496d44958f3bf960d.png" alt="在这里插入图片描述"><br>常见的图像缩放两种方式如下所示，第一种方式是将原图像设置为(160, 160)像素大小，第二种方式是将原始图像缩小为0.5倍。<br>result &#x3D; cv2.resize(src, (160,160))<br>result &#x3D; cv2.resize(src, None, fx&#x3D;0.5, fy&#x3D;0.5)<br>设(x1, y1)是缩放后的坐标，(x0, y0)是缩放前的坐标，sx、sy为缩放因子，则图像缩放的计算公式（6-3）所示：<br><img src="https://img-blog.csdnimg.cn/73aa2ab08685459993bcc67500a633f3.png" alt="在这里插入图片描述"><br>第二种：获取图片“scenery.png”的元素像素值，其rows值为384，cols值为512，接着进行宽度缩小0.6倍、高度放大1.2倍的处理，运行前后对比效果如图所示。<br><img src="https://img-blog.csdnimg.cn/889f0b0f203941a8a0f302de294849d4.png" alt="在这里插入图片描述"><br>输出的结果如图所示，这是按比例0.3×0.3缩小的。<br><img src="https://img-blog.csdnimg.cn/6e377950f8d6449b9d3f9d50e74bd9aa.png" alt="在这里插入图片描述"></p><h2 id="3-图像平移"><a href="#3-图像平移" class="headerlink" title="3.图像平移"></a>3.图像平移</h2><p>图像平移是将图像中的所有像素点按照给定的平移量进行水平或垂直方向上的移动。假设原始像素的位置坐标为（x0，y0），经过平移量（△x，△y）后，坐标变为（x1, y1），如图所示。<br><img src="https://img-blog.csdnimg.cn/64c82a4b5d5a481199b5c0606694db9a.png" alt="在这里插入图片描述"><br>用数学式子表示为公式：<br><img src="https://img-blog.csdnimg.cn/c6f4b9637940458386036168ab826614.png" alt="在这里插入图片描述"><br>用矩阵表示如公式：<br><img src="https://img-blog.csdnimg.cn/818d37dca0f14d7d8116a98aaf17c039.png" alt="在这里插入图片描述"><br>    式子中，矩阵称为平移变换矩阵或因子，△x和△y称为平移量。图像平移首先定义平移矩阵M，再调用warpAffine()函数实现平移，核心函数如下：<br>M &#x3D; np.float32([[1, 0, x], [0, 1, y]])<br>– M表示平移矩阵，其中x表示水平平移量，y表示垂直平移量<br>shifted &#x3D; cv2.warpAffine(src, M, dsize[, dst[, flags[, borderMode[, borderValue]]]])<br>输出结果如图所示<br><img src="https://img-blog.csdnimg.cn/c05d3e8a89bd4914851a33718af23782.png" alt="在这里插入图片描述"><br>输出结果如图所示，它从四个方向都进行了平移，并且调用subplot()函数将四个子图绘制在一起。<br><img src="https://img-blog.csdnimg.cn/5d7393f0792d4b6fa52a8a736845317c.png" alt="在这里插入图片描述"></p><h2 id="4-图像旋转"><a href="#4-图像旋转" class="headerlink" title="4.图像旋转"></a>4.图像旋转</h2><p>图像旋转是指图像以某一点为中心旋转一定的角度，形成一幅新的图像的过程。图像旋转变换会有一个旋转中心，这个旋转中心一般为图像的中心，旋转之后图像的大小一般会发生改变。图表示原始图像的坐标(x0, y0)旋转至(x1, y1)的过程。<br><img src="https://img-blog.csdnimg.cn/8a7de45945ff4842816e54f888898f41.png" alt="在这里插入图片描述"><br>旋转公式如所示，其中(m,n)是旋转中心，a是旋转的角度，(left,top)是旋转后图像的左上角坐标。<br><img src="https://img-blog.csdnimg.cn/f8f23c54a0a443fb8c73f444e87a7135.png" alt="在这里插入图片描述"><br>显示效果如图所示，绕图像中心点逆时针旋转30度。<br><img src="https://img-blog.csdnimg.cn/5dda9aa293d447b2a4228d2dfd4b4d92.png" alt="在这里插入图片描述"><br>扩充：  图像翻转<br>代码实现了三种翻转的方式：水平翻转、垂直翻转以及水平垂直翻转，来看效果。<br><img src="https://img-blog.csdnimg.cn/eb981151f6bc4301b37c9b834d19da4b.png" alt="在这里插入图片描述"><br>使用numpy的索引进行图像反转<br>        刚刚使用了OpenCV的API进行了图像翻转的操作，实际上仅仅使用numpy也是相当的方便，在numpy中使用img[:,::-1]则代表为矩阵水平翻转，使用img[::-1]则为矩阵垂直翻转，所以我们不难看出，水平与垂直同时翻转则为img[::-1, ::-1]。<br><img src="https://img-blog.csdnimg.cn/468202aaecd049a4afcc717cf2ea3a7d.png" alt="在这里插入图片描述"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;第八章 几何变换&lt;/p&gt;</summary>
    
    
    
    <category term="机器视觉" scheme="https://du2279664786.github.io/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    
    <category term="机器视觉" scheme="https://du2279664786.github.io/tags/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    <category term="期末考试" scheme="https://du2279664786.github.io/tags/%E6%9C%9F%E6%9C%AB%E8%80%83%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>第三章 目标提取</title>
    <link href="https://du2279664786.github.io/posts/1fc2945f.html"/>
    <id>https://du2279664786.github.io/posts/1fc2945f.html</id>
    <published>2022-12-15T14:55:10.000Z</published>
    <updated>2022-12-15T12:51:23.274Z</updated>
    
    <content type="html"><![CDATA[<p>第三章 目标提取</p><span id="more"></span><h1 id="第三章-目标提取"><a href="#第三章-目标提取" class="headerlink" title="第三章 目标提取"></a>第三章 目标提取</h1><h2 id="1-如何提取目标物体"><a href="#1-如何提取目标物体" class="headerlink" title="1.如何提取目标物体"></a>1.如何提取目标物体</h2><pre><code>     判断目标为何物或者测量其尺寸大小的第一步是将目标从复杂的图像中提取出来。</code></pre><p>•在街景中只提取人；<br>• 在智能交通系统中识别车辆牌照和交通标志；<br>• 从邮件中查找邮政编码来进行分类；<br>• 使用监控摄像机，当发现有贸然进入的人时，发送警报；<br>• 在流动的生产线上提取零件；<br>• 判别农作物果实的大小，依据其大小进行分类等。<br>        人眼在杂乱的图像中搜寻目标物体时，主要依靠颜色和形状差别，具体过程人们在无意识中完成，其实利用了人们常年生活积累的常识。<br>        同样道理，机器视觉在提取物体时，也是依靠颜色和形状差别，只不过电脑里没有这些知识积累，需要人们利用计算机语言（程序）通过某种方法将目标物体知识输入或计算出来，形成判断依据。<br>         以下分别介绍利用形状和颜色进行目标物提取的方法。</p><h2 id="2-基于阈值的目标提取"><a href="#2-基于阈值的目标提取" class="headerlink" title="2.基于阈值的目标提取"></a>2.基于阈值的目标提取</h2><h3 id="2-1二值化处理"><a href="#2-1二值化处理" class="headerlink" title="2.1二值化处理"></a>2.1二值化处理</h3><pre><code>     二值化处理（binarization）是把目标物从图像中提取出来的一种方法。二值化处理的方法有很多，最简单的一种叫做阈值处理（thresholding），就是对于输入图像的各像素，当其灰度值在某设定值（称为阈值，threshold）以上或以下，赋予对应的输出图像的像素为白色（255）或黑色（0）。</code></pre><p><img src="https://img-blog.csdnimg.cn/ae15789517f34a4ea5e126a45fd1e85a.png" alt="在这里插入图片描述"><br>其中f（x，y）、g（x，y）分别是处理前和处理后的图像在（x，y）处像素的灰度值，t是阈值。<br>根据图像情况，有时需要提取两个阈值之间的部分，如式（3.3）所示。这种方法称为双阈值二值化处理。<br><img src="https://img-blog.csdnimg.cn/a4f04091487d45709e6071527e483bd7.png" alt="在这里插入图片描述"></p><h3 id="2-2阈值的确定"><a href="#2-2阈值的确定" class="headerlink" title="2.2阈值的确定"></a>2.2阈值的确定</h3><pre><code>    灰度图像像素的最大值是255（白色），最小值是0（黑色），从0～255，共有256级，一幅图像上每级有几个像素，把它数出来（计算机程序可以瞬间完成），做个图表，就是直方图。     计算出直方图，是灰度图像目标提取的重要步骤之一。</code></pre><p><img src="https://img-blog.csdnimg.cn/ab5c6d063f0141ffbd5bcb9c6ff8ab45.png" alt="在这里插入图片描述"><br>对于背景单一的图像，一般在直方图上有两个峰值，一个是背景的峰值，一个是目标物的峰值。<br><img src="https://img-blog.csdnimg.cn/9d7d45f466ed4c529f9ef487068b280b.png" alt="在这里插入图片描述"><br>        对这种在直方图上具有明显双峰的图像，把阈值设在双峰之间的凹点，即可较好地提取出目标物。<br>        如果原始图像的直方图凹凸激烈，计算机程序处理时就不好确定波谷的位置。为了比较容易地发现波谷，经常采取在直方图上对邻域点进行平均化处理，以减少直方图的凹凸不平。<br>       直方图就比较容易通过算法编写来找到其波谷位置。像这样取直方图的波谷作为阈值的方法称为模态法。<br><img src="https://img-blog.csdnimg.cn/e757a6414db24f7ca23fbb2d0d8ac8fc.png" alt="在这里插入图片描述"><br>在阈值确定方法中除了模态法以外，还有p参数法（p-tile method）、判别分析法（discriminant analysis method）、可变阈值法（variable thresholding）、大津法（OTSU method）等。<br>        p参数法是当物体占整个图像的比例已知时（如p%），在直方图上，暗灰度（或者亮灰度）一侧起的累计像素数占总像素数p%的地方作为阈值的方法。<br>        判别分析法是当直方图分成物体和背景两部分时，通过分析两部分的统计量来确定阈值的方法。<br>        可变阈值法在背景灰度多变的情况下使用，对图像的不同部位设置不同的阈值。<br>        大津法在各种图像处理中得到了广泛的应用，下面具体介绍一下大津法。<br>大津法也叫最大类间方差法，是由日本学者大津（OTSU）于1979年提出的。它是按图像的灰度特性，将图像分成背景和目标两部分。背景和目标之间的类间方差越大，说明构成图像的两部分的差别越大。因此，使类间方差最大的分割意味着错分概率最小。</p><h2 id="3-基于颜色的目标提取"><a href="#3-基于颜色的目标提取" class="headerlink" title="3.基于颜色的目标提取"></a>3.基于颜色的目标提取</h2><h3 id="3-1-色相、亮度、饱和度及其他"><a href="#3-1-色相、亮度、饱和度及其他" class="headerlink" title="3.1　色相、亮度、饱和度及其他"></a>3.1　色相、亮度、饱和度及其他</h3><pre><code>    彩色图像是由红（R）、绿（G）、蓝（B）三个分量的灰度图像组成。    当拍摄绿草地时，与R、B分量相比，G分量较强；    对于蓝天来说，与R、G分量相比，B分量较强。    根据R、G、B分量值的不同，人们可以见到各种各样的颜色。在进行彩色图像处理时，不仅要考虑位置和灰度信息，还要考虑彩色信息。    对于同一种颜色，不同的人，脑子里所想的颜色可能不相同。为了定量地表现颜色，可以把颜色分成三个特性来表现，第一个特性是色调或者色相H（hue），用来表示颜色的种类。第二个特性是明度V（value）或者亮度Y（brightness）或I（intensity），用来表示图像的明暗程度。第三个特性是饱和度或彩度S（saturation），用来表示颜色的鲜明程度。    这三个特性被称为颜色的三个基本属性。颜色的这三个基本属性可以用一个理想化的双锥体HSI模型来表示。</code></pre><p>双锥体轴线代表亮度值。垂直于轴线的平面表示色调与饱和度，用极坐标形式表示，即夹角表示色调，径向距离表示在一定色调下的饱和度。<br><img src="https://img-blog.csdnimg.cn/aa1a0358bffd4f428ea96981ca679a7c.png" alt="在这里插入图片描述"><br>         色调的表示是从某基准的颜色开始计算在0°～180°之间旋转多少角度，当与基准颜色相同（色调的旋转角为0°）时为255，相对方向的补色（色调的旋转角为180°）时为0。<br>        中间用254级的灰度表示。在色调的表示中，当饱和度为0（即无颜色信号）时不计算色调，常常给予0灰度级。饱和度的图像是将饱和度的最小值作为像素的最小值0，将饱和度的最大值作为像素的最大值255，依次按比例将饱和度的数据转换为图像数据。<br><img src="https://img-blog.csdnimg.cn/96e5e47d2b814e5c9ad073219d37a837.png" alt="在这里插入图片描述"><br>        对实际图像进行上述变换的结果如图3.7所示，其中图（a）是原始图像，图（b）是其亮度信号的图像。原始图像中宠物兔的红色成分较多，由于色调信号以红色为基准，因此图（c）所示的色调信号图像整体偏亮。由于整个图像的颜色不是很深，所以图（d）的饱和度信号偏暗，特别是背景地板砖的饱和度最低。<br>       可以看出，对于该图像，利用H或者S信号图像，对目标物兔子进行二值化提取，应该更容易一些。因此将RGB转换成HSI有时更有利于目标物的提取，但是与利用RGB信号相比，将会付出多倍的处理时间。<br><img src="https://img-blog.csdnimg.cn/105898d3592c47a3a6d95e159028a5e1.png" alt="在这里插入图片描述"></p><h3 id="3-2颜色分量及其组合处理"><a href="#3-2颜色分量及其组合处理" class="headerlink" title="3.2颜色分量及其组合处理"></a>3.2颜色分量及其组合处理</h3><pre><code>    对于自然界的目标提取，可以根据目标的颜色特征，尽量使用R、G、B分量及它们之间的差分组合，这样可以有效避免自然光变化的影响，快速有效地提取目标。    以下举例说明基于颜色差分的目标提取。  （1）果树上红色桃子的提取    ①原图像。</code></pre><p><img src="https://img-blog.csdnimg.cn/bfabf17d7c3644f0aa077c66198fdfaa.png" alt="在这里插入图片描述"><br>        ②桃子的红色区域提取<br>        由于成熟桃子一般带红色，因此对彩色原图像首先利用红、绿色差信息提取图像中桃子的红色区域，然后再采用与原图进行匹配膨胀的方法来获得桃子的完整区域。<br><img src="https://img-blog.csdnimg.cn/cfbc2a9d491b49d8a02b8116cb3526ac.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/768a81d298db4ba8885ecf15e64eee1f.png" alt="在这里插入图片描述"><br>    （2）绿色麦苗的提取<br>        在不同季节小麦苗的颜色有所不同，但是都是呈绿色。如图所示，（a）为11月（秋季）小麦生长初期阴天的图像，土壤比较湿润；（b）为2月（冬季）晴天的图像，土壤干旱，发生干裂；（c）为3月（春季）小麦返青时节阴天的图像，土壤比较松软；（d）～（f）分别为以后不同生长阶段不同天气状况的图像。这6幅图分别代表了小麦的不同生长阶段和不同的天气状况。<br><img src="https://img-blog.csdnimg.cn/a5894247d0164002a6dc0dea9165ab77.png" alt="在这里插入图片描述"><br>由于麦苗的绿色成分大于其他两个颜色成分，为了提取绿色的麦苗，可以通过强调绿色成分、抑制其他成分的方法把麦田彩色图像变化为灰度图像。<br><img src="https://img-blog.csdnimg.cn/6f276031efb6436da0c47b86833e0d55.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/8e3f4fb406a64bf3bb5292b7ba48bf17.png" alt="在这里插入图片描述"></p><h3 id="3-3基于差分的目标提取"><a href="#3-3基于差分的目标提取" class="headerlink" title="3.3基于差分的目标提取"></a>3.3基于差分的目标提取</h3><pre><code>    基于差分的目标提取，一般用于运动图像的目标提取，有帧间差分和背景差分两种方式，以下分别利用工程实践项目来说明两种差分目标提取方式。</code></pre><h3 id="3-1帧间差分"><a href="#3-1帧间差分" class="headerlink" title="3.1帧间差分"></a>3.1帧间差分</h3><pre><code>    所谓帧间差分，就是将前帧图像的每个像素值减去后帧图像上对应点的像素值（或者反之），获得的结果如果大于设定阈值，在输出图像上设为白色像素，否则设为黑色像素。</code></pre>]]></content>
    
    
    <summary type="html">&lt;p&gt;第三章 目标提取&lt;/p&gt;</summary>
    
    
    
    <category term="机器视觉" scheme="https://du2279664786.github.io/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    
    <category term="机器视觉" scheme="https://du2279664786.github.io/tags/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    <category term="期末考试" scheme="https://du2279664786.github.io/tags/%E6%9C%9F%E6%9C%AB%E8%80%83%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>第十一章 运动图像处理</title>
    <link href="https://du2279664786.github.io/posts/f76709d8.html"/>
    <id>https://du2279664786.github.io/posts/f76709d8.html</id>
    <published>2022-12-15T14:55:10.000Z</published>
    <updated>2022-12-15T12:51:23.276Z</updated>
    
    <content type="html"><![CDATA[<p>第十一章 运动图像处理</p><span id="more"></span><h1 id="第十一章-运动图像处理"><a href="#第十一章-运动图像处理" class="headerlink" title="第十一章 运动图像处理"></a>第十一章 运动图像处理</h1><h2 id="1光流法"><a href="#1光流法" class="headerlink" title="1光流法"></a>1光流法</h2><pre><code>   在OpenCV-PythonTutorials上的解释:光流是物体或者摄像头的运动导致的两个连续帧之间的图像对象的视觉运动的模式。它是一个向量场，每个向量是一个位移矢量，显示了从第一帧到第二帧的点的移动。</code></pre><p><img src="https://img-blog.csdnimg.cn/c0bc191b31dc42ccb888301f0ac78731.png" alt="在这里插入图片描述"><br>       上图表示了一个球在5个连续帧里的移动。箭头显示了它的位移矢量。<br>       光流在日常生活中应用还是很广泛的,特别是在视频的监控领域,比如从移动构建再到视频拍摄,再到视频压缩存取,都有很广泛的应用.</p><h2 id="1-1光流法的原理"><a href="#1-1光流法的原理" class="headerlink" title="1.1光流法的原理"></a>1.1光流法的原理</h2><pre><code>    在推广光流法的时候,我们要有两个前提假设：    第一、所追踪的像素目标在连续的帧之间要保持基本不变。    第二、所追踪的像素目标在连续的帧之间要有相似的运动趋势。</code></pre><p>现在我们开始推广一下光流方程:<br>    ①:假设从首发帧的像素I(x,y,t),在dt时间之后的下一帧中移动距离为(dx，dy),且这些像素是相同的,而且亮度不变。<br>因此得到以下推广:<br><img src="https://img-blog.csdnimg.cn/25ff238f6ed24402909390966762d893.png" alt="在这里插入图片描述"><br>    ②:对上边公式的右边做泰勒级数近似。除以dt得到下面的等式:<br><img src="https://img-blog.csdnimg.cn/58511da9d91e48b887e544dc1439a3a6.png" alt="在这里插入图片描述"><br>其中每个参数如下:<br><img src="https://img-blog.csdnimg.cn/7c2874ea2c104f9d8666077b4a4f4bcf.png" alt="在这里插入图片描述"><br>上面的等式被叫做光流等式，但是我们在这里会发现几个问题:<br>       可以找到fx和fy是图像的梯度。类似的ft是沿时间的梯度,这些都可以计算出来.但是(u, v)是未知的。无法解出这个等式。因此需要用到Lucas-Kanade方法来解决这些问题.</p><h2 id="1-2Lucas-Kanade-方法"><a href="#1-2Lucas-Kanade-方法" class="headerlink" title="1.2Lucas-Kanade 方法"></a>1.2Lucas-Kanade 方法</h2><p>现在使用第二条假设，就是所有的相邻像素都有相同的移动。LK算法使用了一个3×3的窗口大小。所以，在这个窗口当中有9个像素点满足公式。<br><img src="https://img-blog.csdnimg.cn/7ed273552c0b4daca53b53ab603b1735.png" alt="在这里插入图片描述"><br>将点代入方程，现在的问题就变成了使用9个点求解两个未知量。<br>所以现在的问题变成解决了9个方程式，其中两个未知变量是过度确定的.解的个数大于未知数的个数，这是个超定方程，使用最小二乘的方法来求解最优值。<br><img src="https://img-blog.csdnimg.cn/753e97317df14463b31295978377a59d.png" alt="在这里插入图片描述"><br>       观察上方矩阵，用Harris角点检测来检查法逆矩阵的相似性。逆矩阵与Harris角点检测很像，说明角点是适合用来做跟踪的。<br>这个算法思路很简单，能够给出一些点用来追踪，再去获得点的光流向量。并且能够实现追踪，但是有另外一个问题需要解决，目前讨论的运动都是小步长的运动，如果有幅度大的运动出现，本算法就会失效。<br>        使用的解决办法是利用图像金字塔。在金字塔顶端的小尺寸图片当中，大幅度的运动就变成了小幅度的运动。所以使用LK算法，可以得到尺度空间上的光流。这个问题就变得复杂了。</p><h2 id="2-蜜蜂采蜜"><a href="#2-蜜蜂采蜜" class="headerlink" title="2.蜜蜂采蜜"></a>2.蜜蜂采蜜</h2><p>有一只小蜜蜂从蜂巢去五片花田采蜜，采完回家，假设以蜂巢为坐标原点(0,0)，花田位置为A(50,0)、B(50,5)、C(50,20)、D(50,30)、E(50,50)，规划小蜜蜂采蜜路线，求解蜜蜂飞行最短距离（输出为整数）<br>用递归法进行排列，二层循环<br>第一步：确定新列表的第1个元素（第1个和第n个元素换了位置）<br>第二步：将除了第一个元素外，剩下所有元素进行排列</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;第十一章 运动图像处理&lt;/p&gt;</summary>
    
    
    
    <category term="机器视觉" scheme="https://du2279664786.github.io/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    
    <category term="机器视觉" scheme="https://du2279664786.github.io/tags/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    <category term="期末考试" scheme="https://du2279664786.github.io/tags/%E6%9C%9F%E6%9C%AB%E8%80%83%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>第九章 单目视觉测量</title>
    <link href="https://du2279664786.github.io/posts/6c25df0e.html"/>
    <id>https://du2279664786.github.io/posts/6c25df0e.html</id>
    <published>2022-12-15T14:55:10.000Z</published>
    <updated>2022-12-15T12:51:23.278Z</updated>
    
    <content type="html"><![CDATA[<p>第九章 单目视觉测量</p><span id="more"></span><h1 id="第九章-单目视觉测量"><a href="#第九章-单目视觉测量" class="headerlink" title="第九章 单目视觉测量"></a>第九章 单目视觉测量</h1><h2 id="1-计算机视觉基础——相机标定"><a href="#1-计算机视觉基础——相机标定" class="headerlink" title="1.计算机视觉基础——相机标定"></a>1.计算机视觉基础——相机标定</h2><h3 id="1-1物理模型"><a href="#1-1物理模型" class="headerlink" title="1.1物理模型"></a>1.1物理模型</h3><pre><code>   首先谈谈相机为什么需要标定？任何理论物理模型都是在特定假设上对真实事物的近似，然而在实际应用中存在误差，普通相机的成像模型也不例外（透视投影）。实际中，普通相机成像误差的主要来源有两部分，第一是sensor制造产生的误差，比如sensor成像单元不是正方形，sensor歪斜；第二是镜头制造和安装产生的误差，镜头一般存在非线性的径向畸变；镜头与相机sensor安装不平行，还会产生切向畸变。</code></pre><p>一个几何变换需要两部分运算：空间变换、灰度插值算法。<br><img src="https://img-blog.csdnimg.cn/e79e180702324210bb2d33e47baafeef.png" alt="在这里插入图片描述"></p><h3 id="1-2透视投影模型"><a href="#1-2透视投影模型" class="headerlink" title="1.2透视投影模型"></a>1.2透视投影模型</h3><pre><code>   普通相机的成像模型一采用小孔成像，初中的物理知识告诉我们，没错，就是那个蜡烛成像实验，物体经小孔后，在成像平面成倒立的像。为了更好的进行理论阐述，一般默认采用虚拟成像平面（virtual image plane）进行分析。虽没有明文规定，但大家（不，是大佬）都是这么做的。Matlab官方有张很形象的图片。</code></pre><p><img src="https://img-blog.csdnimg.cn/5b9c41e4301b4e7bb8745e378bca4d26.png" alt="在这里插入图片描述"><br>将小孔成像模型简化成几何表达的形式。<br><img src="https://img-blog.csdnimg.cn/d425f42681d342fdb4109e8497db7d9b.png" alt="在这里插入图片描述"><br>在理想情况下，根据简单的相似三角形几何知识，可以推出3D目标点在相机坐标系下的坐标与图像像素坐标之间的关系。<br><img src="https://img-blog.csdnimg.cn/342e83a04df94510b1ca0e88c0bb7c63.png" alt="在这里插入图片描述"><br>f是焦距，X、Y、Z是3D点在相机坐标系坐标，u，v是图像坐标；上述公式写成齐次坐标为：<br><img src="https://img-blog.csdnimg.cn/3c68433467424c2bab39f0cfa1fbc745.png" alt="在这里插入图片描述"><br>λ为尺度因子，同一条投影线上的点都满足上述关系，只是λ不同而已；在不换sensor情况下，想增大物体分辨率，其实只要把相机靠近一点就行。</p><h3 id="1-3主点偏移"><a href="#1-3主点偏移" class="headerlink" title="1.3主点偏移"></a>1.3主点偏移</h3><p>主点是光轴和相机成像平面的交点，1.2节考虑的是理想成像情况，图像坐标系和相机坐标系原点重合，因此不存在坐标系偏移。但是在实际情况中，图像坐标系往往在图片的左上角，光轴过图像中心，因此图像坐标系和相机坐标系不重合。两个坐标系之间存在一个平移运动（如图）。<br><img src="https://img-blog.csdnimg.cn/29ea2b4ac2794548a4f6cbe1de50acbc.png" alt="在这里插入图片描述"><br>考虑主点偏移后，图像坐标和3D在相机坐标系坐标的关系为：<br><img src="https://img-blog.csdnimg.cn/1722ac6e7f1e4aa0aeb5f66692885f6a.png" alt="在这里插入图片描述"><br>主点偏移后，透视投影模型的的齐次坐标表达为：<img src="https://img-blog.csdnimg.cn/8b58947275324b0080e99103ccc8b30d.png" alt="在这里插入图片描述"><br>用矩阵表示如公式：<br>图像传感器像原尺寸在制造过程可能不是正方形，同时可能存在歪斜（skewed），因此需要考虑这些影响因素，传感器歪斜和不是正方形主要对相机x和y方向的焦距产生影响，数学表达见公式（1-5）。<br><img src="https://img-blog.csdnimg.cn/890c20edbdcd48eca14f0e95901917df.png" alt="在这里插入图片描述"><br>在不考虑畸变的情况下，考虑主点偏移、图像传感器的特性，3D目标点成像数学模型用公式（1-5）可完全表达。这就是相机内部参数对成像的影响，因此K称为内参矩阵，相机内参标定主要是标定相机的焦距、主点、歪斜等内部参数。<br><img src="https://img-blog.csdnimg.cn/ccfa51dfaf504312ba67992ef1364b60.png" alt="在这里插入图片描述"></p><h3 id="1-4镜头畸变对成像的影响"><a href="#1-4镜头畸变对成像的影响" class="headerlink" title="1.4镜头畸变对成像的影响"></a>1.4镜头畸变对成像的影响</h3><pre><code>    小孔成像模型虽然充分考虑了相机内部参数对成像的影响，但没有考虑成像系统另一个重要的部分，镜头。镜头常用的有普通镜头、广角镜头、鱼眼镜头等，在无人驾驶和视觉slam领域，鱼眼镜头和广角镜头用的很多，主要是视角很大，可以观测到更多的信息。任何镜头都存在不同程度的畸变，不同类型的镜头用到的畸变模型也不相同。根据镜头制造和成像的物理特性，普通镜头主要考虑径向畸变和切向畸变，且畸变模型都可以用多项式来近似。而对于大广角、鱼眼镜头，普通镜头的物理模型不能适用了。</code></pre><h4 id="1-4-1径向畸变"><a href="#1-4-1径向畸变" class="headerlink" title="1.4.1径向畸变"></a>1.4.1径向畸变</h4><p>透过镜头边缘的光线很容易产生径向畸变，光线离镜头中心越远，畸变越大。<br><img src="https://img-blog.csdnimg.cn/aa11e7405f7647c38f3ddee79ca2dc0a.png" alt="在这里插入图片描述"><br>从图像可以看出，径向畸变以某一个中心往外延伸，且越往外，畸变越大；显然畸变与距离成一种非线性的变换关系，参考众多文献，可以用多项式来近似。<br><img src="https://img-blog.csdnimg.cn/bdac3d341b254342911ff502d0269251.png" alt="在这里插入图片描述"><br>x,y是归一化的图像坐标，即坐标原点已经移动到主点，并且像素坐标除以焦距。K1,k2,k3是径向畸变系数，r2&#x3D;x2+y2（2表示2次方）。</p><h4 id="1-4-2切向畸变"><a href="#1-4-2切向畸变" class="headerlink" title="1.4.2切向畸变"></a>1.4.2切向畸变</h4><p>切向畸变主要发生在相机sensor和镜头不平行的情况下；因为有夹角，所以光透过镜头传到图像传感器上时，成像位置发生了变化。<br><img src="https://img-blog.csdnimg.cn/70739ef6303a4e298a9631d26ead72d0.png" alt="在这里插入图片描述"><br>x,y是归一化的图像坐标，即坐标原点已经移动到主点，并且像素坐标除以焦距。p1、p2是径向畸变系数，r2&#x3D;x2+y2。<br><img src="https://img-blog.csdnimg.cn/865f2c873a3a4b62a40a00dd871c4858.png" alt="在这里插入图片描述"></p><h3 id="1-5相机外参"><a href="#1-5相机外参" class="headerlink" title="1.5相机外参"></a>1.5相机外参</h3><pre><code>    上述讨论的范畴全是在相机坐标下发生的事情，然而实际情况是，相机往往装在机械臂末端，移动小车前方，车辆四周，当我们需要知道成像平面内的物体在机器人或者车辆坐标系下的位置时，需要进行一个坐标转换，称为外参（Extrinsic parameters），它与相机制造、镜头畸变没有任何关系，只与相机在世界坐标系内的安装位置和角度有关。从纯数学的角度来说，刚体运动和坐标变换总是可以分解为一个旋转运动和一个平移运动。</code></pre><p><img src="https://img-blog.csdnimg.cn/5758e6609d824243a4c5a8d08ae04d0a.png" alt="在这里插入图片描述"><br>因此世界坐标系下的点P与图像坐标的关系可以表达为：<br><img src="https://img-blog.csdnimg.cn/5fa0d97c2de54da684a59413ce75772a.png" alt="在这里插入图片描述"><br>相机标定就是标定内参和外参，通过一种理论数学模型和优化的手段来近似实际的物理成像关系。</p><h2 id="2-模型求解"><a href="#2-模型求解" class="headerlink" title="2 模型求解"></a>2 模型求解</h2><pre><code>    模型求解数学公式繁多，需要有些线性代数基础，对公式无感者，直接跳过本节，这一节和上一节的公式符号略有出入，保持原paper符号。</code></pre><h3 id="2-1-内参和单应矩阵关系"><a href="#2-1-内参和单应矩阵关系" class="headerlink" title="2.1 内参和单应矩阵关系"></a>2.1 内参和单应矩阵关系</h3><pre><code>   搞清楚了理论模型，接下来就是求解未知的内参和外参了。内参的初始估计有闭环解，不需要凭感觉瞎估，这是非常非常爽的事情。空间中的3D点投影到图像上的关系为：</code></pre><p><img src="https://img-blog.csdnimg.cn/aa29ce9d509a48008e21f4cc4ed48535.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/01d8a81046be4c139358aaeed4bda406.png" alt="在这里插入图片描述"><br>       一般我们都会用标定板来标定，所有的特征点都在一个平面上，不失一般性，可以假设这个平面的空间Z坐标为0，将外参R矩阵写成列向量的形式为：<br><img src="https://img-blog.csdnimg.cn/56c7a455724b4fa2810796e85b1814db.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/976f586bdaa042f5bc48db10d6b9514b.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/67536947b610403d88b3cd74370d1cce.png" alt="在这里插入图片描述"></p><h3 id="2-2-闭环求解（Closed-form-solution）"><a href="#2-2-闭环求解（Closed-form-solution）" class="headerlink" title="2.2 闭环求解（Closed-form solution）"></a>2.2 闭环求解（Closed-form solution）</h3><p>闭环解就是说的完全可以靠理论，数学推导可以求出的，不需要进行数值计算，也是非常爽的，程序按照公式写即可。<br><img src="https://img-blog.csdnimg.cn/da0598e61a7349ae9da777367872bcae.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/2c5da00d1f4d4f33acc28e96ff388b91.png" alt="在这里插入图片描述"><br>V是只由单应矩阵决定的已知量，求解上述线性方程，就可以得到向量b，矩阵B。向量b包含6个未知量，V是2n x 6矩阵，n代表单应矩阵个数（或者图像张数），所以至少需要采集三张不同位置或者角度的图像，才能求解上述方程。实际中，为了降低误差，会采集15-20张图像。<br><img src="https://img-blog.csdnimg.cn/0c75f3a82ac7496bac907b8ecdab6feb.png" alt="在这里插入图片描述"></p><h2 id="3结果"><a href="#3结果" class="headerlink" title="3结果"></a>3结果</h2><p><img src="https://img-blog.csdnimg.cn/e98a7df6f7ce4901b8100740ed931a13.png" alt="在这里插入图片描述"><br>opencv有很好的棋盘格检测效果，想要提高精度的，请参考角点优化、亚像素精度方面的文章。<br><img src="https://img-blog.csdnimg.cn/2f0eb5c031df4c6bb22db0076440facd.png" alt="在这里插入图片描述"></p><h2 id="4-最小凸多边形拟合"><a href="#4-最小凸多边形拟合" class="headerlink" title="4.最小凸多边形拟合"></a>4.最小凸多边形拟合</h2><p>Python图片查找轮廓、多边形拟合、最小外接矩形操作实例。<br>1、概述<br>       经常用到轮廓查找和多边形拟合等opencv操作，因此记录以备后续使用。本文代码中的阈值条件对图片没有实际意义，仅仅是为了测试。<br>       原图为：<br>       <img src="https://img-blog.csdnimg.cn/e8f743b5a61e4beb820e090048f19abd.png" alt="在这里插入图片描述"><br>       <img src="https://img-blog.csdnimg.cn/82f96d50262d4b6987906e954b238741.png" alt="在这里插入图片描述"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;第九章 单目视觉测量&lt;/p&gt;</summary>
    
    
    
    <category term="机器视觉" scheme="https://du2279664786.github.io/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    
    <category term="机器视觉" scheme="https://du2279664786.github.io/tags/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    <category term="期末考试" scheme="https://du2279664786.github.io/tags/%E6%9C%9F%E6%9C%AB%E8%80%83%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>第十三章 小波变换</title>
    <link href="https://du2279664786.github.io/posts/690ed3ec.html"/>
    <id>https://du2279664786.github.io/posts/690ed3ec.html</id>
    <published>2022-12-15T14:55:10.000Z</published>
    <updated>2022-12-15T12:51:23.280Z</updated>
    
    <content type="html"><![CDATA[<p>第十三章 小波变换</p><span id="more"></span><h1 id="第十三章-小波变换"><a href="#第十三章-小波变换" class="headerlink" title="第十三章 小波变换"></a>第十三章 小波变换</h1><h2 id="1-小波变换的发展史———工程到数学"><a href="#1-小波变换的发展史———工程到数学" class="headerlink" title="1.小波变换的发展史———工程到数学"></a>1.小波变换的发展史———工程到数学</h2><p>小波变换的概念是由法国从事石油信号处理的工程师J.Morlet在1974年首先提出的，通过物理的直观和信号处理的实际需要经验的建立了反演公式，当时未能得到数学家的认可.幸运的是，1986年年著名数学家Y.Meyer偶然构造出–个真正的小波基，并与S.Mallat、合作建立了构造小波基的同一方法枣多尺度分析之后小波分析才开始蓬勃发展起来.小波变换是近十几年新发展起来的一种数学工具，是继一百多年前的傅里叶(Fourier)分析之后的又一个重大突破，它对无论是古老的自然学科还是新兴的高新、应用技术学科均产生了强烈的冲击，<br>1909年：阿尔弗雷德·哈尔-发现了Haar小波1980年：莫莱特-.Morlet小波，并分别与20世纪70年代提.出了小波变换的概念，20世纪80年代开发出了连续小。波变换连续小波变换1986年：Y.Meyer-提出了第一个正交小波meyer小波1988年：斯蒂芬-马拉特–Mallat快速算法(塔式分解和重构算法)<br>1988年：英里德·多贝吉斯作为小波的创始人，揭示了小波变换和滤波器组(滤波器组)之间的内在关系使离散小波分析变成为现实.罗纳德·科夫曼和维克多·威克豪瑟等著名科学家在把小波理论引入到工程应用方面做出了极其重要.贡献在信号处理领域中，自InridDaubecports完善了小波变换的数学理论和StephaneMallat构造了小波分解和重构的快速算法后，小波变换在各个工程领域中得到了广泛的应用，典型的如语音信号处理、医学信号处理、图像信息处理等.<br>小波分析是在傅里叶分析的基础上发展起来的，但小波分析与傅里叶分析存在着极大的不同，与傅里叶变换相比，小波变换是空间(时间)和频率的局部变换，因而能有效地从信号中提取信息.通过伸缩和平移等运算功能可对函数或信号进行多尺度的细化分析，解决了Fourier变换不能解决的许多困难问题C型小波变换联系了应用数学、物理学、计算机科学、信号与信息处理、图像处理、地震勘探等多个学科.</p><h2 id="2-小波变换与傅里叶变换的比较"><a href="#2-小波变换与傅里叶变换的比较" class="headerlink" title="2.小波变换与傅里叶变换的比较"></a>2.小波变换与傅里叶变换的比较</h2><p>傅立叶变换的理论是人类数学发展史上的一个里程碑，从1807年开始，直到1966年整整用了一一个半世纪多才发展成熟，她在各个领域产生了深刻的影响得到了广泛的应用，推动了人类文明的发展.其原因是傅立叶理论不仅仅在数学上有很大的理论价值，更重要的是傅立叶变换或傅立叶积分得到的频谱信息具有物理意义.遗憾的是，这种理论具有一定的局限性.<br>用傅立叶变换提取信号的频谱需要利用信号的全部时域信息.傅立叶变换没有反映出随着时间的变化信号频率成分的变化情况.<br>傅立叶变换的积分作用平滑了非平稳信号的突变成分<br>由于上述原因，必须进一步改进，克服上述不足，这就导致了小波分析了<br>（1）克服第一个不足：小波系数不仅像傅立叶系数那样，是随频率不同而变化的，而且对于同一个频率指标j，在不同时刻k，小波系数也是不同的。<br>（2）克服第二个不足：由于小波函数具有紧支撑的性质即某一区间外为零。这样在求各频率水平不同时刻的小波系数时，只用到该时刻附近的局部信息。<br>从而克服了上面所述的第二个不足。<br>（3）克服第三个不足：通过与加窗傅立叶变换的“<br>时间—频率窗”的相似分析，可得到小波变换的“时间一频率窗”的笛卡儿积。小波变换的“时间–频率窗”的宽度，检测高频信号时变窄，检测低频信号时变宽。<br>这正是时间–频率分析所希望的。根据小波变换的“时间一频率窗”的宽度可变的特点，为了克服上面所述的第二个不足只要不同时检测高频与低频信息，问题就迎刃而解了。</p><h2 id="3-小波变换的基本原理与性质"><a href="#3-小波变换的基本原理与性质" class="headerlink" title="3.小波变换的基本原理与性质"></a>3.小波变换的基本原理与性质</h2><p>小波是什么？<br>小波可以简单的描述为一种函数，这种函数在有限时间范围内变化，并且平均值为0.这种定性的描述意味着小波具有两种性质：、具有有限的持续时间和突变的频率和振幅；B、在有限时间范围内平均值为0.<br><img src="https://img-blog.csdnimg.cn/44970200ca6c40afb88bd4b8025e2d34.png" alt="在这里插入图片描述"><br>小波的“容许”条件用一种数学的语言来定义小波，即满足“容许”条件的一种函数，“容许”条件非常重要，它限定了小波变换的可逆性.<br><img src="https://img-blog.csdnimg.cn/61ab6a1b80ed4427bc10c03ee123a561.png" alt="在这里插入图片描述"><br>小波本身是紧支撑的，即只有小的局部非零定义域，在窗口之外函数为零；本身是振荡的，具有波的性质并且完全不含有直流趋势成分，即满足<br><img src="https://img-blog.csdnimg.cn/15fd01758f484136a20f2d501769d4c1.png" alt="在这里插入图片描述"><br>信号的信息表示<br>时域表示:信号随时间变化的规律，信息包括均值、方差、峰度以及峭陡等，更精细的表示就是概率密度(分布(工程上常常采用其分布参数)<br>频域表示:信号在各个频率上的能量分布，信息为频率和谱值(频谱或功率谱)，、为了精确恢复原信号、需要加.上相位信息(相位谱)，典型的工具为FT<br>时频表示:时间和频率联合表示的一种信号表示方法信息为瞬时频率、瞬时能量谱信号处理中，对不同信号要区别对待，以选择哪种或者哪几种信号表示方法<br>信号的时域表示和频域表示只适用于平稳信号，对于非平稳信号而言，在时间域各种时间统计量会随着时间的变化而变化，失去统计意义；而在频率域，由于非平稳信号频谱结构随时间的变化而变化导致谱值失去意义<br><img src="https://img-blog.csdnimg.cn/b80f9a074a254aee86cbbf2287ade39c.png" alt="在这里插入图片描述"><br>时频表示主要目的在于实现对非平稳信号的分析，同样的可以应用于平稳信号的分析<br><img src="https://img-blog.csdnimg.cn/88e0c62e436442de9ea167321dded556.png" alt="在这里插入图片描述"><br>为什么选择小波.<br>小波提供了一-种非平稳信号的时间-尺度分析手段，不同于FT方法，与STFT方法比较具有更为明显的优势<br><img src="https://img-blog.csdnimg.cn/a57cea7b694347568284ae54bff8e033.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/961c86d128f44bcc84c2bbacce4eae2a.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/c198890abe1647bd8e43562fcd72c368.png" alt="在这里插入图片描述"><br>小波变换的定义：<br>小波变换是一种信号的时间一尺度(时间-频率)分析方法，它具有多分辨分析的特点，而且在时频两域都具有表征信号局部特征的能力，是一-种窗口大小固定不变但其形状可改变，时间窗和频率窗都可以改变的时频局部化分析方法.即在低频部分具有较<br>有较高的时间分辨率和较低的频率分辨率，很适合于分析非平稳的信号和提取信号的局部特征，所以小波变换被誉为分析处理信号的显微镜.在处理分析信号时，小波变换具有对信号的自适应性，也是是一种优、于傅里叶变换和窗口傅里叶变换的信号处理方法.<br><img src="https://img-blog.csdnimg.cn/d2dbe90200f5411f9bd92bc1f77da115.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/0e1c4ce33aa6436780b6d674397ad95c.png" alt="在这里插入图片描述"><br>平移因子对小波的作用<br><img src="https://img-blog.csdnimg.cn/4ef7a7be47d84b57a4f36fb60c999dec.png" alt="在这里插入图片描述"><br>连续小波变换实现过程<br>首先选择-一个小波基函数，固定一个尺度因子，将它与信号的初始段进行比较；通过CWT的计算公式计算小波系数(反映了当前尺度下的小波与所对应的信号段的相似程度)；改变平移因子，使小波沿时间轴位移，重复上述两个步骤完成一次分析；增加尺度因子，重复上述三个步骤进行第二次分析；循环执行，上述四个步骤，直到满足分析要求为止.<br><img src="https://img-blog.csdnimg.cn/29daab75c59d44b59b6793f68859e65c.png" alt="在这里插入图片描述"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;第十三章 小波变换&lt;/p&gt;</summary>
    
    
    
    <category term="机器视觉" scheme="https://du2279664786.github.io/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    
    <category term="机器视觉" scheme="https://du2279664786.github.io/tags/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    <category term="期末考试" scheme="https://du2279664786.github.io/tags/%E6%9C%9F%E6%9C%AB%E8%80%83%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>第十二章 傅里叶变换</title>
    <link href="https://du2279664786.github.io/posts/f1d41baf.html"/>
    <id>https://du2279664786.github.io/posts/f1d41baf.html</id>
    <published>2022-12-15T14:55:10.000Z</published>
    <updated>2022-12-15T12:51:23.281Z</updated>
    
    <content type="html"><![CDATA[<p>第十二章 傅里叶变换</p><span id="more"></span><h1 id="第十二章-傅里叶变换"><a href="#第十二章-傅里叶变换" class="headerlink" title="第十二章 傅里叶变换"></a>第十二章 傅里叶变换</h1><p>一、什么是频域<br>从我们出生，我们看到的世界都以时间贯穿，股票的走势、人的身高、汽车的轨迹都会随着时间发生改变。这种以时间作为参照来观察动态世界的方法我们称其为时域分析。而我们也想当然的认为，世间万物都在随着时间不停的改变，并且永远不会静止下来。但如果我告诉你，用另一种方法来观察世界的话，你会发现世界是永恒不变的，你会不会觉得我疯了？我没有疯，这个静止的世界就叫做频域。<br>先举一个公式上并非很恰当，但意义上再贴切不过的例子：<br>在你的理解中，一段音乐是什么呢？<br><img src="https://img-blog.csdnimg.cn/91db8cdf2d3b44aab08b980bef74afa3.png" alt="在这里插入图片描述"><br>这是我们对音乐最普遍的理解，一个随着时间变化的震动。但我相信对于乐器小能手们来说，音乐更直观的理解是这样的：<br><img src="https://img-blog.csdnimg.cn/3db0aec46e46471483ab9a374960e445.png" alt="在这里插入图片描述"><br>现在我们可以回过头来重新看看一开始那句痴人说梦般的话：世界是永恒的。将以上两图简化：<br>时域：<br><img src="https://img-blog.csdnimg.cn/403f2f25e60a4df5a812f43c4bac86a0.png" alt="在这里插入图片描述"><br>频域：<br><img src="https://img-blog.csdnimg.cn/081040049d564acc97ca512b92402147.png" alt="在这里插入图片描述"><br>在时域，我们观察到钢琴的琴弦一会上一会下的摆动，就如同一支股票的走势；而在频域，只有那一个永恒的音符。<br>傅里叶级数(Fourier Series)的频谱<br>如果我说我能用前面说的正弦曲线波叠加出一个带90度角的矩形波来，你会相信吗？但是看看下图：<br><img src="https://img-blog.csdnimg.cn/b4da0d9b20e042db922dcd3720ffa0b9.png" alt="在这里插入图片描述"><br>第一幅图是一个的正弦波cos（x）<br>第二幅图是2个的正弦波的叠加cos(x)+a.cos(3x)<br>第三幅图是4个的正弦波的叠加<br>第四幅图是10个的正弦波的叠加<br>随着叠加的递增，所有正弦波中上升的部分逐渐让原本缓慢增加的曲线不断变陡，而所有正弦波中下降的部分又抵消了上升到最高处时继续上升的部分使其变为水平线。一个矩形就这么叠加而成了。但是要多少个正弦波叠加起来才能形成一个标准90度角的矩形波呢？不幸的告诉大家，答案是无穷多个。<br>不仅仅是矩形，你能想到的任何波形都是可以如此方法用正弦波叠加起来的。这是没有接触过傅里叶分析的人在直觉上的第一个难点，但是一旦接受了这样的设定，游戏就开始有意思起来了。<br>还是上图的正弦波累加成矩形波，换一个角度来看看：<br><img src="https://img-blog.csdnimg.cn/c92810919f7746d3adca46df6246e3d3.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/3742c6905add441caa57ce10c9536c30.png" alt="在这里插入图片描述"><br>在这几幅图中，最前面黑色的线就是所有正弦波叠加而成的总和，也就是越来越接近矩形波的那个图形。而后面依不同颜色排列而成的正弦波就是组合为矩形波的各个分量。这些正弦波按照频率从低到高从前向后排列开来，而每一个波的振幅都是不同的。一定有细心的读者发现了，每两个正弦波之间都还有一条直线，那并不是分割线，而是振幅为0的正弦波！也就是说，为了组成特殊的曲线，有些正弦波成分是不需要的。<br>用快速傅里叶变换求解薛定谔方程<br>        薛定谔方程（Schrödinger equation），又称薛定谔波动方程（Schrödinger wave equation），是由奥地利物理学家薛定谔提出的量子力学中的一个基本方程，也是量子力学的一个基本假定。它是将物质波的概念和波动方程相结合建立的二阶偏微分，可描述观察粒子的运动，每个微观系统都有一个相应的薛定谔方程式，通过解方程可得到波函数的具体形式以及对应的能量，从而了解微观系统的性质。<br><img src="https://img-blog.csdnimg.cn/4c0d81d6beef43d1b1c99aed6670df73.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/49d263f1a07a44b2a08f069bce01007c.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/8253cad0453340949d03cec843599f34.png" alt="在这里插入图片描述"><br>算法思想：<br><img src="https://img-blog.csdnimg.cn/b2820c996e3f4977abb12b551308f468.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/96dac79c49c546a28e652923d4db4281.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/ae6f01e171874127a307ecc9b29753f3.png" alt="在这里插入图片描述"><br>编程求解：<br><img src="https://img-blog.csdnimg.cn/8e368b199095472ba1bdcc533aa352a2.png" alt="在这里插入图片描述"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;第十二章 傅里叶变换&lt;/p&gt;</summary>
    
    
    
    <category term="机器视觉" scheme="https://du2279664786.github.io/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    
    <category term="机器视觉" scheme="https://du2279664786.github.io/tags/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    <category term="期末考试" scheme="https://du2279664786.github.io/tags/%E6%9C%9F%E6%9C%AB%E8%80%83%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>第十章 双目视觉测量</title>
    <link href="https://du2279664786.github.io/posts/cfe29466.html"/>
    <id>https://du2279664786.github.io/posts/cfe29466.html</id>
    <published>2022-12-15T14:55:10.000Z</published>
    <updated>2022-12-15T12:51:23.283Z</updated>
    
    <content type="html"><![CDATA[<p>第十章 双目视觉测量</p><span id="more"></span><h1 id="第十章-双目视觉测量"><a href="#第十章-双目视觉测量" class="headerlink" title="第十章 双目视觉测量"></a>第十章 双目视觉测量</h1><pre><code>   根据预测网络所使用的特征空间，本文将双目视觉目标检测方法分为两类：</code></pre><p>1、基于直接视锥空间的目标检测方法<br>2、基于显式逆投影空间的目标检测方法。<br>      基于直接视锥空间的检测过程一般不包含逆投影变换，直接使用基于视锥空间的双目特征进行检测；而基于显式逆投影空间的检测方法一般需要将双目特征进行逆投影变换，生成三维空间上均匀的特征，适合构造体素或转换为俯视图进行检测。<br>     图给出了上述两类方法发展历程，并给出了一些代表性方法。时间轴以上为基于直接视锥空间的方法，时间轴以下为基于显式逆投影空间的方法。图中箭头越长表示该方法在KITTI数据集（Geiger等，2012）中等难度车辆类别上的平均精度（Average Precision，AP）越高。<br><img src="https://img-blog.csdnimg.cn/bdbe9e973b574c43b0e20656433f1729.png" alt="在这里插入图片描述"></p><h2 id="1-基于直接视锥空间的双目目标检测方法"><a href="#1-基于直接视锥空间的双目目标检测方法" class="headerlink" title="1 基于直接视锥空间的双目目标检测方法"></a>1 基于直接视锥空间的双目目标检测方法</h2><pre><code>     基于直接视锥空间的双目目标检测不需要进行额外的坐标空间转换，只需要使用基础骨干提取的两个单目特征构造双目特征。现有方法主要通过串接和平面扫描两种方式构造视锥空间的双目特征。</code></pre><h3 id="1-1-基于串接构造视锥空间特征的方法"><a href="#1-1-基于串接构造视锥空间特征的方法" class="headerlink" title="1.1 基于串接构造视锥空间特征的方法"></a>1.1 基于串接构造视锥空间特征的方法</h3><pre><code>     基于串接构造视锥空间特征的方法将基础骨干提取的两个单目视锥空间特征串接起来，利用卷积神经网络强大的拟合能力提取候选框或直接检测三维目标。串接操作不改变原单目特征的坐标空间，是一种简单快速的视锥空间双目特征构造方式。</code></pre><p><img src="https://img-blog.csdnimg.cn/24bb465a5e7b433bbf176d2ebb0956b0.png" alt="在这里插入图片描述"><br>        Li等人（2019b）提出两阶段方法Stereo R-CNN。在第一阶段，Stereo R-CNN利用串接特征得到左右两个成对的候选框。在第二阶段，Stereo R-CNN分别提取左右目的RoI特征，再次串接特征进行回归。为了得到三维框顶点在左目RoI特征内的投影，Stereo R-CNN引入了一种简化的关键点检测网络，利用得到的关键点信息对最小化投影误差进行数值求解，从而得到质量较高的三维目标检测结果。<br>        Shi等人（2021）借鉴Stereo R-CNN双目候选框定义双目包围框，并提出类似于CenterNet（Zhou等，2019a）的单阶段无锚点框双目检测方法StereoCenterNet。StereoCenterNet在串接的双目特征上预测双目二维框和三位维框的朝向、尺寸、底面顶点等信息。预测这些信息后，<br>        StereoCenterNet根据物体遮挡程 度不同采用对应的策略来进行最小化投影误差求解，提高了严重遮挡物体的检测精度。</p><h2 id="2-基于显式逆投影空间的双目目标检测方法"><a href="#2-基于显式逆投影空间的双目目标检测方法" class="headerlink" title="2 基于显式逆投影空间的双目目标检测方法"></a>2 基于显式逆投影空间的双目目标检测方法</h2><pre><code>     在自动驾驶等场景中，感兴趣的目标（如车辆、行人、骑行者等）在三维空间中没有重叠。因此，将存在尺度变化和遮挡问题的视锥空间图像逆投影到尺度均匀、不存在重叠遮挡的三维空间，能够缓解视锥投影带来的问题。此外，考虑俯视方向上不存在遮挡问题，我们还可以把三维空间压缩至俯视二维空间，在保证性能的同时进一步简化预测网络。逆投影变换主要可以应用在输入图像、特征、候选区域三个不同环节。图3给出了三种方案的示意图。</code></pre><p><img src="https://img-blog.csdnimg.cn/f912bdae95d14f24b53fe4469fbd83c5.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/b99d92478704469b949759ba662c1758.png" alt="在这里插入图片描述"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;第十章 双目视觉测量&lt;/p&gt;</summary>
    
    
    
    <category term="机器视觉" scheme="https://du2279664786.github.io/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    
    <category term="机器视觉" scheme="https://du2279664786.github.io/tags/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    <category term="期末考试" scheme="https://du2279664786.github.io/tags/%E6%9C%9F%E6%9C%AB%E8%80%83%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>第十七章　遗传算法</title>
    <link href="https://du2279664786.github.io/posts/f8b424f8.html"/>
    <id>https://du2279664786.github.io/posts/f8b424f8.html</id>
    <published>2022-12-15T14:55:10.000Z</published>
    <updated>2022-12-16T06:31:16.692Z</updated>
    
    <content type="html"><![CDATA[<p>第十七章　遗传算法</p><span id="more"></span><h1 id="第17章-遗传算法"><a href="#第17章-遗传算法" class="headerlink" title="第17章　遗传算法"></a>第17章　遗传算法</h1><p>11.25 (1)PPT</p><p>遗传算法(Genetic Algorithm）是模拟达尔文生物进化论的自然选择和遗传学机理的生物进化过程的计算模型，是一种通过模拟自然进化过程搜索最优解的方法。[1遗传算法是从代表问题可能潜在的解集的一个种群（ population）开始的，而一个种群则由经过基因(gene）编码的一定数目的个体(individual)组成。每个个体实际上是染色体(chromosome)带有特征的实体。染色体作为遗传物质的主要载体，即多个基因的集合，其内部表现〈即基因型〉是某种基因组合，决定了个体的形状的外部表现。在一开始需要实现从表现型到基因型的映射即编码工作。由于仿照基因编码的工作很复杂，我们往往进行简化，如二进制编码，初代种群产生之后，按照适者生存和优胜劣汰的原理，逐代(generation）演化产生出越来越好的近似解，在每一代，根据问题域中个体的适应度〈 fitness）大小选择〈selection&gt;个体，并借助于自然遗传学的遗传算子(genetic operators）进行组合交叉( crossover〉和变异( mutation)，产生出代表新的解集的种群。</p><h2 id="运算过程"><a href="#运算过程" class="headerlink" title="运算过程"></a>运算过程</h2><p>遗传算法(GeneticAlgorithm)是一类借鉴生物界的进化规律（适者生存，优胜劣汰遗传机制〉演化而来的随材化搜索方法。它是由美国的J.Holland教授1975年首先提出，其主要特点是直接对结构对象进行操作，不存在求导和函数连续性的限定﹔具有内在的隐并行性和更好的全局寻优能力﹔采用概率化的寻优方法，能自动获取和指导优化的搜索空间，自适应地调整搜索方向，不需要确定的规则。遗传算法的这些性质，已被人们广泛地应用于组合优化、机器学习、信号处理、自适应控制和人工生命等领域。它是现代有关智能计算中的关键技术。<br>对于一个求函数最大值的优化问题〈求函数最小值也类同〉，一般可以描述为下列数学规划模型:</p><p><img src="https://s2.loli.net/2022/12/16/JIbOuX9oDRYEN4V.png" alt="Snipaste_2022-12-16_13-45-50.png"></p><p>式中X为决策变量，为max f(x)目标函数式，X∈R、RcU为约束条件，u是基本空间，R是u的子集。满足约束条件的解X称为可行解，集合R表示所有满足约束条件的解所组成的集合，称为可行解集合。</p><p>遗传算法也是计算机科学人工智能领域中用于解决最优化的一种搜索启发式算法，是进化算法的一种。这种启发式通常用来生成有用的解决方案来优化和搜索问题。进化算法最初是借鉴了进化生物学中的一些现象而发展起来的，这些现象包括遗传、突变、自然选择以及杂交等。遗传算法在适应度函数选择不当的情况下有可能收敛于局部最优，而不能达到全局最优。遗传算法的基本运算过程如下:<br>    a初始化:设置进化代数计数器t&#x3D;0，设置最大进化代数T，随机生成M个个体作为初始群体P(0)。<br>    b)个体评价:计算群体P(t)中各个个体的适应度。<br>    c)选择运算∶将选择算子作用于群体。选择的目的是把优化的个体直接遗传到下一代或通过配对交叉产生新的个体再遗传到下一代。选择操作是建立在群体中个体的适应度评估基础上的。<br>    d)交叉运算:将交叉算子作用于群体。遗传算法中起核心作用的就是交叉算子。<br>    e)变异运算:将变异算子作用于群体。即是对群体中的个体串的某些基因座上的基因值作变动。群体P(t)经过选择、交叉、变异运算之后得到下一代群体P(t+1)。<br>    f)终止条件判断:若t&#x3D;T.则以进化过程中所得到的具有最大适应度个体作为最优解输出，终止计算。</p><h2 id="遗传算法特点"><a href="#遗传算法特点" class="headerlink" title="遗传算法特点"></a>遗传算法特点</h2><p>遗传算法是解决搜索问题的一种通用算法，对于各种通用问题都可以使用。搜索算法的共同特征为:<br>①首先组成一组候选解<br>2依据某些适应性条件测算这些候选解的适应度<br>③根据适应度保留某些候选解，放弃其他候选解<br>对保留的候选解进行某些操作，生成新的候选解。</p><p>在遗传算法中，上述几个特征以一种特殊的方式组合在一起:基于染色体群的并行搜索，带有猜测性质的选择操作、交换操作和突变操作。这种特殊的组合方式将遗传算法与其它搜索算法区别开来。<br>遗传算法还具有以下几方面的特点:<br>(1)遗传算法从问题解的串集开始搜索，而不是从单个解开始。这是遗传算法与传统优化算法的极大区别。传统优化算法是从单个初始值迭代求最优解的﹔容易误入局部最优解。遗传算法从串集开始搜索，覆盖面大，利于全局择优。<br>(2)遗传算法同时处理群体中的多个个体，即对搜索空间中的多个解进行评估，减少了陷入局部最优解的风险，同时算法本身易于实现并行化。</p><p>(3)遗传算法基本上不用搜索空间的知识或其它辅助信息，而仅用适应度函数值来评估个体，在此基础上进行遗传操作。适应度函数不仅不受连续可微的约束，而且其定义域可以任意设定。这一特点使得遗传算法的应用范围大大扩展。<br>(4)遗传算法不是采用确定性规则，而是采用概率的变迁规则来指导他的搜索方向。<br>(5)具有自组织、自适应和自学习性。遗传算法利用进化过程获得的信息自行组织搜索时，适应度大的个体具有较高的生存概率，并获得更适应环境的基因结构。<br>(6)此外，算法本身也可以采用动态自适应技术，在进化过程中自动调整算法控制参数和编码精度，比如使用模糊自适应法</p><h2 id="基本框架"><a href="#基本框架" class="headerlink" title="基本框架"></a>基本框架</h2><p>编码<br>遗传算法不能直接处理问题空间的参数，必须把它们转换成遗传空间的由基因按一定结构组成的染色体或个体。这一转换操作就叫做编码，也可以称作（问题的）表示(representation)。</p><p>评估编码策略常采用以下3个规范:<br>a)完备性(completeness):问题空间中的所有点(候选解)都能作为GA空间中的点(染色体)表现。<br>b)健全性(soundness): GA空间中的染色体能对应所有问题空间中的候选解。</p><p>c)非冗余性(nonredundancy);:染色体和候选解一—对应。<br>目前的几种常用的编码技术有二进制编码，浮点数编码，字符编码，变成编码等。</p><p>遗传算法简称GA (Genetic Algorithms）模拟自然界生物遗传学（孟德尔）和生物进化论(达尔文)通过人工方式所构造的一类并行随机搜索最优化方法，是对生物进化过程“优胜劣汰，适者生存”这—过程进行的一种数学仿真。</p><p>基本操作&#x3D;&#x3D;1.复制&#x3D;&#x3D;:复制是从一个旧种群中选择生命力强的个体位串产生新种群的过程。具有高适应度的位串更有可能在下一代中产生一个或多个子孙。(从旧种群中选择出优秀者，但不能创造新的染色体）复制操作可以通过随机方法来实现。首先产生0-1之间均匀分布的随机数，若某串的复制概率为40%，则当产生的随机数在0~0.40之间时，该串被复制，否则被淘汰。<br>&#x3D;&#x3D;2.交叉&#x3D;&#x3D;∶交叉模拟了生物进化过程中的繁殖现象，通过两个染色体的交换组合，来产生新的优良品种。交叉体现了自然界中信息交换的思想。交叉有单点交叉、两点交叉、还有一致交叉、顺序交叉和周期交叉。单点交叉是最基本的方法，应用较广。它是指在匹配池中任选两个染色体，随机选择一个交换点位置，交换双亲染色体交换点右边的部分，即可得到两个新的染色体，例:</p><p><img src="https://s2.loli.net/2022/12/16/MwYXo5e4WlIsKNL.png" alt="Snipaste_2022-12-16_13-51-26.png"></p><p>3.&#x3D;&#x3D;变异&#x3D;&#x3D;:变异运算用来模拟生物在自然的遗传环境中由于各种偶然因素引起的基因突变，它以很小的概率随机地改变遗传基因（表示染色体的符号串的某一位)的值。在染色体以二进制编码的系统中，变异表现为随机地将染色体的某一个基因由1变为0，或由0变为1。</p><p><img src="https://s2.loli.net/2022/12/16/OUqclgA8yFNk7eh.png" alt="Snipaste_2022-12-16_13-52-24.png"></p><p>&#x3D;&#x3D;注&#x3D;&#x3D;: Gen:遗传（迭代)的代次。表明遗传算法反复执行的次数，即已产生群体的代次数<br>目。M:群体中拥有的个体数目。i:已处理个体的累计数，当i等于M，表明这一代的个体已全部处理完毕，需要转入下一代群体。交叉率$P_c$就是参加交叉运算的染色体个数占全体染色体总数的比例，记为Pc,取值范围一般为0.4<del>0.99。变异率$P_m$是指发生变异的基因位数所占全<br>体染色体的基因总位数的比例，记为Pm，取值范围一般为0.0001</del>0.1。复制概率 $P_t$用于控制复制与淘汰的个体数目。<br>遗传算法主要执行以下四步:(1）随机地建立由字符串组成的初始群体;(2）计算各个体的适应度;(3）根据遗传概率，利用下述操作产生新群体:<br>a.复制。将已有的优良个体复制后添入新群体中，删除劣质个体; b.交换。将选出的两个个体进行交换，所产生的新个体添入新群体中。c.突变。随机地改变某一个体的某个字符后添入新群体中。<br>(4）反复执行(2)、(3)后，一旦达到终止条件，选择最佳个体作为遗传算法的结果。</p><h2 id="算法示例"><a href="#算法示例" class="headerlink" title="算法示例"></a>算法示例</h2><p>求f(x) &#x3D; $x^2$极大值问题，设自变量x介于0~31，求其二次函数的最大值，即: max f(x) &#x3D;$x^2$,xE[0,31]</p><p>(1）编码遗传算法首先要对实际问题进行编码，用字符串表达问题。这种字符串相当于遗传学中的染色体。每一代所产生的字符串个体总和称为群体。为了实现的方便，通常字符串长度固定，字符选0或1。本例中，利用5位二进制数表示x值，采用随机产生的方法，假设得出拥有四个个体的初始群体，即:01101,11000，01000，10011。x值相应为13，24，8，19。</p><p><img src="https://s2.loli.net/2022/12/16/ZI6faKOBu3b8Wio.png" alt="Snipaste_2022-12-16_13-54-22.png"></p><p>(2)计算适应度衡量字符串(染色体）好坏的指标是适应度，它也就是遗传算法的目标函数。例中用$x个2$计算。</p><p><img src="https://s2.loli.net/2022/12/16/x2Bow3Otbu4If1d.png" alt="Snipaste_2022-12-16_13-55-02.png"></p><p>表中还列出了当前适应度的总和$&gt;f(x_i)$及平均值f<br>表中第6列的 f(xi)&#x2F;f 表示每个个体的相对适应度，它反映了个体之间的相对优劣性。如2号个体的f(xi)&#x2F;f值最高(1.97)，为优良个体，3号个体最低(0.22)，为不良个体。</p><p>(3）复制根据相对适应度的大小对个体进行取舍，2号个体性能最优，予以复制繁殖。3号个体性能最差，将它删除，使之死亡，表中的M表示传递给下一代的个体数目，其中2号个体占2个，3号个体为0，1号、4号个体保持为1个。这样，就产生了下一代群体</p><p><img src="https://s2.loli.net/2022/12/16/LKslZYOGToizaF1.png" alt="Snipaste_2022-12-16_13-55-48.png"></p><p>复制后产生的新一代群体的平均适应度明显增加，由原来的293增加到421 (4）交换利用随机配对的方法，决定1号和2号个体、3号和4号个体分别交换，如表中第5列。再利用随机定位的方法，确定这两对母体交叉换位的位置分别从字符长度的第4位及第3位开始。如:3号、4号个体从字符长度第3位开始交换。交换开始的位置称交换点</p><p><img src="https://s2.loli.net/2022/12/16/PstQVOrKMe8cvEL.png" alt="Snipaste_2022-12-16_13-56-21.png">(5）突变将个体字符串某位符号进行逆变，即由1变为0或由0变为1。例如，下式左侧的个体于第3位突变，得到新个体如右侧所示。</p><p>{ 10000 }——{ 10100 }</p><p>遗传算法中，个体是否进行突变以及在哪个部位突变，都由事先给定的概率决定。通常，突变概率很小，本例的第一代中就没有发生突变。<br>上述(2) ~ (5）反复执行，直至得出满意的最优解。<br>综上可以看出，遗传算法参考生物中有关进化与遗传的过程，利用复制、交换、突变等操作，不断循环执行，逐渐逼近全局最优解。</p><h2 id="算法实现"><a href="#算法实现" class="headerlink" title="算法实现"></a>算法实现</h2><p>(1）编码与解码将不同的实数表示成不同的0，1二进制串表示就完成了编码，因此我们并不需要去了解一个实数对应的二进制具体是多少，我们只需要保证有一个映射能够将十进制的数编码为二进制即可。而在最后我们肯定要将编码后的二进制串转换为我们理解的十进制串，所以我们需要的是y &#x3D; f (x)的逆映射，也就是将二进制转化为十进制，也就是解码，十进制与二进制相互映射的关系以下为例进行说明:例如∶对于一个长度为10的二进制串,如[0,0,0,1,0,0,0,0,0,1]，将其映射到[1,3]这个区间1.首先将二进制数按权展开:$0<br>2A9+02^8+02^7+12^6+02个5+02^4+02^3+02个2+0241+12^O&#x3D;65$⒉.然后将其压缩到区间[0,1]: $65&#x2F;(2^{10} - 1) lapprox0.0635386$ 3.最后将[0.1]区间的数映射到我们想要的区间[1,3]: $0.0635386*(3-1) + 1\approx1.12707722$，可以看出规律为: num * (high-<br>low)+low其中num为[0,1]之间的数对应此处的0.0635386，high和low表示我们想要映射的区间的上边界和下边界，分别对应此处的3和1。<br>现在再来看看编码过程。不难看出上面我们的DNA (二进制串)长为10，10位二进制可以表示$2^{10}$种不同的状态，可以看成是将最后要转化为的十进制区间[1，3 ]切分成$2^{10}$份。可看出，如果我们增加二进制串的长度，那么我们对区间的切分可以更加精细，转化后的十进制解也更加精确。所以DNA长度越长，解码为10进制的实数越精确</p><p>另外需要注意的是一个基因可能存储了多个数据的信息，在进行解码时注意将其分开，如一个基因含有x,y两个数据，该基因型的长度为20，可以用前10位表示x，后10位表示y，解码时分开进行解码。<br>(2)）适应度在实际问题中，有时希望适应度越大越好(如赢利、劳动生产率），有时要求适应度越小越好(费用、方差)。为了使遗传算法有通用性，这种最大、最小值问题宜统一表达。通常都统一按最大值问题处理，而且不允许适应度小于0。对于最小值问题，其适应度按下式转换:</p><p><img src="https://s2.loli.net/2022/12/16/J5rInmCQlsxOGa1.png" alt="Snipaste_2022-12-16_13-58-11.png">f(x):转换后的适应度。<br>g(x):最小值问题下的适应度。<br>Cmax:足够大的常数，可取g(x)的最志值年</p><p>为了保证适应度不出现负值，对于有可能产生负值的最大值问题，可以采用下式进行变换</p><p><img src="https://s2.loli.net/2022/12/16/Mtys4wXievgYS31.png" alt="Snipaste_2022-12-16_13-59-01.png">f(x):变换后的适应度。<br>U(x):最大值问题下的适应度。</p><p>Cmin︰足够大的常数。</p><p>(⑶)选择有了适度函数，然后就可以根据某个基因的适应度函数的值与所有基因适应度的总和的比值作为选择的依据，该值大的个体更易被选择，可以通过有放回的随机采样来模拟选择的过程，有放回的随机采样的方式可以参考我的这篇博客:随机采样(4)交叉和变异交叉和变异都是随机发生的，对于交叉而言，随机选择其双亲，并随机选择交叉点位，按照一定的概率进行交叉操作。可以通过以下方式实现:首先选择种群中的每个基因作为父亲，然后通过产生一个[0,1]随机数,将其与定义的交叉概率比较，如果小于该数，则在种群中随机选择另外的母亲，随机选择交叉点位进行交叉。(5)举例利用遗传算法求Rosenbrock函数的极大值</p><p><img src="https://s2.loli.net/2022/12/16/bu9C1ztDdfKTnO8.png" alt="Snipaste_2022-12-16_13-59-41.png"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;第十七章　遗传算法&lt;/p&gt;</summary>
    
    
    
    <category term="机器视觉" scheme="https://du2279664786.github.io/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    
    <category term="机器视觉" scheme="https://du2279664786.github.io/tags/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    <category term="期末考试" scheme="https://du2279664786.github.io/tags/%E6%9C%9F%E6%9C%AB%E8%80%83%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>第15章　神经网络</title>
    <link href="https://du2279664786.github.io/posts/ac78f52c.html"/>
    <id>https://du2279664786.github.io/posts/ac78f52c.html</id>
    <published>2022-12-15T14:55:10.000Z</published>
    <updated>2022-12-16T06:30:43.014Z</updated>
    
    <content type="html"><![CDATA[<p>第15章　神经网络</p><span id="more"></span><h1 id="第15章-神经网络"><a href="#第15章-神经网络" class="headerlink" title="第15章　神经网络"></a>第15章　神经网络</h1><p>人工神经网络（Artificial Neural Network，即ANN）是从信息处理角度对人脑神经元网络进行抽象，建立某种简单模型，按不同的连接方式组成不同的网络，是20世纪80年代以来人工智能领域兴起的研究热点。<br>神经网络是一种运算模型，由大量的节点（或称神经元）之间相互联接构成。随着对人工神经网络的深入研究，其在模式识别、智能机器人、自动控制、生物、医学、经济等领域已成功地解决了许多现代计算机难以解决的实际问题，表现出了良好的智能特性。</p><p><img src="https://s2.loli.net/2022/12/16/2wsBM8jfZp6hDzC.png" alt="Snipaste_2022-12-16_14-23-49.png">如下图所示<br>a1<del>an为输入向量的各个分量<br>w1</del>wn为神经元各个突触的权值<br>b为偏置<br>f为传递函数，通常为非线性函数。以下默认为hardlim()<br>t为神经元输出<br>数学表示 t&#x3D;f(WA’+b)<br>w为权向量<br>A为输入向量，A’为A向量的转置<br>b为偏置<br>f为传递函数</p><p><img src="https://s2.loli.net/2022/12/16/XIdAmZMczwV48Rg.png" alt="Snipaste_2022-12-16_14-24-33.png">可见，一个神经元的功能是求得输入向量与权向量的内积后，经一个非线性传递函数得到一个标量结果。<br>单个神经元的作用:把一个n维向量空间用一个超平面分割成两部分（称之为判断边界），给定一个输入向量，神经元可以判断出这个向量位于超平面的哪一边。<br>该超平面的方程: Wp+b&#x3D;O<br>w权向量<br>b偏置<br>p超平面上的向量</p><h2 id="基本特征"><a href="#基本特征" class="headerlink" title="基本特征"></a>基本特征</h2><p>人工神经网络是由大量处理单元互联组成的非线性、自适应信息处理系统。它是在现代神经科学研究成果的基础上提出的，试图通过模拟大脑神经网络处理、记忆信息的方式进行信息处理。人工神经网络具有四个基本特征:<br>(1）非线性非线性关系是自然界的普遍特性。大脑的智慧就是一种非线性现象。人工神经元处于激活或抑制二种不同的状态，这种行为在数学上表现为一种非线性关系。具有阈值的神经元构成的网络具有更好的性能，可以提高容错性和存储容量。<br>(2）非局限性一个神经网络通常由多个神经元广泛连接而成。一个系统的整体行为不仅取决于单个神经元的特征，而且可能主要由单元之间的相互作用、相互连接所决定。通过单元之间的大量连接模拟大脑的非局限性。联想记忆是非局限性的典型例子。<br>(3）非常定性人工神经网络具有自适应、自组织、自学习能力。神经网络不但处理的信息可以有各种变化，而且在处理信息的同时，非线性动力系统本身也在不断变化。经常采用迭代过程描写动力系统的演化过程。</p><p>(4）非凸性一个系统的演化方向，在一定条件下将取决于某个特定的状态函数。例如能量函数，它的极值相应于系统比较稳定的状态。非凸性是指这种函数有多个极值，故系统具有多个较稳定的平衡态，这将导致系统演化的多样性。</p><p>人工神经网络中，神经元处理单元可表示不同的对象，例如特征、字母、概念，或者一些有意义的抽象模式。网络中处理单元的类型分为三类:输入单元、输出单元和隐单元。输入单元接受外部世界的信号与数据；输出单元实现系统处理结果的输出﹔隐单元是处在输入和输出单元之间，不能由系统外部观察的单元。神经元间的连接权值反映了单元间的连接强度，信息的表示和处理体现在网络处理单元的连接关系中。人工神经网络是一种非程序化、适应性、大脑风格的信息处理，其本质是通过网络的变换和动力学行为得到一种并行分布式的信息处理功能，并在不同程度和层次上模仿人脑神经系统的信息处理功能。它是涉及神经科学、思维科学、人工智能、计算机科学等多个领域的交叉学科。<img src="https://s2.loli.net/2022/12/16/SNFheEow3LnXCJa.png" alt="Snipaste_2022-12-16_14-26-51.png"></p><p>人工神经网络是并行分布式系统，采用了与传统人工智能和信息处理技术完全不同的机理，克服了传统的基于逻辑符号的人工智能在处理直觉、非结构化信息方面的缺陷，具有自适应、自组织和实时学习的特点。[1]</p><h2 id="网络模型"><a href="#网络模型" class="headerlink" title="网络模型"></a>网络模型</h2><p>人工神经网络模型主要考虑网络连接的拓扑结构、神经元的特征、学习规则等。目前，已有近40种神经网络模型，其中有反传网络、感知器、自组织映射、Hopfield网络、波耳兹曼机、适应谐振理论等。根据连接的拓扑结构，神经网络模型可以分为:[1]<img src="https://s2.loli.net/2022/12/16/IhoJyTlaMj8LBCs.png" alt="Snipaste_2022-12-16_14-28-00.png"></p><h2 id="特点优点"><a href="#特点优点" class="headerlink" title="特点优点"></a>特点优点</h2><p>人工神经网络的特点和优越性，主要表现在三个方面:第一，具有自学习功能。例如实现图像识别时，只在先把许多不同的图像样板和对应的应识别的结果输入人工神经网络，网络就会通过自学习功能，慢慢学会识别类似的图像。自学习功能对于预测有特别重要的意义。预期未来的人工神经网络计算机将为人类提供经济预测、市场预测、效益预测，其应用前途是很远大的。<br>第二，具有联想存储功能。用人工神经网络的反馈网络就可以实现这种联想。<br>第三，具有高速寻找优化解的能力。寻找一个复杂问题的优化解，往往需要很大的计算量，利用一个针对某问题而设计的反馈型人工神经网络，发挥计算机的高速运算能力，可能很快找到有化解</p><p><img src="https://s2.loli.net/2022/12/16/B9SzlNYJUW82tKb.png" alt="Snipaste_2022-12-16_14-29-08.png"></p><p>神经网络的研究可以分为理论研究和应用研究两大方面。理论研究可分为以下两类:[4]<br>1、利用神经生理与认知科学研究人类思维以及智能机理。<br>2、利用神经基础理论的研究成果，用数理方法探索功能更加完善、性能更加优越的神经网络模型，深入研究网络算法和性能，如:稳定性、收敛性、容错性、鲁棒性等﹔开发新的网络数理理论，如:神经网络动力学、非线性神经场等。<br>应用研究可分为以下两类:<br>1、神经网络的软件模拟和硬件实现的研究。<br>2、神经网络在各个领域中应用的研究。这些领域主要包括</p><p>:模式识别、信号处理、知识工程、专家系统、优化组合、机器人控制等。随看神经网给理比伞列人反B人理论、相关技术的不断发展，神经网络的应用定将更加深入。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;第15章　神经网络&lt;/p&gt;</summary>
    
    
    
    <category term="机器视觉" scheme="https://du2279664786.github.io/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    
    <category term="机器视觉" scheme="https://du2279664786.github.io/tags/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    <category term="期末考试" scheme="https://du2279664786.github.io/tags/%E6%9C%9F%E6%9C%AB%E8%80%83%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>第十五章　深度学习</title>
    <link href="https://du2279664786.github.io/posts/c4ed1baa.html"/>
    <id>https://du2279664786.github.io/posts/c4ed1baa.html</id>
    <published>2022-12-15T14:55:10.000Z</published>
    <updated>2022-12-16T06:31:44.404Z</updated>
    
    <content type="html"><![CDATA[<p>第十五章　深度学习</p><span id="more"></span><h1 id="第15章-深度学习"><a href="#第15章-深度学习" class="headerlink" title="第15章　深度学习"></a>第15章　深度学习</h1><p>深度学习(deep learning）是机器学习的分支，是一种以人工神经网络为架构，对数据进行表征学习的算法。<br>至今已有数种深度学习框架，如深度神经网络、卷积神经网络和深度置信网络和递归神经网络已被应用在计算机视觉、语音识别、自然语言处理、音频识别与生物信息学等领域并获取了极好的效果。另外，”深度学习”已成为类似术语，或者说是神经网络的品牌重塑。<br>深度学习正在推动人工智能进入工业化大生产阶段，具有很强的通用性，同时具备了标准化、自动化和模块化的基本特征。[1]</p><h2 id="解释"><a href="#解释" class="headerlink" title="解释"></a>解释</h2><p>通过多层处理，逐渐将初始的“低层”特征表示转化为“高层”特征表示后，用简单模型”即可完成复杂的分类等学习任务。由此可将深度学习理解为进行”特征学习”( feature learning）或“表示学习””( representation learning)。<br>以往在机器学习用于现实任务时，描述样本的特征通常需由人类专家来设计，这成为”特征工程”( feature engineering）。众所周知，特征的好坏对泛化性能有至关重要的影响，人类专家设计出好特征也并非易事﹔特征学习(表征学习）则通过机器学习技术自身来产生好特征，这使机器学习向“全自动数据分析”又前进了一步。</p><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>机器学习(Machine Learning）是一门专门研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构使之不断改善自身的性能的学科。<br>机器能否<br>像人类一样能具有学习能力呢?1959年美国的塞缪尔(Samuel)设计了一个下棋程序，这个程序具有学习能力，它可以在不断的对弈中改善自己的棋艺。4年后，这个程序战胜了设计者本人。又过了3年，这个程序战胜了美国一个保持8年之久的常胜不败的冠军。这个程序向人们展示了机器学习的能力，提出了许多令人深思的社会问题与哲学问题。[2]</p><h2 id="深度概念"><a href="#深度概念" class="headerlink" title="深度概念"></a>深度概念</h2><p>从一个输入中产生一个输出所涉及的计算可以通过一个流向图(flow graph)来表示:流向图是一种能够表示计算的图，在这种图中每一个节点表示一个基本的计算以及一个计算的值，计算的<br>结果被应用到这个节点的子节点的值。考虑这样一个计算集合，它可以被允许<br>在每一个节点和可能的图结构中，并定义了一个函数族。输入节点没有父节点，输出节点没有子节点。</p><p>这种流向图的一个特别属性是深度(depth):从一个输入到一个输出的最长路径的长度。<br>传统的前馈神经网络能够被看做拥有等于层数的深度(比如对于输出层为隐层数加1)。SVMs有深度2(一个对应于核输出或者特征空间，另一个对应于所产生输出的线性混合)。<br>人工智能研究的方向之一，是以所谓“专家系统”为代表的，用大量”如果-就”(lf - Then)规则定义的，自上而下的思路。人工神经网络( Artifical Neural Network)，标志着另外一种自下而上的思路。神经网络没有一个严格的正式定义。它的基本特点，是试图模仿大脑的神经元之间传递，处理信息的模式。</p><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>需要使用深度学习解决的问题有以下的特征:<br>深度不足会出现问题。<br>人脑具有一个深度结构。<br>认知过程逐层进行，逐步抽象。深度不足会出现问题<br>在许多情形中深度2就足够表示任何一个带有给定目标精度的函数。但是其代价是:图中所需要的节点数(比如计算和参数数量)可能变的非常大。理论结果证实那些事实上所需要的节点数随着输入的大小指数增长的函数族是存在的。</p><p>我们可以将深度架构看做一种因子分解。大部分随机选择的函数不能被有效地表示，无论是用深的或者浅的架构。但是许多能够有效地被深度架构表示的却不能被用浅的架构高效表示。一个紧的和深度的表示的存在意味着在潜在的可被表示的函数中存在某种结构。如果不存在任何结构，那将不可能很好地泛化。</p><p>大脑有一个深度架构<br>例如，视觉皮质得到了很好的研究，并显示出一系列的区域，在每一个这种区域中包含一个输入的表示和从一个到另一个的信号流(这里忽略了在一些层次并行路径上的关联，因此更复杂)。这个特征层次的每一层表示在一个不同的抽象层上的输入，并在层次的更上层有着更多的抽象特征，他们根据低层特征定义。<br>需要注意的是大脑中的表示是在中间紧密分布并且纯局部:他们是稀疏的:1%的神经元是同时活动的。给定大量的神经元，仍然有一个非常高效地(指数级高效)表示。<br>认知过程逐层进行，逐步抽象<br>人类层次化地组织思想和概念;<br>人类首先学习简单的概念，然后用他们去表示更抽象的;工程师将任务分解成多个抽象层次去处理;<br>学习&#x2F;发现这些概念(知识工程由于没有反省而失败?)是很美好的。对语言可表达的概念的反省也建议我们一个稀疏的表示:仅所有可能单词&#x2F;概念中的一个小的部分是可被应用到一个特别的输入(一个视觉场景)。</p><h2 id="基本思想"><a href="#基本思想" class="headerlink" title="基本思想"></a>基本思想</h2><p>假设我们有一个系统s，它有n层(S1,….n），它的输入是l，输出是o,形象地表示为:l &#x3D;&gt;S1&#x3D;&gt;S2&#x3D;&gt;…..&#x3D;&gt;Sn &#x3D;&gt; o，如果输出O等于输入l，即输入l经过这个系统变化之后没有任何的信息损失，设处理a信息得到b，再对b处理得到c，那么可以证明: a和c的互信息不会超过a和b的互信息。这表明信息处理不会增加信息，大部分处理会丢失信息。保持了不变，这意味着输入l经过每一层Si都没有任何的信息损失，即在任何一层si，它都是原有信息《即输入I)的另外一种表示。现在回到主题Deep Learning，需要自动地学习特征，假设我们有一堆输入l〈如一堆图像或者文本〉，假设设计了一个系统S(有n层〉，通过调整系统中参数，使得它的输出仍然是输入l，那么就可以自动地获取得到输入l的一系列层次特征，即S1，…, sn。[2]</p><p>对于深度学习来说，其思想就是对堆桑多个层，也就是说这一层的输出作为下一层的输入。通过这种方式，就可以实现对输入信息进行分级表达了。[2]<br>另外，前面是假设输出严格地等于输入，这个限制太严格，可以略微地放松这个限制，例如只要使得输入与输出的差别尽可能地小即可，这个放松会导致另外一类不同的Deep Learning方法。上述就是Deep Learning的基本思想。[2]把学习结构看作一个网络，则深度学习的核心思路如下:<br>无监督学习用于每一层网络的pre-train ;<br>2每次用无监督学习只训练一层，将其训练结果作为其高一层的输产</p><p>③用自顶而下的监督算法去调整所有层</p><h2 id="主要技术"><a href="#主要技术" class="headerlink" title="主要技术"></a>主要技术</h2><p>线性代数、概率和信息论<br>欠拟合、过拟合、正则化<br>最大似然估计和贝叶斯统计<br>随机梯度下降<br>监督学习和无监督学习<br>深度前馈网络、代价函数和反向传播<br>正则化、稀疏编码和dropout<br>自适应学习算法</p><p>卷积神经网络<br>循环神经网络<br>递归神经网络<br>深度神经网络和深度堆桑网络<br>LSTM长短时记忆<br>主成分分析<br>正则自动编码器<br>表征学习<br>蒙特卡洛<br>受限波兹曼机<br>深度置信网络</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;第十五章　深度学习&lt;/p&gt;</summary>
    
    
    
    <category term="机器视觉" scheme="https://du2279664786.github.io/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    
    <category term="机器视觉" scheme="https://du2279664786.github.io/tags/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    <category term="期末考试" scheme="https://du2279664786.github.io/tags/%E6%9C%9F%E6%9C%AB%E8%80%83%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>Web攻击检测与分类识别思路</title>
    <link href="https://du2279664786.github.io/posts/d0147289.html"/>
    <id>https://du2279664786.github.io/posts/d0147289.html</id>
    <published>2022-12-05T14:55:10.000Z</published>
    <updated>2022-12-05T04:20:40.266Z</updated>
    
    <content type="html"><![CDATA[<p>CCF BDCI Web攻击检测与分类识别 Top8思路</p><span id="more"></span><h1 id="CCF-BDCI-Web攻击检测与分类识别-Top8思路"><a href="#CCF-BDCI-Web攻击检测与分类识别-Top8思路" class="headerlink" title="CCF BDCI Web攻击检测与分类识别 Top8思路"></a>CCF BDCI Web攻击检测与分类识别 Top8思路</h1><p><strong>赛题地址</strong>：<a href="https://www.datafountain.cn/competitions/596">https://www.datafountain.cn/competitions/596</a></p><p><img src="https://s2.loli.net/2022/12/05/FHOr3m67MXeTv4w.png" alt="Snipaste_2022-12-05_12-05-48.png"></p><h2 id="赛题背景："><a href="#赛题背景：" class="headerlink" title="赛题背景："></a>赛题背景：</h2><p>某业务平台平均每月捕获到Web攻击数量超过2亿，涉及常见注入攻击，代码执行等类型。传统威胁检测手段通过分析已知攻击特征进行规则匹配，无法检测未知漏洞或攻击手法。如何快速准确地识别未知威胁攻击并且将不同攻击正确分类，对提升Web攻击检测能力至关重要。利用机器学习和深度学习技术对攻击报文进行识别和分类已经成为解决该问题的创新思路，有利于推动AI技术在威胁检测分析场景的研究与应用。</p><h2 id="赛题任务："><a href="#赛题任务：" class="headerlink" title="赛题任务："></a>赛题任务：</h2><p>参赛团队需要对前期提供的训练集进行分析，通过特征工程、机器学习和深度学习等方法构建AI模型，实现对每一条样本正确且快速分类，不断提高模型精确率和召回率。待模型优化稳定后，通过无标签测试集评估各参赛团队模型分类效果，以正确率评估各参赛团队模型质量。</p><h2 id="决赛答辩："><a href="#决赛答辩：" class="headerlink" title="决赛答辩："></a>决赛答辩：</h2><p>决赛答辩中，评审专家将根据答辩作品的创新性、可用性等进行打分；最终成绩将综合考虑初赛成绩、创新性、可用性等方面确定最终排名，最终成绩 &#x3D; 初赛复现成绩 * 80% + 决赛成绩 * 20%。<br>注意，答辩着重考察以下方面：<br>(1) 模型发现未知攻击类型的能力<br>(2) 模型的时间复杂度<br>(3) 其他创新</p><h2 id="数据简介"><a href="#数据简介" class="headerlink" title="数据简介"></a>数据简介</h2><p>赛题训练集分为6种不同标签，共计约3.5万条数据。训练数据集字段内容主要包括：<br>●　ID：样本编号<br>●　label：攻击类型编号<br>●　其他：HTTP协议内容</p><h2 id="评测标准"><a href="#评测标准" class="headerlink" title="评测标准"></a>评测标准</h2><p>评比期间将提供无标签测试集，参赛团队需提交对该测试集每条数据的模型分类结果，即每条数据中增加一个predict字段（模型分类结果），与训练集label字段含义保持一致。<br>评估程序将模型预测结果predict与标准答案label对比，统计精确率、召回率和F1，最终以F1为准。</p><table><thead><tr><th align="center">标签</th><th align="center">分类为正标签</th><th align="center">分类为负标签</th></tr></thead><tbody><tr><td align="center">正标签</td><td align="center">TP</td><td align="center">FN</td></tr><tr><td align="center">负标签</td><td align="center">FP</td><td align="center">TN</td></tr></tbody></table><p>精确率计算公式：Precision &#x3D; TP&#x2F;(TP + FP)<br>召回率计算公式：Recall &#x3D; TP&#x2F;(TP + FN)<br>F1计算公式：F1 &#x3D; 2 * Precision * Recall&#x2F;(Precision + Recall)<br>注：该F1为 macro F1</p><h1 id="代码如下"><a href="#代码如下" class="headerlink" title="代码如下"></a>代码如下</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># lgb删掉tfidf+refer：线下0.9644，线上0.95997</span></span><br><span class="line"><span class="comment"># lgb未删tfidf+refer：线下0.96432，线上0.95828</span></span><br><span class="line"><span class="comment"># xgb:线下0.96494</span></span><br><span class="line"><span class="comment"># cat:线下9650，线上0.9613</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> lightgbm <span class="keyword">as</span> lgb</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> lightgbm <span class="keyword">import</span> early_stopping</span><br><span class="line"><span class="keyword">from</span> lightgbm <span class="keyword">import</span> log_evaluation</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> TruncatedSVD</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score,f1_score</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedKFold</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">from</span> user_agents <span class="keyword">import</span> parse</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"><span class="keyword">from</span> catboost <span class="keyword">import</span> CatBoostClassifier</span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> quote, unquote, urlparse</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> glob  </span><br><span class="line"></span><br><span class="line">pd.set_option(<span class="string">&#x27;display.max_columns&#x27;</span>, <span class="literal">None</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># iPhone的UserAgent</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_ua</span>(<span class="params">row</span>):</span><br><span class="line">    user_agent = parse(row[<span class="string">&#x27;user_agent&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    browser_family=<span class="built_in">str</span>(user_agent.browser.family)</span><br><span class="line">    os_family=<span class="built_in">str</span>(user_agent.os.family)</span><br><span class="line">    device_family=<span class="built_in">str</span>(user_agent.device.family)</span><br><span class="line">    device_brand=<span class="built_in">str</span>(user_agent.device.brand)</span><br><span class="line">    device_model=<span class="built_in">str</span>(user_agent.device.model)</span><br><span class="line">    <span class="keyword">return</span> browser_family,os_family,device_family,device_brand,device_model</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">prob = np.load(<span class="string">&#x27;E://data//DF//Web攻击检测与分类识别//large/deberta-v3-large_probs.npy&#x27;</span>)</span><br><span class="line">prob.shape</span><br></pre></td></tr></table></figure><pre><code>(4000, 6)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">train=pd.read_pickle(<span class="string">&#x27;E:\\data\\DF\\Web攻击检测与分类识别/large/oof_df.pkl&#x27;</span>)     <span class="comment"># 33037 rows × 15 columns</span></span><br><span class="line">sub = pd.read_csv(<span class="string">&#x27;E:\\data\\DF\\Web攻击检测与分类识别\\submit_example (10).csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line">test=pd.read_csv(<span class="string">&#x27;E:\\data\\DF\\Web攻击检测与分类识别/test.csv&#x27;</span>)</span><br><span class="line">train.head()</span><br></pre></td></tr></table></figure><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>id</th>      <th>method</th>      <th>user_agent</th>      <th>url</th>      <th>refer</th>      <th>body</th>      <th>label</th>      <th>text</th>      <th>fold</th>      <th>0</th>      <th>1</th>      <th>2</th>      <th>3</th>      <th>4</th>      <th>5</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>13429</td>      <td>GET</td>      <td>'||(select 1 from (select pg_sleep(8))x)||'</td>      <td>/kelev/scripts/?C=M%3BO%3DA</td>      <td>NAN</td>      <td>GET /kelev/scripts/?C=M%3BO%3DA HTTP/1.1 Accep...</td>      <td>1</td>      <td>method:GET[SEP]user_agent:'||(select 1 from (s...</td>      <td>0</td>      <td>0.000238</td>      <td>0.999110</td>      <td>0.000445</td>      <td>0.000058</td>      <td>0.000040</td>      <td>0.000110</td>    </tr>    <tr>      <th>1</th>      <td>18125</td>      <td>GET</td>      <td>Dalvik/2.1.0 (Linux; U; Android 11; M2102K1C B...</td>      <td>/livemsg?ad_type=WL_WK&amp;oadid=&amp;ty=web&amp;pu=0&amp;adap...</td>      <td>NAN</td>      <td>GET /livemsg?ad_type=WL_WK&amp;oadid=&amp;ty=web&amp;pu=0&amp;...</td>      <td>1</td>      <td>method:GET[SEP]user_agent:Dalvik/2.1.0 (Linux;...</td>      <td>0</td>      <td>0.006598</td>      <td>0.992451</td>      <td>0.000763</td>      <td>0.000086</td>      <td>0.000067</td>      <td>0.000035</td>    </tr>    <tr>      <th>2</th>      <td>14538</td>      <td>GET</td>      <td>Dalvik/2.1.0 (Linux; U; Android 11; M2011K2C B...</td>      <td>/livemsg?ad_type=WL_WK&amp;ty=web&amp;pu=0&amp;openudid=d2...</td>      <td>NAN</td>      <td>GET /livemsg?ad_type=WL_WK&amp;ty=web&amp;pu=0&amp;openudi...</td>      <td>1</td>      <td>method:GET[SEP]user_agent:Dalvik/2.1.0 (Linux;...</td>      <td>0</td>      <td>0.000783</td>      <td>0.999017</td>      <td>0.000138</td>      <td>0.000031</td>      <td>0.000017</td>      <td>0.000013</td>    </tr>    <tr>      <th>3</th>      <td>7127</td>      <td>GET</td>      <td>Dalvik/2.1.0 (Linux; U; Android 10; MI 9 MIUI/...</td>      <td>/livemsg?ad_type=WL_WK&amp;oadid=&amp;ty=web&amp;pu=0&amp;adap...</td>      <td>NAN</td>      <td>NAN</td>      <td>1</td>      <td>method:GET[SEP]user_agent:Dalvik/2.1.0 (Linux;...</td>      <td>0</td>      <td>0.007603</td>      <td>0.991491</td>      <td>0.000725</td>      <td>0.000087</td>      <td>0.000062</td>      <td>0.000033</td>    </tr>    <tr>      <th>4</th>      <td>7</td>      <td>GET</td>      <td>Dalvik/2.1.0 (Linux; U; Android 10; ELS-AN00 B...</td>      <td>/livemsg?sdtfrom=v5004&amp;ad_type=WL_WK&amp;oadid=&amp;ty...</td>      <td>NAN</td>      <td>GET /livemsg?sdtfrom=v5004&amp;ad_type=WL_WK&amp;oadid...</td>      <td>1</td>      <td>method:GET[SEP]user_agent:Dalvik/2.1.0 (Linux;...</td>      <td>0</td>      <td>0.000529</td>      <td>0.999257</td>      <td>0.000153</td>      <td>0.000020</td>      <td>0.000021</td>      <td>0.000019</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">test.head()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>id</th>      <th>method</th>      <th>user_agent</th>      <th>url</th>      <th>refer</th>      <th>body</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>0</td>      <td>GET</td>      <td>Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...</td>      <td>/demo/aisec/upload.php?act='%7C%7C(select+1+fr...</td>      <td>http://demo.aisec.cn/demo/aisec/upload.php?t=0...</td>      <td>GET /demo/aisec/upload.php?act='%7C%7C(select+...</td>    </tr>    <tr>      <th>1</th>      <td>1</td>      <td>GET</td>      <td>Dalvik/2.1.0 (Linux; U; Android 11; M2102J2SC ...</td>      <td>/livemsg?ad_type=WL_WK&amp;ty=web&amp;pu=1&amp;openudid=5f...</td>      <td>NaN</td>      <td>GET /livemsg?ad_type=WL_WK&amp;ty=web&amp;pu=1&amp;openudi...</td>    </tr>    <tr>      <th>2</th>      <td>2</td>      <td>GET</td>      <td>Mozilla/5.0 (Windows NT 10.0; rv:78.0) Gecko/2...</td>      <td>/create_user/?username=%3Cscript%3Ealert(docum...</td>      <td>NaN</td>      <td>NaN</td>    </tr>    <tr>      <th>3</th>      <td>3</td>      <td>GET</td>      <td>NaN</td>      <td>/mmsns/WeDwicXmkOl4kjKsBycicI0H3q41r6syFFvu46h...</td>      <td>NaN</td>      <td>NaN</td>    </tr>    <tr>      <th>4</th>      <td>4</td>      <td>PUT</td>      <td>Mozilla/5.0 (Windows NT 10.0; rv:78.0) Gecko/2...</td>      <td>/naizau.jsp/</td>      <td>NaN</td>      <td>GET /login HTTP/1.1 Host: 111.160.211.18:8088 ...</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train.isnull().<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure><pre><code>id            0method        0user_agent    0url           0refer         0body          0label         0text          0fold          00             01             02             03             04             05             0dtype: int64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train.columns</span><br></pre></td></tr></table></figure><pre><code>Index([&#39;id&#39;, &#39;method&#39;, &#39;user_agent&#39;, &#39;url&#39;, &#39;refer&#39;, &#39;body&#39;, &#39;label&#39;, &#39;text&#39;,       &#39;fold&#39;, &#39;0&#39;, &#39;1&#39;, &#39;2&#39;, &#39;3&#39;, &#39;4&#39;, &#39;5&#39;],      dtype=&#39;object&#39;)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">test[[<span class="string">&#x27;0&#x27;</span>, <span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;2&#x27;</span>,</span><br><span class="line">       <span class="string">&#x27;3&#x27;</span>, <span class="string">&#x27;4&#x27;</span>, <span class="string">&#x27;5&#x27;</span>]]=prob</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># test[&#x27;label&#x27;]=pd.read_csv(&#x27;models/v4/lgb.csv&#x27;)[&#x27;predict&#x27;]</span></span><br><span class="line">train=train.drop(<span class="string">&#x27;text&#x27;</span>,axis=<span class="number">1</span>)</span><br><span class="line">train=train.drop(<span class="string">&#x27;fold&#x27;</span>,axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train=train[[<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;method&#x27;</span>, <span class="string">&#x27;user_agent&#x27;</span>, <span class="string">&#x27;url&#x27;</span>, <span class="string">&#x27;refer&#x27;</span>, <span class="string">&#x27;body&#x27;</span>, <span class="string">&#x27;0&#x27;</span>, <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">       <span class="string">&#x27;2&#x27;</span>, <span class="string">&#x27;3&#x27;</span>, <span class="string">&#x27;4&#x27;</span>, <span class="string">&#x27;5&#x27;</span>, <span class="string">&#x27;label&#x27;</span>]]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;train.shape&quot;</span>,train.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;test.shape&quot;</span>,test.shape)</span><br></pre></td></tr></table></figure><pre><code>train.shape (33037, 13)test.shape (4000, 12)</code></pre><h1 id="数据分析"><a href="#数据分析" class="headerlink" title="数据分析"></a>数据分析</h1><p>赛题训练集分为6种不同标签，共计约3.5万条数据。训练数据集字段内容主要包括：<br>●　lable：攻击类型编号<br>●　其他：HTTP协议内容</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看训练集的字段</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train.columns</span><br></pre></td></tr></table></figure><pre><code>Index([&#39;id&#39;, &#39;method&#39;, &#39;user_agent&#39;, &#39;url&#39;, &#39;refer&#39;, &#39;body&#39;, &#39;0&#39;, &#39;1&#39;, &#39;2&#39;,       &#39;3&#39;, &#39;4&#39;, &#39;5&#39;, &#39;label&#39;],      dtype=&#39;object&#39;)</code></pre><p>‘lable’看着很别扭，重新rename一下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train=train.rename(columns=&#123;<span class="string">&#x27;lable&#x27;</span>:<span class="string">&#x27;label&#x27;</span>&#125;)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train.dtypes</span><br></pre></td></tr></table></figure><pre><code>id              int64method         objectuser_agent     objecturl            objectrefer          objectbody           object0             float321             float322             float323             float324             float325             float32label           int64dtype: object</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 标签个数统计</span></span><br><span class="line">train[<span class="string">&#x27;label&#x27;</span>].value_counts()</span><br></pre></td></tr></table></figure><pre><code>1    140382     99390     64893     12154      6975      659Name: label, dtype: int64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train[<span class="string">&#x27;label&#x27;</span>].value_counts().plot(kind=<span class="string">&#x27;bar&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/12/05/2x7AWXbvuoigw8n.png" alt="Snipaste_2022-12-05_12-13-30.png"></p><p>​    </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data=pd.concat([train,test],axis=<span class="number">0</span>).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">data.nunique()</span><br></pre></td></tr></table></figure><pre><code>id            19497method           21user_agent     1087url           36613refer           941body          223800             359151             316182             360613             369614             369655             36959label             6dtype: int64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 缺失值处理：</span></span><br><span class="line">data[<span class="string">&#x27;user_agent&#x27;</span>]=data[<span class="string">&#x27;user_agent&#x27;</span>].fillna(<span class="string">&#x27;NAN&#x27;</span>)</span><br><span class="line">data[<span class="string">&#x27;refer&#x27;</span>]=data[<span class="string">&#x27;refer&#x27;</span>].fillna(<span class="string">&#x27;NAN&#x27;</span>)</span><br><span class="line">data[<span class="string">&#x27;body&#x27;</span>]=data[<span class="string">&#x27;body&#x27;</span>].fillna(<span class="string">&#x27;NAN&#x27;</span>)</span><br><span class="line">data[<span class="string">&#x27;url&#x27;</span>]=data[<span class="string">&#x27;url&#x27;</span>].fillna(<span class="string">&#x27;NAN&#x27;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 提取user_agent特征</span></span><br><span class="line">ua_cols=[<span class="string">&#x27;browser_family&#x27;</span>, <span class="string">&#x27;os_family&#x27;</span>, <span class="string">&#x27;device_family&#x27;</span>,<span class="string">&#x27;device_brand&#x27;</span>,<span class="string">&#x27;device_model&#x27;</span>]</span><br><span class="line">data[ua_cols] = data.apply(get_ua, axis=<span class="number">1</span>, result_type=<span class="string">&quot;expand&quot;</span>)</span><br><span class="line">data.head()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>id</th>      <th>method</th>      <th>user_agent</th>      <th>url</th>      <th>refer</th>      <th>body</th>      <th>0</th>      <th>1</th>      <th>2</th>      <th>3</th>      <th>4</th>      <th>5</th>      <th>label</th>      <th>browser_family</th>      <th>os_family</th>      <th>device_family</th>      <th>device_brand</th>      <th>device_model</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>13429</td>      <td>GET</td>      <td>'||(select 1 from (select pg_sleep(8))x)||'</td>      <td>/kelev/scripts/?C=M%3BO%3DA</td>      <td>NAN</td>      <td>GET /kelev/scripts/?C=M%3BO%3DA HTTP/1.1 Accep...</td>      <td>0.000238</td>      <td>0.999110</td>      <td>0.000445</td>      <td>0.000058</td>      <td>0.000040</td>      <td>0.000110</td>      <td>1.0</td>      <td>Other</td>      <td>Other</td>      <td>Other</td>      <td>None</td>      <td>None</td>    </tr>    <tr>      <th>1</th>      <td>18125</td>      <td>GET</td>      <td>Dalvik/2.1.0 (Linux; U; Android 11; M2102K1C B...</td>      <td>/livemsg?ad_type=WL_WK&amp;oadid=&amp;ty=web&amp;pu=0&amp;adap...</td>      <td>NAN</td>      <td>GET /livemsg?ad_type=WL_WK&amp;oadid=&amp;ty=web&amp;pu=0&amp;...</td>      <td>0.006598</td>      <td>0.992451</td>      <td>0.000763</td>      <td>0.000086</td>      <td>0.000067</td>      <td>0.000035</td>      <td>1.0</td>      <td>Android</td>      <td>Android</td>      <td>M2102K1C</td>      <td>Generic_Android</td>      <td>M2102K1C</td>    </tr>    <tr>      <th>2</th>      <td>14538</td>      <td>GET</td>      <td>Dalvik/2.1.0 (Linux; U; Android 11; M2011K2C B...</td>      <td>/livemsg?ad_type=WL_WK&amp;ty=web&amp;pu=0&amp;openudid=d2...</td>      <td>NAN</td>      <td>GET /livemsg?ad_type=WL_WK&amp;ty=web&amp;pu=0&amp;openudi...</td>      <td>0.000783</td>      <td>0.999017</td>      <td>0.000138</td>      <td>0.000031</td>      <td>0.000017</td>      <td>0.000013</td>      <td>1.0</td>      <td>Android</td>      <td>Android</td>      <td>M2011K2C</td>      <td>Generic_Android</td>      <td>M2011K2C</td>    </tr>    <tr>      <th>3</th>      <td>7127</td>      <td>GET</td>      <td>Dalvik/2.1.0 (Linux; U; Android 10; MI 9 MIUI/...</td>      <td>/livemsg?ad_type=WL_WK&amp;oadid=&amp;ty=web&amp;pu=0&amp;adap...</td>      <td>NAN</td>      <td>NAN</td>      <td>0.007603</td>      <td>0.991491</td>      <td>0.000725</td>      <td>0.000087</td>      <td>0.000062</td>      <td>0.000033</td>      <td>1.0</td>      <td>Android</td>      <td>Android</td>      <td>XiaoMi MI 9</td>      <td>XiaoMi</td>      <td>MI 9</td>    </tr>    <tr>      <th>4</th>      <td>7</td>      <td>GET</td>      <td>Dalvik/2.1.0 (Linux; U; Android 10; ELS-AN00 B...</td>      <td>/livemsg?sdtfrom=v5004&amp;ad_type=WL_WK&amp;oadid=&amp;ty...</td>      <td>NAN</td>      <td>GET /livemsg?sdtfrom=v5004&amp;ad_type=WL_WK&amp;oadid...</td>      <td>0.000529</td>      <td>0.999257</td>      <td>0.000153</td>      <td>0.000020</td>      <td>0.000021</td>      <td>0.000019</td>      <td>1.0</td>      <td>Android</td>      <td>Android</td>      <td>ELS-AN00</td>      <td>Huawei</td>      <td>ELS-AN00</td>    </tr>  </tbody></table></div><h1 id="基础特征"><a href="#基础特征" class="headerlink" title="基础特征"></a>基础特征</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"><span class="keyword">import</span> urllib</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">data[<span class="string">&#x27;user_agent_len&#x27;</span>]=data[<span class="string">&#x27;user_agent&#x27;</span>].apply(<span class="keyword">lambda</span> x:<span class="built_in">len</span>(x))</span><br><span class="line">data[<span class="string">&#x27;url_len&#x27;</span>]=data[<span class="string">&#x27;url&#x27;</span>].apply(<span class="keyword">lambda</span> x:<span class="built_in">len</span>(x))</span><br><span class="line">data[<span class="string">&#x27;refer_len&#x27;</span>]=data[<span class="string">&#x27;refer&#x27;</span>].apply(<span class="keyword">lambda</span> x:<span class="built_in">len</span>(x))</span><br><span class="line">data[<span class="string">&#x27;body_len&#x27;</span>]=data[<span class="string">&#x27;body&#x27;</span>].apply(<span class="keyword">lambda</span> x:<span class="built_in">len</span>(x))</span><br><span class="line">data[<span class="string">&#x27;body_user_agent_len_diff&#x27;</span>]=data[<span class="string">&#x27;body_len&#x27;</span>]-data[<span class="string">&#x27;user_agent_len&#x27;</span>]</span><br><span class="line">data[<span class="string">&#x27;body_url_len_diff&#x27;</span>]=data[<span class="string">&#x27;body_len&#x27;</span>]-data[<span class="string">&#x27;url_len&#x27;</span>]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将user_agent列进行tfidf特征提取，再SVD变成16维度</span></span><br><span class="line">texts=data[<span class="string">&#x27;user_agent&#x27;</span>].values.tolist()</span><br><span class="line"></span><br><span class="line">n_components = <span class="number">16</span>      <span class="comment"># 期望维数 </span></span><br><span class="line">tf = TfidfVectorizer(min_df= <span class="number">1</span>, max_df=<span class="number">0.5</span>,analyzer = <span class="string">&#x27;char_wb&#x27;</span>, ngram_range = (<span class="number">1</span>,<span class="number">3</span>))     <span class="comment"># ngram_range = (2,5)</span></span><br><span class="line">X = tf.fit_transform(texts)</span><br><span class="line">svd = TruncatedSVD(n_components=n_components,</span><br><span class="line">                   random_state=<span class="number">42</span>)</span><br><span class="line">X_svd = svd.fit_transform(X)</span><br><span class="line">df_tfidf = pd.DataFrame(X_svd)</span><br><span class="line">df_tfidf.columns = [<span class="string">f&#x27;user_agent_name_tfidf_<span class="subst">&#123;i&#125;</span>&#x27;</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_components)]</span><br><span class="line">data=pd.concat([data,df_tfidf],axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">texts=data[<span class="string">&#x27;url&#x27;</span>].values.tolist()</span><br><span class="line"></span><br><span class="line">n_components = <span class="number">16</span></span><br><span class="line">tf = TfidfVectorizer(min_df= <span class="number">1</span>, max_df=<span class="number">0.5</span>,analyzer = <span class="string">&#x27;char_wb&#x27;</span>, ngram_range = (<span class="number">1</span>,<span class="number">3</span>))</span><br><span class="line">X = tf.fit_transform(texts)</span><br><span class="line">svd = TruncatedSVD(n_components=n_components,</span><br><span class="line">                   random_state=<span class="number">42</span>)</span><br><span class="line">X_svd = svd.fit_transform(X)</span><br><span class="line">df_tfidf = pd.DataFrame(X_svd)</span><br><span class="line">df_tfidf.columns = [<span class="string">f&#x27;url_name_tfidf_<span class="subst">&#123;i&#125;</span>&#x27;</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_components)]</span><br><span class="line">data=pd.concat([data,df_tfidf],axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># texts=data[&#x27;refer&#x27;].values.tolist()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># n_components = 16</span></span><br><span class="line"><span class="comment"># tf = TfidfVectorizer(min_df= 1, max_df=0.5,analyzer = &#x27;char_wb&#x27;, ngram_range = (1,3))</span></span><br><span class="line"><span class="comment"># X = tf.fit_transform(texts)</span></span><br><span class="line"><span class="comment"># svd = TruncatedSVD(n_components=n_components,</span></span><br><span class="line"><span class="comment">#                    random_state=42)</span></span><br><span class="line"><span class="comment"># X_svd = svd.fit_transform(X)</span></span><br><span class="line"><span class="comment"># df_tfidf = pd.DataFrame(X_svd)</span></span><br><span class="line"><span class="comment"># df_tfidf.columns = [f&#x27;refer_tfidf_&#123;i&#125;&#x27; for i in range(n_components)]</span></span><br><span class="line"><span class="comment"># data=pd.concat([data,df_tfidf],axis=1)</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">texts=data[<span class="string">&#x27;body&#x27;</span>].values.tolist()</span><br><span class="line"></span><br><span class="line">n_components = <span class="number">32</span></span><br><span class="line">tf = TfidfVectorizer(min_df= <span class="number">1</span>, max_df=<span class="number">0.5</span>,analyzer = <span class="string">&#x27;char_wb&#x27;</span>, ngram_range = (<span class="number">1</span>,<span class="number">3</span>))</span><br><span class="line">X = tf.fit_transform(texts)</span><br><span class="line">svd = TruncatedSVD(n_components=n_components,</span><br><span class="line">                   random_state=<span class="number">42</span>)</span><br><span class="line">X_svd = svd.fit_transform(X)</span><br><span class="line">df_tfidf = pd.DataFrame(X_svd)</span><br><span class="line">df_tfidf.columns = [<span class="string">f&#x27;body_tfidf_<span class="subst">&#123;i&#125;</span>&#x27;</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_components)]</span><br><span class="line">data=pd.concat([data,df_tfidf],axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> f <span class="keyword">in</span> [<span class="string">&#x27;method&#x27;</span>, <span class="string">&#x27;url&#x27;</span>,<span class="string">&#x27;refer&#x27;</span>, <span class="string">&#x27;body&#x27;</span>,<span class="string">&#x27;browser_family&#x27;</span>,<span class="string">&#x27;os_family&#x27;</span>,<span class="string">&#x27;device_family&#x27;</span>,<span class="string">&#x27;device_brand&#x27;</span>,<span class="string">&#x27;device_model&#x27;</span>]:    <span class="comment"># refer</span></span><br><span class="line">    data[<span class="string">f&#x27;id_<span class="subst">&#123;f&#125;</span>_nunique&#x27;</span>] = data.groupby([<span class="string">&#x27;id&#x27;</span>])[f].transform(<span class="string">&#x27;nunique&#x27;</span>)</span><br><span class="line">    data[<span class="string">f&#x27;id_<span class="subst">&#123;f&#125;</span>_count&#x27;</span>] = data.groupby([<span class="string">&#x27;id&#x27;</span>])[f].transform(<span class="string">&#x27;count&#x27;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">re.split(<span class="string">&#x27;[=&amp;]&#x27;</span>, urlparse(data[<span class="string">&#x27;url&#x27;</span>][<span class="number">0</span>])[<span class="number">4</span>])</span><br></pre></td></tr></table></figure><pre><code>[&#39;C&#39;, &#39;M%3BO%3DA&#39;]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_url_query</span>(<span class="params">s</span>):</span><br><span class="line">    li = re.split(<span class="string">&#x27;[=&amp;]&#x27;</span>, urlparse(s)[<span class="number">4</span>])</span><br><span class="line">    <span class="keyword">return</span> [li[i] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(li)) <span class="keyword">if</span> i % <span class="number">2</span> == <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">find_max_str_length</span>(<span class="params">x</span>):</span><br><span class="line">    max_ = <span class="number">0</span></span><br><span class="line">    li = [<span class="built_in">len</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> x]</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">max</span>(li) <span class="keyword">if</span> <span class="built_in">len</span>(li) &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">find_str_length_std</span>(<span class="params">x</span>):</span><br><span class="line">    max_ = <span class="number">0</span></span><br><span class="line">    li = [<span class="built_in">len</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> x]</span><br><span class="line">    <span class="keyword">return</span> np.std(li) <span class="keyword">if</span> <span class="built_in">len</span>(li) &gt; <span class="number">0</span> <span class="keyword">else</span> -<span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">data[<span class="string">&#x27;url_unquote&#x27;</span>] = data[<span class="string">&#x27;url&#x27;</span>].apply(unquote)</span><br><span class="line">data[<span class="string">&#x27;url_query&#x27;</span>] = data[<span class="string">&#x27;url_unquote&#x27;</span>].apply(<span class="keyword">lambda</span> x: get_url_query(x))</span><br><span class="line">data[<span class="string">&#x27;url_query_num&#x27;</span>] = data[<span class="string">&#x27;url_query&#x27;</span>].apply(<span class="built_in">len</span>)</span><br><span class="line">data[<span class="string">&#x27;url_query_max_len&#x27;</span>] = data[<span class="string">&#x27;url_query&#x27;</span>].apply(find_max_str_length)</span><br><span class="line">data[<span class="string">&#x27;url_query_len_std&#x27;</span>] = data[<span class="string">&#x27;url_query&#x27;</span>].apply(find_str_length_std)</span><br><span class="line">data[<span class="string">&#x27;url&#x27;</span>].apply(unquote)</span><br></pre></td></tr></table></figure><pre><code>0                                  /kelev/scripts/?C=M;O=A1        /livemsg?ad_type=WL_WK&amp;oadid=&amp;ty=web&amp;pu=0&amp;adap...2        /livemsg?ad_type=WL_WK&amp;ty=web&amp;pu=0&amp;openudid=d2...3        /livemsg?ad_type=WL_WK&amp;oadid=&amp;ty=web&amp;pu=0&amp;adap...4        /livemsg?sdtfrom=v5004&amp;ad_type=WL_WK&amp;oadid=&amp;ty...                               ...                        37032    /livemsg?ad_type=WL_WK&amp;ty=web&amp;pu=1&amp;openudid=64...37033                                          /runtime.js37034                                     /query?49352181237035              /stats.php?rand=JtmT4wBtrpNy5RJnNX9wCUo37036    /api/gateway.do?method=qihoo.sdk.user.mobile.l...Name: url, Length: 37037, dtype: object</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data.head()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>id</th>      <th>method</th>      <th>user_agent</th>      <th>url</th>      <th>refer</th>      <th>body</th>      <th>0</th>      <th>1</th>      <th>2</th>      <th>3</th>      <th>4</th>      <th>5</th>      <th>label</th>      <th>browser_family</th>      <th>os_family</th>      <th>device_family</th>      <th>device_brand</th>      <th>device_model</th>      <th>user_agent_len</th>      <th>url_len</th>      <th>refer_len</th>      <th>body_len</th>      <th>body_user_agent_len_diff</th>      <th>body_url_len_diff</th>      <th>user_agent_name_tfidf_0</th>      <th>user_agent_name_tfidf_1</th>      <th>user_agent_name_tfidf_2</th>      <th>user_agent_name_tfidf_3</th>      <th>user_agent_name_tfidf_4</th>      <th>user_agent_name_tfidf_5</th>      <th>user_agent_name_tfidf_6</th>      <th>user_agent_name_tfidf_7</th>      <th>user_agent_name_tfidf_8</th>      <th>user_agent_name_tfidf_9</th>      <th>user_agent_name_tfidf_10</th>      <th>user_agent_name_tfidf_11</th>      <th>user_agent_name_tfidf_12</th>      <th>user_agent_name_tfidf_13</th>      <th>user_agent_name_tfidf_14</th>      <th>user_agent_name_tfidf_15</th>      <th>url_name_tfidf_0</th>      <th>url_name_tfidf_1</th>      <th>url_name_tfidf_2</th>      <th>url_name_tfidf_3</th>      <th>url_name_tfidf_4</th>      <th>url_name_tfidf_5</th>      <th>url_name_tfidf_6</th>      <th>url_name_tfidf_7</th>      <th>url_name_tfidf_8</th>      <th>url_name_tfidf_9</th>      <th>url_name_tfidf_10</th>      <th>url_name_tfidf_11</th>      <th>url_name_tfidf_12</th>      <th>url_name_tfidf_13</th>      <th>url_name_tfidf_14</th>      <th>url_name_tfidf_15</th>      <th>body_tfidf_0</th>      <th>body_tfidf_1</th>      <th>body_tfidf_2</th>      <th>body_tfidf_3</th>      <th>body_tfidf_4</th>      <th>body_tfidf_5</th>      <th>body_tfidf_6</th>      <th>body_tfidf_7</th>      <th>body_tfidf_8</th>      <th>body_tfidf_9</th>      <th>body_tfidf_10</th>      <th>body_tfidf_11</th>      <th>body_tfidf_12</th>      <th>body_tfidf_13</th>      <th>body_tfidf_14</th>      <th>body_tfidf_15</th>      <th>body_tfidf_16</th>      <th>body_tfidf_17</th>      <th>body_tfidf_18</th>      <th>body_tfidf_19</th>      <th>body_tfidf_20</th>      <th>body_tfidf_21</th>      <th>body_tfidf_22</th>      <th>body_tfidf_23</th>      <th>body_tfidf_24</th>      <th>body_tfidf_25</th>      <th>body_tfidf_26</th>      <th>body_tfidf_27</th>      <th>body_tfidf_28</th>      <th>body_tfidf_29</th>      <th>body_tfidf_30</th>      <th>body_tfidf_31</th>      <th>id_method_nunique</th>      <th>id_method_count</th>      <th>id_url_nunique</th>      <th>id_url_count</th>      <th>id_refer_nunique</th>      <th>id_refer_count</th>      <th>id_body_nunique</th>      <th>id_body_count</th>      <th>id_browser_family_nunique</th>      <th>id_browser_family_count</th>      <th>id_os_family_nunique</th>      <th>id_os_family_count</th>      <th>id_device_family_nunique</th>      <th>id_device_family_count</th>      <th>id_device_brand_nunique</th>      <th>id_device_brand_count</th>      <th>id_device_model_nunique</th>      <th>id_device_model_count</th>      <th>url_unquote</th>      <th>url_query</th>      <th>url_query_num</th>      <th>url_query_max_len</th>      <th>url_query_len_std</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>13429</td>      <td>GET</td>      <td>'||(select 1 from (select pg_sleep(8))x)||'</td>      <td>/kelev/scripts/?C=M%3BO%3DA</td>      <td>NAN</td>      <td>GET /kelev/scripts/?C=M%3BO%3DA HTTP/1.1 Accep...</td>      <td>0.000238</td>      <td>0.999110</td>      <td>0.000445</td>      <td>0.000058</td>      <td>0.000040</td>      <td>0.000110</td>      <td>1.0</td>      <td>Other</td>      <td>Other</td>      <td>Other</td>      <td>None</td>      <td>None</td>      <td>43</td>      <td>27</td>      <td>3</td>      <td>212</td>      <td>169</td>      <td>185</td>      <td>0.010070</td>      <td>0.009456</td>      <td>0.001205</td>      <td>0.003217</td>      <td>0.021082</td>      <td>0.000999</td>      <td>-0.000847</td>      <td>-0.002107</td>      <td>0.008443</td>      <td>0.002747</td>      <td>0.023997</td>      <td>-0.003526</td>      <td>-0.001894</td>      <td>-0.013000</td>      <td>-0.005918</td>      <td>0.009153</td>      <td>0.066298</td>      <td>0.059683</td>      <td>-0.057310</td>      <td>-0.006595</td>      <td>-0.001159</td>      <td>0.094755</td>      <td>-0.021858</td>      <td>0.023071</td>      <td>-0.001968</td>      <td>0.043890</td>      <td>0.022147</td>      <td>-0.006037</td>      <td>-0.005375</td>      <td>0.014239</td>      <td>0.077494</td>      <td>0.081818</td>      <td>0.000054</td>      <td>0.115960</td>      <td>0.105404</td>      <td>-0.027789</td>      <td>-0.002577</td>      <td>0.064009</td>      <td>-0.039324</td>      <td>0.006577</td>      <td>0.023000</td>      <td>-0.064038</td>      <td>0.021134</td>      <td>-0.058787</td>      <td>0.011353</td>      <td>0.066560</td>      <td>0.010658</td>      <td>0.189591</td>      <td>-0.067039</td>      <td>-0.116538</td>      <td>-0.014128</td>      <td>-0.029329</td>      <td>0.047018</td>      <td>-0.023777</td>      <td>-0.035825</td>      <td>0.005829</td>      <td>0.013030</td>      <td>-0.022777</td>      <td>-0.007482</td>      <td>0.039357</td>      <td>0.046385</td>      <td>-0.007902</td>      <td>-0.029089</td>      <td>-0.051989</td>      <td>1</td>      <td>2</td>      <td>2</td>      <td>2</td>      <td>1</td>      <td>2</td>      <td>2</td>      <td>2</td>      <td>2</td>      <td>2</td>      <td>2</td>      <td>2</td>      <td>1</td>      <td>2</td>      <td>1</td>      <td>2</td>      <td>1</td>      <td>2</td>      <td>/kelev/scripts/?C=M;O=A</td>      <td>[M;O]</td>      <td>1</td>      <td>3</td>      <td>0.000000</td>    </tr>    <tr>      <th>1</th>      <td>18125</td>      <td>GET</td>      <td>Dalvik/2.1.0 (Linux; U; Android 11; M2102K1C B...</td>      <td>/livemsg?ad_type=WL_WK&amp;oadid=&amp;ty=web&amp;pu=0&amp;adap...</td>      <td>NAN</td>      <td>GET /livemsg?ad_type=WL_WK&amp;oadid=&amp;ty=web&amp;pu=0&amp;...</td>      <td>0.006598</td>      <td>0.992451</td>      <td>0.000763</td>      <td>0.000086</td>      <td>0.000067</td>      <td>0.000035</td>      <td>1.0</td>      <td>Android</td>      <td>Android</td>      <td>M2102K1C</td>      <td>Generic_Android</td>      <td>M2102K1C</td>      <td>67</td>      <td>1747</td>      <td>3</td>      <td>2016</td>      <td>1949</td>      <td>269</td>      <td>0.035096</td>      <td>0.120188</td>      <td>0.270092</td>      <td>0.655747</td>      <td>-0.042591</td>      <td>-0.024738</td>      <td>-0.019824</td>      <td>-0.000642</td>      <td>-0.015951</td>      <td>-0.183311</td>      <td>-0.026321</td>      <td>-0.061993</td>      <td>-0.018288</td>      <td>0.027496</td>      <td>-0.012776</td>      <td>-0.002250</td>      <td>0.617250</td>      <td>-0.130247</td>      <td>0.079094</td>      <td>-0.023195</td>      <td>0.003702</td>      <td>-0.030486</td>      <td>-0.013201</td>      <td>-0.021136</td>      <td>0.012303</td>      <td>-0.006278</td>      <td>-0.023727</td>      <td>-0.003599</td>      <td>0.027036</td>      <td>0.006405</td>      <td>-0.005268</td>      <td>0.010234</td>      <td>0.000132</td>      <td>0.530101</td>      <td>-0.277845</td>      <td>0.022171</td>      <td>-0.069403</td>      <td>-0.062703</td>      <td>-0.006813</td>      <td>0.001156</td>      <td>-0.028995</td>      <td>-0.009364</td>      <td>-0.013567</td>      <td>0.015499</td>      <td>-0.009968</td>      <td>-0.032960</td>      <td>-0.000036</td>      <td>-0.008127</td>      <td>-0.000813</td>      <td>0.001447</td>      <td>0.009261</td>      <td>-0.017541</td>      <td>-0.000682</td>      <td>-0.003697</td>      <td>0.007340</td>      <td>-0.010968</td>      <td>0.008710</td>      <td>-0.067023</td>      <td>-0.014870</td>      <td>-0.024112</td>      <td>0.011792</td>      <td>0.004538</td>      <td>0.014397</td>      <td>-0.003550</td>      <td>1</td>      <td>2</td>      <td>2</td>      <td>2</td>      <td>1</td>      <td>2</td>      <td>2</td>      <td>2</td>      <td>2</td>      <td>2</td>      <td>2</td>      <td>2</td>      <td>2</td>      <td>2</td>      <td>2</td>      <td>2</td>      <td>2</td>      <td>2</td>      <td>/livemsg?ad_type=WL_WK&amp;oadid=&amp;ty=web&amp;pu=0&amp;adap...</td>      <td>[WL_WK, , web, 0, 1, 210810, 116, 1, 8, fa0d30...</td>      <td>23</td>      <td>1324</td>      <td>268.709026</td>    </tr>    <tr>      <th>2</th>      <td>14538</td>      <td>GET</td>      <td>Dalvik/2.1.0 (Linux; U; Android 11; M2011K2C B...</td>      <td>/livemsg?ad_type=WL_WK&amp;ty=web&amp;pu=0&amp;openudid=d2...</td>      <td>NAN</td>      <td>GET /livemsg?ad_type=WL_WK&amp;ty=web&amp;pu=0&amp;openudi...</td>      <td>0.000783</td>      <td>0.999017</td>      <td>0.000138</td>      <td>0.000031</td>      <td>0.000017</td>      <td>0.000013</td>      <td>1.0</td>      <td>Android</td>      <td>Android</td>      <td>M2011K2C</td>      <td>Generic_Android</td>      <td>M2011K2C</td>      <td>67</td>      <td>1688</td>      <td>3</td>      <td>1986</td>      <td>1919</td>      <td>298</td>      <td>0.034866</td>      <td>0.170330</td>      <td>0.292857</td>      <td>0.713273</td>      <td>-0.047369</td>      <td>-0.025480</td>      <td>-0.014846</td>      <td>-0.002015</td>      <td>-0.095211</td>      <td>-0.199969</td>      <td>0.001352</td>      <td>0.004859</td>      <td>0.026900</td>      <td>-0.000053</td>      <td>-0.045812</td>      <td>-0.003042</td>      <td>0.662307</td>      <td>-0.134895</td>      <td>0.074788</td>      <td>-0.033836</td>      <td>0.004867</td>      <td>-0.012766</td>      <td>-0.014195</td>      <td>-0.019396</td>      <td>0.016613</td>      <td>-0.006143</td>      <td>-0.018700</td>      <td>-0.012640</td>      <td>0.030395</td>      <td>0.004169</td>      <td>-0.005899</td>      <td>0.005060</td>      <td>0.000137</td>      <td>0.557311</td>      <td>-0.298627</td>      <td>0.021799</td>      <td>-0.072395</td>      <td>-0.035369</td>      <td>-0.009561</td>      <td>-0.020158</td>      <td>-0.030540</td>      <td>-0.019107</td>      <td>-0.011824</td>      <td>0.016220</td>      <td>-0.010370</td>      <td>-0.021592</td>      <td>0.002470</td>      <td>0.001666</td>      <td>-0.004027</td>      <td>-0.000666</td>      <td>0.012006</td>      <td>-0.009133</td>      <td>-0.007882</td>      <td>-0.001795</td>      <td>-0.003188</td>      <td>-0.015516</td>      <td>0.010797</td>      <td>-0.083144</td>      <td>-0.021120</td>      <td>-0.029922</td>      <td>0.020777</td>      <td>0.001687</td>      <td>0.006579</td>      <td>-0.001808</td>      <td>1</td>      <td>2</td>      <td>2</td>      <td>2</td>      <td>1</td>      <td>2</td>      <td>2</td>      <td>2</td>      <td>2</td>      <td>2</td>      <td>2</td>      <td>2</td>      <td>2</td>      <td>2</td>      <td>2</td>      <td>2</td>      <td>2</td>      <td>2</td>      <td>/livemsg?ad_type=WL_WK&amp;ty=web&amp;pu=0&amp;openudid=d2...</td>      <td>[WL_WK, web, 0, d24c93f6c8de719a00f1676f3a9a53...</td>      <td>29</td>      <td>1154</td>      <td>209.374211</td>    </tr>    <tr>      <th>3</th>      <td>7127</td>      <td>GET</td>      <td>Dalvik/2.1.0 (Linux; U; Android 10; MI 9 MIUI/...</td>      <td>/livemsg?ad_type=WL_WK&amp;oadid=&amp;ty=web&amp;pu=0&amp;adap...</td>      <td>NAN</td>      <td>NAN</td>      <td>0.007603</td>      <td>0.991491</td>      <td>0.000725</td>      <td>0.000087</td>      <td>0.000062</td>      <td>0.000033</td>      <td>1.0</td>      <td>Android</td>      <td>Android</td>      <td>XiaoMi MI 9</td>      <td>XiaoMi</td>      <td>MI 9</td>      <td>64</td>      <td>1613</td>      <td>3</td>      <td>3</td>      <td>-61</td>      <td>-1610</td>      <td>0.038503</td>      <td>0.058521</td>      <td>0.184916</td>      <td>0.434441</td>      <td>0.026507</td>      <td>-0.024867</td>      <td>-0.016191</td>      <td>0.021308</td>      <td>0.058906</td>      <td>0.048677</td>      <td>-0.015773</td>      <td>-0.017188</td>      <td>0.012508</td>      <td>0.026593</td>      <td>0.009872</td>      <td>0.001220</td>      <td>0.621003</td>      <td>-0.119104</td>      <td>0.071898</td>      <td>-0.014246</td>      <td>-0.005748</td>      <td>-0.025066</td>      <td>-0.015300</td>      <td>-0.006643</td>      <td>0.011277</td>      <td>-0.011099</td>      <td>-0.026949</td>      <td>-0.013011</td>      <td>0.027294</td>      <td>0.006678</td>      <td>0.006156</td>      <td>0.004784</td>      <td>1.000000</td>      <td>-0.000356</td>      <td>-0.000224</td>      <td>-0.000019</td>      <td>0.000078</td>      <td>0.000016</td>      <td>-0.000132</td>      <td>-0.000012</td>      <td>-0.000029</td>      <td>0.000011</td>      <td>-0.000044</td>      <td>-0.000041</td>      <td>-0.000041</td>      <td>0.000027</td>      <td>-0.000017</td>      <td>-0.000027</td>      <td>-0.000017</td>      <td>-0.000096</td>      <td>0.000005</td>      <td>0.000026</td>      <td>0.000013</td>      <td>0.000016</td>      <td>-0.000005</td>      <td>-0.000005</td>      <td>0.000015</td>      <td>-0.000004</td>      <td>0.000011</td>      <td>0.000021</td>      <td>-0.000004</td>      <td>0.000045</td>      <td>0.000019</td>      <td>-0.000019</td>      <td>1</td>      <td>3</td>      <td>3</td>      <td>3</td>      <td>1</td>      <td>3</td>      <td>2</td>      <td>3</td>      <td>2</td>      <td>3</td>      <td>2</td>      <td>3</td>      <td>3</td>      <td>3</td>      <td>2</td>      <td>3</td>      <td>3</td>      <td>3</td>      <td>/livemsg?ad_type=WL_WK&amp;oadid=&amp;ty=web&amp;pu=0&amp;adap...</td>      <td>[WL_WK, , web, 0, 1, 201209, 116, 1, 8, bbe035...</td>      <td>24</td>      <td>1186</td>      <td>235.820461</td>    </tr>    <tr>      <th>4</th>      <td>7</td>      <td>GET</td>      <td>Dalvik/2.1.0 (Linux; U; Android 10; ELS-AN00 B...</td>      <td>/livemsg?sdtfrom=v5004&amp;ad_type=WL_WK&amp;oadid=&amp;ty...</td>      <td>NAN</td>      <td>GET /livemsg?sdtfrom=v5004&amp;ad_type=WL_WK&amp;oadid...</td>      <td>0.000529</td>      <td>0.999257</td>      <td>0.000153</td>      <td>0.000020</td>      <td>0.000021</td>      <td>0.000019</td>      <td>1.0</td>      <td>Android</td>      <td>Android</td>      <td>ELS-AN00</td>      <td>Huawei</td>      <td>ELS-AN00</td>      <td>66</td>      <td>1467</td>      <td>3</td>      <td>1704</td>      <td>1638</td>      <td>237</td>      <td>0.023016</td>      <td>0.076053</td>      <td>0.211935</td>      <td>0.431614</td>      <td>-0.013015</td>      <td>-0.028123</td>      <td>0.016032</td>      <td>-0.039645</td>      <td>0.129501</td>      <td>0.388460</td>      <td>-0.012173</td>      <td>-0.016553</td>      <td>-0.012854</td>      <td>-0.049835</td>      <td>-0.037182</td>      <td>-0.024569</td>      <td>0.615644</td>      <td>-0.116622</td>      <td>0.066164</td>      <td>-0.019455</td>      <td>-0.007366</td>      <td>-0.022974</td>      <td>-0.016564</td>      <td>-0.006819</td>      <td>-0.000959</td>      <td>-0.011903</td>      <td>-0.022060</td>      <td>-0.011351</td>      <td>0.002437</td>      <td>-0.008505</td>      <td>-0.008668</td>      <td>-0.004333</td>      <td>0.000129</td>      <td>0.535128</td>      <td>-0.294560</td>      <td>0.024614</td>      <td>-0.084538</td>      <td>-0.049889</td>      <td>-0.019040</td>      <td>-0.000086</td>      <td>-0.029467</td>      <td>-0.026259</td>      <td>-0.010166</td>      <td>0.009809</td>      <td>-0.017834</td>      <td>-0.018439</td>      <td>0.007596</td>      <td>-0.017013</td>      <td>-0.005269</td>      <td>0.002957</td>      <td>0.006733</td>      <td>-0.010658</td>      <td>-0.006394</td>      <td>-0.005429</td>      <td>0.011300</td>      <td>-0.024379</td>      <td>0.006489</td>      <td>-0.061012</td>      <td>-0.019155</td>      <td>-0.021446</td>      <td>0.021441</td>      <td>-0.001876</td>      <td>0.002968</td>      <td>-0.005974</td>      <td>2</td>      <td>5</td>      <td>5</td>      <td>5</td>      <td>3</td>      <td>5</td>      <td>5</td>      <td>5</td>      <td>3</td>      <td>5</td>      <td>3</td>      <td>5</td>      <td>3</td>      <td>5</td>      <td>3</td>      <td>5</td>      <td>3</td>      <td>5</td>      <td>/livemsg?sdtfrom=v5004&amp;ad_type=WL_WK&amp;oadid=&amp;ty...</td>      <td>[v5004, WL_WK, , web, 0, 20220209V0BT5X00, 1, ...</td>      <td>27</td>      <td>972</td>      <td>182.378599</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">find_url_filetype</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">return</span> re.search(<span class="string">r&#x27;\.[a-z]+&#x27;</span>, x).group()</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;__NaN__&#x27;</span></span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">data[<span class="string">&#x27;url_path&#x27;</span>] = data[<span class="string">&#x27;url_unquote&#x27;</span>].apply(<span class="keyword">lambda</span> x: urlparse(x)[<span class="number">2</span>])</span><br><span class="line">data[<span class="string">&#x27;url_filetype&#x27;</span>] = data[<span class="string">&#x27;url_path&#x27;</span>].apply(<span class="keyword">lambda</span> x: find_url_filetype(x))</span><br><span class="line"></span><br><span class="line">data[<span class="string">&#x27;url_path_len&#x27;</span>] = data[<span class="string">&#x27;url_path&#x27;</span>].apply(<span class="built_in">len</span>)</span><br><span class="line">data[<span class="string">&#x27;url_path_num&#x27;</span>] = data[<span class="string">&#x27;url_path&#x27;</span>].apply(<span class="keyword">lambda</span> x: <span class="built_in">len</span>(re.findall(<span class="string">&#x27;/&#x27;</span>,  x)))</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data[<span class="string">&#x27;ua_short&#x27;</span>] = data[<span class="string">&#x27;user_agent&#x27;</span>].apply(<span class="keyword">lambda</span> x: x.split(<span class="string">&#x27;/&#x27;</span>)[<span class="number">0</span>])</span><br><span class="line">data[<span class="string">&#x27;ua_first&#x27;</span>] = data[<span class="string">&#x27;user_agent&#x27;</span>].apply(<span class="keyword">lambda</span> x: x.split(<span class="string">&#x27; &#x27;</span>)[<span class="number">0</span>])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># def strs_contains(strs, keyword):</span></span><br><span class="line"><span class="comment">#     return True if re.search(keyword, strs, re.IGNORECASE) else False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># data[&#x27;url_contains_select&#x27;] = data[&#x27;url_unquote&#x27;].apply(lambda x: strs_contains(x, &#x27;select&#x27;))</span></span><br><span class="line"><span class="comment"># data[&#x27;url_contains_select_from&#x27;] = data[&#x27;url_unquote&#x27;].apply(lambda x: strs_contains(x, &#x27;select.*from&#x27;))</span></span><br><span class="line"><span class="comment"># data[&#x27;url_contains_union&#x27;] = data[&#x27;url_unquote&#x27;].apply(lambda x: strs_contains(x, &#x27;union&#x27;))</span></span><br><span class="line"><span class="comment"># data[&#x27;url_contains_where&#x27;] = data[&#x27;url_unquote&#x27;].apply(lambda x: strs_contains(x, &#x27;where&#x27;))</span></span><br><span class="line"><span class="comment"># data[&#x27;url_contains_struts2&#x27;] = data[&#x27;url_unquote&#x27;].apply(lambda x: strs_contains(x, &#x27;struts2&#x27;))</span></span><br><span class="line"><span class="comment"># data[&#x27;url_contains_alert&#x27;] = data[&#x27;url_unquote&#x27;].apply(lambda x: strs_contains(x, &#x27;alert&#x27;))</span></span><br><span class="line"><span class="comment"># data[&#x27;url_contains_sudo&#x27;] = data[&#x27;url_unquote&#x27;].apply(lambda x: strs_contains(x, &#x27;sudo&#x27;))</span></span><br><span class="line"><span class="comment"># data[&#x27;url_contains_etc_passwd&#x27;] = data[&#x27;url_unquote&#x27;].apply(lambda x: strs_contains(x, &#x27;etc.*passwd&#x27;))</span></span><br><span class="line"><span class="comment"># data[&#x27;url_contains_dot_dot&#x27;] = data[&#x27;url_unquote&#x27;].apply(lambda x: strs_contains(x, &#x27;%2e%2e%2f&#x27;))</span></span><br><span class="line"><span class="comment"># data[&#x27;url_contains_dot_dot2&#x27;] = data[&#x27;url_unquote&#x27;].apply(lambda x: strs_contains(x, &#x27;\.\./&#x27;))</span></span><br><span class="line"><span class="comment"># data[&#x27;url_contains_javascript&#x27;] = data[&#x27;url_unquote&#x27;].apply(lambda x: strs_contains(x, &#x27;javascript&#x27;))</span></span><br><span class="line"><span class="comment"># data[&#x27;url_contains_shell&#x27;] = data[&#x27;url_unquote&#x27;].apply(lambda x: strs_contains(x, &#x27;shell&#x27;))</span></span><br><span class="line"><span class="comment"># data[&#x27;url_contains_java_lang&#x27;] = data[&#x27;url_unquote&#x27;].apply(lambda x: strs_contains(x, &#x27;java.lang&#x27;))</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> tqdm([<span class="string">&#x27;method&#x27;</span>, <span class="string">&#x27;refer&#x27;</span>, <span class="string">&#x27;browser_family&#x27;</span>,<span class="string">&#x27;os_family&#x27;</span>,<span class="string">&#x27;device_family&#x27;</span>, <span class="string">&#x27;device_brand&#x27;</span>, <span class="string">&#x27;device_model&#x27;</span>,<span class="string">&#x27;url_filetype&#x27;</span>,<span class="string">&#x27;ua_short&#x27;</span>,<span class="string">&#x27;ua_first&#x27;</span>]):</span><br><span class="line">    le = LabelEncoder()</span><br><span class="line">    data[col] = le.fit_transform(data[col])</span><br></pre></td></tr></table></figure><pre><code>100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00&lt;00:00, 82.97it/s]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">len</span>(data.select_dtypes(include=[<span class="string">&#x27;int&#x27;</span>,<span class="string">&#x27;float&#x27;</span>]).columns.tolist())</span><br></pre></td></tr></table></figure><pre><code>109</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">col = data.select_dtypes(include=[<span class="string">&#x27;int&#x27;</span>,<span class="string">&#x27;float&#x27;</span>]).columns.tolist()</span><br><span class="line">data = data[col]</span><br><span class="line">feature_names = [i <span class="keyword">for</span> i <span class="keyword">in</span> col <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">&#x27;id&#x27;</span>,<span class="string">&#x27;label&#x27;</span>]]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">train = data[data[<span class="string">&#x27;label&#x27;</span>].notnull()].reset_index(drop = <span class="literal">True</span>)</span><br><span class="line">test = data[~data[<span class="string">&#x27;label&#x27;</span>].notnull()].reset_index(drop = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">x_train = train[feature_names]</span><br><span class="line">y_train = train[<span class="string">&#x27;label&#x27;</span>]</span><br><span class="line">x_test = test[feature_names]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x_train.shape</span><br></pre></td></tr></table></figure><pre><code>(33037, 107)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">lgb_model</span>(<span class="params">train, target, test, k</span>):</span><br><span class="line">    feats = [f <span class="keyword">for</span> f <span class="keyword">in</span> train.columns <span class="keyword">if</span> f <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">&#x27;id&#x27;</span>,<span class="string">&#x27;label&#x27;</span>,  <span class="string">&#x27;url&#x27;</span>, <span class="string">&#x27;url_count&#x27;</span>]]</span><br><span class="line">    <span class="comment">#     feats=import_cols</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Current num of features:&#x27;</span>, <span class="built_in">len</span>(feats))</span><br><span class="line"></span><br><span class="line">    oof_probs = np.zeros((train.shape[<span class="number">0</span>],<span class="number">6</span>))</span><br><span class="line">    output_preds = <span class="number">0</span></span><br><span class="line">    offline_score = []</span><br><span class="line">    feature_importance_df = pd.DataFrame()</span><br><span class="line">    parameters = &#123;</span><br><span class="line">        <span class="string">&#x27;learning_rate&#x27;</span>: <span class="number">0.03</span>,</span><br><span class="line">        <span class="string">&#x27;boosting_type&#x27;</span>: <span class="string">&#x27;gbdt&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;objective&#x27;</span>: <span class="string">&#x27;multiclass&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;metric&#x27;</span>: <span class="string">&#x27;multi_error&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;num_class&#x27;</span>: <span class="number">6</span>,</span><br><span class="line">        <span class="string">&#x27;num_leaves&#x27;</span>: <span class="number">31</span>,</span><br><span class="line">        <span class="string">&#x27;feature_fraction&#x27;</span>: <span class="number">0.6</span>,</span><br><span class="line">        <span class="string">&#x27;bagging_fraction&#x27;</span>: <span class="number">0.8</span>,</span><br><span class="line">        <span class="string">&#x27;min_data_in_leaf&#x27;</span>: <span class="number">15</span>,</span><br><span class="line">        <span class="string">&#x27;verbose&#x27;</span>: -<span class="number">1</span>,</span><br><span class="line">        <span class="string">&#x27;nthread&#x27;</span>: -<span class="number">1</span>,</span><br><span class="line">        <span class="string">&#x27;max_depth&#x27;</span>: <span class="number">7</span></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># parameters = &#123;</span></span><br><span class="line">    <span class="comment">#         &#x27;learning_rate&#x27;: 0.1,</span></span><br><span class="line">    <span class="comment">#         &#x27;metric&#x27;: &#x27;multiclass&#x27;,</span></span><br><span class="line">    <span class="comment">#         &#x27;objective&#x27;: &#x27;multiclass&#x27;,</span></span><br><span class="line">    <span class="comment">#         &#x27;num_classes&#x27;: 6,</span></span><br><span class="line">    <span class="comment">#         &#x27;feature_fraction&#x27;: 0.75,</span></span><br><span class="line">    <span class="comment">#         &#x27;bagging_fraction&#x27;: 0.75,</span></span><br><span class="line">    <span class="comment">#         &#x27;bagging_freq&#x27;: 2,</span></span><br><span class="line">    <span class="comment">#         &#x27;n_jobs&#x27;: -1,</span></span><br><span class="line">    <span class="comment">#         &#x27;seed&#x27;: 1029,</span></span><br><span class="line">    <span class="comment">#         &#x27;max_depth&#x27;: 10,</span></span><br><span class="line">    <span class="comment">#         &#x27;num_leaves&#x27;: 100,</span></span><br><span class="line">    <span class="comment">#         &#x27;lambda_l1&#x27;: 0.5,</span></span><br><span class="line">    <span class="comment">#         &#x27;lambda_l2&#x27;: 0.8,</span></span><br><span class="line">    <span class="comment">#         &#x27;verbose&#x27;: -1</span></span><br><span class="line">    <span class="comment">#     &#125;</span></span><br><span class="line"></span><br><span class="line">    seeds = [<span class="number">2020</span>]</span><br><span class="line">    <span class="keyword">for</span> seed <span class="keyword">in</span> seeds:</span><br><span class="line">        folds = StratifiedKFold(n_splits=k, shuffle=<span class="literal">True</span>, random_state=seed)</span><br><span class="line">        <span class="keyword">for</span> i, (train_index, test_index) <span class="keyword">in</span> <span class="built_in">enumerate</span>(folds.split(train, target)):</span><br><span class="line">            train_y, test_y = target.iloc[train_index], target.iloc[test_index]</span><br><span class="line">            train_X, test_X = train[feats].iloc[train_index, :], train[feats].iloc[test_index, :]</span><br><span class="line"></span><br><span class="line">            dtrain = lgb.Dataset(train_X,</span><br><span class="line">                                 label=train_y)</span><br><span class="line">            dval = lgb.Dataset(test_X,</span><br><span class="line">                               label=test_y)</span><br><span class="line">            lgb_model = lgb.train(</span><br><span class="line">                parameters,</span><br><span class="line">                dtrain,</span><br><span class="line">                num_boost_round=<span class="number">8000</span>,</span><br><span class="line">                valid_sets=[dval],</span><br><span class="line">                <span class="comment"># feval = evalerror,</span></span><br><span class="line">                callbacks=[early_stopping(<span class="number">100</span>), log_evaluation(<span class="number">100</span>)],</span><br><span class="line">            )</span><br><span class="line">            oof_probs[test_index] = lgb_model.predict(test_X[feats], num_iteration=lgb_model.best_iteration) / <span class="built_in">len</span>(</span><br><span class="line">                seeds)</span><br><span class="line">            offline_score.append(lgb_model.best_score[<span class="string">&#x27;valid_0&#x27;</span>][<span class="string">&#x27;multi_error&#x27;</span>])</span><br><span class="line">            output_preds += lgb_model.predict(test[feats],</span><br><span class="line">                                              num_iteration=lgb_model.best_iteration) / folds.n_splits / <span class="built_in">len</span>(seeds)</span><br><span class="line">            <span class="built_in">print</span>(offline_score)</span><br><span class="line">            <span class="comment"># feature importance</span></span><br><span class="line">            fold_importance_df = pd.DataFrame()</span><br><span class="line">            fold_importance_df[<span class="string">&quot;feature&quot;</span>] = feats</span><br><span class="line">            fold_importance_df[<span class="string">&quot;importance&quot;</span>] = lgb_model.feature_importance(importance_type=<span class="string">&#x27;gain&#x27;</span>)</span><br><span class="line">            fold_importance_df[<span class="string">&quot;fold&quot;</span>] = i + <span class="number">1</span></span><br><span class="line">            feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=<span class="number">0</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;OOF-MEAN-AUC:%.6f, OOF-STD-AUC:%.6f&#x27;</span> % (np.mean(offline_score), np.std(offline_score)))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;feature importance:&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(feature_importance_df.groupby([<span class="string">&#x27;feature&#x27;</span>])[<span class="string">&#x27;importance&#x27;</span>].mean().sort_values(ascending=<span class="literal">False</span>).head(<span class="number">50</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> output_preds, oof_probs, np.mean(offline_score), feature_importance_df</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># feature_names = list(</span></span><br><span class="line"><span class="comment">#     filter(</span></span><br><span class="line"><span class="comment">#         lambda x: x not in [&#x27;id&#x27;,&#x27;label&#x27;,&#x27;url&#x27;, &#x27;url_count&#x27;,&#x27;url_query&#x27;],</span></span><br><span class="line"><span class="comment">#         train.columns))</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;开始模型训练train&#x27;</span>)</span><br><span class="line">lgb_preds, lgb_oof, lgb_score, feature_importance_df = lgb_model(train=train[feature_names],</span><br><span class="line">                                                                 target=train[<span class="string">&#x27;label&#x27;</span>],</span><br><span class="line">                                                                 test=test[feature_names], k=<span class="number">5</span>)</span><br></pre></td></tr></table></figure><pre><code>开始模型训练trainCurrent num of features: 107Training until validation scores don&#39;t improve for 100 rounds[100]valid_0&#39;s multi_error: 0.0145278[200]valid_0&#39;s multi_error: 0.0136199[300]valid_0&#39;s multi_error: 0.0134685Early stopping, best iteration is:[203]valid_0&#39;s multi_error: 0.0133172[0.013317191283292978]Training until validation scores don&#39;t improve for 100 rounds[100]valid_0&#39;s multi_error: 0.0119552Early stopping, best iteration is:[63]valid_0&#39;s multi_error: 0.0116525[0.013317191283292978, 0.011652542372881356]Training until validation scores don&#39;t improve for 100 rounds[100]valid_0&#39;s multi_error: 0.011503Early stopping, best iteration is:[92]valid_0&#39;s multi_error: 0.011503[0.013317191283292978, 0.011652542372881356, 0.011502951415165732]Training until validation scores don&#39;t improve for 100 rounds[100]valid_0&#39;s multi_error: 0.011503Early stopping, best iteration is:[55]valid_0&#39;s multi_error: 0.0107462[0.013317191283292978, 0.011652542372881356, 0.011502951415165732, 0.010746178295746934]Training until validation scores don&#39;t improve for 100 rounds[100]valid_0&#39;s multi_error: 0.011503Early stopping, best iteration is:[21]valid_0&#39;s multi_error: 0.0112002[0.013317191283292978, 0.011652542372881356, 0.011502951415165732, 0.010746178295746934, 0.011200242167398214]OOF-MEAN-AUC:0.011684, OOF-STD-AUC:0.000873feature importance:feature2                           222576.4399841                           211736.6668760                           147032.1741784                           108800.5989453                            86021.756831browser_family               62270.5018395                            39814.736140body_tfidf_0                 27317.752312body_tfidf_1                 23303.336642url_name_tfidf_2             16427.787706url_name_tfidf_14            15618.236285url_name_tfidf_3             14344.577968user_agent_len                9418.270741body_user_agent_len_diff      9103.063841user_agent_name_tfidf_2       8463.647873url_query_max_len             6510.758108user_agent_name_tfidf_5       4018.171339body_tfidf_3                  3672.676081body_tfidf_23                 3355.861338user_agent_name_tfidf_4       3142.178290url_name_tfidf_4              3127.492671url_name_tfidf_13             2886.949569url_name_tfidf_1              2849.448233url_name_tfidf_5              2676.723486user_agent_name_tfidf_7       2330.854639user_agent_name_tfidf_14      2310.199494refer_len                     2145.159362user_agent_name_tfidf_3       2103.610035body_tfidf_10                 1986.768004url_name_tfidf_6              1866.483835body_url_len_diff             1849.085455body_tfidf_6                  1846.585181body_len                      1821.060478user_agent_name_tfidf_0       1743.131918id_method_count               1659.460621user_agent_name_tfidf_13      1627.554725body_tfidf_5                  1539.584926url_name_tfidf_8              1485.817275url_name_tfidf_9              1449.335372url_name_tfidf_12             1429.778973url_name_tfidf_10             1413.196746url_name_tfidf_11             1296.268733user_agent_name_tfidf_9       1290.671890url_len                       1284.274063body_tfidf_12                 1279.712368body_tfidf_9                  1209.730761body_tfidf_8                  1161.935181url_name_tfidf_15             1158.114828url_name_tfidf_7               998.550187url_name_tfidf_0               998.193206Name: importance, dtype: float64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># xgb_params = &#123;&#x27;n_estimators&#x27;: 10000,</span></span><br><span class="line"><span class="comment">#               &#x27;learning_rate&#x27;: 0.03689407512484644,</span></span><br><span class="line"><span class="comment">#               &#x27;max_depth&#x27;: 8,</span></span><br><span class="line"><span class="comment">#               &#x27;objective&#x27;: &#x27;multi:softproba&#x27;,</span></span><br><span class="line"><span class="comment">#               &#x27;colsample_bytree&#x27;: 0.3723914688159835,</span></span><br><span class="line"><span class="comment">#               &#x27;subsample&#x27;: 0.780714581166012,</span></span><br><span class="line"><span class="comment">#               &#x27;eval_metric&#x27;: &#x27;mlogloss&#x27;,</span></span><br><span class="line"><span class="comment">#               &#x27;gamma&#x27;: 0,</span></span><br><span class="line"><span class="comment">#               &#x27;nthread&#x27;: 1,</span></span><br><span class="line"><span class="comment">#               &#x27;reg_lambda&#x27;: 50.0,</span></span><br><span class="line"><span class="comment">#               &#x27;random_state&#x27;: 42&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># cat_params = &#123;&#x27;iterations&#x27;: 8000,</span></span><br><span class="line"><span class="comment">#               &#x27;learning_rate&#x27;: 0.03429054860458741,</span></span><br><span class="line"><span class="comment">#               &#x27;reg_lambda&#x27;: 0.3242286463210283,</span></span><br><span class="line"><span class="comment">#               &#x27;subsample&#x27;: 0.9433911589913944,</span></span><br><span class="line"><span class="comment">#               &#x27;random_strength&#x27;: 22.4849972385133,</span></span><br><span class="line"><span class="comment">#               &#x27;depth&#x27;: 8,</span></span><br><span class="line"><span class="comment">#               &#x27;thread_count&#x27;: 1,</span></span><br><span class="line"><span class="comment">#               #         &#x27;min_data_in_leaf&#x27;: 4,</span></span><br><span class="line"><span class="comment">#               &#x27;leaf_estimation_iterations&#x27;: 8,</span></span><br><span class="line"><span class="comment">#               &#x27;task_type&#x27;: &quot;CPU&quot;,</span></span><br><span class="line"><span class="comment">#               &#x27;bootstrap_type&#x27;: &#x27;Bernoulli&#x27;,</span></span><br><span class="line"><span class="comment">#               &#x27;verbose&#x27;: 50,</span></span><br><span class="line"><span class="comment">#               &#x27;early_stopping_rounds&#x27;: 50,</span></span><br><span class="line"><span class="comment">#               # &#x27;eval_metric&#x27;: &#x27;AUC&#x27;,</span></span><br><span class="line"><span class="comment">#               &#x27;loss_function&#x27;:&#x27;MultiClass&#x27;</span></span><br><span class="line"><span class="comment">#               &#125;</span></span><br><span class="line"><span class="comment"># # lgb = LGBMClassifier(**lgb_params)</span></span><br><span class="line"><span class="comment"># xgb = XGBClassifier(**xgb_params)</span></span><br><span class="line"><span class="comment"># cat = CatBoostClassifier(**cat_params)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># # In[18]:</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># def get_oof(feats, target, test, kfold, clf):</span></span><br><span class="line"><span class="comment">#     oof_preds = np.zeros((feats.shape[0],6))</span></span><br><span class="line"><span class="comment">#     sub_preds = np.zeros((test.shape[0],6))</span></span><br><span class="line"><span class="comment">#     for i, (train_idx, valid_idx) in enumerate(kfold.split(feats, target)):</span></span><br><span class="line"><span class="comment">#         train_X, train_y = feats.loc[train_idx], target.loc[train_idx]</span></span><br><span class="line"><span class="comment">#         valid_X, valid_y = feats.loc[valid_idx], target.loc[valid_idx]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#         clf.fit(train_X, train_y, eval_set=[(valid_X, valid_y)], verbose=100, early_stopping_rounds=50, )</span></span><br><span class="line"><span class="comment">#         oof_preds[valid_idx] = clf.predict_proba(valid_X)</span></span><br><span class="line"><span class="comment">#         sub_preds += clf.predict_proba(test)</span></span><br><span class="line"><span class="comment">#         del train_X, train_y, valid_X, valid_y</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#     evalution_result = accuracy_score(target, np.argmax(oof_preds,axis=1))</span></span><br><span class="line"><span class="comment">#     print(&#x27;*&#x27; * 10)</span></span><br><span class="line"><span class="comment">#     print(&#x27;roc auc score:&#x27;, evalution_result)</span></span><br><span class="line"><span class="comment">#     print(&#x27;*&#x27; * 20)</span></span><br><span class="line"><span class="comment">#     sub_preds_result = sub_preds / kfold.n_splits</span></span><br><span class="line"><span class="comment">#     return oof_preds, sub_preds_result</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=2021)</span></span><br><span class="line"><span class="comment"># # 45开始</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># oof_preds_2, sub_preds_2 = get_oof(train[feature_names], train[&#x27;label&#x27;], test[feature_names], kfold, xgb)i</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># oof_preds_3, sub_preds_3 = get_oof(train[feature_names], train[&#x27;label&#x27;], test[feature_names], kfold, cat)</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sub[<span class="string">&#x27;predict&#x27;</span>]=np.argmax(lgb_preds,axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sub[<span class="string">&#x27;predict&#x27;</span>].value_counts()</span><br></pre></td></tr></table></figure><pre><code>2    8551    8280    8043    6664    4475    400Name: predict, dtype: int64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># sub.to_csv(&#x27;E:/data/DF/Web攻击检测与分类识别/res/9-8-1.csv&#x27;)</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">accuracy_score(train[<span class="string">&#x27;label&#x27;</span>],np.argmax(lgb_oof,axis=<span class="number">1</span>))</span><br></pre></td></tr></table></figure><pre><code>0.9883161303992494</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># lgb</span></span><br><span class="line">f1_score(np.argmax(lgb_oof,axis=<span class="number">1</span>),train[<span class="string">&#x27;label&#x27;</span>],average= <span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># xgb</span></span><br><span class="line"><span class="comment"># f1_score(np.argmax(oof_preds_2,axis=1),train[&#x27;label&#x27;],average= &#x27;macro&#x27;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># cat</span></span><br><span class="line"><span class="comment"># f1_score(np.argmax(lgb_oof,axis=1),train[&#x27;label&#x27;],average= &#x27;macro&#x27;)</span></span><br></pre></td></tr></table></figure><pre><code>0.9650199644033531</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(classification_report(train[<span class="string">&#x27;label&#x27;</span>],np.argmax(lgb_oof,axis=<span class="number">1</span>)))</span><br></pre></td></tr></table></figure><pre><code>              precision    recall  f1-score   support         0.0       0.99      1.00      1.00      6489         1.0       0.99      0.99      0.99     14038         2.0       0.99      0.99      0.99      9939         3.0       0.94      0.93      0.94      1215         4.0       0.94      0.87      0.90       697         5.0       0.97      0.98      0.98       659    accuracy                           0.99     33037   macro avg       0.97      0.96      0.97     33037weighted avg       0.99      0.99      0.99     33037</code></pre><p>​    </p>]]></content>
    
    
    <summary type="html">&lt;p&gt;CCF BDCI Web攻击检测与分类识别 Top8思路&lt;/p&gt;</summary>
    
    
    
    <category term="竞赛" scheme="https://du2279664786.github.io/categories/%E7%AB%9E%E8%B5%9B/"/>
    
    
    <category term="数据挖掘" scheme="https://du2279664786.github.io/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"/>
    
    <category term="文本挖掘" scheme="https://du2279664786.github.io/tags/%E6%96%87%E6%9C%AC%E6%8C%96%E6%8E%98/"/>
    
  </entry>
  
  <entry>
    <title>BERT梳理</title>
    <link href="https://du2279664786.github.io/posts/31537f8b.html"/>
    <id>https://du2279664786.github.io/posts/31537f8b.html</id>
    <published>2022-11-28T14:55:10.000Z</published>
    <updated>2022-11-28T02:42:11.697Z</updated>
    
    <content type="html"><![CDATA[<p>BERT的总结与梳理</p><span id="more"></span><p>在学习BERT之前，我们需要回顾一下Transformer，看一下这篇文章：<a href="https://du2279664786.github.io/posts/55106.html">Transformer总结和梳理</a></p><p>而BERT只包括Transformer中的Encoder结构</p><h1 id="总体概览"><a href="#总体概览" class="headerlink" title="总体概览"></a>总体概览</h1><p>本文通过以下几部分来梳理BERT</p><ul><li><p>BERT的输入</p></li><li><p>BERT的结构</p></li><li><p>BERT所做的任务</p></li></ul><h1 id="BERT的输入"><a href="#BERT的输入" class="headerlink" title="BERT的输入"></a>BERT的输入</h1><p>先放一张图片来看一下BERT的输入结构:</p><p><img src="https://s2.loli.net/2022/11/27/se3KlBPxuyZzhMJ.png" alt="Snipaste_2022-11-27_17-11-50.png"></p><p>可以看出BERT的输入包括三部分:Token Embedding+Segment Embedding+Position Embedding组成</p><h2 id="Token-Embedding"><a href="#Token-Embedding" class="headerlink" title="Token Embedding"></a>Token Embedding</h2><p>Token Embedding为将原始文本转化为embedding后的结果，其shape为[N,d_model]，N为seq_lenght，d_model词向量的维度</p><h2 id="Segment-Embedding"><a href="#Segment-Embedding" class="headerlink" title="Segment Embedding"></a>Segment Embedding</h2><p>Segment Embedding为句子分割嵌入，主要用来区分前后两句话，其shape为[N,d_model]，N为seq_lenght，d_model句子嵌入的维度</p><h2 id="Position-Embedding"><a href="#Position-Embedding" class="headerlink" title="Position Embedding"></a>Position Embedding</h2><p>Position Embedding为位置嵌入，用来区分token的位置，其shape为[N,d_model],N为seq_length，d_model为位置嵌入的维度,详细的Position Embedding<a href="https://du2279664786.github.io/posts/7459.html">请点击此处查看</a></p><p>可以看出，三种Embedding之后shape是一样的，由上图可以看出，input是将三个Embedding进行相加求和，即为输入的向量</p><p><img src="https://s2.loli.net/2022/11/27/boAzwiyY7S14DOB.png" alt="Snipaste_2022-11-27_19-15-47.png"></p><p>在输入BERT前还需进行修改，添加特殊token，[CLS]表示一句话的开头，s_m和p_n分别为两句话，输⼊序列⾸标记[SEP]⽤作分类任务表示；特殊标记[SEP]⽤作区分句⼦对各⼦句。</p><h1 id="BERT的结构"><a href="#BERT的结构" class="headerlink" title="BERT的结构"></a>BERT的结构</h1><h2 id="整体结构"><a href="#整体结构" class="headerlink" title="整体结构"></a>整体结构</h2><p><img src="https://s2.loli.net/2022/11/27/MCDvQJ7wetBnl8d.jpg" alt="bert-模型结构.jpg"></p><p>由上图可以看出：BERT是由多个Trm组成，Trm为Transformer的Encoder结构，即BERT是由多个Transformer的Encoder堆叠而成</p><p>根据堆叠的层数不同，将BERT分为两类</p><pre><code>+ BERT-base：12层，768维度，12头，110百万参数+ BERT-large：24层，1024维度，16头，340百万参数</code></pre><h2 id="单个Block"><a href="#单个Block" class="headerlink" title="单个Block"></a>单个Block</h2><p>单个Block就是Transformer的Encoder,结构如下:</p><p><img src="https://s2.loli.net/2022/11/27/mfy98lKF7jYNhGu.png" alt="Snipaste_2022-11-27_20-40-47.png"></p><p>关于input输入,篇幅刚开始已经做详细介绍</p><h3 id="多头注意力与缩放点积"><a href="#多头注意力与缩放点积" class="headerlink" title="多头注意力与缩放点积"></a>多头注意力与缩放点积</h3><p><img src="https://s2.loli.net/2022/11/27/QvYcZlz8H29AmxV.png" alt="Snipaste_2022-11-27_20-44-36.png"></p><p>这里的多头注意力和缩放点积均和Transformer中的相同,缩放点积打分函数如下:</p><p><img src="https://s2.loli.net/2022/11/27/x4KVYBuPs8CaQUf.png" alt="Snipaste_2022-11-27_20-53-16.png"></p><p>具体详细解析可以<a href="https://du2279664786.github.io/posts/17366.html">点击此处查看</a></p><h3 id="ADD-amp-Norm"><a href="#ADD-amp-Norm" class="headerlink" title="ADD &amp; Norm"></a>ADD &amp; Norm</h3><p>关于ADD &amp; Norm可以<a href="https://du2279664786.github.io/posts/34541.html">点击此处</a>查看解释</p><h3 id="前馈神经网络"><a href="#前馈神经网络" class="headerlink" title="前馈神经网络"></a>前馈神经网络</h3><p>FeedForward是Multi-Head Attention的输出做了残差连接和Norm之后得数据，然后FeedForward做了两次线性线性变换，为的是更加深入的提取特征。<br>在每次线性变换都引入了非线性激活函数Relu，在Multi-Head Attention中，主要是进行矩阵乘法，即都是线性变换，而线性变换的学习能力不如非线性变换的学习能力强，FeedForward的计算公式如下：max相当于Relu<br><img src="https://s2.loli.net/2022/11/27/BgoDL1sen7GU6Fx.png" alt="Snipaste_2022-11-27_20-57-27.png"></p><p>所以FeedForward的作用是：通过线性变换，先将数据映射到高纬度的空间再映射到低纬度的空间，提取了更深层次的特征</p><h3 id="PAD掩码"><a href="#PAD掩码" class="headerlink" title="PAD掩码"></a>PAD掩码</h3><p>对于Transformer而言，每次的输入为：[batch_size,seq_length,d_module]结构，由于句子一般是长短不一的，而输入的数据需要是固定的格式，所以要对句子进行处理。<br>通常会把每个句子按照最大长度进行补齐，所以当句子不够长时，需要进行补0操作，以保证输入数据结构的完整性<br>但是在计算注意力机制时的Softmax函数时，就会出现问题，Padding数值为0的话，仍然会影响到Softmax的计算结果，即无效数据参加了运算。<br>为了不让Padding数据产生影响，通常会将Padding数据变为负无穷，这样的话就不会影响Softmax函数了</p><h1 id="BERT的两个任务"><a href="#BERT的两个任务" class="headerlink" title="BERT的两个任务"></a>BERT的两个任务</h1><h2 id="遮蔽语言模型-MLM-训练任务"><a href="#遮蔽语言模型-MLM-训练任务" class="headerlink" title="遮蔽语言模型(MLM)训练任务"></a>遮蔽语言模型(MLM)训练任务</h2><p>遮蔽语⾔模型可描述为给定单词上下⽂序列后，当前单词出现的条件概率的乘积：</p><p><img src="https://s2.loli.net/2022/11/27/dx6AvlVQ7PD1jJK.png" alt="Snipaste_2022-11-27_21-23-41.png"></p><p>其中, $W_t$是第t个单词，$W_i^j$&#x3D;（$W_i$,$W_{i+1}$,………..$W_{j+1}$,$W_{j}$）是从第i个单词到第j个单词的子序列。</p><p>具体的表现形式如下：</p><p>在输入Embedding中会选择15%的单词进行MASK，再将其预测出来，MASK操作只会发生在Pre-training中，而在Fine-turning中不会出现，为了减少MASK对微调的影响，采用以下策略：</p><pre><code>+ 80%的词会被真正[MASK]+ 10%的次会被随机替换成其它Token+ 10%的词保持不变</code></pre><h2 id="预测下个句子-NSP-任务"><a href="#预测下个句子-NSP-任务" class="headerlink" title="预测下个句子(NSP)任务"></a>预测下个句子(NSP)任务</h2><p>从语料库中⽣成⼆值化的下⼀句句⼦预测任务。</p><p>具体的，当为每个预训练选择句⼦A和B时，B的50％的时间是跟随A的实际下⼀个句⼦，⽽50％的时间是来⾃语料库的<br>随机句⼦。</p><ul><li>input &#x3D; [CLS] the man went to [MASK] store [SEP] he bought a gallon [MASK] milk [SEP] label &#x3D; IsNext</li><li>input &#x3D; [CLS] the man [MASK] to the store [SEP] penguin [MASK] are filght ##less birds [SEP] label &#x3D; NotNext</li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;BERT的总结与梳理&lt;/p&gt;</summary>
    
    
    
    <category term="自然语言处理" scheme="https://du2279664786.github.io/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"/>
    
    
    <category term="NLP" scheme="https://du2279664786.github.io/tags/NLP/"/>
    
    <category term="Transformer" scheme="https://du2279664786.github.io/tags/Transformer/"/>
    
    <category term="BERT" scheme="https://du2279664786.github.io/tags/BERT/"/>
    
  </entry>
  
  <entry>
    <title>基于ResNet50的口罩检测</title>
    <link href="https://du2279664786.github.io/posts/2b88de7d.html"/>
    <id>https://du2279664786.github.io/posts/2b88de7d.html</id>
    <published>2022-11-26T14:55:10.000Z</published>
    <updated>2022-11-26T12:41:01.411Z</updated>
    
    <content type="html"><![CDATA[<p>基于 ResNet50 模型的口罩佩戴检测</p><span id="more"></span><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>​在公共场所佩戴口罩，是防止新型冠状病毒传染的最主要手段，在必要的场所，每个人都必须佩戴口罩以进行自我保护。在人群相对集中的公共场所，相互之间不可避免地存在遮挡干扰，从而产生了小范围内的复杂干扰识别问题。</p><p>​如果使用单一的卷积神经网络对口罩佩戴进行识别，有可能造成提取关键特征信息时聚焦度欠缺，出现特征提取不足等问题。因此本文提出一种两渠道卷积神经网络的佩戴口罩识别方法。在卷积神经网络的基础上，通过 2 个输入渠道，分别对眼睛区域和眼睛以下的区域，进行特征提取; 最后通过基于决策层的信息融合方法，将 2 个渠道的识别结果加以融合，从而得到最终的识别结果，其平均识别准确率达到了 98.8%。经过实验验证，该方法在佩戴口罩的识别上，取得了较好的识别准确率。</p><p>​    在过去的十年间，人工智能（ArtificialIntelligence，AI）相关技术日新月异，几乎颠覆了传统的计算机视觉领域，随着机器学习、大数据处理、深度学习等重要理论的日益完善，很多十年前听起来像是天方夜谭的任务，例如智能机器人、图像识别、语音识别和个性化推荐系统等，如今已经变得触手可及，密切融入了我们的日常社会生活之中。卷积神经网络（Convolutional NeuralNetworks，CNN）是一类具有层级构造并以卷积运算为主的神经网络，是过去十年里计算机视觉领域的绝对主角。1998年，Le Cun 等人首次提出了用于手写数字图像识别的卷积神经网络 LeNet，通过梯度下降（GradientDescent）算法训练的 LeNet 模型取得了当时世界最先进的准确率，这一奠基性的尝试首次让卷积神经网络走向了全世界，并对后来人工智能技术的发展产生了深远的影响。随着2006年深度学习理论的提出，卷积神经网络对图像数据的学习能力和表达能力得到了非常广泛的关注，并且计算机硬件性能的高速更新迭代也为卷积神经网络的应用推广提供了相当有利的条件[2]。自从 2012 年 AlexNet 的横空出世以来，在现代 GPU 计算集群的支持下，VGGNet、GoogLeNet 和 ResNet 等结构更为复杂的卷积神经网络不停地在 ImageNet 等著名的大型视觉比赛中刷新记录，卷积神经网络在传统的计算机视觉领域掀起了重要的变革。得益于深度学习理论的快速发展，除了较为成熟的图像分类领域之外，图像分割、目标检测和目标追踪等关联领域同样涌现出了很多颠覆性的算法。新冠疫情防控工作中，需要在机场、车站等公共场所对人流的口罩佩戴情况实施监测，这可以被抽象为一种目标检测任务，该任务中需要检测的目标包含了口罩目标<br>（佩戴口罩）和人脸目标（未佩戴口罩），共 2 个类别，如下图所示。</p><p><img src="https://s2.loli.net/2022/11/26/lRUVOz5P8Bsq1ju.png" alt="Snipaste_2022-11-26_20-20-08.png"></p><h1 id="ResNet50-模型的介绍"><a href="#ResNet50-模型的介绍" class="headerlink" title="ResNet50 模型的介绍"></a>ResNet50 模型的介绍</h1><p>神经网络微调是一种深度迁移学习，是将具有通用的特征提取能力的预训练模型迁入到目标网络，根据不同的训练任务对预训练模型网络结构进行调整，在目标数据集上训练微调模型参数，将其转化为目标领域神经网络的一部分。文献中残差网络有效地解决了深度卷积神经网络出现的退化问题。下图为一个 bottleneck 残差单元输入与输出关系。</p><p><img src="https://s2.loli.net/2022/11/26/sRQ9rXKWDZtb6Pw.png" alt="Snipaste_2022-11-26_20-30-35.png"></p><p>​                                                               图 3-1 Ｒesidual network unit</p><p>图 3-1 中:x 表示该残差单元的输入;F(x)表示输入在经过卷积层后的残差值;H(x)表示当前残差单元的输出，其的表达式如下:<br>                        H(x)&#x3D;F(x)+x<br>设卷积神经网络的期望输出为 H’(x)，在网络训练达到较饱和准确率的情况下，接下来的学习相当于一个恒等映射学习，也就是 H(x)&#x3D;x，之后的训练目标就变成使残差 F(x)趋近于 0，随着网络加深，准确率不再下降。Bottleneck 是构成ＲesNet50 的基本单元，每个 Bottleneck 残差块由 3 个卷积层构成，图 3-1 中采用 1×1 卷积降低输入通道，最后再用 1×1 卷积恢复，从而减少计算量。输入数据在经过 3 次卷积后得出的输出数据再与输入相加得到该残差块最终输出。<br>图 3-2 为 ResNet50 预训练模型参数迁移，从 ImageNet 中迁移预训练模型，根据是否佩戴口罩修改全链接(fc)层结构、冻结不同卷积层参数，通过训练，进一步调整模型参数以适应口罩数据集。</p><p>​因为卷积神经网络在训练时参与训练的参数量对训练效率，最终准确率有很大影响。在不迁移参数的情况下，模型的性能是随着冻结参数的增多而下降的，但是训练效率会提升。因此本文将ＲesNet50 网络的部分卷积层参数替换为预训练模型参数并锁定，其余卷积层参与对口罩数据集的训练。因此在实验部分重点探究ＲesNet50 网络不同参数迁移量对识别准确率，训练耗时的影响。</p><p><img src="https://s2.loli.net/2022/11/26/wtR2LZzsPX15C7a.png" alt="Snipaste_2022-11-26_20-32-15.png"></p><h2 id="模型的建立"><a href="#模型的建立" class="headerlink" title="模型的建立"></a>模型的建立</h2><p>​模型构建采用的是 TensorFlow 的序列模型框架，首先转换图片数据作为模型的输入，之后再加载 Resnet50 网络去做微调。之后再添加两个 dense 层，两个 dence 层的 activation 分别使用的 relu 和 sigmoid。另外，在模型训练过程中，采用 dropout 以防止过拟合。编译过程采用梯度下降算法进行权重的更新迭代。</p><h2 id="模型的评估"><a href="#模型的评估" class="headerlink" title="模型的评估"></a>模型的评估</h2><p>损失函数 LOSS 如下图所示：</p><p><img src="https://s2.loli.net/2022/11/26/r8Ey3vgQxTScp9w.png" alt="Snipaste_2022-11-26_20-34-24.png"></p><p>准确率 Accuracy 如下图所示：</p><p><img src="https://s2.loli.net/2022/11/26/hcVTUzAbpwQd98s.png" alt="Snipaste_2022-11-26_20-35-20.png"></p><h1 id="最终实现的效果"><a href="#最终实现的效果" class="headerlink" title="最终实现的效果"></a>最终实现的效果</h1><p><img src="https://s2.loli.net/2022/11/26/UYL4PohJz3rWF1A.png" alt="Snipaste_2022-11-26_20-37-28.png"></p><p><img src="https://s2.loli.net/2022/11/26/31WTuCJe7jvHP68.png" alt="Snipaste_2022-11-26_20-38-04.png"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;基于 ResNet50 模型的口罩佩戴检测&lt;/p&gt;</summary>
    
    
    
    <category term="机器视觉" scheme="https://du2279664786.github.io/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    
    <category term="深度学习" scheme="https://du2279664786.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="CV" scheme="https://du2279664786.github.io/tags/CV/"/>
    
    <category term="Resnet" scheme="https://du2279664786.github.io/tags/Resnet/"/>
    
    <category term="微调" scheme="https://du2279664786.github.io/tags/%E5%BE%AE%E8%B0%83/"/>
    
  </entry>
  
  <entry>
    <title>机器视觉-手势识别</title>
    <link href="https://du2279664786.github.io/posts/486b0f81.html"/>
    <id>https://du2279664786.github.io/posts/486b0f81.html</id>
    <published>2022-11-25T13:55:10.000Z</published>
    <updated>2022-11-26T12:55:53.786Z</updated>
    
    <content type="html"><![CDATA[<p>使用keras搭建网络进行手势识别，并查看准确率和损失函数曲线</p><span id="more"></span><h1 id="实验要求"><a href="#实验要求" class="headerlink" title="实验要求"></a>实验要求</h1><p><img src="https://s2.loli.net/2022/11/26/4E8hcfkVGP3nRjH.png" alt="实验1手势识别.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> platform</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">your_name, your_code, work_counter = <span class="string">&quot;人工智能20本杜培博&quot;</span>, <span class="number">200507340136</span>, <span class="number">2</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;我是：<span class="subst">&#123;your_name&#125;</span>，学号：<span class="subst">&#123;your_code&#125;</span>，这是我的第 <span class="subst">&#123;work_counter&#125;</span> 次作业。&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;现在是&#x27;</span>, datetime.datetime.now())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;我的机器信息如下：&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(platform.uname())</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\n当前工作目录：&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(os.getcwd())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\n当前目录的文件信息如下：&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(os.listdir())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\n我安装包的情况:&#x27;</span>)</span><br><span class="line">!pip <span class="built_in">list</span></span><br></pre></td></tr></table></figure><pre><code>我是：人工智能20本杜培博，学号：200507340136，这是我的第 2 次作业。现在是 2022-10-21 16:39:19.008657我的机器信息如下：uname_result(system=&#39;Windows&#39;, node=&#39;LAPTOP-5PHEQ8I3&#39;, release=&#39;10&#39;, version=&#39;10.0.18362&#39;, machine=&#39;AMD64&#39;, processor=&#39;AMD64 Family 23 Model 24 Stepping 1, AuthenticAMD&#39;)当前工作目录：E:\jupyter\curriculum_code\da three\competition\week02当前目录的文件信息如下：[&#39;.ipynb_checkpoints&#39;, &#39;hand_gesture_dataset&#39;, &#39;Untitled.ipynb&#39;]我安装包的情况:Package                Version---------------------- -----------</code></pre><h1 id="导入包"><a href="#导入包" class="headerlink" title="导入包"></a>导入包</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt <span class="comment"># for plotting</span></span><br><span class="line"><span class="keyword">import</span> os <span class="comment"># provides a way of using operating system dependent functionality</span></span><br><span class="line"><span class="keyword">import</span> cv2 <span class="comment">#Image handling library</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> keras.backend <span class="keyword">as</span> K</span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> Callback,ModelCheckpoint</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential,load_model</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense, Dropout</span><br><span class="line"><span class="keyword">from</span> keras.wrappers.scikit_learn <span class="keyword">import</span> KerasClassifier</span><br><span class="line"><span class="keyword">import</span> keras.backend <span class="keyword">as</span> K</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_multilabel_classification</span><br><span class="line"><span class="comment"># Import of keras model and hidden layers for our convolutional network</span></span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Conv2D, Activation, MaxPool2D, Dense, Flatten, Dropout</span><br></pre></td></tr></table></figure><pre><code>Using TensorFlow backend.</code></pre><h1 id="读取目录，遍历文件夹"><a href="#读取目录，遍历文件夹" class="headerlink" title="读取目录，遍历文件夹"></a>读取目录，遍历文件夹</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># paths for dataset</span></span><br><span class="line">data_path = <span class="string">&quot;./hand_gesture_dataset&quot;</span></span><br><span class="line">IMG_SIZE = <span class="number">40</span></span><br><span class="line">CATEGORIES = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> os.listdir(data_path):</span><br><span class="line">    CATEGORIES.append(i)</span><br><span class="line">CATEGORIES</span><br></pre></td></tr></table></figure><pre><code>[&#39;EIGHT&#39;, &#39;FIVE&#39;, &#39;FOUR&#39;, &#39;GOOD&#39;, &#39;NINE&#39;, &#39;OK&#39;, &#39;ONE&#39;, &#39;SEVEN&#39;, &#39;SIX&#39;, &#39;TEN&#39;, &#39;THREE&#39;, &#39;TWO&#39;]</code></pre><h1 id="将label进行编码"><a href="#将label进行编码" class="headerlink" title="将label进行编码"></a>将label进行编码</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">revice</span>(<span class="params">name</span>):</span><br><span class="line">    <span class="keyword">if</span> name==<span class="string">&#x27;ONE&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">elif</span> name==<span class="string">&#x27;TWO&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">2</span></span><br><span class="line">    <span class="keyword">elif</span> name==<span class="string">&#x27;THREE&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">3</span></span><br><span class="line">    <span class="keyword">elif</span> name==<span class="string">&#x27;FOUR&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">4</span></span><br><span class="line">    <span class="keyword">elif</span> name==<span class="string">&#x27;FIVE&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">5</span></span><br><span class="line">    <span class="keyword">elif</span> name==<span class="string">&#x27;SIX&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">6</span></span><br><span class="line">    <span class="keyword">elif</span> name==<span class="string">&#x27;SEVEN&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">7</span></span><br><span class="line">    <span class="keyword">elif</span> name==<span class="string">&#x27;EIGHT&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">8</span></span><br><span class="line">    <span class="keyword">elif</span> name==<span class="string">&#x27;NINE&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">9</span></span><br><span class="line">    <span class="keyword">elif</span> name==<span class="string">&#x27;TEN&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">10</span></span><br><span class="line">    <span class="keyword">elif</span> name==<span class="string">&#x27;GOOD&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">11</span></span><br><span class="line">    <span class="keyword">elif</span> name==<span class="string">&#x27;OK&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">12</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="遍历读取图片data"><a href="#遍历读取图片data" class="headerlink" title="遍历读取图片data"></a>遍历读取图片data</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">image_data = []</span><br><span class="line"></span><br><span class="line">data = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> category <span class="keyword">in</span> CATEGORIES:</span><br><span class="line">    path = os.path.join(data_path, category)</span><br><span class="line"><span class="comment">#     print(os.listdir(path))</span></span><br><span class="line">    <span class="keyword">for</span> img <span class="keyword">in</span> os.listdir(path):</span><br><span class="line">        img_arr = cv2.imread(os.path.join(path,img))       <span class="comment"># ,cv2.IMREAD_GRAYSCALE</span></span><br><span class="line">        image_data.append([img_arr,revice(category)])</span><br><span class="line"><span class="comment">#     data[category] =image_data</span></span><br><span class="line"><span class="comment">#     print(data.get(categorys,img_arr))</span></span><br><span class="line"></span><br><span class="line">plt.imshow(img_arr)</span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.image.AxesImage at 0x19a7e675e80&gt;</code></pre><p><img src="https://s2.loli.net/2022/11/26/e4lEYjsFpOdNxZS.png" alt="Snipaste_2022-11-26_20-50-10.png"></p><p>​    </p><h1 id="打乱数据"><a href="#打乱数据" class="headerlink" title="打乱数据"></a>打乱数据</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># shuffle the input data</span></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line">random.shuffle(image_data)</span><br></pre></td></tr></table></figure><h1 id="将数据和label分离"><a href="#将数据和label分离" class="headerlink" title="将数据和label分离"></a>将数据和label分离</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">input_data = []</span><br><span class="line">label = []</span><br><span class="line"><span class="keyword">for</span> X, y <span class="keyword">in</span> image_data:</span><br><span class="line">    input_data.append(X)</span><br><span class="line">    label.append(y)</span><br><span class="line"><span class="comment"># input_data[:5]</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># label</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(<span class="number">1</span>, figsize=(<span class="number">10</span>,<span class="number">10</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">17</span>):</span><br><span class="line">    plt.subplot(<span class="number">4</span>,<span class="number">4</span>,i)</span><br><span class="line">    plt.imshow(image_data[i][<span class="number">0</span>], cmap=<span class="string">&#x27;hot&#x27;</span>)</span><br><span class="line">    plt.xticks([])</span><br><span class="line">    plt.yticks([])</span><br><span class="line"><span class="comment">#     plt.title(CATEGORIES[label[i]][3:])</span></span><br><span class="line"><span class="comment">#plt.show()</span></span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/11/26/e4lEYjsFpOdNxZS.png" alt="Snipaste_2022-11-26_20-50-10.png"></p><p>​    </p><h1 id="归一化数值"><a href="#归一化数值" class="headerlink" title="归一化数值"></a>归一化数值</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Normalizing the data</span></span><br><span class="line">input_data = np.array(input_data)</span><br><span class="line">label = np.array(label)</span><br><span class="line">input_data = input_data/<span class="number">255.0</span></span><br><span class="line">input_data.shape</span><br></pre></td></tr></table></figure><pre><code>(96252, 40, 40, 3)</code></pre><h1 id="数据分割"><a href="#数据分割" class="headerlink" title="数据分割"></a>数据分割</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_multilabel_classification</span><br><span class="line">X,y=make_multilabel_classification(n_samples=<span class="number">500</span>,n_features=<span class="number">4</span>,n_classes=<span class="number">2</span>,n_labels=<span class="number">3</span>,random_state=<span class="number">1</span>)</span><br><span class="line">X</span><br></pre></td></tr></table></figure><pre><code>array([[ 9., 12.,  6., 12.],       [ 5.,  2., 12., 22.],       [15.,  5., 12., 11.],       ...,       [ 5., 10., 15., 28.],       [ 0.,  8., 16., 27.],       [ 6.,  9., 13., 22.]])</code></pre><h1 id="独热编码"><a href="#独热编码" class="headerlink" title="独热编码"></a>独热编码</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.utils <span class="keyword">import</span> to_categorical</span><br><span class="line">label = to_categorical(label, num_classes=<span class="number">13</span>,dtype=<span class="string">&#x27;i1&#x27;</span>)</span><br><span class="line">label.shape</span><br></pre></td></tr></table></figure><pre><code>(96252, 13)</code></pre><h1 id="训练集和测试集9-1分割"><a href="#训练集和测试集9-1分割" class="headerlink" title="训练集和测试集9:1分割"></a>训练集和测试集9:1分割</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="comment">#X_train, X_test, y_train, y_test = train_test_split(input_data, label, test_size = 0.3, random_state=0)</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(input_data, label, test_size = <span class="number">0.10</span>, random_state=<span class="number">0</span>)</span><br><span class="line">X_train.shape,y_train.shape,X_test.shape,y_test.shape</span><br></pre></td></tr></table></figure><pre><code>((86626, 40, 40, 3), (86626, 13), (9626, 40, 40, 3), (9626, 13))</code></pre><h1 id="搭建模型"><a href="#搭建模型" class="headerlink" title="搭建模型"></a>搭建模型</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">model = keras.models.Sequential()</span><br><span class="line"></span><br><span class="line">model.add(Conv2D(filters = <span class="number">32</span>, kernel_size = (<span class="number">3</span>,<span class="number">3</span>), input_shape = (IMG_SIZE, IMG_SIZE, <span class="number">3</span>)))</span><br><span class="line">model.add(Activation(<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line"></span><br><span class="line">model.add(Conv2D(filters = <span class="number">32</span>, kernel_size = (<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(Activation(<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(MaxPool2D(pool_size=(<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line">model.add(Dropout(<span class="number">0.3</span>))</span><br><span class="line"></span><br><span class="line">model.add(Conv2D(filters = <span class="number">64</span>, kernel_size = (<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">model.add(Activation(<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(MaxPool2D(pool_size=(<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line">model.add(Dropout(<span class="number">0.3</span>))</span><br><span class="line"></span><br><span class="line">model.add(Flatten())</span><br><span class="line">model.add(Dense(<span class="number">256</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(Dense(<span class="number">13</span>, activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">         optimizer = <span class="string">&#x27;rmsprop&#x27;</span>,</span><br><span class="line">         metrics = [<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">    </span><br></pre></td></tr></table></figure><h1 id="训练模型-32batch-size-7epoch"><a href="#训练模型-32batch-size-7epoch" class="headerlink" title="训练模型:32batch_size,7epoch"></a>训练模型:32batch_size,7epoch</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.fit(X_train, y_train, epochs = <span class="number">7</span>, batch_size=<span class="number">32</span>, validation_data=(X_test, y_test))</span><br></pre></td></tr></table></figure><pre><code>Train on 86626 samples, validate on 9626 samplesEpoch 1/786626/86626 [==============================] - 224s 3ms/step - loss: 0.5109 - accuracy: 0.8228 - val_loss: 0.2274 - val_accuracy: 0.9259Epoch 2/786626/86626 [==============================] - 234s 3ms/step - loss: 0.1164 - accuracy: 0.9630 - val_loss: 0.0445 - val_accuracy: 0.9876Epoch 3/786626/86626 [==============================] - 230s 3ms/step - loss: 0.0731 - accuracy: 0.9773 - val_loss: 0.0430 - val_accuracy: 0.9889Epoch 4/786626/86626 [==============================] - 230s 3ms/step - loss: 0.0574 - accuracy: 0.9825 - val_loss: 0.0309 - val_accuracy: 0.9913Epoch 5/786626/86626 [==============================] - 236s 3ms/step - loss: 0.0508 - accuracy: 0.9847 - val_loss: 0.0329 - val_accuracy: 0.9909Epoch 6/786626/86626 [==============================] - 238s 3ms/step - loss: 0.0468 - accuracy: 0.9863 - val_loss: 0.0197 - val_accuracy: 0.9947Epoch 7/786626/86626 [==============================] - 239s 3ms/step - loss: 0.0464 - accuracy: 0.9870 - val_loss: 0.0219 - val_accuracy: 0.9936&lt;keras.callbacks.callbacks.History at 0x19a1ead3b38&gt;</code></pre><h1 id="查看模型的网络结构"><a href="#查看模型的网络结构" class="headerlink" title="查看模型的网络结构"></a>查看模型的网络结构</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.summary()</span><br></pre></td></tr></table></figure><pre><code>Model: &quot;sequential_1&quot;_________________________________________________________________Layer (type)                 Output Shape              Param #   =================================================================conv2d_1 (Conv2D)            (None, 38, 38, 32)        896       _________________________________________________________________activation_1 (Activation)    (None, 38, 38, 32)        0         _________________________________________________________________conv2d_2 (Conv2D)            (None, 36, 36, 32)        9248      _________________________________________________________________activation_2 (Activation)    (None, 36, 36, 32)        0         _________________________________________________________________max_pooling2d_1 (MaxPooling2 (None, 18, 18, 32)        0         _________________________________________________________________dropout_1 (Dropout)          (None, 18, 18, 32)        0         _________________________________________________________________conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     _________________________________________________________________activation_3 (Activation)    (None, 16, 16, 64)        0         _________________________________________________________________max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         _________________________________________________________________dropout_2 (Dropout)          (None, 8, 8, 64)          0         _________________________________________________________________flatten_1 (Flatten)          (None, 4096)              0         _________________________________________________________________dense_1 (Dense)              (None, 256)               1048832   _________________________________________________________________dense_2 (Dense)              (None, 13)                3341      =================================================================Total params: 1,080,813Trainable params: 1,080,813Non-trainable params: 0_________________________________________________________________</code></pre><h1 id="查看损失"><a href="#查看损失" class="headerlink" title="查看损失"></a>查看损失</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(model.history.history[<span class="string">&#x27;loss&#x27;</span>])</span><br><span class="line">plt.plot(model.history.history[<span class="string">&#x27;val_loss&#x27;</span>])</span><br><span class="line">plt.title(<span class="string">&#x27;Model Loss&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Loss&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Epochs&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;test&#x27;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/11/26/a1T5MzBxKvRoOrw.png" alt="output_30_0.png"></p><h1 id="查看准确率"><a href="#查看准确率" class="headerlink" title="查看准确率"></a>查看准确率</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(model.history.history[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">plt.plot(model.history.history[<span class="string">&#x27;val_accuracy&#x27;</span>])</span><br><span class="line">plt.title(<span class="string">&#x27;Model Accuracy&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Accuracy&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Epochs&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;test&#x27;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/11/26/rmNMpLe549qxHv7.png" alt="output_32_0.png"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;使用keras搭建网络进行手势识别，并查看准确率和损失函数曲线&lt;/p&gt;</summary>
    
    
    
    <category term="机器视觉" scheme="https://du2279664786.github.io/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
    
    <category term="CV" scheme="https://du2279664786.github.io/tags/CV/"/>
    
  </entry>
  
  <entry>
    <title>中文语义病句识别挑战</title>
    <link href="https://du2279664786.github.io/posts/3652056.html"/>
    <id>https://du2279664786.github.io/posts/3652056.html</id>
    <published>2022-11-24T14:55:10.000Z</published>
    <updated>2022-11-24T13:29:30.399Z</updated>
    
    <content type="html"><![CDATA[<p>预测句子是否是语义病句,语义错误和拼写错误、语法错误</p><span id="more"></span><h1 id="中文语义病句识别挑战赛"><a href="#中文语义病句识别挑战赛" class="headerlink" title="中文语义病句识别挑战赛"></a>中文语义病句识别挑战赛</h1><h1 id="一、赛事背景"><a href="#一、赛事背景" class="headerlink" title="一、赛事背景"></a>一、赛事背景</h1><p>近年来随着自媒体热潮的掀起，人人都是信息的生产者，互联网上文本错误的内容暴增，如何避免这些文本错误，成为了人们迫切关注的问题。因此，各大有关文本校对的比赛蜂拥而至。然而，过往的文本错误主要针对拼写错误和语法错误，这些错误对于人类来说相对简单，往往是由外国语言学习者和中文母语写作者的疏忽而产生的。对于出版、教育等一些对深层次的中文语义错误识别有需求的行业，中文语义病句的识别将会有更大的帮助。语义病句经常出现在初高中的语文考试题目中，用来衡量学生对语文知识的掌握程度，这类语义病句对于学生来说是比较困难的，对于研究也有重大意义。</p><h1 id="二、赛事任务"><a href="#二、赛事任务" class="headerlink" title="二、赛事任务"></a>二、赛事任务</h1><p>中文语义病句识别是一个二分类的问题，预测句子是否是语义病句。语义错误和拼写错误、语法错误不同，语义错误更加关注句子语义层面的合法性，语义病句例子如下表所示。</p><table><thead><tr><th>病句</th><th>解析</th></tr></thead><tbody><tr><td>英法联军烧毁并洗劫了北京圆明园。</td><td>应该先“洗劫”，再“烧毁”</td></tr><tr><td>山上的水宝贵，我们把它留给晚上来的人喝。</td><td>歧义，“晚上&#x2F;来”“晚&#x2F;上来”</td></tr><tr><td>国内彩电市场严重滞销。</td><td>“市场”不能“滞销”</td></tr></tbody></table><h1 id="三、评审规则"><a href="#三、评审规则" class="headerlink" title="三、评审规则"></a>三、评审规则</h1><h2 id="1-数据说明"><a href="#1-数据说明" class="headerlink" title="1.数据说明"></a>1.数据说明</h2><p>本次比赛使用的数据一部分来自网络上的中小学病句题库，一部分来自人工标注。每条数据包括句子id、句子标签（0：正确句子&#x2F;1：病句）、句子，以上三个字段用制表符分隔。数据格式示例如下表所示：</p><table><thead><tr><th>id</th><th>标签</th><th>句子</th></tr></thead><tbody><tr><td>1</td><td>1</td><td>英法联军烧毁并洗劫了北京圆明园。</td></tr><tr><td>2</td><td>1</td><td>山上的水宝贵，我们把它留给晚上来的人喝。</td></tr><tr><td>3</td><td>0</td><td>国内彩电严重滞销。</td></tr></tbody></table><p>本次大赛由哈工大讯飞联合实验室提供的数据作为训练样本。训练集中病句和正确句子的比例大致7：3，要求参赛者使用且仅能使用组织方提供的训练集进行训练，不允许使用额外的人工标注的数据进行训练、更不允许将测试集的数据用于训练。此次比赛分为初赛和复赛两个阶段，两个阶段所使用的训练集相同。</p><h2 id="2-评估指标"><a href="#2-评估指标" class="headerlink" title="2.评估指标"></a>2.评估指标</h2><p>本模型依据提交的结果文件，采用针对语义病句的F1-score进行评价。</p><h1 id="实现代码"><a href="#实现代码" class="headerlink" title="实现代码"></a>实现代码</h1><h2 id="导入所需包"><a href="#导入所需包" class="headerlink" title="导入所需包"></a>导入所需包</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> partial</span><br><span class="line"><span class="keyword">from</span> sklearn.utils.class_weight <span class="keyword">import</span> compute_class_weight</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"><span class="keyword">import</span> paddle <span class="keyword">as</span> P</span><br><span class="line"><span class="keyword">import</span> paddle.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> paddlenlp <span class="keyword">as</span> ppnlp</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> paddle.io <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">from</span> paddlenlp.data <span class="keyword">import</span> Stack, <span class="type">Tuple</span>, Pad</span><br><span class="line"><span class="keyword">from</span> paddlenlp.datasets <span class="keyword">import</span> MapDataset</span><br><span class="line"><span class="keyword">from</span> paddlenlp.transformers <span class="keyword">import</span> LinearDecayWithWarmup</span><br><span class="line"><span class="keyword">from</span> paddlenlp.transformers <span class="keyword">import</span> ErnieGramModel</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedKFold</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> paddle.fluid <span class="keyword">as</span> fluid</span><br><span class="line"><span class="keyword">import</span> paddle.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> f1_score</span><br></pre></td></tr></table></figure><h2 id="初始化所有需要的用到的参数"><a href="#初始化所有需要的用到的参数" class="headerlink" title="初始化所有需要的用到的参数"></a>初始化所有需要的用到的参数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># =============================== 初始化 ========================</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Config</span>:</span><br><span class="line">    text_col = <span class="string">&#x27;text&#x27;</span></span><br><span class="line">    target_col = <span class="string">&#x27;label&#x27;</span></span><br><span class="line">    <span class="comment"># 最大长度大小</span></span><br><span class="line">    max_len = <span class="number">90</span></span><br><span class="line">    <span class="comment"># 模型运行批处理大小</span></span><br><span class="line">    batch_size = <span class="number">32</span></span><br><span class="line">    target_size = <span class="number">2</span></span><br><span class="line">    seed = <span class="number">71</span></span><br><span class="line">    n_fold = <span class="number">5</span></span><br><span class="line">    <span class="comment"># 训练过程中的最大学习率</span></span><br><span class="line">    learning_rate = <span class="number">5e-5</span></span><br><span class="line">    <span class="comment"># 训练轮次</span></span><br><span class="line">    epochs = <span class="number">5</span>  <span class="comment"># 3</span></span><br><span class="line">    <span class="comment"># 学习率预热比例</span></span><br><span class="line">    warmup_proportion = <span class="number">0.1</span></span><br><span class="line">    <span class="comment"># 权重衰减系数，类似模型正则项策略，避免模型过拟合</span></span><br><span class="line">    weight_decay = <span class="number">0.01</span></span><br><span class="line">    <span class="comment"># model_name = &quot;ernie-gram-zh&quot;</span></span><br><span class="line">    <span class="comment"># model_name = &quot;ernie-doc-base-zh&quot;</span></span><br><span class="line">    model_name = <span class="string">&quot;ernie-1.0&quot;</span></span><br><span class="line">    print_freq = <span class="number">100</span></span><br></pre></td></tr></table></figure><h2 id="使用FGM-Fast-Gradient-Method-对抗训练过程"><a href="#使用FGM-Fast-Gradient-Method-对抗训练过程" class="headerlink" title="使用FGM(Fast Gradient Method)对抗训练过程"></a>使用FGM(Fast Gradient Method)对抗训练过程</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">FGM</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;针对embedding层梯度上升干扰的对抗训练方法,Fast Gradient Method（FGM）&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, model</span>):</span><br><span class="line">        self.model = model</span><br><span class="line">        self.backup = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">attack</span>(<span class="params">self, epsilon=<span class="number">0.15</span>, emb_name=<span class="string">&#x27;embeddings&#x27;</span></span>):</span><br><span class="line">        <span class="comment"># emb_name这个参数要换成你模型中embedding的参数名</span></span><br><span class="line">        <span class="keyword">for</span> name, param <span class="keyword">in</span> self.model.named_parameters():</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> param.stop_gradient <span class="keyword">and</span> emb_name <span class="keyword">in</span> name:  <span class="comment"># 检验参数是否可训练及范围</span></span><br><span class="line">                self.backup[name] = param.numpy()  <span class="comment"># 备份原有参数值</span></span><br><span class="line">                grad_tensor = paddle.to_tensor(param.grad)  <span class="comment"># param.grad是个numpy对象</span></span><br><span class="line">                norm = paddle.norm(grad_tensor)  <span class="comment"># norm化</span></span><br><span class="line">                <span class="keyword">if</span> norm != <span class="number">0</span>:</span><br><span class="line">                    r_at = epsilon * grad_tensor / norm</span><br><span class="line">                    param.add(r_at)  <span class="comment"># 在原有embed值上添加向上梯度干扰</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">restore</span>(<span class="params">self, emb_name=<span class="string">&#x27;embeddings&#x27;</span></span>):</span><br><span class="line">        <span class="comment"># emb_name这个参数要换成你模型中embedding的参数名</span></span><br><span class="line">        <span class="keyword">for</span> name, param <span class="keyword">in</span> self.model.named_parameters():</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> param.stop_gradient <span class="keyword">and</span> emb_name <span class="keyword">in</span> name:</span><br><span class="line">                <span class="keyword">assert</span> name <span class="keyword">in</span> self.backup</span><br><span class="line">                param.set_value(self.backup[name])  <span class="comment"># 将原有embed参数还原</span></span><br><span class="line">        self.backup = &#123;&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="设置随机种子，保证结果复现"><a href="#设置随机种子，保证结果复现" class="headerlink" title="设置随机种子，保证结果复现"></a>设置随机种子，保证结果复现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">seed_torch</span>(<span class="params">seed=<span class="number">42</span></span>):</span><br><span class="line">    random.seed(seed)</span><br><span class="line">    os.environ[<span class="string">&#x27;PYTHONHASHSEED&#x27;</span>] = <span class="built_in">str</span>(seed)</span><br><span class="line">    np.random.seed(seed)</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.listdir(<span class="string">&#x27;/home/aistudio/data/data176811/&#x27;</span>)</span><br></pre></td></tr></table></figure><pre><code>[&#39;data.xlsx&#39;, &#39;test1.csv&#39;, &#39;提交示例.csv&#39;]</code></pre><h2 id="数据的读取"><a href="#数据的读取" class="headerlink" title="数据的读取"></a>数据的读取</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">CFG = Config()</span><br><span class="line">seed_torch(seed=CFG.seed)</span><br><span class="line">train = pd.read_excel(<span class="string">&#x27;data/data176811/data.xlsx&#x27;</span>)</span><br><span class="line">test = pd.read_table(<span class="string">&#x27;data/data176811/test1.csv&#x27;</span>)</span><br><span class="line"><span class="comment"># train[&#x27;text&#x27;] = train.apply(lambda row: concat_text(row), axis=1)</span></span><br><span class="line"><span class="comment"># test[&#x27;text&#x27;] = test.apply(lambda row: concat_text(row), axis=1)</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train</span><br></pre></td></tr></table></figure><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>id</th>      <th>label</th>      <th>text</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>1</td>      <td>1</td>      <td>通过大力发展社区教育，使我省全民终身学习的教育体系已深入人心。</td>    </tr>    <tr>      <th>1</th>      <td>2</td>      <td>1</td>      <td>再次投入巨资的英超劲旅曼城队能否在2010-2011年度的英超联赛中夺得英超冠军，曼联、切尔...</td>    </tr>    <tr>      <th>2</th>      <td>3</td>      <td>1</td>      <td>广西居民纸质图书的阅读率偏低，手机阅读将成为了广西居民极倾向的阅读方式。</td>    </tr>    <tr>      <th>3</th>      <td>4</td>      <td>1</td>      <td>文字书写时代即将结束，预示着人与字之间最亲密的一种关系已经终结。与此同时，屏幕文化造就了另一...</td>    </tr>    <tr>      <th>4</th>      <td>5</td>      <td>1</td>      <td>安徽合力公司2006年叉车销售强劲，销售收入涨幅很有可能将超过40%以上。公司预计2006年...</td>    </tr>    <tr>      <th>...</th>      <td>...</td>      <td>...</td>      <td>...</td>    </tr>    <tr>      <th>45242</th>      <td>45244</td>      <td>0</td>      <td>进入5月以来，全国新增人感染H7N9禽流感病例呈明显下降趋势。</td>    </tr>    <tr>      <th>45243</th>      <td>45245</td>      <td>1</td>      <td>建设中国新一代天气雷达监测网，能够明显改善对热带气旋或台风登陆位置及强度预报的准确性，尤其对...</td>    </tr>    <tr>      <th>45244</th>      <td>45246</td>      <td>1</td>      <td>每当回忆起和他朝夕相处的一段生活，他那循循善诱的教导和那和蔼可亲的音容笑貌，又重新出现在我的面前。</td>    </tr>    <tr>      <th>45245</th>      <td>45247</td>      <td>1</td>      <td>8月，延安市公开拍卖35辆超编超标公务车。在拍卖过程中，多辆年份较新、行驶里程较少的公务车竞...</td>    </tr>    <tr>      <th>45246</th>      <td>45248</td>      <td>1</td>      <td>清华大学联合剑桥大学、麻省理工学院，成立低碳能源大学联盟未来交通研究中心，他们试图寻找解决北...</td>    </tr>  </tbody></table><p>45247 rows × 3 columns</p><h2 id="定义5折交叉验证"><a href="#定义5折交叉验证" class="headerlink" title="定义5折交叉验证"></a>定义5折交叉验证</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># CV split</span></span><br><span class="line">folds = train.copy()</span><br><span class="line">Fold = StratifiedKFold(n_splits=CFG.n_fold, shuffle=<span class="literal">True</span>, random_state=CFG.seed)</span><br><span class="line"><span class="keyword">for</span> n, (train_index, val_index) <span class="keyword">in</span> <span class="built_in">enumerate</span>(Fold.split(folds, folds[CFG.target_col])):</span><br><span class="line">    folds.loc[val_index, <span class="string">&#x27;fold&#x27;</span>] = <span class="built_in">int</span>(n)</span><br><span class="line">folds[<span class="string">&#x27;fold&#x27;</span>] = folds[<span class="string">&#x27;fold&#x27;</span>].astype(<span class="built_in">int</span>)</span><br></pre></td></tr></table></figure><h2 id="数据预处理操作"><a href="#数据预处理操作" class="headerlink" title="数据预处理操作"></a>数据预处理操作</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ====================================== 数据集以及转换函数==============================</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CustomDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, df</span>):</span><br><span class="line">        self.data = df.values.tolist()</span><br><span class="line">        self.texts = df[CFG.text_col]</span><br><span class="line">        self.labels = df[CFG.target_col]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.texts)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        索引数据</span></span><br><span class="line"><span class="string">        :param idx:</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        text = <span class="built_in">str</span>(self.texts[idx])</span><br><span class="line">        label = self.labels[idx]</span><br><span class="line">        example = &#123;<span class="string">&#x27;text&#x27;</span>: text, <span class="string">&#x27;label&#x27;</span>: label&#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> example</span><br></pre></td></tr></table></figure><h2 id="将data进行Embedding"><a href="#将data进行Embedding" class="headerlink" title="将data进行Embedding"></a>将data进行Embedding</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">convert_example</span>(<span class="params">example, tokenizer, max_seq_length=<span class="number">512</span>, is_test=<span class="literal">False</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    创建Bert输入</span></span><br><span class="line"><span class="string">    ::</span></span><br><span class="line"><span class="string">        0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1</span></span><br><span class="line"><span class="string">        | first sequence    | second sequence |</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        input_ids(obj:`list[int]`): The list of token ids.</span></span><br><span class="line"><span class="string">        token_type_ids(obj: `list[int]`): List of sequence pair mask.</span></span><br><span class="line"><span class="string">        label(obj:`numpy.array`, data type of int64, optional): The input label if not is_test.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    encoded_inputs = tokenizer(text=example[<span class="string">&quot;text&quot;</span>], max_seq_len=max_seq_length)</span><br><span class="line">    input_ids = encoded_inputs[<span class="string">&quot;input_ids&quot;</span>]</span><br><span class="line">    <span class="comment"># print(input_ids)</span></span><br><span class="line">    token_type_ids = encoded_inputs[<span class="string">&quot;token_type_ids&quot;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> is_test:</span><br><span class="line">        label = np.array([example[<span class="string">&quot;label&quot;</span>]], dtype=<span class="string">&quot;int64&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> input_ids, token_type_ids, label</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> input_ids, token_type_ids</span><br></pre></td></tr></table></figure><h2 id="创建DataLoader"><a href="#创建DataLoader" class="headerlink" title="创建DataLoader"></a>创建DataLoader</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">create_dataloader</span>(<span class="params">dataset,</span></span><br><span class="line"><span class="params">                      mode=<span class="string">&#x27;train&#x27;</span>,</span></span><br><span class="line"><span class="params">                      batch_size=<span class="number">1</span>,</span></span><br><span class="line"><span class="params">                      batchify_fn=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                      trans_fn=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="keyword">if</span> trans_fn:</span><br><span class="line">        dataset = dataset.<span class="built_in">map</span>(trans_fn)</span><br><span class="line"></span><br><span class="line">    shuffle = <span class="literal">True</span> <span class="keyword">if</span> mode == <span class="string">&#x27;train&#x27;</span> <span class="keyword">else</span> <span class="literal">False</span></span><br><span class="line">    <span class="keyword">if</span> mode == <span class="string">&#x27;train&#x27;</span>:</span><br><span class="line">        batch_sampler = paddle.io.DistributedBatchSampler(</span><br><span class="line">            dataset, batch_size=batch_size, shuffle=shuffle)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        batch_sampler = paddle.io.BatchSampler(</span><br><span class="line">            dataset, batch_size=batch_size, shuffle=shuffle)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> paddle.io.DataLoader(</span><br><span class="line">        dataset=dataset,</span><br><span class="line">        batch_sampler=batch_sampler,</span><br><span class="line">        collate_fn=batchify_fn,</span><br><span class="line">        return_list=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># tokenizer = ppnlp.transformers.ErnieTokenizer.from_pretrained(CFG.model_name)</span></span><br><span class="line"><span class="comment"># tokenizer = ppnlp.transformers.ErnieGramTokenizer.from_pretrained(CFG.model_name)</span></span><br><span class="line"><span class="comment"># tokenizer = ppnlp.transformers.ErnieTokenizer.from_pretrained(CFG.model_name)</span></span><br><span class="line"><span class="keyword">if</span> CFG.model_name == <span class="string">&#x27;ernie-1.0&#x27;</span>:</span><br><span class="line"></span><br><span class="line">    tokenizer = ppnlp.transformers.ErnieTokenizer.from_pretrained(<span class="string">&#x27;ernie-1.0&#x27;</span>)</span><br><span class="line"><span class="keyword">elif</span> CFG.model_name == <span class="string">&#x27;ernie-doc-base-zh&#x27;</span>:</span><br><span class="line">    tokenizer = ppnlp.transformers.ErnieDocTokenizer.from_pretrained(<span class="string">&#x27;ernie-doc-base-zh&#x27;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    tokenizer = ppnlp.transformers.ErnieGramTokenizer.from_pretrained(CFG.model_name)</span><br><span class="line">trans_func = partial(</span><br><span class="line">    convert_example,</span><br><span class="line">    tokenizer=tokenizer,</span><br><span class="line">    max_seq_length=CFG.max_len)</span><br><span class="line">batchify_fn = <span class="keyword">lambda</span> samples, fn=<span class="type">Tuple</span>(</span><br><span class="line">    Pad(axis=<span class="number">0</span>, pad_val=tokenizer.pad_token_id),  <span class="comment"># input</span></span><br><span class="line">    Pad(axis=<span class="number">0</span>, pad_val=tokenizer.pad_token_type_id),  <span class="comment"># segment</span></span><br><span class="line">    Stack(dtype=<span class="string">&quot;int64&quot;</span>)  <span class="comment"># label</span></span><br><span class="line">): [data <span class="keyword">for</span> data <span class="keyword">in</span> fn(samples)]</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="评估模型"><a href="#评估模型" class="headerlink" title="评估模型"></a>评估模型</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ====================================== 验证与预测函数 ==============================</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@paddle.no_grad()</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate</span>(<span class="params">model, criterion, metric, data_loader</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    验证函数</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    metric.reset()</span><br><span class="line">    losses = []</span><br><span class="line">    preds_list = []</span><br><span class="line">    labels_list = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> data_loader:</span><br><span class="line">        input_ids, token_type_ids, labels = batch</span><br><span class="line">        logits = model(input_ids, token_type_ids)</span><br><span class="line">        preds_list.append(np.argmax(logits.numpy(), axis=<span class="number">1</span>))</span><br><span class="line">        labels_list.append(labels)</span><br><span class="line">        loss = criterion(logits, labels)</span><br><span class="line">        losses.append(loss.numpy())</span><br><span class="line">        correct = metric.compute(logits, labels)</span><br><span class="line">        metric.update(correct)</span><br><span class="line">        accu = metric.accumulate()</span><br><span class="line">    f1_macro = f1_score(np.concatenate(preds_list, axis=<span class="number">0</span>), np.concatenate(labels_list, axis=<span class="number">0</span>), average=<span class="string">&#x27;binary&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;eval loss: %.5f, accu: %.5f&quot;</span> % (np.mean(losses), accu))</span><br><span class="line">    model.train()</span><br><span class="line">    metric.reset()</span><br><span class="line">    <span class="keyword">return</span> accu, f1_macro</span><br></pre></td></tr></table></figure><h2 id="模型进行预测"><a href="#模型进行预测" class="headerlink" title="模型进行预测"></a>模型进行预测</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">model, data, tokenizer, batch_size=<span class="number">1</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    预测函数</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    examples = []</span><br><span class="line">    <span class="keyword">for</span> text <span class="keyword">in</span> data:</span><br><span class="line">        input_ids, segment_ids = convert_example(</span><br><span class="line">            text,</span><br><span class="line">            tokenizer,</span><br><span class="line">            max_seq_length=CFG.max_len,</span><br><span class="line">            is_test=<span class="literal">True</span>)</span><br><span class="line">        examples.append((input_ids, segment_ids))</span><br><span class="line"></span><br><span class="line">    batchify_fn = <span class="keyword">lambda</span> samples, fn=<span class="type">Tuple</span>(</span><br><span class="line">        Pad(axis=<span class="number">0</span>, pad_val=tokenizer.pad_token_id),  <span class="comment"># input id</span></span><br><span class="line">        Pad(axis=<span class="number">0</span>, pad_val=tokenizer.pad_token_id),  <span class="comment"># segment id</span></span><br><span class="line">    ): fn(samples)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Seperates data into some batches.</span></span><br><span class="line">    batches = []</span><br><span class="line">    one_batch = []</span><br><span class="line">    <span class="keyword">for</span> example <span class="keyword">in</span> examples:</span><br><span class="line">        one_batch.append(example)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(one_batch) == batch_size:</span><br><span class="line">            batches.append(one_batch)</span><br><span class="line">            one_batch = []</span><br><span class="line">    <span class="keyword">if</span> one_batch:</span><br><span class="line">        <span class="comment"># The last batch whose size is less than the config batch_size setting.</span></span><br><span class="line">        batches.append(one_batch)</span><br><span class="line"></span><br><span class="line">    results = []</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> tqdm(batches):</span><br><span class="line">        input_ids, segment_ids = batchify_fn(batch)</span><br><span class="line">        input_ids = paddle.to_tensor(input_ids)</span><br><span class="line">        segment_ids = paddle.to_tensor(segment_ids)</span><br><span class="line">        logits = model(input_ids, segment_ids)</span><br><span class="line">        probs = F.softmax(logits, axis=<span class="number">1</span>)</span><br><span class="line">        results.append(probs.numpy())</span><br><span class="line">    <span class="keyword">return</span> np.vstack(results)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="预测数据"><a href="#预测数据" class="headerlink" title="预测数据"></a>预测数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">inference</span>():</span><br><span class="line">    model_paths = [</span><br><span class="line">        <span class="string">f&#x27;<span class="subst">&#123;CFG.model_name&#125;</span>_fold0.bin&#x27;</span>,</span><br><span class="line">        <span class="string">f&#x27;<span class="subst">&#123;CFG.model_name&#125;</span>_fold1.bin&#x27;</span>,</span><br><span class="line">        <span class="string">f&#x27;<span class="subst">&#123;CFG.model_name&#125;</span>_fold2.bin&#x27;</span>,</span><br><span class="line">        <span class="string">f&#x27;<span class="subst">&#123;CFG.model_name&#125;</span>_fold3.bin&#x27;</span>,</span><br><span class="line">        <span class="string">f&#x27;<span class="subst">&#123;CFG.model_name&#125;</span>_fold4.bin&#x27;</span>,</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> CFG.model_name == <span class="string">&#x27;ernie-1.0&#x27;</span>:</span><br><span class="line">        model = ppnlp.transformers.ErnieForSequenceClassification.from_pretrained(CFG.model_name,</span><br><span class="line">                                                                                  num_classes=CFG.target_size)</span><br><span class="line">    <span class="keyword">elif</span> CFG.model_name == <span class="string">&#x27;ernie-doc-base-zh&#x27;</span>:</span><br><span class="line">        model = ppnlp.transformers.ErnieDocForSequenceClassification.from_pretrained(<span class="string">&#x27;ernie-doc-base-zh&#x27;</span>,</span><br><span class="line">                                                                                     num_classes=CFG.target_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line"></span><br><span class="line">        model = ppnlp.transformers.ErnieGramForSequenceClassification.from_pretrained(CFG.model_name,</span><br><span class="line">                                                                                      num_classes=CFG.target_size)</span><br><span class="line">    <span class="comment"># model = ppnlp.transformers.ErnieForSequenceClassification.from_pretrained(CFG.model_name,</span></span><br><span class="line">    <span class="comment">#                                                                           num_classes=25)</span></span><br><span class="line">    <span class="comment"># model = ppnlp.transformers.ErnieGramForSequenceClassification.from_pretrained(CFG.model_name,</span></span><br><span class="line">    <span class="comment">#                                                                               num_classes=25)</span></span><br><span class="line">    fold_preds = []</span><br><span class="line">    <span class="keyword">for</span> model_path <span class="keyword">in</span> model_paths:</span><br><span class="line">        model.load_dict(P.load(model_path))</span><br><span class="line">        pred = predict(model, test.to_dict(orient=<span class="string">&#x27;records&#x27;</span>), tokenizer, <span class="number">16</span>)</span><br><span class="line">        fold_preds.append(pred)</span><br><span class="line">    preds = np.mean(fold_preds, axis=<span class="number">0</span>)</span><br><span class="line">    np.save(<span class="string">&quot;preds.npy&quot;</span>, preds)</span><br><span class="line">    labels = np.argmax(preds, axis=<span class="number">1</span>)</span><br><span class="line">    test[<span class="string">&#x27;label&#x27;</span>] = labels</span><br><span class="line">    test[[<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;label&#x27;</span>]].to_csv(<span class="string">&#x27;paddle.csv&#x27;</span>,sep=<span class="string">&#x27;\t&#x27;</span>, index=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><h2 id="训练函数"><a href="#训练函数" class="headerlink" title="训练函数"></a>训练函数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>():</span><br><span class="line">    <span class="comment"># ====================================  交叉验证训练 ==========================</span></span><br><span class="line">    <span class="keyword">for</span> fold <span class="keyword">in</span> <span class="built_in">range</span>(CFG.n_fold):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;===============training fold_nth:<span class="subst">&#123;fold + <span class="number">1</span>&#125;</span>======================&quot;</span>)</span><br><span class="line">        trn_idx = folds[folds[<span class="string">&#x27;fold&#x27;</span>] != fold].index</span><br><span class="line">        val_idx = folds[folds[<span class="string">&#x27;fold&#x27;</span>] == fold].index</span><br><span class="line"></span><br><span class="line">        train_folds = folds.loc[trn_idx].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">        valid_folds = folds.loc[val_idx].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">        <span class="comment"># 训练集的数据格式转换</span></span><br><span class="line">        train_dataset = CustomDataset(train_folds)</span><br><span class="line">        train_ds = MapDataset(train_dataset)</span><br><span class="line">        <span class="comment"># 验证集的数据转换</span></span><br><span class="line">        dev_dataset = CustomDataset(valid_folds)</span><br><span class="line">        dev_ds = MapDataset(dev_dataset)</span><br><span class="line">        <span class="comment"># print(trans_func)</span></span><br><span class="line">        train_data_loader = create_dataloader(</span><br><span class="line">            train_ds,</span><br><span class="line">            mode=<span class="string">&#x27;train&#x27;</span>,</span><br><span class="line">            batch_size=CFG.batch_size,</span><br><span class="line">            batchify_fn=batchify_fn,</span><br><span class="line">            trans_fn=trans_func)</span><br><span class="line">        dev_data_loader = create_dataloader(</span><br><span class="line">            dev_ds,</span><br><span class="line">            mode=<span class="string">&#x27;dev&#x27;</span>,</span><br><span class="line">            batch_size=CFG.batch_size,</span><br><span class="line">            batchify_fn=batchify_fn,</span><br><span class="line">            trans_fn=trans_func)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># model = ppnlp.transformers.ErnieGramForSequenceClassification.from_pretrained(CFG.model_name,</span></span><br><span class="line">        <span class="comment">#                                                                               num_classes=25)</span></span><br><span class="line">        <span class="comment"># model = ppnlp.transformers.ErnieForSequenceClassification.from_pretrained(CFG.model_name,</span></span><br><span class="line">        <span class="comment">#                                                                               num_classes=25)</span></span><br><span class="line">        <span class="comment"># 选择模型</span></span><br><span class="line">        <span class="keyword">if</span> CFG.model_name == <span class="string">&#x27;ernie-1.0&#x27;</span>:</span><br><span class="line">            model = ppnlp.transformers.ErnieForSequenceClassification.from_pretrained(CFG.model_name,</span><br><span class="line">                                                                                      num_classes=CFG.target_size)</span><br><span class="line">        <span class="keyword">elif</span> CFG.model_name == <span class="string">&#x27;ernie-doc-base-zh&#x27;</span>:</span><br><span class="line">            model = ppnlp.transformers.ErnieDocForSequenceClassification.from_pretrained(<span class="string">&#x27;ernie-doc-base-zh&#x27;</span>,</span><br><span class="line">                                                                                         num_classes=CFG.target_size)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            model = ppnlp.transformers.ErnieGramForSequenceClassification.from_pretrained(CFG.model_name,</span><br><span class="line">                                                                                          num_classes=CFG.target_size)</span><br><span class="line">        <span class="comment"># print(model)</span></span><br><span class="line">        num_training_steps = <span class="built_in">len</span>(train_data_loader) * CFG.epochs</span><br><span class="line">        lr_scheduler = LinearDecayWithWarmup(CFG.learning_rate, num_training_steps, CFG.warmup_proportion)</span><br><span class="line">        <span class="comment"># 构建优化器</span></span><br><span class="line">        optimizer = paddle.optimizer.AdamW(</span><br><span class="line">            learning_rate=lr_scheduler,</span><br><span class="line">            parameters=model.parameters(),</span><br><span class="line">            weight_decay=CFG.weight_decay,    </span><br><span class="line">            apply_decay_param_fun=<span class="keyword">lambda</span> x: x <span class="keyword">in</span> [</span><br><span class="line">                p.name <span class="keyword">for</span> n, p <span class="keyword">in</span> model.named_parameters()</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">any</span>(nd <span class="keyword">in</span> n <span class="keyword">for</span> nd <span class="keyword">in</span> [<span class="string">&quot;bias&quot;</span>, <span class="string">&quot;norm&quot;</span>])</span><br><span class="line">            ])</span><br><span class="line">        <span class="comment"># 定义交叉熵函数</span></span><br><span class="line">        criterion = paddle.nn.loss.CrossEntropyLoss()</span><br><span class="line">        <span class="comment"># criterion = paddle.nn.loss.CrossEntropyLoss(weight=paddle.to_tensor(np.array(weight)))</span></span><br><span class="line">        <span class="comment"># criterion = FocalLoss()</span></span><br><span class="line"></span><br><span class="line">        metric = paddle.metric.Accuracy()</span><br><span class="line"></span><br><span class="line">        global_step = <span class="number">0</span></span><br><span class="line">        best_val_acc = <span class="number">0</span></span><br><span class="line">        best_val_f1 = <span class="number">0</span></span><br><span class="line">        fgm = FGM(model)</span><br><span class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, CFG.epochs + <span class="number">1</span>):</span><br><span class="line">            <span class="keyword">for</span> step, batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_data_loader, start=<span class="number">1</span>):</span><br><span class="line">                input_ids, segment_ids, labels = batch</span><br><span class="line">                <span class="comment"># print(segment_ids.shape)</span></span><br><span class="line">                logits = model(input_ids, segment_ids)</span><br><span class="line">                <span class="comment"># probs_ = paddle.to_tensor(logits, dtype=&quot;float64&quot;)</span></span><br><span class="line">                loss = criterion(logits, labels)</span><br><span class="line">                probs = F.softmax(logits, axis=<span class="number">1</span>)</span><br><span class="line">                correct = metric.compute(probs, labels)</span><br><span class="line">                metric.update(correct)</span><br><span class="line">                acc = metric.accumulate()</span><br><span class="line">                f1_macro = f1_score(np.argmax(probs.numpy(), axis=<span class="number">1</span>), labels, average=<span class="string">&#x27;binary&#x27;</span>)</span><br><span class="line">                global_step += <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> global_step % CFG.print_freq == <span class="number">0</span>:</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">&quot;global step %d, epoch: %d, batch: %d, loss: %.5f, acc: %.5f,f1_macro: %.5f&quot;</span> % (</span><br><span class="line">                        global_step, epoch, step, loss, acc, f1_macro))</span><br><span class="line">                loss.backward()</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 对抗训练</span></span><br><span class="line">                fgm.attack()  <span class="comment"># 在embedding上添加对抗扰动</span></span><br><span class="line">                logits_adv = model(input_ids, segment_ids)</span><br><span class="line">                loss_adv = criterion(logits_adv, labels)</span><br><span class="line">                loss_adv.backward()  <span class="comment"># 反向传播，并在正常的grad基础上，累加对抗训练的梯度</span></span><br><span class="line">                fgm.restore()  <span class="comment"># 恢复embedding参数</span></span><br><span class="line"></span><br><span class="line">                optimizer.step()</span><br><span class="line">                lr_scheduler.step()</span><br><span class="line">                optimizer.clear_grad()</span><br><span class="line">            acc, f1 = evaluate(model, criterion, metric, dev_data_loader)</span><br><span class="line">            <span class="keyword">if</span> acc &gt; best_val_acc:</span><br><span class="line">                best_val_acc = acc</span><br><span class="line">            <span class="comment">#if f1 &gt; best_val_f1:</span></span><br><span class="line">                <span class="comment">#best_val_f1 = f1</span></span><br><span class="line">                P.save(model.state_dict(), <span class="string">f&#x27;<span class="subst">&#123;CFG.model_name&#125;</span>_fold<span class="subst">&#123;fold&#125;</span>.bin&#x27;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Best Val acc %.5f&#x27;</span> % best_val_acc)</span><br><span class="line">        <span class="keyword">del</span> model</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train()</span><br></pre></td></tr></table></figure><pre><code>===============training fold_nth:1======================[2022-11-23 19:03:33,381] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/ernie-1.0/ernie_v1_chn_base.pdparamsW1123 19:03:33.386370   628 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 11.2W1123 19:03:33.390496   628 gpu_resources.cc:91] device: 0, cuDNN Version: 8.2.global step 100, epoch: 1, batch: 100, loss: 0.46791, acc: 0.73188,f1_macro: 0.89655global step 200, epoch: 1, batch: 200, loss: 0.65628, acc: 0.73625,f1_macro: 0.79245global step 300, epoch: 1, batch: 300, loss: 0.73637, acc: 0.74031,f1_macro: 0.79245global step 400, epoch: 1, batch: 400, loss: 0.57431, acc: 0.74234,f1_macro: 0.83636global step 500, epoch: 1, batch: 500, loss: 0.37923, acc: 0.74138,f1_macro: 0.91525global step 600, epoch: 1, batch: 600, loss: 0.38467, acc: 0.74344,f1_macro: 0.91228global step 700, epoch: 1, batch: 700, loss: 0.51419, acc: 0.74562,f1_macro: 0.78261global step 800, epoch: 1, batch: 800, loss: 0.38103, acc: 0.74750,f1_macro: 0.89286global step 900, epoch: 1, batch: 900, loss: 0.34946, acc: 0.74899,f1_macro: 0.91304global step 1000, epoch: 1, batch: 1000, loss: 0.53628, acc: 0.75106,f1_macro: 0.92308global step 1100, epoch: 1, batch: 1100, loss: 0.42920, acc: 0.75298,f1_macro: 0.91525eval loss: 0.44171, accu: 0.78530Best Val acc 0.78530global step 1200, epoch: 2, batch: 68, loss: 0.22114, acc: 0.83042,f1_macro: 0.91667global step 1300, epoch: 2, batch: 168, loss: 0.29129, acc: 0.83464,f1_macro: 0.90476global step 1400, epoch: 2, batch: 268, loss: 0.58879, acc: 0.83605,f1_macro: 0.80000global step 1500, epoch: 2, batch: 368, loss: 0.42207, acc: 0.83993,f1_macro: 0.85714global step 1600, epoch: 2, batch: 468, loss: 0.18622, acc: 0.83747,f1_macro: 0.95833global step 1700, epoch: 2, batch: 568, loss: 0.26564, acc: 0.83814,f1_macro: 0.93617global step 1800, epoch: 2, batch: 668, loss: 0.38719, acc: 0.84108,f1_macro: 0.86364global step 1900, epoch: 2, batch: 768, loss: 0.35982, acc: 0.84204,f1_macro: 0.88889global step 2000, epoch: 2, batch: 868, loss: 0.33469, acc: 0.84465,f1_macro: 0.89474global step 2100, epoch: 2, batch: 968, loss: 0.52275, acc: 0.84475,f1_macro: 0.81818global step 2200, epoch: 2, batch: 1068, loss: 0.23787, acc: 0.84574,f1_macro: 0.96552eval loss: 0.45888, accu: 0.79613Best Val acc 0.79613global step 2300, epoch: 3, batch: 36, loss: 0.04629, acc: 0.94878,f1_macro: 0.98246global step 2400, epoch: 3, batch: 136, loss: 0.19579, acc: 0.94003,f1_macro: 0.97778global step 2500, epoch: 3, batch: 236, loss: 0.03761, acc: 0.93988,f1_macro: 1.00000global step 2600, epoch: 3, batch: 336, loss: 0.21055, acc: 0.93899,f1_macro: 0.88235global step 2700, epoch: 3, batch: 436, loss: 0.07569, acc: 0.94030,f1_macro: 0.97674global step 2800, epoch: 3, batch: 536, loss: 0.17687, acc: 0.94076,f1_macro: 0.97674global step 2900, epoch: 3, batch: 636, loss: 0.19501, acc: 0.94099,f1_macro: 0.92000global step 3000, epoch: 3, batch: 736, loss: 0.25105, acc: 0.94153,f1_macro: 0.93617global step 3100, epoch: 3, batch: 836, loss: 0.09677, acc: 0.94109,f1_macro: 0.95833global step 3200, epoch: 3, batch: 936, loss: 0.12877, acc: 0.94071,f1_macro: 0.96000global step 3300, epoch: 3, batch: 1036, loss: 0.12475, acc: 0.94058,f1_macro: 0.96154eval loss: 0.50610, accu: 0.82055Best Val acc 0.82055global step 3400, epoch: 4, batch: 4, loss: 0.03767, acc: 0.98438,f1_macro: 1.00000global step 3500, epoch: 4, batch: 104, loss: 0.00521, acc: 0.98257,f1_macro: 1.00000global step 3600, epoch: 4, batch: 204, loss: 0.01782, acc: 0.98100,f1_macro: 1.00000global step 3700, epoch: 4, batch: 304, loss: 0.03877, acc: 0.97995,f1_macro: 1.00000global step 3800, epoch: 4, batch: 404, loss: 0.03308, acc: 0.98028,f1_macro: 1.00000global step 3900, epoch: 4, batch: 504, loss: 0.02905, acc: 0.98065,f1_macro: 1.00000global step 4000, epoch: 4, batch: 604, loss: 0.00859, acc: 0.97987,f1_macro: 1.00000global step 4100, epoch: 4, batch: 704, loss: 0.00564, acc: 0.97954,f1_macro: 1.00000global step 4200, epoch: 4, batch: 804, loss: 0.02505, acc: 0.97905,f1_macro: 1.00000global step 4300, epoch: 4, batch: 904, loss: 0.01213, acc: 0.97905,f1_macro: 1.00000global step 4400, epoch: 4, batch: 1004, loss: 0.30969, acc: 0.97883,f1_macro: 0.92683global step 4500, epoch: 4, batch: 1104, loss: 0.11206, acc: 0.97905,f1_macro: 0.98039eval loss: 0.65418, accu: 0.82221Best Val acc 0.82221global step 4600, epoch: 5, batch: 72, loss: 0.04641, acc: 0.99045,f1_macro: 0.98182global step 4700, epoch: 5, batch: 172, loss: 0.00841, acc: 0.99001,f1_macro: 1.00000global step 4800, epoch: 5, batch: 272, loss: 0.00417, acc: 0.99081,f1_macro: 1.00000global step 4900, epoch: 5, batch: 372, loss: 0.00382, acc: 0.98975,f1_macro: 1.00000global step 5000, epoch: 5, batch: 472, loss: 0.00420, acc: 0.99060,f1_macro: 1.00000global step 5100, epoch: 5, batch: 572, loss: 0.01085, acc: 0.99088,f1_macro: 1.00000global step 5200, epoch: 5, batch: 672, loss: 0.02734, acc: 0.99056,f1_macro: 0.97778global step 5300, epoch: 5, batch: 772, loss: 0.00837, acc: 0.99053,f1_macro: 1.00000global step 5400, epoch: 5, batch: 872, loss: 0.05018, acc: 0.99097,f1_macro: 0.97674global step 5500, epoch: 5, batch: 972, loss: 0.04738, acc: 0.99126,f1_macro: 0.97959global step 5600, epoch: 5, batch: 1072, loss: 0.01556, acc: 0.99128,f1_macro: 1.00000eval loss: 0.79161, accu: 0.82597Best Val acc 0.82597</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># if __name__ == &#x27;__main__&#x27;:</span></span><br><span class="line"><span class="comment">#     train()</span></span><br><span class="line"><span class="comment">#     inference()</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">inference()</span><br></pre></td></tr></table></figure><pre><code>[2022-11-23 19:47:36,006] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/ernie-1.0/ernie_v1_chn_base.pdparams100%|██████████| 65/65 [00:02&lt;00:00, 31.80it/s]100%|██████████| 65/65 [00:01&lt;00:00, 33.80it/s]100%|██████████| 65/65 [00:01&lt;00:00, 32.83it/s]100%|██████████| 65/65 [00:01&lt;00:00, 33.76it/s]100%|██████████| 65/65 [00:01&lt;00:00, 33.67it/s]</code></pre>]]></content>
    
    
    <summary type="html">&lt;p&gt;预测句子是否是语义病句,语义错误和拼写错误、语法错误&lt;/p&gt;</summary>
    
    
    
    <category term="自然语言处理" scheme="https://du2279664786.github.io/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"/>
    
    
    <category term="NLP" scheme="https://du2279664786.github.io/tags/NLP/"/>
    
    <category term="病句识别" scheme="https://du2279664786.github.io/tags/%E7%97%85%E5%8F%A5%E8%AF%86%E5%88%AB/"/>
    
    <category term="WarmUP" scheme="https://du2279664786.github.io/tags/WarmUP/"/>
    
  </entry>
  
  <entry>
    <title>Pre-training</title>
    <link href="https://du2279664786.github.io/posts/36882.html"/>
    <id>https://du2279664786.github.io/posts/36882.html</id>
    <published>2022-11-21T12:55:10.000Z</published>
    <updated>2022-11-24T06:54:45.773Z</updated>
    
    <content type="html"><![CDATA[<p>Pre-train BERT (Chinese language model) from scratch</p><span id="more"></span><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> transformers,tokenizers</span><br><span class="line">transformers.__version__,tokenizers.__version__</span><br></pre></td></tr></table></figure><pre><code>(&#39;4.24.0&#39;, &#39;0.13.2&#39;)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tokenizers</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> BertTokenizer, LineByLineTextDataset</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> BertConfig, BertForMaskedLM, DataCollatorForLanguageModeling</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> Trainer, TrainingArguments</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> pipeline</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Train a tokenizer</span></span><br><span class="line"></span><br><span class="line">bwpt = tokenizers.BertWordPieceTokenizer(vocab_file=<span class="literal">None</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># filepath = &quot;../input/bert-bangla/raw_bangla_for_BERT.txt&quot;</span></span><br><span class="line">filepath = <span class="string">&quot;./train.txt&quot;</span></span><br><span class="line"></span><br><span class="line">bwpt.train(</span><br><span class="line">    files=[filepath],</span><br><span class="line">    vocab_size=<span class="number">50000</span>,</span><br><span class="line">    min_frequency=<span class="number">3</span>,</span><br><span class="line">    limit_alphabet=<span class="number">1000</span></span><br><span class="line">)</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bwpt.save(<span class="string">&#x27;./训练中文的bert输出/&#x27;</span>, <span class="string">&#x27;name&#x27;</span>)</span><br></pre></td></tr></table></figure><pre><code>[&#39;./训练中文的bert输出/name-vocab.txt&#39;]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Load the tokenizer</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># vocab_file_dir = &#x27;/kaggle/input/bert-bangla/bangla-vocab.txt&#x27; </span></span><br><span class="line">vocab_file_dir = <span class="string">&#x27;./vocab.txt&#x27;</span> </span><br><span class="line"></span><br><span class="line">tokenizer = BertTokenizer.from_pretrained(vocab_file_dir)</span><br><span class="line"></span><br><span class="line">sentence = <span class="string">&#x27;今天晚上我要吃啵啵鱼&#x27;</span></span><br><span class="line"></span><br><span class="line">encoded_input = tokenizer.tokenize(sentence)</span><br><span class="line"><span class="built_in">print</span>(encoded_input)</span><br><span class="line"><span class="comment"># print(encoded_input[&#x27;input_ids&#x27;])</span></span><br></pre></td></tr></table></figure><pre><code>[&#39;今&#39;, &#39;天&#39;, &#39;晚&#39;, &#39;上&#39;, &#39;我&#39;, &#39;要&#39;, &#39;吃&#39;, &#39;啵&#39;, &#39;啵&#39;, &#39;鱼&#39;]C:\Users\dupeibo\Anaconda3\envs\pt\lib\site-packages\transformers\tokenization_utils_base.py:1679: FutureWarning: Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated and won&#39;t be possible anymore in v5. Use a model identifier or the path to a directory instead.  warnings.warn(</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">%%time</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">transformers has a predefined class LineByLineTextDataset()</span></span><br><span class="line"><span class="string">which reads your text line by line and converts them to tokens</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">dataset= LineByLineTextDataset(</span><br><span class="line">    tokenizer = tokenizer,</span><br><span class="line"><span class="comment">#     file_path = &#x27;/kaggle/input/bert-bangla/raw_bangla_for_BERT.txt&#x27;,</span></span><br><span class="line">    file_path = <span class="string">&#x27;./train.txt&#x27;</span>,</span><br><span class="line">    block_size = <span class="number">128</span>  <span class="comment"># maximum sequence length</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;No. of lines: &#x27;</span>, <span class="built_in">len</span>(dataset)) <span class="comment"># No of lines in your datset</span></span><br><span class="line">dataset</span><br></pre></td></tr></table></figure><pre><code>No. of lines:  24494Wall time: 10.4 s&lt;transformers.data.datasets.language_modeling.LineByLineTextDataset at 0x2084eb42ac8&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">config = BertConfig(</span><br><span class="line">    vocab_size=<span class="number">50000</span>,</span><br><span class="line">    hidden_size=<span class="number">768</span>, </span><br><span class="line">    num_hidden_layers=<span class="number">6</span>, </span><br><span class="line">    num_attention_heads=<span class="number">12</span>,</span><br><span class="line">    max_position_embeddings=<span class="number">512</span></span><br><span class="line">)</span><br><span class="line"> </span><br><span class="line">model = BertForMaskedLM(config)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;No of parameters: &#x27;</span>, model.num_parameters())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 做掩码机制</span></span><br><span class="line">data_collator = DataCollatorForLanguageModeling(</span><br><span class="line">    tokenizer=tokenizer, mlm=<span class="literal">True</span>, mlm_probability=<span class="number">0.15</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><pre><code>No of parameters:  82556240</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">training_args = TrainingArguments(</span><br><span class="line">    output_dir=<span class="string">&#x27;./训练中文的bert输出/&#x27;</span>,</span><br><span class="line">    overwrite_output_dir=<span class="literal">True</span>,</span><br><span class="line">    num_train_epochs=<span class="number">1</span>,</span><br><span class="line">    per_device_train_batch_size=<span class="number">4</span>,</span><br><span class="line">    save_steps=<span class="number">10_000</span>,</span><br><span class="line">    save_total_limit=<span class="number">2</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">trainer = Trainer(</span><br><span class="line">    model=model,</span><br><span class="line">    args=training_args,</span><br><span class="line">    data_collator=data_collator,</span><br><span class="line">    train_dataset=dataset,</span><br><span class="line">    prediction_loss_only=<span class="literal">True</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">%%time</span><br><span class="line">trainer.train()</span><br><span class="line"></span><br></pre></td></tr></table></figure><pre><code>Epoch:   0%|          | 0/1 [00:00&lt;?, ?it/s]Iteration:   0%|          | 0/6124 [00:00&lt;?, ?it/s]&#123;&quot;loss&quot;: 7.0956006441116335, &quot;learning_rate&quot;: 4.591770084911823e-05, &quot;epoch&quot;: 0.08164598301763554, &quot;step&quot;: 500&#125;&#123;&quot;loss&quot;: 6.214028715133667, &quot;learning_rate&quot;: 4.183540169823645e-05, &quot;epoch&quot;: 0.16329196603527107, &quot;step&quot;: 1000&#125;&#123;&quot;loss&quot;: 5.860672056674957, &quot;learning_rate&quot;: 3.775310254735467e-05, &quot;epoch&quot;: 0.24493794905290658, &quot;step&quot;: 1500&#125;&#123;&quot;loss&quot;: 5.599938702583313, &quot;learning_rate&quot;: 3.367080339647289e-05, &quot;epoch&quot;: 0.32658393207054215, &quot;step&quot;: 2000&#125;&#123;&quot;loss&quot;: 5.412256263256073, &quot;learning_rate&quot;: 2.958850424559112e-05, &quot;epoch&quot;: 0.4082299150881777, &quot;step&quot;: 2500&#125;&#123;&quot;loss&quot;: 5.261007954120636, &quot;learning_rate&quot;: 2.550620509470934e-05, &quot;epoch&quot;: 0.48987589810581317, &quot;step&quot;: 3000&#125;&#123;&quot;loss&quot;: 5.095327672958374, &quot;learning_rate&quot;: 2.1423905943827566e-05, &quot;epoch&quot;: 0.5715218811234487, &quot;step&quot;: 3500&#125;&#123;&quot;loss&quot;: NaN, &quot;learning_rate&quot;: 1.734160679294579e-05, &quot;epoch&quot;: 0.6531678641410843, &quot;step&quot;: 4000&#125;&#123;&quot;loss&quot;: NaN, &quot;learning_rate&quot;: 1.3259307642064011e-05, &quot;epoch&quot;: 0.7348138471587198, &quot;step&quot;: 4500&#125;&#123;&quot;loss&quot;: NaN, &quot;learning_rate&quot;: 9.177008491182235e-06, &quot;epoch&quot;: 0.8164598301763554, &quot;step&quot;: 5000&#125;&#123;&quot;loss&quot;: NaN, &quot;learning_rate&quot;: 5.094709340300458e-06, &quot;epoch&quot;: 0.8981058131939909, &quot;step&quot;: 5500&#125;&#123;&quot;loss&quot;: NaN, &quot;learning_rate&quot;: 1.0124101894186806e-06, &quot;epoch&quot;: 0.9797517962116263, &quot;step&quot;: 6000&#125;Wall time: 17min 31sTrainOutput(global_step=6124, training_loss=nan)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># trainer.save_model(&#x27;./训练中文的bert输出&#x27;)</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">model = BertForMaskedLM.from_pretrained(<span class="string">&#x27;./&#x27;</span>)</span><br><span class="line"></span><br><span class="line">fill_mask = pipeline(</span><br><span class="line">    <span class="string">&quot;fill-mask&quot;</span>,</span><br><span class="line">    model=model,</span><br><span class="line">    tokenizer=tokenizer</span><br><span class="line">)</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fill_mask(<span class="string">&#x27;心[MASK]病&#x27;</span>)</span><br></pre></td></tr></table></figure><pre><code>[&#123;&#39;score&#39;: 0.3431047201156616,  &#39;token&#39;: 5552,  &#39;token_str&#39;: &#39;脏&#39;,  &#39;sequence&#39;: &#39;心 脏 病&#39;&#125;, &#123;&#39;score&#39;: 0.07011183351278305,  &#39;token&#39;: 2552,  &#39;token_str&#39;: &#39;心&#39;,  &#39;sequence&#39;: &#39;心 心 病&#39;&#125;, &#123;&#39;score&#39;: 0.05838495120406151,  &#39;token&#39;: 4567,  &#39;token_str&#39;: &#39;病&#39;,  &#39;sequence&#39;: &#39;心 病 病&#39;&#125;, &#123;&#39;score&#39;: 0.014283978380262852,  &#39;token&#39;: 107,  &#39;token_str&#39;: &#39;&quot;&#39;,  &#39;sequence&#39;: &#39;心 &quot; 病&#39;&#125;, &#123;&#39;score&#39;: 0.011550793424248695,  &#39;token&#39;: 7315,  &#39;token_str&#39;: &#39;闷&#39;,  &#39;sequence&#39;: &#39;心 闷 病&#39;&#125;]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fill_mask(<span class="string">&#x27;怀[MASK]&#x27;</span>)</span><br></pre></td></tr></table></figure><pre><code>[&#123;&#39;score&#39;: 0.4942161738872528,  &#39;token&#39;: 2097,  &#39;token_str&#39;: &#39;孕&#39;,  &#39;sequence&#39;: &#39;怀 孕&#39;&#125;, &#123;&#39;score&#39;: 0.050573259592056274,  &#39;token&#39;: 2577,  &#39;token_str&#39;: &#39;怀&#39;,  &#39;sequence&#39;: &#39;怀 怀&#39;&#125;, &#123;&#39;score&#39;: 0.01493070088326931,  &#39;token&#39;: 107,  &#39;token_str&#39;: &#39;&quot;&#39;,  &#39;sequence&#39;: &#39;怀 &quot;&#39;&#125;, &#123;&#39;score&#39;: 0.010810167528688908,  &#39;token&#39;: 5307,  &#39;token_str&#39;: &#39;经&#39;,  &#39;sequence&#39;: &#39;怀 经&#39;&#125;, &#123;&#39;score&#39;: 0.00741073302924633,  &#39;token&#39;: 1453,  &#39;token_str&#39;: &#39;周&#39;,  &#39;sequence&#39;: &#39;怀 周&#39;&#125;]</code></pre>]]></content>
    
    
    <summary type="html">&lt;p&gt;Pre-train BERT (Chinese language model) from scratch&lt;/p&gt;</summary>
    
    
    
    <category term="自然语言处理" scheme="https://du2279664786.github.io/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"/>
    
    
    <category term="深度学习" scheme="https://du2279664786.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="NLP" scheme="https://du2279664786.github.io/tags/NLP/"/>
    
    <category term="HuggingFace" scheme="https://du2279664786.github.io/tags/HuggingFace/"/>
    
    <category term="BERT" scheme="https://du2279664786.github.io/tags/BERT/"/>
    
    <category term="Pre-training" scheme="https://du2279664786.github.io/tags/Pre-training/"/>
    
  </entry>
  
  <entry>
    <title>基于BERT的文本分类</title>
    <link href="https://du2279664786.github.io/posts/20881.html"/>
    <id>https://du2279664786.github.io/posts/20881.html</id>
    <published>2022-11-21T10:55:10.000Z</published>
    <updated>2022-11-24T06:54:45.776Z</updated>
    
    <content type="html"><![CDATA[<p>通过智能化手段识别其中是否存在“虚报、假报”的情况</p><span id="more"></span><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>企业自主填报安全生产隐患，对于将风险消除在事故萌芽阶段具有重要意义。企业在填报隐患时，往往存在不认真填报的情况，“虚报、假报”隐患内容，增大了企业监管的难度。采用大数据手段分析隐患内容，找出不切实履行主体责任的企业，向监管部门进行推送，实现精准执法，能够提高监管手段的有效性，增强企业安全责任意识。</p><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>本赛题提供企业填报隐患数据，参赛选手需通过智能化手段识别其中是否存在“虚报、假报”的情况。</p><h1 id="数据简介"><a href="#数据简介" class="headerlink" title="数据简介"></a>数据简介</h1><p>本赛题数据集为脱敏后的企业填报自查隐患记录,数据说明如下：</p><ul><li><p>训练集数据包含“【id、level_1（一级标准）、level_2（二级标准）、level_3（三级标准）、level_4（四级标准）、content（隐患内容）和label（标签）】”共7个字段。<br>其中“id”为主键，无业务意义；“一级标准、二级标准、三级标准、四级标准”为《深圳市安全隐患自查和巡查基本指引（2016年修订版）》规定的排查指引，一级标准对应不同隐患类型，二至四级标准是对一级标准的细化，企业自主上报隐患时，根据不同类型隐患的四级标准开展隐患自查工作；“隐患内容”为企业上报的具体隐患；“标签”标识的是该条隐患的合格性，“1”表示隐患填报不合格，“0”表示隐患填报合格。</p></li><li><p>预测结果文件results.csv</p></li></ul><p><img src="C:\Users\dupeibo\AppData\Roaming\Typora\typora-user-images\1669078534834.png" alt="1669078534834"></p><h1 id="评测标准"><a href="#评测标准" class="headerlink" title="评测标准"></a>评测标准</h1><p>本赛题采用F1 -score作为模型评判标准。</p><h1 id="具体实现代码如下："><a href="#具体实现代码如下：" class="headerlink" title="具体实现代码如下："></a>具体实现代码如下：</h1><h2 id="导入所以需要的包"><a href="#导入所以需要的包" class="headerlink" title="导入所以需要的包"></a>导入所以需要的包</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入transformers</span></span><br><span class="line"><span class="keyword">import</span> transformers</span><br><span class="line"><span class="comment"># from transformers import BertModel, BertTokenizer,BertConfig, AdamW, get_linear_schedule_with_warmup</span></span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModel, AutoTokenizer,AutoConfig, AdamW, get_linear_schedule_with_warmup</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn, optim</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="comment"># 常用包</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> pylab <span class="keyword">import</span> rcParams</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> rc</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix, classification_report</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"><span class="keyword">from</span> textwrap <span class="keyword">import</span> wrap</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">&quot;ignore&quot;</span>)</span><br><span class="line">%matplotlib inline</span><br><span class="line">%config InlineBackend.figure_format=<span class="string">&#x27;retina&#x27;</span> <span class="comment"># 主题</span></span><br></pre></td></tr></table></figure><h2 id="初始化设置"><a href="#初始化设置" class="headerlink" title="初始化设置"></a>初始化设置</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">sns.<span class="built_in">set</span>(style=<span class="string">&#x27;whitegrid&#x27;</span>, palette=<span class="string">&#x27;muted&#x27;</span>, font_scale=<span class="number">1.2</span>)</span><br><span class="line">HAPPY_COLORS_PALETTE = [<span class="string">&quot;#01BEFE&quot;</span>, <span class="string">&quot;#FFDD00&quot;</span>, <span class="string">&quot;#FF7D00&quot;</span>, <span class="string">&quot;#FF006D&quot;</span>, <span class="string">&quot;#ADFF02&quot;</span>, <span class="string">&quot;#8F00FF&quot;</span>]</span><br><span class="line">sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))</span><br><span class="line">rcParams[<span class="string">&#x27;figure.figsize&#x27;</span>] = <span class="number">12</span>, <span class="number">8</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 固定随机种子</span></span><br><span class="line">RANDOM_SEED = <span class="number">42</span></span><br><span class="line">np.random.seed(RANDOM_SEED)</span><br><span class="line">torch.manual_seed(RANDOM_SEED)</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">device</span><br></pre></td></tr></table></figure><pre><code>device(type=&#39;cuda&#39;, index=0)</code></pre><h1 id="读取数据"><a href="#读取数据" class="headerlink" title="读取数据"></a>读取数据</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sub=pd.read_csv(<span class="string">&#x27;./data/02企业隐患排查/sub.csv&#x27;</span>)</span><br><span class="line">test=pd.read_csv(<span class="string">&#x27;./data/02企业隐患排查/test.csv&#x27;</span>)</span><br><span class="line">train=pd.read_csv(<span class="string">&#x27;./data/02企业隐患排查/train.csv&#x27;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train.head()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>id</th>      <th>level_1</th>      <th>level_2</th>      <th>level_3</th>      <th>level_4</th>      <th>content</th>      <th>label</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>0</td>      <td>工业/危化品类（现场）—2016版</td>      <td>（二）电气安全</td>      <td>6、移动用电产品、电动工具及照明</td>      <td>1、移动使用的用电产品和I类电动工具的绝缘线，必须采用三芯(单相)或四芯(三相)多股铜芯橡套软线。</td>      <td>使用移动手动电动工具,外接线绝缘皮破损,应停止使用.</td>      <td>0</td>    </tr>    <tr>      <th>1</th>      <td>1</td>      <td>工业/危化品类（现场）—2016版</td>      <td>（一）消防检查</td>      <td>1、防火巡查</td>      <td>3、消防设施、器材和消防安全标志是否在位、完整；</td>      <td>一般</td>      <td>1</td>    </tr>    <tr>      <th>2</th>      <td>2</td>      <td>工业/危化品类（现场）—2016版</td>      <td>（一）消防检查</td>      <td>2、防火检查</td>      <td>6、重点工种人员以及其他员工消防知识的掌握情况；</td>      <td>消防知识要加强</td>      <td>0</td>    </tr>    <tr>      <th>3</th>      <td>3</td>      <td>工业/危化品类（现场）—2016版</td>      <td>（一）消防检查</td>      <td>1、防火巡查</td>      <td>3、消防设施、器材和消防安全标志是否在位、完整；</td>      <td>消防通道有货物摆放 清理不及时</td>      <td>0</td>    </tr>    <tr>      <th>4</th>      <td>4</td>      <td>工业/危化品类（现场）—2016版</td>      <td>（一）消防检查</td>      <td>1、防火巡查</td>      <td>4、常闭式防火门是否处于关闭状态，防火卷帘下是否堆放物品影响使用；</td>      <td>防火门打开状态</td>      <td>0</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">test.head()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>id</th>      <th>level_1</th>      <th>level_2</th>      <th>level_3</th>      <th>level_4</th>      <th>content</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>0</td>      <td>交通运输类（现场）—2016版</td>      <td>（一）消防安全</td>      <td>2、防火检查</td>      <td>2、安全疏散通道、疏散指示标志、应急照明和安全出口情况。</td>      <td>RB1洗地机占用堵塞安全通道</td>    </tr>    <tr>      <th>1</th>      <td>1</td>      <td>工业/危化品类（选项）—2016版</td>      <td>（二）仓库</td>      <td>1、一般要求</td>      <td>1、库房内储存物品应分类、分堆、限额存放。</td>      <td>未分类堆放</td>    </tr>    <tr>      <th>2</th>      <td>2</td>      <td>工业/危化品类（现场）—2016版</td>      <td>（一）消防检查</td>      <td>1、防火巡查</td>      <td>3、消防设施、器材和消防安全标志是否在位、完整；</td>      <td>消防设施、器材和消防安全标志是否在位、完整</td>    </tr>    <tr>      <th>3</th>      <td>3</td>      <td>商贸服务教文卫类（现场）—2016版</td>      <td>（二）电气安全</td>      <td>3、电气线路及电源插头插座</td>      <td>3、电源插座、电源插头应按规定正确接线。</td>      <td>插座随意放在电器旁边</td>    </tr>    <tr>      <th>4</th>      <td>4</td>      <td>商贸服务教文卫类（现场）—2016版</td>      <td>（一）消防检查</td>      <td>1、防火巡查</td>      <td>6、其他消防安全情况。</td>      <td>检查中发现一瓶灭火器过期</td>    </tr>  </tbody></table></div><h2 id="查看数据的形状"><a href="#查看数据的形状" class="headerlink" title="查看数据的形状"></a>查看数据的形状</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;train.shape,test.shape,sub.shape&quot;</span>,train.shape,test.shape,sub.shape)</span><br></pre></td></tr></table></figure><pre><code>train.shape,test.shape,sub.shape (12000, 7) (18000, 6) (18000, 2)</code></pre><h2 id="查看是否存在空值"><a href="#查看是否存在空值" class="headerlink" title="查看是否存在空值"></a>查看是否存在空值</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train[train[<span class="string">&#x27;content&#x27;</span>].isna()]</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>id</th>      <th>level_1</th>      <th>level_2</th>      <th>level_3</th>      <th>level_4</th>      <th>content</th>      <th>label</th>    </tr>  </thead>  <tbody>    <tr>      <th>6193</th>      <td>6193</td>      <td>工业/危化品类（现场）—2016版</td>      <td>（一）消防检查</td>      <td>1、防火巡查</td>      <td>3、消防设施、器材和消防安全标志是否在位、完整；</td>      <td>NaN</td>      <td>1</td>    </tr>    <tr>      <th>9248</th>      <td>9248</td>      <td>工业/危化品类（现场）—2016版</td>      <td>（一）消防检查</td>      <td>1、防火巡查</td>      <td>4、常闭式防火门是否处于关闭状态，防火卷帘下是否堆放物品影响使用；</td>      <td>NaN</td>      <td>1</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;train null nums&#x27;</span>)</span><br><span class="line">train.shape[<span class="number">0</span>]-train.count()</span><br></pre></td></tr></table></figure><pre><code>train null numsid         0level_1    0level_2    0level_3    0level_4    0content    2label      0dtype: int64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;test null nums&#x27;</span>)</span><br><span class="line">test.shape[<span class="number">0</span>]-test.count()</span><br></pre></td></tr></table></figure><pre><code>test null numsid         0level_1    0level_2    0level_3    0level_4    0content    4dtype: int64</code></pre><h2 id="查看标签的分布"><a href="#查看标签的分布" class="headerlink" title="查看标签的分布"></a>查看标签的分布</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train[<span class="string">&#x27;label&#x27;</span>].value_counts()</span><br></pre></td></tr></table></figure><pre><code>0    107121     1288Name: label, dtype: int64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># sns.countplot(train.label)</span></span><br><span class="line"><span class="comment"># plt.xlabel(&#x27;label count&#x27;)</span></span><br></pre></td></tr></table></figure><h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train.fillna(<span class="string">&quot;空值&quot;</span>,inplace=<span class="literal">True</span>)</span><br><span class="line">test.fillna(<span class="string">&quot;空值&quot;</span>,inplace=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train.shape[<span class="number">0</span>]-train.count()</span><br></pre></td></tr></table></figure><pre><code>id         0level_1    0level_2    0level_3    0level_4    0content    0label      0dtype: int64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train[<span class="string">&#x27;level_3&#x27;</span>].value_counts()</span><br></pre></td></tr></table></figure><pre><code>1、防火巡查             42252、防火检查             29112、配电箱（柜、板）          7101、作业通道              6643、电气线路及电源插头插座       497                   ... 3、安全带                 14、特种设备及操作人员管理记录       14、安全技术交底              13、停车场                 11、水库安全                1Name: level_3, Length: 153, dtype: int64</code></pre><h3 id="对训练集处理"><a href="#对训练集处理" class="headerlink" title="对训练集处理"></a>对训练集处理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train[<span class="string">&#x27;level_1&#x27;</span>] = train[<span class="string">&#x27;level_1&#x27;</span>].apply(<span class="keyword">lambda</span> x:x.split(<span class="string">&#x27;（&#x27;</span>)[<span class="number">0</span>])</span><br><span class="line">train[<span class="string">&#x27;level_2&#x27;</span>] = train[<span class="string">&#x27;level_2&#x27;</span>].apply(<span class="keyword">lambda</span> x:x.split(<span class="string">&#x27;）&#x27;</span>)[<span class="number">1</span>])</span><br><span class="line">train[<span class="string">&#x27;level_3&#x27;</span>] = train[<span class="string">&#x27;level_3&#x27;</span>].apply(<span class="keyword">lambda</span> x:re.split(<span class="string">&#x27;[0-9]、&#x27;</span>,x)[-<span class="number">1</span>])</span><br><span class="line">train[<span class="string">&#x27;level_4&#x27;</span>] = train[<span class="string">&#x27;level_4&#x27;</span>].apply(<span class="keyword">lambda</span> x:re.split(<span class="string">&#x27;[0-9]、&#x27;</span>,x)[-<span class="number">1</span>])</span><br></pre></td></tr></table></figure><h3 id="对测试集处理"><a href="#对测试集处理" class="headerlink" title="对测试集处理"></a>对测试集处理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">test[<span class="string">&#x27;level_1&#x27;</span>] = test[<span class="string">&#x27;level_1&#x27;</span>].apply(<span class="keyword">lambda</span> x:x.split(<span class="string">&#x27;（&#x27;</span>)[<span class="number">0</span>])</span><br><span class="line">test[<span class="string">&#x27;level_2&#x27;</span>] = test[<span class="string">&#x27;level_2&#x27;</span>].apply(<span class="keyword">lambda</span> x:x.split(<span class="string">&#x27;）&#x27;</span>)[-<span class="number">1</span>])</span><br><span class="line">test[<span class="string">&#x27;level_3&#x27;</span>] = test[<span class="string">&#x27;level_3&#x27;</span>].apply(<span class="keyword">lambda</span> x:re.split(<span class="string">&#x27;[0-9]、&#x27;</span>,x)[-<span class="number">1</span>])</span><br><span class="line">test[<span class="string">&#x27;level_4&#x27;</span>] = test[<span class="string">&#x27;level_4&#x27;</span>].apply(<span class="keyword">lambda</span> x:re.split(<span class="string">&#x27;[0-9]、&#x27;</span>,x)[-<span class="number">1</span>])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train.head()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>id</th>      <th>level_1</th>      <th>level_2</th>      <th>level_3</th>      <th>level_4</th>      <th>content</th>      <th>label</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>0</td>      <td>工业/危化品类</td>      <td>电气安全</td>      <td>移动用电产品、电动工具及照明</td>      <td>移动使用的用电产品和I类电动工具的绝缘线，必须采用三芯(单相)或四芯(三相)多股铜芯橡套软线。</td>      <td>使用移动手动电动工具,外接线绝缘皮破损,应停止使用.</td>      <td>0</td>    </tr>    <tr>      <th>1</th>      <td>1</td>      <td>工业/危化品类</td>      <td>消防检查</td>      <td>防火巡查</td>      <td>消防设施、器材和消防安全标志是否在位、完整；</td>      <td>一般</td>      <td>1</td>    </tr>    <tr>      <th>2</th>      <td>2</td>      <td>工业/危化品类</td>      <td>消防检查</td>      <td>防火检查</td>      <td>重点工种人员以及其他员工消防知识的掌握情况；</td>      <td>消防知识要加强</td>      <td>0</td>    </tr>    <tr>      <th>3</th>      <td>3</td>      <td>工业/危化品类</td>      <td>消防检查</td>      <td>防火巡查</td>      <td>消防设施、器材和消防安全标志是否在位、完整；</td>      <td>消防通道有货物摆放 清理不及时</td>      <td>0</td>    </tr>    <tr>      <th>4</th>      <td>4</td>      <td>工业/危化品类</td>      <td>消防检查</td>      <td>防火巡查</td>      <td>常闭式防火门是否处于关闭状态，防火卷帘下是否堆放物品影响使用；</td>      <td>防火门打开状态</td>      <td>0</td>    </tr>  </tbody></table></div><h2 id="文本拼接"><a href="#文本拼接" class="headerlink" title="文本拼接"></a>文本拼接</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">train[<span class="string">&#x27;text&#x27;</span>]=train[<span class="string">&#x27;content&#x27;</span>]+<span class="string">&#x27;[SEP]&#x27;</span>+train[<span class="string">&#x27;level_1&#x27;</span>]+<span class="string">&#x27;[SEP]&#x27;</span>+train[<span class="string">&#x27;level_2&#x27;</span>]+<span class="string">&#x27;[SEP]&#x27;</span>+train[<span class="string">&#x27;level_3&#x27;</span>]+<span class="string">&#x27;[SEP]&#x27;</span>+train[<span class="string">&#x27;level_4&#x27;</span>]</span><br><span class="line">test[<span class="string">&#x27;text&#x27;</span>]=test[<span class="string">&#x27;content&#x27;</span>]+<span class="string">&#x27;[SEP]&#x27;</span>+test[<span class="string">&#x27;level_1&#x27;</span>]+<span class="string">&#x27;[SEP]&#x27;</span>+test[<span class="string">&#x27;level_2&#x27;</span>]+<span class="string">&#x27;[SEP]&#x27;</span>+test[<span class="string">&#x27;level_3&#x27;</span>]+<span class="string">&#x27;[SEP]&#x27;</span>+test[<span class="string">&#x27;level_4&#x27;</span>]</span><br><span class="line">train.head()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>id</th>      <th>level_1</th>      <th>level_2</th>      <th>level_3</th>      <th>level_4</th>      <th>content</th>      <th>label</th>      <th>text</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>0</td>      <td>工业/危化品类</td>      <td>电气安全</td>      <td>移动用电产品、电动工具及照明</td>      <td>移动使用的用电产品和I类电动工具的绝缘线，必须采用三芯(单相)或四芯(三相)多股铜芯橡套软线。</td>      <td>使用移动手动电动工具,外接线绝缘皮破损,应停止使用.</td>      <td>0</td>      <td>使用移动手动电动工具,外接线绝缘皮破损,应停止使用.[SEP]工业/危化品类[SEP]电气安...</td>    </tr>    <tr>      <th>1</th>      <td>1</td>      <td>工业/危化品类</td>      <td>消防检查</td>      <td>防火巡查</td>      <td>消防设施、器材和消防安全标志是否在位、完整；</td>      <td>一般</td>      <td>1</td>      <td>一般[SEP]工业/危化品类[SEP]消防检查[SEP]防火巡查[SEP]消防设施、器材和消...</td>    </tr>    <tr>      <th>2</th>      <td>2</td>      <td>工业/危化品类</td>      <td>消防检查</td>      <td>防火检查</td>      <td>重点工种人员以及其他员工消防知识的掌握情况；</td>      <td>消防知识要加强</td>      <td>0</td>      <td>消防知识要加强[SEP]工业/危化品类[SEP]消防检查[SEP]防火检查[SEP]重点工种...</td>    </tr>    <tr>      <th>3</th>      <td>3</td>      <td>工业/危化品类</td>      <td>消防检查</td>      <td>防火巡查</td>      <td>消防设施、器材和消防安全标志是否在位、完整；</td>      <td>消防通道有货物摆放 清理不及时</td>      <td>0</td>      <td>消防通道有货物摆放 清理不及时[SEP]工业/危化品类[SEP]消防检查[SEP]防火巡查[...</td>    </tr>    <tr>      <th>4</th>      <td>4</td>      <td>工业/危化品类</td>      <td>消防检查</td>      <td>防火巡查</td>      <td>常闭式防火门是否处于关闭状态，防火卷帘下是否堆放物品影响使用；</td>      <td>防火门打开状态</td>      <td>0</td>      <td>防火门打开状态[SEP]工业/危化品类[SEP]消防检查[SEP]防火巡查[SEP]常闭式防...</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train[<span class="string">&#x27;text_len&#x27;</span>]=train[<span class="string">&#x27;text&#x27;</span>].<span class="built_in">map</span>(<span class="built_in">len</span>)</span><br><span class="line">train[<span class="string">&#x27;text&#x27;</span>].<span class="built_in">map</span>(<span class="built_in">len</span>).describe()<span class="comment"># 298-12=286</span></span><br></pre></td></tr></table></figure><pre><code>count    12000.000000mean        80.444500std         21.910859min         43.00000025%         66.00000050%         75.00000075%         92.000000max        298.000000Name: text, dtype: float64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">test[<span class="string">&#x27;text&#x27;</span>].<span class="built_in">map</span>(<span class="built_in">len</span>).describe() <span class="comment"># 520-12=518</span></span><br></pre></td></tr></table></figure><pre><code>count    18000.000000mean        80.762611std         22.719823min         43.00000025%         66.00000050%         76.00000075%         92.000000max        520.000000Name: text, dtype: float64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train[<span class="string">&#x27;text_len&#x27;</span>].plot(kind=<span class="string">&#x27;kde&#x27;</span>)</span><br></pre></td></tr></table></figure><pre><code>&lt;AxesSubplot:ylabel=&#39;Density&#39;&gt;</code></pre><p><img src="C:\Users\dupeibo\AppData\Roaming\Typora\typora-user-images\1669079055167.png" alt="1669079055167"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sum</span>(train[<span class="string">&#x27;text_len&#x27;</span>]&gt;<span class="number">100</span>) <span class="comment"># text文本长度大于100的个数     1878</span></span><br><span class="line"><span class="built_in">sum</span>(train[<span class="string">&#x27;text_len&#x27;</span>]&gt;<span class="number">200</span>) <span class="comment"># text文本长度大于200的个数     11</span></span><br></pre></td></tr></table></figure><h1 id="模型的加载和配置"><a href="#模型的加载和配置" class="headerlink" title="模型的加载和配置"></a>模型的加载和配置</h1><h3 id="embedding"><a href="#embedding" class="headerlink" title="embedding"></a>embedding</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">PRE_TRAINED_MODEL_NAME = <span class="string">&#x27;bert-base-chinese&#x27;</span></span><br><span class="line"><span class="comment"># PRE_TRAINED_MODEL_NAME = &#x27;hfl/chinese-roberta-wwm-ext&#x27;</span></span><br><span class="line"><span class="comment"># PRE_TRAINED_MODEL_NAME = &#x27;hfl/chinese-roberta-wwm&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)</span></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tokenizer</span><br></pre></td></tr></table></figure><pre><code>PreTrainedTokenizerFast(name_or_path=&#39;bert-base-chinese&#39;, vocab_size=21128, model_max_len=512, is_fast=True, padding_side=&#39;right&#39;, truncation_side=&#39;right&#39;, special_tokens=&#123;&#39;unk_token&#39;: &#39;[UNK]&#39;, &#39;sep_token&#39;: &#39;[SEP]&#39;, &#39;pad_token&#39;: &#39;[PAD]&#39;, &#39;cls_token&#39;: &#39;[CLS]&#39;, &#39;mask_token&#39;: &#39;[MASK]&#39;&#125;)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sample_txt = <span class="string">&#x27;今天早上9点半起床，我在学习预训练模型的使用.&#x27;</span></span><br><span class="line"><span class="built_in">len</span>(sample_txt)</span><br></pre></td></tr></table></figure><pre><code>23</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tokens = tokenizer.tokenize(sample_txt)</span><br><span class="line">token_ids = tokenizer.convert_tokens_to_ids(tokens)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;文本为: <span class="subst">&#123;sample_txt&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;分词的列表为: <span class="subst">&#123;tokens&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;词对应的唯一id: <span class="subst">&#123;token_ids&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure><pre><code>文本为: 今天早上9点半起床，我在学习预训练模型的使用.分词的列表为: [&#39;今&#39;, &#39;天&#39;, &#39;早&#39;, &#39;上&#39;, &#39;9&#39;, &#39;点&#39;, &#39;半&#39;, &#39;起&#39;, &#39;床&#39;, &#39;，&#39;, &#39;我&#39;, &#39;在&#39;, &#39;学&#39;, &#39;习&#39;, &#39;预&#39;, &#39;训&#39;, &#39;练&#39;, &#39;模&#39;, &#39;型&#39;, &#39;的&#39;, &#39;使&#39;, &#39;用&#39;, &#39;.&#39;]词对应的唯一id: [791, 1921, 3193, 677, 130, 4157, 1288, 6629, 2414, 8024, 2769, 1762, 2110, 739, 7564, 6378, 5298, 3563, 1798, 4638, 886, 4500, 119]</code></pre><h3 id="查看特殊的Token"><a href="#查看特殊的Token" class="headerlink" title="查看特殊的Token"></a>查看特殊的Token</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tokenizer.sep_token,tokenizer.sep_token_id</span><br></pre></td></tr></table></figure><pre><code>(&#39;[SEP]&#39;, 102)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tokenizer.cls_token,tokenizer.cls_token_id</span><br></pre></td></tr></table></figure><pre><code>(&#39;[CLS]&#39;, 101)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tokenizer.pad_token,tokenizer.pad_token_id</span><br></pre></td></tr></table></figure><pre><code>(&#39;[PAD]&#39;, 0)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tokenizer.mask_token,tokenizer.mask_token_id</span><br></pre></td></tr></table></figure><pre><code>(&#39;[MASK]&#39;, 103)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tokenizer.unk_token,tokenizer.unk_token_id</span><br></pre></td></tr></table></figure><pre><code>(&#39;[UNK]&#39;, 100)</code></pre><h3 id="简单的编码测试"><a href="#简单的编码测试" class="headerlink" title="简单的编码测试"></a>简单的编码测试</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">encoding=tokenizer.encode_plus(</span><br><span class="line">    sample_txt,</span><br><span class="line">    <span class="comment"># sample_txt_another,</span></span><br><span class="line">    max_length=<span class="number">32</span>,</span><br><span class="line">    add_special_tokens=<span class="literal">True</span>,<span class="comment"># [CLS]和[SEP]</span></span><br><span class="line">    return_token_type_ids=<span class="literal">True</span>,</span><br><span class="line">    pad_to_max_length=<span class="literal">True</span>,</span><br><span class="line">    return_attention_mask=<span class="literal">True</span>,</span><br><span class="line">    return_tensors=<span class="string">&#x27;pt&#x27;</span>,<span class="comment"># Pytorch tensor张量</span></span><br><span class="line"></span><br><span class="line">)</span><br><span class="line">encoding</span><br></pre></td></tr></table></figure><pre><code>Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to &#39;longest_first&#39; truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.&#123;&#39;input_ids&#39;: tensor([[ 101,  791, 1921, 3193,  677,  130, 4157, 1288, 6629, 2414, 8024, 2769,         1762, 2110,  739, 7564, 6378, 5298, 3563, 1798, 4638,  886, 4500,  119,          102,    0,    0,    0,    0,    0,    0,    0]]), &#39;token_type_ids&#39;: tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,         0, 0, 0, 0, 0, 0, 0, 0]]), &#39;attention_mask&#39;: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,         1, 0, 0, 0, 0, 0, 0, 0]])&#125;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">encoding[<span class="string">&#x27;attention_mask&#x27;</span>][<span class="number">0</span>]</span><br></pre></td></tr></table></figure><pre><code>tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,        1, 0, 0, 0, 0, 0, 0, 0])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">token_lens = []</span><br><span class="line"><span class="comment"># 选的是每一句话的长度</span></span><br><span class="line"><span class="keyword">for</span> txt <span class="keyword">in</span> train.text:</span><br><span class="line"><span class="comment">#     print(txt)</span></span><br><span class="line">    tokens = tokenizer.encode(txt, max_length=<span class="number">512</span>)</span><br><span class="line">    token_lens.append(<span class="built_in">len</span>(tokens))</span><br><span class="line"><span class="comment"># token_lens</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sns.distplot(token_lens)</span><br><span class="line">plt.xlim([<span class="number">0</span>, <span class="number">256</span>]);</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Token count&#x27;</span>);</span><br></pre></td></tr></table></figure><p><img src="C:\Users\dupeibo\AppData\Roaming\Typora\typora-user-images\1669079168255.png" alt="1669079168255"></p><p>​    </p><h3 id="通过分析，长度一般都在160之内"><a href="#通过分析，长度一般都在160之内" class="headerlink" title="通过分析，长度一般都在160之内"></a>通过分析，长度一般都在160之内</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MAX_LEN = <span class="number">160</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">encoding[<span class="string">&#x27;input_ids&#x27;</span>].flatten()</span><br></pre></td></tr></table></figure><pre><code>tensor([ 101,  791, 1921, 3193,  677,  130, 4157, 1288, 6629, 2414, 8024, 2769,        1762, 2110,  739, 7564, 6378, 5298, 3563, 1798, 4638,  886, 4500,  119,         102,    0,    0,    0,    0,    0,    0,    0])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">encoding[<span class="string">&#x27;input_ids&#x27;</span>]</span><br></pre></td></tr></table></figure><pre><code>tensor([[ 101,  791, 1921, 3193,  677,  130, 4157, 1288, 6629, 2414, 8024, 2769,         1762, 2110,  739, 7564, 6378, 5298, 3563, 1798, 4638,  886, 4500,  119,          102,    0,    0,    0,    0,    0,    0,    0]])</code></pre><h2 id="处理数据"><a href="#处理数据" class="headerlink" title="处理数据"></a>处理数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">EnterpriseDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,texts,labels,tokenizer,max_len</span>):</span><br><span class="line">        self.texts=texts</span><br><span class="line">        self.labels=labels</span><br><span class="line">        self.tokenizer=tokenizer</span><br><span class="line">        self.max_len=max_len</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.texts)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self,item</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        item 为数据索引，迭代取第item条数据</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        text=<span class="built_in">str</span>(self.texts[item])</span><br><span class="line">        label=self.labels[item]</span><br><span class="line">        </span><br><span class="line">        encoding=self.tokenizer.encode_plus(</span><br><span class="line">            text,</span><br><span class="line">            add_special_tokens=<span class="literal">True</span>,</span><br><span class="line">            max_length=self.max_len,</span><br><span class="line">            return_token_type_ids=<span class="literal">True</span>,</span><br><span class="line">            pad_to_max_length=<span class="literal">True</span>,</span><br><span class="line">            return_attention_mask=<span class="literal">True</span>,</span><br><span class="line">            return_tensors=<span class="string">&#x27;pt&#x27;</span>,</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line"><span class="comment">#         print(encoding[&#x27;input_ids&#x27;])</span></span><br><span class="line">        <span class="keyword">return</span> &#123;</span><br><span class="line">            <span class="string">&#x27;texts&#x27;</span>:text,</span><br><span class="line">            <span class="string">&#x27;input_ids&#x27;</span>:encoding[<span class="string">&#x27;input_ids&#x27;</span>].flatten(),</span><br><span class="line">            <span class="string">&#x27;attention_mask&#x27;</span>:encoding[<span class="string">&#x27;attention_mask&#x27;</span>].flatten(),</span><br><span class="line">            <span class="comment"># toeken_type_ids:0</span></span><br><span class="line">            <span class="string">&#x27;labels&#x27;</span>:torch.tensor(label,dtype=torch.long)</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><h3 id="分割数据集"><a href="#分割数据集" class="headerlink" title="分割数据集"></a>分割数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df_train, df_test = train_test_split(train, test_size=<span class="number">0.1</span>, random_state=RANDOM_SEED)</span><br><span class="line">df_val, df_test = train_test_split(df_test, test_size=<span class="number">0.5</span>, random_state=RANDOM_SEED)</span><br><span class="line">df_train.shape, df_val.shape, df_test.shape</span><br></pre></td></tr></table></figure><pre><code>((10800, 9), (600, 9), (600, 9))</code></pre><h3 id="创建DataLoader"><a href="#创建DataLoader" class="headerlink" title="创建DataLoader"></a>创建DataLoader</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">create_data_loader</span>(<span class="params">df,tokenizer,max_len,batch_size</span>):</span><br><span class="line">    ds=EnterpriseDataset(</span><br><span class="line">        texts=df[<span class="string">&#x27;text&#x27;</span>].values,</span><br><span class="line">        labels=df[<span class="string">&#x27;label&#x27;</span>].values,</span><br><span class="line">        tokenizer=tokenizer,</span><br><span class="line">        max_len=max_len</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> DataLoader(</span><br><span class="line">        ds,</span><br><span class="line">        batch_size=batch_size,</span><br><span class="line"><span class="comment">#         num_workers=4 # windows多线程</span></span><br><span class="line">    )</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">BATCH_SIZE = <span class="number">4</span></span><br><span class="line"></span><br><span class="line">train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)</span><br><span class="line">val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)</span><br><span class="line">test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">next</span>(<span class="built_in">iter</span>(train_data_loader))</span><br></pre></td></tr></table></figure><pre><code>&#123;&#39;texts&#39;: [&#39;指示标识不清楚[SEP]工业/危化品类[SEP]消防检查[SEP]防火巡查[SEP]安全出口、疏散通道是否畅通，安全疏散指示标志、应急照明是否完好；&#39;,  &#39;发现本月有灭火器过期，已安排购买灭火器更换[SEP]商贸服务教文卫类[SEP]消防检查[SEP]防火检查[SEP]灭火器材配置及有效情况。&#39;,  &#39;安全出口标志灯有一个有故障，已买回安装改正。[SEP]工业/危化品类[SEP]消防检查[SEP]防火巡查[SEP]安全出口、疏散通道是否畅通，安全疏散指示标志、应急照明是否完好；&#39;,  &#39;堵了消防通道[SEP]工业/危化品类[SEP]消防检查[SEP]防火巡查[SEP]安全出口、疏散通道是否畅通，安全疏散指示标志、应急照明是否完好；&#39;], &#39;input_ids&#39;: tensor([[ 101, 2900, 4850, 3403, 6399,  679, 3926, 3504,  102, 2339,  689,  120,          1314, 1265, 1501, 5102,  102, 3867, 7344, 3466, 3389,  102, 7344, 4125,          2337, 3389,  102, 2128, 1059, 1139, 1366,  510, 4541, 3141, 6858, 6887,          3221, 1415, 4517, 6858, 8024, 2128, 1059, 4541, 3141, 2900, 4850, 3403,          2562,  510, 2418, 2593, 4212, 3209, 3221, 1415, 2130, 1962, 8039,  102,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0],         [ 101, 1355, 4385, 3315, 3299, 3300, 4127, 4125, 1690, 6814, 3309, 8024,          2347, 2128, 2961, 6579,  743, 4127, 4125, 1690, 3291, 2940,  102, 1555,          6588, 3302, 1218, 3136, 3152, 1310, 5102,  102, 3867, 7344, 3466, 3389,           102, 7344, 4125, 3466, 3389,  102, 4127, 4125, 1690, 3332, 6981, 5390,          1350, 3300, 3126, 2658, 1105,  511,  102,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0],         [ 101, 2128, 1059, 1139, 1366, 3403, 2562, 4128, 3300,  671,  702, 3300,          3125, 7397, 8024, 2347,  743, 1726, 2128, 6163, 3121, 3633,  511,  102,          2339,  689,  120, 1314, 1265, 1501, 5102,  102, 3867, 7344, 3466, 3389,           102, 7344, 4125, 2337, 3389,  102, 2128, 1059, 1139, 1366,  510, 4541,          3141, 6858, 6887, 3221, 1415, 4517, 6858, 8024, 2128, 1059, 4541, 3141,          2900, 4850, 3403, 2562,  510, 2418, 2593, 4212, 3209, 3221, 1415, 2130,          1962, 8039,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0],         [ 101, 1843,  749, 3867, 7344, 6858, 6887,  102, 2339,  689,  120, 1314,          1265, 1501, 5102,  102, 3867, 7344, 3466, 3389,  102, 7344, 4125, 2337,          3389,  102, 2128, 1059, 1139, 1366,  510, 4541, 3141, 6858, 6887, 3221,          1415, 4517, 6858, 8024, 2128, 1059, 4541, 3141, 2900, 4850, 3403, 2562,           510, 2418, 2593, 4212, 3209, 3221, 1415, 2130, 1962, 8039,  102,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,             0,    0,    0,    0]]), &#39;attention_mask&#39;: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,          1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,          1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), &#39;labels&#39;: tensor([0, 0, 0, 0])&#125;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data = <span class="built_in">next</span>(<span class="built_in">iter</span>(train_data_loader))</span><br><span class="line">data.keys()</span><br></pre></td></tr></table></figure><pre><code>dict_keys([&#39;texts&#39;, &#39;input_ids&#39;, &#39;attention_mask&#39;, &#39;labels&#39;])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(data[<span class="string">&#x27;input_ids&#x27;</span>].shape)</span><br><span class="line"><span class="built_in">print</span>(data[<span class="string">&#x27;attention_mask&#x27;</span>].shape)</span><br><span class="line"><span class="built_in">print</span>(data[<span class="string">&#x27;labels&#x27;</span>].shape)</span><br></pre></td></tr></table></figure><pre><code>torch.Size([4, 160])torch.Size([4, 160])torch.Size([4])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bert_model = AutoModel.from_pretrained(PRE_TRAINED_MODEL_NAME)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">encoding[<span class="string">&#x27;input_ids&#x27;</span>]</span><br></pre></td></tr></table></figure><pre><code>tensor([[ 101,  791, 1921, 3193,  677,  130, 4157, 1288, 6629, 2414, 8024, 2769,         1762, 2110,  739, 7564, 6378, 5298, 3563, 1798, 4638,  886, 4500,  119,          102,    0,    0,    0,    0,    0,    0,    0]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">last_hidden_state, pooled_output = bert_model(</span><br><span class="line">    input_ids=encoding[<span class="string">&#x27;input_ids&#x27;</span>], </span><br><span class="line">    attention_mask=encoding[<span class="string">&#x27;attention_mask&#x27;</span>],</span><br><span class="line">    return_dict = <span class="literal">False</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><h2 id="查看输出结果"><a href="#查看输出结果" class="headerlink" title="查看输出结果"></a>查看输出结果</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">last_hidden_state[<span class="number">0</span>][<span class="number">0</span>].shape</span><br></pre></td></tr></table></figure><pre><code>torch.Size([768])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pooled_output</span><br></pre></td></tr></table></figure><pre><code>tensor([[ 0.9999,  0.9998,  0.9989,  0.9629,  0.3075, -0.1866, -0.9904,  0.8628,          0.9710, -0.9993,  1.0000,  1.0000,  0.9312, -0.9394,  0.9998, -0.9999,          0.0417,  0.9999,  0.9458,  0.3190,  1.0000, -1.0000, -0.9062, -0.9048,          0.1764,  0.9983,  0.9346, -0.8122, -0.9999,  0.9996,  0.7879,  0.9999,          0.8475, -1.0000, -1.0000,  0.9413, -0.8260,  0.9889, -0.4976, -0.9857,         -0.9955, -0.9580,  0.5833, -0.9996, -0.8932,  0.8563, -1.0000, -0.9999,          0.9719,  0.9999, -0.7430, -0.9993,  0.9756, -0.9754,  0.2991,  0.8933,         -0.9991,  0.9987,  1.0000,  0.4156,  0.9992, -0.9452, -0.8020, -0.9999,          1.0000, -0.9964, -0.9900,  0.4365,  1.0000,  1.0000, -0.9400,  0.8794,          1.0000,  0.9105, -0.6616,  1.0000, -0.9999,  0.6892, -1.0000, -0.9817,          1.0000,  0.9957, -0.8844, -0.8248, -0.9921, -0.9999, -0.9998,  1.0000,          0.5228,  0.1297,  0.9932, -0.9999, -1.0000,  0.9993, -0.9996, -0.9948,         -0.9561,  0.9996, -0.5785, -0.9386, -0.2035,  0.9086, -0.9999, -0.9993,          0.9959,  0.9984,  0.6953, -0.9995,  1.0000,  0.8610, -1.0000, -0.4507,         -1.0000,  0.2384, -0.9812,  0.9998,  0.9504,  0.5421,  0.9995, -0.9998,          0.9320, -0.9941, -0.9718, -0.9910,  0.9822,  1.0000,  0.9997, -0.9990,          1.0000,  1.0000,  0.8608,  0.9964, -0.9997,  0.9799,  0.5985, -0.9098,          0.5329, -0.6345,  1.0000,  0.9872,  0.9970, -0.9719,  0.9988, -0.9933,          1.0000, -0.9999,  0.9973, -1.0000, -0.6550,  0.9996,  0.8899,  1.0000,          0.2969,  0.9999, -0.9983, -0.9991,  0.9906, -0.6590,  0.9872, -1.0000,          0.7658,  0.7876, -0.8556,  0.6304, -1.0000,  1.0000, -0.7938,  1.0000,          0.9898,  0.2216, -0.9942, -0.9969,  0.8345, -0.9998, -0.9779,  0.9914,          0.5227,  0.9992, -0.9893, -0.9889,  0.2325, -0.9887, -0.9999,  0.9885,          0.0340,  0.9284,  0.5197,  0.4143,  0.8315,  0.1585, -0.5348,  1.0000,          0.2361,  0.9985,  0.9999, -0.3446,  0.1012, -0.9924, -1.0000, -0.7542,          0.9999, -0.2807, -0.9999,  0.9490, -1.0000,  0.9906, -0.7288, -0.5263,         -0.9545, -0.9999,  0.9998, -0.9286, -0.9997, -0.5303,  0.8886,  0.5605,         -0.9989, -0.3324,  0.9804, -0.9075,  0.9905, -0.9800, -0.9946,  0.6855,         -0.9393,  0.9929,  0.9874,  1.0000,  0.9997, -0.0714, -0.9440,  1.0000,          0.1676, -1.0000,  0.5573, -0.9611,  0.8835,  0.9999, -0.9980,  0.9294,          1.0000,  0.7968,  1.0000, -0.7065, -0.9793, -0.9997,  1.0000,  0.9922,          0.9999, -0.9984, -0.9995, -0.1701, -0.5426, -1.0000, -1.0000, -0.6334,          0.9969,  0.9999, -0.1620, -0.9818, -0.9921, -0.9994,  1.0000, -0.9759,          1.0000,  0.8570, -0.7434, -0.9164,  0.9438, -0.7311, -0.9986, -0.3936,         -0.9997, -0.9650, -1.0000,  0.9433, -0.9999, -1.0000,  0.6913,  1.0000,          0.8762, -1.0000,  0.9997,  0.9764,  0.7094, -0.9294,  0.9522, -1.0000,          1.0000, -0.9965,  0.9428, -0.9972, -0.9897, -0.7680,  0.9922,  0.9999,         -0.9999, -0.9597, -0.9922, -0.9807, -0.3632,  0.9936, -0.7280,  0.4117,         -0.9498, -0.9666,  0.9545, -0.9957, -0.9970,  0.4028,  1.0000, -0.9798,          1.0000,  0.9941,  1.0000,  0.9202, -0.9942,  0.9996,  0.5352, -0.5836,         -0.8829, -0.9418,  0.9497, -0.0532,  0.6966, -0.9999,  0.9998,  0.9917,          0.9612,  0.7289,  0.0167,  0.3179,  0.9627, -0.9911,  0.9995, -0.9996,         -0.6737,  0.9991,  1.0000,  0.9932,  0.4880, -0.7488,  0.9986, -0.9961,          0.9995, -1.0000,  0.9999, -0.9940,  0.9705, -0.9970, -0.9856,  1.0000,          0.9846, -0.7932,  0.9997, -0.9386,  0.9938,  0.9738,  0.8173,  0.9913,          0.9981,  1.0000, -0.9998, -0.9918, -0.9727, -0.9987, -0.9955, -1.0000,         -0.1038, -1.0000, -0.9874, -0.9287,  0.5109, -0.9056,  0.1022,  0.7864,         -0.8197,  0.5724, -0.5905,  0.2713, -0.7239, -0.9976, -0.9844, -1.0000,         -0.9988,  0.8835,  0.9999, -0.9997,  0.9999, -0.9999, -0.9782,  0.9383,         -0.5609,  0.7721,  0.9999, -1.0000,  0.9585,  0.9987,  1.0000,  0.9960,          0.9993, -0.9741, -0.9999, -0.9989, -0.9999, -1.0000, -0.9998,  0.9343,          0.6337, -1.0000,  0.0902,  0.8980,  1.0000,  0.9964, -0.9985, -0.6136,         -0.9996, -0.8252,  0.9996, -0.0566, -1.0000,  0.9962, -0.8744,  1.0000,         -0.8865,  0.9879,  0.8897,  0.9571,  0.9823, -1.0000,  0.9145,  1.0000,          0.0365, -1.0000, -0.9985, -0.9075, -0.9998,  0.0369,  0.8120,  0.9999,         -1.0000, -0.9155, -0.9975,  0.7988,  0.9922,  0.9998,  0.9982,  0.9267,          0.9165,  0.5368,  0.1464,  0.9998,  0.4663, -0.9989,  0.9996, -0.7952,          0.4527, -1.0000,  0.9998,  0.4073,  0.9999,  0.9159, -0.5480, -0.6821,         -0.9904,  0.9938,  1.0000, -0.4229, -0.4845, -0.9981, -1.0000, -0.9861,         -0.0950, -0.4625, -0.9629, -0.9998,  0.6675, -0.5244,  1.0000,  1.0000,          0.9924, -0.9253, -0.9974,  0.9974, -0.9012,  0.9900, -0.2582, -1.0000,         -0.9919, -0.9986,  1.0000, -0.9716, -0.9262, -0.9911, -0.2593,  0.5919,         -0.9999, -0.4994, -0.9962,  0.9818,  1.0000, -0.9996,  0.9918, -0.9970,          0.7085, -0.1369,  0.8077,  0.9955, -0.3394, -0.5860, -0.6887, -0.9841,          0.9970,  0.9987, -0.9948, -0.8401,  0.9999,  0.0856,  0.9999,  0.5099,          0.9466,  0.9567,  1.0000,  0.8771,  1.0000, -0.0815,  1.0000,  0.9999,         -0.9392,  0.5744,  0.8723, -0.9686,  0.5958,  0.9822,  0.9997,  0.8854,         -0.1952, -0.9967,  0.9994,  1.0000,  1.0000, -0.3391,  0.9883, -0.4452,          0.9252,  0.4495,  0.9870,  0.3479,  0.2266,  0.9942,  0.9990, -0.9999,         -0.9999, -1.0000,  1.0000,  0.9996, -0.6637, -1.0000,  0.9999,  0.4543,          0.7471,  0.9983,  0.3772, -0.9812,  0.9853, -0.9995, -0.3404,  0.9788,          0.9867,  0.7564,  0.9995, -0.9997,  0.7990,  1.0000,  0.0752,  0.9999,          0.2912, -0.9941,  0.9970, -0.9935, -0.9995, -0.9743,  0.9991,  0.9981,         -0.9273, -0.8402,  0.9996, -0.9999,  0.9999, -0.9998,  0.9724, -0.9939,          1.0000, -0.9752, -0.9998, -0.3806,  0.8830,  0.8352, -0.8892,  1.0000,         -0.8875, -0.8107,  0.7083, -0.8909, -0.9931, -0.9630,  0.0800, -1.0000,          0.7777, -0.9611,  0.5867, -0.9947, -0.9999,  1.0000, -0.9084, -0.9414,          0.9999, -0.8838, -1.0000,  0.9549, -0.9999, -0.6522,  0.7967, -0.6850,          0.1524, -1.0000,  0.4800,  0.9999, -0.9998, -0.7089, -0.9129, -0.9864,          0.6220,  0.8855,  0.9855, -0.8651,  0.3988, -0.2548,  0.9793, -0.7212,         -0.2582, -0.9999, -0.8692, -0.6282, -0.9999, -0.9999, -1.0000,  1.0000,          0.9996,  0.9999, -0.5600,  0.7442,  0.9460,  0.9927, -0.9999,  0.4407,         -0.0461,  0.9937, -0.4887, -0.9994, -0.9198, -1.0000, -0.6905,  0.3538,         -0.7728,  0.6622,  1.0000,  0.9999, -0.9999, -0.9994, -0.9995, -0.9979,          0.9998,  0.9999,  0.9996, -0.9072, -0.5844,  0.9997,  0.9689,  0.5231,         -0.9999, -0.9981, -0.9999,  0.7505, -0.9922, -0.9986,  0.9971,  1.0000,          0.8730, -1.0000, -0.9533,  1.0000,  0.9997,  1.0000, -0.7768,  0.9999,         -0.9838,  0.9819, -0.9993,  1.0000, -1.0000,  1.0000,  0.9999,  0.9809,          0.9984, -0.9928,  0.9776, -0.9998, -0.7407,  0.9298, -0.4495, -0.9902,          0.8053,  0.9996, -0.9952,  1.0000,  0.9243, -0.2028,  0.8002,  0.9873,          0.9419, -0.6913, -0.9999,  0.8162,  0.9995,  0.9509,  1.0000,  0.9177,          0.9996, -0.9839, -0.9998,  0.9914, -0.6991, -0.7821, -0.9998,  1.0000,          1.0000, -0.9999, -0.9227,  0.7483,  0.1186,  1.0000,  0.9963,  0.9971,          0.9857,  0.3887,  0.9996, -0.9999,  0.8526, -0.9980, -0.8613,  0.9999,         -0.9899,  0.9999, -0.9981,  1.0000, -0.9858,  0.9944,  0.9989,  0.9684,         -0.9968,  1.0000,  0.8246, -0.9956, -0.8348, -0.9374, -0.9999,  0.7827]],       grad_fn=&lt;TanhBackward0&gt;)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">last_hidden_state.shape <span class="comment"># 每个token的向量表示</span></span><br></pre></td></tr></table></figure><pre><code>torch.Size([1, 32, 768])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bert_model.config</span><br></pre></td></tr></table></figure><pre><code>BertConfig &#123;  &quot;_name_or_path&quot;: &quot;bert-base-chinese&quot;,  &quot;architectures&quot;: [    &quot;BertForMaskedLM&quot;  ],  &quot;attention_probs_dropout_prob&quot;: 0.1,  &quot;classifier_dropout&quot;: null,  &quot;directionality&quot;: &quot;bidi&quot;,  &quot;hidden_act&quot;: &quot;gelu&quot;,  &quot;hidden_dropout_prob&quot;: 0.1,  &quot;hidden_size&quot;: 768,  &quot;initializer_range&quot;: 0.02,  &quot;intermediate_size&quot;: 3072,  &quot;layer_norm_eps&quot;: 1e-12,  &quot;max_position_embeddings&quot;: 512,  &quot;model_type&quot;: &quot;bert&quot;,  &quot;num_attention_heads&quot;: 12,  &quot;num_hidden_layers&quot;: 12,  &quot;pad_token_id&quot;: 0,  &quot;pooler_fc_size&quot;: 768,  &quot;pooler_num_attention_heads&quot;: 12,  &quot;pooler_num_fc_layers&quot;: 3,  &quot;pooler_size_per_head&quot;: 128,  &quot;pooler_type&quot;: &quot;first_token_transform&quot;,  &quot;position_embedding_type&quot;: &quot;absolute&quot;,  &quot;transformers_version&quot;: &quot;4.24.0&quot;,  &quot;type_vocab_size&quot;: 2,  &quot;use_cache&quot;: true,  &quot;vocab_size&quot;: 21128&#125;</code></pre><h2 id="bert后面又接了一个全连接层"><a href="#bert后面又接了一个全连接层" class="headerlink" title="bert后面又接了一个全连接层"></a>bert后面又接了一个全连接层</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">EnterpriseDangerClassifier</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, n_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(EnterpriseDangerClassifier, self).__init__()</span><br><span class="line">        self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)</span><br><span class="line">        self.drop = nn.Dropout(p=<span class="number">0.3</span>)</span><br><span class="line">        self.out = nn.Linear(self.bert.config.hidden_size, n_classes) <span class="comment"># 两个类别</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, input_ids, attention_mask</span>):</span><br><span class="line">        _, pooled_output = self.bert(</span><br><span class="line">            input_ids=input_ids,</span><br><span class="line">            attention_mask=attention_mask,</span><br><span class="line">            return_dict = <span class="literal">False</span></span><br><span class="line">        )</span><br><span class="line">        output = self.drop(pooled_output) <span class="comment"># dropout</span></span><br><span class="line">        <span class="keyword">return</span> self.out(output)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">class_names=[<span class="number">0</span>,<span class="number">1</span>]</span><br></pre></td></tr></table></figure><h2 id="将数据和模型送到CUDA"><a href="#将数据和模型送到CUDA" class="headerlink" title="将数据和模型送到CUDA"></a>将数据和模型送到CUDA</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> BertModel, BertTokenizer,BertConfig, AdamW, get_linear_schedule_with_warmup</span><br><span class="line"></span><br><span class="line">model = EnterpriseDangerClassifier(<span class="built_in">len</span>(class_names))</span><br><span class="line">model = model.to(device)</span><br></pre></td></tr></table></figure><pre><code>Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: [&#39;cls.seq_relationship.bias&#39;, &#39;cls.predictions.transform.dense.bias&#39;, &#39;cls.predictions.bias&#39;, &#39;cls.predictions.transform.dense.weight&#39;, &#39;cls.predictions.decoder.weight&#39;, &#39;cls.predictions.transform.LayerNorm.bias&#39;, &#39;cls.predictions.transform.LayerNorm.weight&#39;, &#39;cls.seq_relationship.weight&#39;]- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">input_ids = data[<span class="string">&#x27;input_ids&#x27;</span>].to(device)</span><br><span class="line">attention_mask = data[<span class="string">&#x27;attention_mask&#x27;</span>].to(device)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(input_ids.shape) <span class="comment"># batch size x seq length</span></span><br><span class="line"><span class="built_in">print</span>(attention_mask.shape) <span class="comment"># batch size x seq length</span></span><br></pre></td></tr></table></figure><pre><code>torch.Size([4, 160])torch.Size([4, 160])</code></pre><h2 id="得到单个batch的输出token"><a href="#得到单个batch的输出token" class="headerlink" title="得到单个batch的输出token"></a>得到单个batch的输出token</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model(input_ids, attention_mask)</span><br></pre></td></tr></table></figure><pre><code>tensor([[ 0.2120, -0.4050],        [ 0.3156, -0.4160],        [ 0.5127, -0.4634],        [ 0.3168,  0.5057]], device=&#39;cuda:0&#39;, grad_fn=&lt;AddmmBackward0&gt;)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">F.softmax(model(input_ids, attention_mask), dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><pre><code>tensor([[0.4999, 0.5001],        [0.5258, 0.4742],        [0.5899, 0.4101],        [0.4575, 0.5425]], device=&#39;cuda:0&#39;, grad_fn=&lt;SoftmaxBackward0&gt;)</code></pre><h2 id="训练模型前期配置"><a href="#训练模型前期配置" class="headerlink" title="训练模型前期配置"></a>训练模型前期配置</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">EPOCHS = <span class="number">10</span> <span class="comment"># 训练轮数</span></span><br><span class="line"></span><br><span class="line">optimizer = AdamW(model.parameters(), lr=<span class="number">2e-5</span>, correct_bias=<span class="literal">False</span>)</span><br><span class="line">total_steps = <span class="built_in">len</span>(train_data_loader) * EPOCHS</span><br><span class="line"></span><br><span class="line"><span class="comment"># Warmup预热学习率的方式，可以使得开始训练的几个epoches或者一些steps内学习率较小,在预热的小学习率下，模型可以慢慢趋于稳定,</span></span><br><span class="line"><span class="comment"># 等模型相对稳定后再选择预先设置的学习率进行训练,使得模型收敛速度变得更快，模型效果更佳</span></span><br><span class="line">scheduler = get_linear_schedule_with_warmup(</span><br><span class="line">  optimizer,</span><br><span class="line">  num_warmup_steps=<span class="number">0</span>,</span><br><span class="line">  num_training_steps=total_steps</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># optimizer： 优化器</span></span><br><span class="line"><span class="comment"># num_warmup_steps：初始预热步数</span></span><br><span class="line"><span class="comment"># num_training_steps：整个训练过程的总步数</span></span><br><span class="line"></span><br><span class="line">loss_fn = nn.CrossEntropyLoss().to(device)</span><br></pre></td></tr></table></figure><h2 id="定义模型的训练"><a href="#定义模型的训练" class="headerlink" title="定义模型的训练"></a>定义模型的训练</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_epoch</span>(<span class="params"></span></span><br><span class="line"><span class="params">  model, </span></span><br><span class="line"><span class="params">  data_loader, </span></span><br><span class="line"><span class="params">  loss_fn, </span></span><br><span class="line"><span class="params">  optimizer, </span></span><br><span class="line"><span class="params">  device, </span></span><br><span class="line"><span class="params">  scheduler, </span></span><br><span class="line"><span class="params">  n_examples</span></span><br><span class="line"><span class="params"></span>):</span><br><span class="line">    model = model.train() <span class="comment"># train模式</span></span><br><span class="line">    losses = []</span><br><span class="line">    correct_predictions = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> d <span class="keyword">in</span> data_loader:</span><br><span class="line">        input_ids = d[<span class="string">&quot;input_ids&quot;</span>].to(device)</span><br><span class="line">        attention_mask = d[<span class="string">&quot;attention_mask&quot;</span>].to(device)</span><br><span class="line">        targets = d[<span class="string">&quot;labels&quot;</span>].to(device)</span><br><span class="line">        outputs = model(</span><br><span class="line">            input_ids=input_ids,</span><br><span class="line">            attention_mask=attention_mask</span><br><span class="line">        )</span><br><span class="line">        _, preds = torch.<span class="built_in">max</span>(outputs, dim=<span class="number">1</span>)</span><br><span class="line">        loss = loss_fn(outputs, targets)</span><br><span class="line">        correct_predictions += torch.<span class="built_in">sum</span>(preds == targets)</span><br><span class="line">        losses.append(loss.item())</span><br><span class="line">        loss.backward()</span><br><span class="line">        nn.utils.clip_grad_norm_(model.parameters(), max_norm=<span class="number">1.0</span>)</span><br><span class="line">        optimizer.step()</span><br><span class="line">        <span class="comment"># 预热学习率</span></span><br><span class="line">        scheduler.step()</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">    <span class="keyword">return</span> correct_predictions.double() / n_examples, np.mean(losses)</span><br></pre></td></tr></table></figure><h2 id="模型的评估函数"><a href="#模型的评估函数" class="headerlink" title="模型的评估函数"></a>模型的评估函数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">eval_model</span>(<span class="params">model, data_loader, loss_fn, device, n_examples</span>):</span><br><span class="line">    model = model.<span class="built_in">eval</span>() <span class="comment"># 验证预测模式</span></span><br><span class="line"></span><br><span class="line">    losses = []</span><br><span class="line">    correct_predictions = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> d <span class="keyword">in</span> data_loader:</span><br><span class="line">            input_ids = d[<span class="string">&quot;input_ids&quot;</span>].to(device)</span><br><span class="line">            attention_mask = d[<span class="string">&quot;attention_mask&quot;</span>].to(device)</span><br><span class="line">            targets = d[<span class="string">&quot;labels&quot;</span>].to(device)</span><br><span class="line"></span><br><span class="line">            outputs = model(</span><br><span class="line">                input_ids=input_ids,</span><br><span class="line">                attention_mask=attention_mask</span><br><span class="line">            )</span><br><span class="line">            _, preds = torch.<span class="built_in">max</span>(outputs, dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">            loss = loss_fn(outputs, targets)</span><br><span class="line"></span><br><span class="line">            correct_predictions += torch.<span class="built_in">sum</span>(preds == targets)</span><br><span class="line">            losses.append(loss.item())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> correct_predictions.double() / n_examples, np.mean(losses)</span><br></pre></td></tr></table></figure><h2 id="训练模型：10EPOCHS"><a href="#训练模型：10EPOCHS" class="headerlink" title="训练模型：10EPOCHS"></a>训练模型：10EPOCHS</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">history = defaultdict(<span class="built_in">list</span>) <span class="comment"># 记录10轮loss和acc</span></span><br><span class="line">best_accuracy = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(EPOCHS):</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Epoch <span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;EPOCHS&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;-&#x27;</span> * <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    train_acc, train_loss = train_epoch(</span><br><span class="line">        model,</span><br><span class="line">        train_data_loader,</span><br><span class="line">        loss_fn,</span><br><span class="line">        optimizer,</span><br><span class="line">        device,</span><br><span class="line">        scheduler,</span><br><span class="line">        <span class="built_in">len</span>(df_train)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Train loss <span class="subst">&#123;train_loss&#125;</span> accuracy <span class="subst">&#123;train_acc&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    val_acc, val_loss = eval_model(</span><br><span class="line">        model,</span><br><span class="line">        val_data_loader,</span><br><span class="line">        loss_fn,</span><br><span class="line">        device,</span><br><span class="line">        <span class="built_in">len</span>(df_val)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Val   loss <span class="subst">&#123;val_loss&#125;</span> accuracy <span class="subst">&#123;val_acc&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line"></span><br><span class="line">    history[<span class="string">&#x27;train_acc&#x27;</span>].append(train_acc)</span><br><span class="line">    history[<span class="string">&#x27;train_loss&#x27;</span>].append(train_loss)</span><br><span class="line">    history[<span class="string">&#x27;val_acc&#x27;</span>].append(val_acc)</span><br><span class="line">    history[<span class="string">&#x27;val_loss&#x27;</span>].append(val_loss)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> val_acc &gt; best_accuracy:</span><br><span class="line">        torch.save(model.state_dict(), <span class="string">&#x27;best_model_state.bin&#x27;</span>)</span><br><span class="line">        best_accuracy = val_acc</span><br></pre></td></tr></table></figure><pre><code>Epoch 1/10----------Train loss 0.4988938277521757 accuracy 0.8899999999999999Val   loss 0.4194765945523977 accuracy 0.9Epoch 2/10----------Train loss 0.4967574527254328 accuracy 0.8905555555555555Val   loss 0.43736912585794924 accuracy 0.9Epoch 3/10----------Train loss 0.49347498720511795 accuracy 0.8905555555555555Val   loss 0.41818931301434836 accuracy 0.9Epoch 4/10----------Train loss 0.4900011462407807 accuracy 0.8905555555555555Val   loss 0.42409916249414287 accuracy 0.9Epoch 5/10----------Train loss 0.4952681002088098 accuracy 0.8888888888888888Val   loss 0.31909402589624125 accuracy 0.9Epoch 6/10----------Train loss 0.2478140213253425 accuracy 0.9463888888888888Val   loss 0.1787985412031412 accuracy 0.9666666666666667Epoch 7/10----------Train loss 0.17434944392257387 accuracy 0.9677777777777777Val   loss 0.15001839348037416 accuracy 0.9700000000000001Epoch 8/10----------Train loss 0.12048366091100939 accuracy 0.9775925925925926Val   loss 0.11547344802587758 accuracy 0.9783333333333334Epoch 9/10----------Train loss 0.10136666681817992 accuracy 0.9813888888888889Val   loss 0.10292303454208498 accuracy 0.9800000000000001Epoch 10/10----------Train loss 0.08721379442805402 accuracy 0.9831481481481481Val   loss 0.12598223814862042 accuracy 0.9766666666666667</code></pre><h2 id="准确率绘图"><a href="#准确率绘图" class="headerlink" title="准确率绘图"></a>准确率绘图</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">plt.plot([i.cpu() <span class="keyword">for</span> i <span class="keyword">in</span> history[<span class="string">&#x27;train_acc&#x27;</span>]], label=<span class="string">&#x27;train accuracy&#x27;</span>)</span><br><span class="line">plt.plot([i.cpu() <span class="keyword">for</span> i <span class="keyword">in</span> history[<span class="string">&#x27;val_acc&#x27;</span>]], label=<span class="string">&#x27;validation accuracy&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&#x27;Training history&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Accuracy&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Epoch&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.ylim([<span class="number">0</span>, <span class="number">1</span>]);</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="C:\Users\dupeibo\AppData\Roaming\Typora\typora-user-images\1669079408883.png" alt="1669079408883"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">test_acc, _ = eval_model(</span><br><span class="line">  model,</span><br><span class="line">  test_data_loader,</span><br><span class="line">  loss_fn,</span><br><span class="line">  device,</span><br><span class="line">  <span class="built_in">len</span>(df_test)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">test_acc.item()</span><br></pre></td></tr></table></figure><pre><code>0.9783333333333334</code></pre><h2 id="预测模型"><a href="#预测模型" class="headerlink" title="预测模型"></a>预测模型</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_predictions</span>(<span class="params">model, data_loader</span>):</span><br><span class="line">    model = model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    raw_texts = []</span><br><span class="line">    predictions = []</span><br><span class="line">    prediction_probs = []</span><br><span class="line">    real_values = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> d <span class="keyword">in</span> data_loader:</span><br><span class="line">            texts = d[<span class="string">&quot;texts&quot;</span>]</span><br><span class="line">            input_ids = d[<span class="string">&quot;input_ids&quot;</span>].to(device)</span><br><span class="line">            attention_mask = d[<span class="string">&quot;attention_mask&quot;</span>].to(device)</span><br><span class="line">            targets = d[<span class="string">&quot;labels&quot;</span>].to(device)</span><br><span class="line"></span><br><span class="line">            outputs = model(</span><br><span class="line">                input_ids=input_ids,</span><br><span class="line">                attention_mask=attention_mask</span><br><span class="line">            )</span><br><span class="line">            _, preds = torch.<span class="built_in">max</span>(outputs, dim=<span class="number">1</span>) <span class="comment"># 类别</span></span><br><span class="line"></span><br><span class="line">            probs = F.softmax(outputs, dim=<span class="number">1</span>) <span class="comment"># 概率</span></span><br><span class="line"></span><br><span class="line">            raw_texts.extend(texts)</span><br><span class="line">            predictions.extend(preds)</span><br><span class="line">            prediction_probs.extend(probs)</span><br><span class="line">            real_values.extend(targets)</span><br><span class="line"></span><br><span class="line">    predictions = torch.stack(predictions).cpu()</span><br><span class="line">    prediction_probs = torch.stack(prediction_probs).cpu()</span><br><span class="line">    real_values = torch.stack(real_values).cpu()</span><br><span class="line">    <span class="keyword">return</span> raw_texts, predictions, prediction_probs, real_values</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">y_texts, y_pred, y_pred_probs, y_test = get_predictions(</span><br><span class="line">  model,</span><br><span class="line">  test_data_loader</span><br><span class="line">)</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred, target_names=[<span class="built_in">str</span>(label) <span class="keyword">for</span> label <span class="keyword">in</span> class_names])) <span class="comment"># 分类报告</span></span><br></pre></td></tr></table></figure><pre><code>              precision    recall  f1-score   support           0       0.99      0.99      0.99       554           1       0.84      0.89      0.86        46    accuracy                           0.98       600   macro avg       0.91      0.94      0.93       600weighted avg       0.98      0.98      0.98       600</code></pre><h2 id="查看混淆矩阵"><a href="#查看混淆矩阵" class="headerlink" title="查看混淆矩阵"></a>查看混淆矩阵</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">show_confusion_matrix</span>(<span class="params">confusion_matrix</span>):</span><br><span class="line">    hmap = sns.heatmap(confusion_matrix, annot=<span class="literal">True</span>, fmt=<span class="string">&quot;d&quot;</span>, cmap=<span class="string">&quot;Blues&quot;</span>)</span><br><span class="line">    hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=<span class="number">0</span>, ha=<span class="string">&#x27;right&#x27;</span>)</span><br><span class="line">    hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=<span class="number">30</span>, ha=<span class="string">&#x27;right&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;True label&#x27;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;Predicted label&#x27;</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cm = confusion_matrix(y_test, y_pred)</span><br><span class="line">df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)</span><br><span class="line">show_confusion_matrix(df_cm)</span><br></pre></td></tr></table></figure><p><img src="C:\Users\dupeibo\AppData\Roaming\Typora\typora-user-images\1669079467197.png" alt="1669079467197">    </p><h2 id="评估单条数据"><a href="#评估单条数据" class="headerlink" title="评估单条数据"></a>评估单条数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">idx = <span class="number">2</span></span><br><span class="line"></span><br><span class="line">sample_text = y_texts[idx]</span><br><span class="line">true_label = y_test[idx]</span><br><span class="line">pred_df = pd.DataFrame(&#123;</span><br><span class="line">  <span class="string">&#x27;class_names&#x27;</span>: class_names,</span><br><span class="line">  <span class="string">&#x27;values&#x27;</span>: y_pred_probs[idx]</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pred_d</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>class_names</th>      <th>values</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>0</td>      <td>0.999889</td>    </tr>    <tr>      <th>1</th>      <td>1</td>      <td>0.000111</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span>.join(wrap(sample_text)))</span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;True label: <span class="subst">&#123;class_names[true_label]&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure><pre><code>小A班应急照明灯坏[SEP]商贸服务教文卫类[SEP]消防检查[SEP]防火巡查[SEP]安全出口、疏散通道是否畅通，安全疏散指示标志、应急照明是否完好。True label: 0</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sns.barplot(x=<span class="string">&#x27;values&#x27;</span>, y=<span class="string">&#x27;class_names&#x27;</span>, data=pred_df, orient=<span class="string">&#x27;h&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;sentiment&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;probability&#x27;</span>)</span><br><span class="line">plt.xlim([<span class="number">0</span>, <span class="number">1</span>]);</span><br></pre></td></tr></table></figure><p><img src="C:\Users\dupeibo\AppData\Roaming\Typora\typora-user-images\1669079499324.png" alt="1669079499324"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sample_text = <span class="string">&#x27; &#x27;</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">encoded_text = tokenizer.encode_plus(</span><br><span class="line">  sample_text,</span><br><span class="line">  max_length=MAX_LEN,</span><br><span class="line">  add_special_tokens=<span class="literal">True</span>,</span><br><span class="line">  return_token_type_ids=<span class="literal">False</span>,</span><br><span class="line">  pad_to_max_length=<span class="literal">True</span>,</span><br><span class="line">  return_attention_mask=<span class="literal">True</span>,</span><br><span class="line">  return_tensors=<span class="string">&#x27;pt&#x27;</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">input_ids = encoded_text[<span class="string">&#x27;input_ids&#x27;</span>].to(device)</span><br><span class="line">attention_mask = encoded_text[<span class="string">&#x27;attention_mask&#x27;</span>].to(device)</span><br><span class="line"></span><br><span class="line">output = model(input_ids, attention_mask)</span><br><span class="line">_, prediction = torch.<span class="built_in">max</span>(output, dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Sample text: <span class="subst">&#123;sample_text&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Danger label  : <span class="subst">&#123;class_names[prediction]&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure><pre><code>Sample text:  Danger label  : 1</code></pre>]]></content>
    
    
    <summary type="html">&lt;p&gt;通过智能化手段识别其中是否存在“虚报、假报”的情况&lt;/p&gt;</summary>
    
    
    
    <category term="自然语言处理" scheme="https://du2279664786.github.io/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"/>
    
    
    <category term="深度学习" scheme="https://du2279664786.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="NLP" scheme="https://du2279664786.github.io/tags/NLP/"/>
    
    <category term="HuggingFace" scheme="https://du2279664786.github.io/tags/HuggingFace/"/>
    
    <category term="文本分类" scheme="https://du2279664786.github.io/tags/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"/>
    
    <category term="BERT" scheme="https://du2279664786.github.io/tags/BERT/"/>
    
  </entry>
  
</feed>
